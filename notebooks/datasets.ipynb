{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.pardir))\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from tdparse.helper import read_config, full_path\n",
    "from tdparse.parsers import semeval_14, semeval_15_16, dong, election\n",
    "from tdparse.data_types import TargetCollection\n",
    "from tdparse.tokenisers import ark_twokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the datasets\n",
    "semeval_14_rest_train = semeval_14(full_path(read_config('semeval_2014_rest_train')))\n",
    "semeval_14_lap_train = semeval_14(full_path(read_config('semeval_2014_lap_train')))\n",
    "semeval_14_rest_test = semeval_14(full_path(read_config('semeval_2014_rest_test')))\n",
    "semeval_14_lap_test = semeval_14(full_path(read_config('semeval_2014_lap_test')))\n",
    "semeval_15_rest_test = semeval_15_16(full_path(read_config('semeval_2015_rest_test')))\n",
    "semeval_16_rest_test = semeval_15_16(full_path(read_config('semeval_2016_rest_test')),\n",
    "                                     sep_16_from_15=True)\n",
    "dong_train = dong(full_path(read_config('dong_twit_train_data')))\n",
    "dong_test = dong(full_path(read_config('dong_twit_test_data')))\n",
    "election_train, election_test = election(full_path(read_config('election_folder_dir')))\n",
    "# Product reviews are made up of three different products: 1. Computer, 2. Router, and 3. Speaker\n",
    "product_reviews_folder = full_path(read_config('product_reviews_dir'))\n",
    "speaker_reviews = semeval_14(os.path.join(product_reviews_folder, 'Speaker.xml'))\n",
    "computer_reviews = semeval_14(os.path.join(product_reviews_folder, 'Computer.xml'))\n",
    "router_reviews = semeval_14(os.path.join(product_reviews_folder, 'Router.xml'))\n",
    "\n",
    "youtubean = semeval_14(full_path(read_config('youtubean')))\n",
    "semeval_14_rest = TargetCollection.combine_collections(semeval_14_rest_train,\n",
    "                                                           semeval_14_rest_test)\n",
    "semeval_14_laptop = TargetCollection.combine_collections(semeval_14_lap_train,\n",
    "                                                         semeval_14_lap_test)\n",
    "semeval_15_rest = semeval_15_16(full_path(read_config('semeval_2015_rest_test')))\n",
    "semeval_16_rest = semeval_15_16(full_path(read_config('semeval_2016_rest_test')),\n",
    "                                     sep_16_from_15=True)\n",
    "dong = TargetCollection.combine_collections(dong_train, dong_test)\n",
    "election = TargetCollection.combine_collections(election_train, election_test)\n",
    "# Combine all of the product reviews\n",
    "product_reviews = TargetCollection.combine_collections(speaker_reviews, computer_reviews,\n",
    "                                                       router_reviews)\n",
    "datasets = {'SemEval 14 Laptop' : semeval_14_laptop, 'SemEval 14 Resturant' : semeval_14_rest,\n",
    "            'SemEval 15 Resturant' : semeval_15_rest, 'SemEval 16 Resturant' : semeval_16_rest,\n",
    "            'Product Reviews' : product_reviews, 'Dong Twitter' : dong, \n",
    "            'Election Twitter' : election, 'YouTuBean' : youtubean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "This notebook will describe the different datasets that have been used as well as the statistics of these datasets. The datasets used are the following:\n",
    "1. [Dong et al.](https://aclanthology.coli.uni-saarland.de/papers/P14-2009/p14-2009) [Twitter dataset](https://github.com/bluemonk482/tdparse/tree/master/data/lidong) NOTE that the dataset does not link to the paper as the dataset released from the paper has already been pre-processed where as this dataset has not.\n",
    "2. [SemEval 2014 Resturant dataset](http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools). We used Train dataset version 2 and the test dataset. This dataset contains 4 sentiment values; 1. Positive, 2. Neutral, 3. Negative, and 4. Conflict but we are only going to use the first 3 to make it comparable to the other datasets and the fact that the conflict label only has 91 instances in the training set and 14 in the test set.\n",
    "3. [SemEval 2014 Laptop dataset](http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools). We used Train dataset version2 and the test dataset. This dataset contains 4 sentiment values; 1. Positive, 2. Neutral, 3. Negative, and 4. Conflict but we are only going to use the first 3 to make it comparable to the other datasets and the fact that the conflict label only has 45 instances in the training set and 16 in the test set.\n",
    "4. [SemEval 2015 Resturant dataset](). We only used the test dataset as the training set has overlap with the original 2014 version.\n",
    "5. [SemEval 2016 Resturant dataset](http://alt.qcri.org/semeval2016/task5/index.php?id=data-and-tools). We only used the test dataset as the training set has overlap with the original 2014 version.\n",
    "6. [Election dataset](https://figshare.com/articles/EACL_2017_-_Multi-target_UK_election_Twitter_sentiment_corpus/4479563/1)\n",
    "7. [Product review by Liu et al, IJCAI-2015](https://www.aaai.org/ocs/index.php/IJCAI/IJCAI15/paper/view/10766) [dataset](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html#datasets)\n",
    "8. [Youtubean dataset](https://github.com/epochx/opinatt/blob/master/samsung_galaxy_s5.xml) [by Marrese-Taylor et al.](https://www.aclweb.org/anthology/W17-5213) - Dataset of 7 youtube reviews of the Samsung Galaxy S5. The text are the closed captions of the videos where the captions were provided by the authors and not automatically generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No. Targets (Dataset Size)</th>\n",
       "      <th>No. Senti Labels</th>\n",
       "      <th>Mean Targets per Sent</th>\n",
       "      <th>No Unique Targets</th>\n",
       "      <th>% Targets with 1 Sentiment per Sentence</th>\n",
       "      <th>% Targets with 2 Sentiment per Sentence</th>\n",
       "      <th>% Targets with 3 Sentiment per Sentence</th>\n",
       "      <th>Avg sentence length per target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Laptop</th>\n",
       "      <td>2951</td>\n",
       "      <td>3</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1295</td>\n",
       "      <td>81.09</td>\n",
       "      <td>17.62</td>\n",
       "      <td>1.29</td>\n",
       "      <td>18.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Resturant</th>\n",
       "      <td>4722</td>\n",
       "      <td>3</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1630</td>\n",
       "      <td>75.26</td>\n",
       "      <td>22.94</td>\n",
       "      <td>1.80</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 15 Resturant</th>\n",
       "      <td>597</td>\n",
       "      <td>3</td>\n",
       "      <td>1.49</td>\n",
       "      <td>269</td>\n",
       "      <td>79.90</td>\n",
       "      <td>19.60</td>\n",
       "      <td>0.50</td>\n",
       "      <td>15.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 16 Resturant</th>\n",
       "      <td>649</td>\n",
       "      <td>3</td>\n",
       "      <td>1.55</td>\n",
       "      <td>312</td>\n",
       "      <td>89.83</td>\n",
       "      <td>9.71</td>\n",
       "      <td>0.46</td>\n",
       "      <td>16.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product Reviews</th>\n",
       "      <td>1101</td>\n",
       "      <td>2</td>\n",
       "      <td>1.40</td>\n",
       "      <td>468</td>\n",
       "      <td>94.37</td>\n",
       "      <td>5.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dong Twitter</th>\n",
       "      <td>6940</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>145</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Twitter</th>\n",
       "      <td>11899</td>\n",
       "      <td>3</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2190</td>\n",
       "      <td>44.50</td>\n",
       "      <td>46.72</td>\n",
       "      <td>8.78</td>\n",
       "      <td>21.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTuBean</th>\n",
       "      <td>798</td>\n",
       "      <td>3</td>\n",
       "      <td>2.07</td>\n",
       "      <td>522</td>\n",
       "      <td>81.45</td>\n",
       "      <td>18.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>22.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      No. Targets (Dataset Size)  No. Senti Labels  \\\n",
       "SemEval 14 Laptop                           2951                 3   \n",
       "SemEval 14 Resturant                        4722                 3   \n",
       "SemEval 15 Resturant                         597                 3   \n",
       "SemEval 16 Resturant                         649                 3   \n",
       "Product Reviews                             1101                 2   \n",
       "Dong Twitter                                6940                 3   \n",
       "Election Twitter                           11899                 3   \n",
       "YouTuBean                                    798                 3   \n",
       "\n",
       "                      Mean Targets per Sent  No Unique Targets  \\\n",
       "SemEval 14 Laptop                      1.58               1295   \n",
       "SemEval 14 Resturant                   1.83               1630   \n",
       "SemEval 15 Resturant                   1.49                269   \n",
       "SemEval 16 Resturant                   1.55                312   \n",
       "Product Reviews                        1.40                468   \n",
       "Dong Twitter                           1.00                145   \n",
       "Election Twitter                       2.94               2190   \n",
       "YouTuBean                              2.07                522   \n",
       "\n",
       "                      % Targets with 1 Sentiment per Sentence  \\\n",
       "SemEval 14 Laptop                                       81.09   \n",
       "SemEval 14 Resturant                                    75.26   \n",
       "SemEval 15 Resturant                                    79.90   \n",
       "SemEval 16 Resturant                                    89.83   \n",
       "Product Reviews                                         94.37   \n",
       "Dong Twitter                                           100.00   \n",
       "Election Twitter                                        44.50   \n",
       "YouTuBean                                               81.45   \n",
       "\n",
       "                      % Targets with 2 Sentiment per Sentence  \\\n",
       "SemEval 14 Laptop                                       17.62   \n",
       "SemEval 14 Resturant                                    22.94   \n",
       "SemEval 15 Resturant                                    19.60   \n",
       "SemEval 16 Resturant                                     9.71   \n",
       "Product Reviews                                          5.63   \n",
       "Dong Twitter                                             0.00   \n",
       "Election Twitter                                        46.72   \n",
       "YouTuBean                                               18.17   \n",
       "\n",
       "                      % Targets with 3 Sentiment per Sentence  \\\n",
       "SemEval 14 Laptop                                        1.29   \n",
       "SemEval 14 Resturant                                     1.80   \n",
       "SemEval 15 Resturant                                     0.50   \n",
       "SemEval 16 Resturant                                     0.46   \n",
       "Product Reviews                                          0.00   \n",
       "Dong Twitter                                             0.00   \n",
       "Election Twitter                                         8.78   \n",
       "YouTuBean                                                0.38   \n",
       "\n",
       "                      Avg sentence length per target  \n",
       "SemEval 14 Laptop                              18.57  \n",
       "SemEval 14 Resturant                           17.25  \n",
       "SemEval 15 Resturant                           15.85  \n",
       "SemEval 16 Resturant                           16.36  \n",
       "Product Reviews                                20.12  \n",
       "Dong Twitter                                   17.37  \n",
       "Election Twitter                               21.68  \n",
       "YouTuBean                                      22.53  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict = defaultdict(list)\n",
    "index = []\n",
    "columns = ['No. Targets (Dataset Size)', 'No. Senti Labels', \n",
    "          'Mean Targets per Sent', 'No Unique Targets',\n",
    "          '% Targets with 1 Sentiment per Sentence', '% Targets with 2 Sentiment per Sentence', \n",
    "          '% Targets with 3 Sentiment per Sentence', 'Avg sentence length per target']\n",
    "for name, dataset in datasets.items():\n",
    "    index.append(name)\n",
    "    targets_i_senti = []\n",
    "    num_targets = len(dataset)\n",
    "    num_sentiment_labels = len(dataset.stored_sentiments())\n",
    "    avg_sent_length = dataset.avg_sentence_length_per_target()\n",
    "    for i in range(1, 4):\n",
    "        if i > num_sentiment_labels:\n",
    "            targets_i_senti.append(0)\n",
    "        else:\n",
    "            i_senti_targets = len(dataset.subset_by_sentiment(i))\n",
    "            targets_i_senti\\\n",
    "            .append((i_senti_targets / num_targets) * 100)\n",
    "    \n",
    "    dataset_dict['No. Targets (Dataset Size)'].append(num_targets)\n",
    "    dataset_dict['No. Senti Labels'].append(num_sentiment_labels)\n",
    "    dataset_dict['Mean Targets per Sent'].append(dataset\\\n",
    "                                                 .avg_targets_per_sentence())\n",
    "    dataset_dict['No Unique Targets'].append(dataset.number_unique_targets())\n",
    "    dataset_dict['% Targets with 1 Sentiment per Sentence'].append(targets_i_senti[0])\n",
    "    dataset_dict['% Targets with 2 Sentiment per Sentence'].append(targets_i_senti[1])\n",
    "    dataset_dict['% Targets with 3 Sentiment per Sentence'].append(targets_i_senti[2])\n",
    "    dataset_dict['Avg sentence length per target'].append(avg_sent_length, ark_twokenize)\n",
    "    \n",
    "\n",
    "dataset_stats = pd.DataFrame(dataset_dict, index=index, columns=columns)\n",
    "dataset_stats.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high level statistics are presented above. At first it is a surprising that the Twittwer data has a higher average sentence length but the sentence in the Twitter cases is actually a Tweet compared to the product, SemEval, and YouTuBean data which has been sentence split. However the YouTuBean data even when sentence split is still the longest this could be due to the data being speech text rather than written.\n",
    "\n",
    "Again the datasets vary with the number of Targets with distinct sentiments per sentence but most have only one distinct sentiment per sentence apart from the Election dataset which has quiet an even split between 1 and 2 distinct sentiments.\n",
    "\n",
    "Lastly the Election dataset has the highest number of targets per sentence by a long way and this is not porportinal to the average sentence length either.\n",
    "\n",
    "## Syntactic Complexity of the dataset\n",
    "The above statistics are all based on quiet high level summary statistics and do not contain any lingustic specfic statistic apart from perhaps the average sentence length. Therefore below is the table of average constituency tree depth for the datasets which can be viewed as showing the sentence syntax complexity this was also shown in the [Marrese-Taylor et al.](https://www.aclweb.org/anthology/W17-5213) paper on the datasets they used and here we present the same statistic on a large number of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_ling_dict = defaultdict(list)\n",
    "index = []\n",
    "columns = ['Average constituency tree depth']\n",
    "for name, dataset in datasets.items():\n",
    "    index.append(name)\n",
    "    dataset_ling_dict['Average constituency tree depth'].append(dataset.avg_constituency_depth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average constituency tree depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Laptop</th>\n",
       "      <td>10.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Resturant</th>\n",
       "      <td>9.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 15 Resturant</th>\n",
       "      <td>9.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 16 Resturant</th>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product Reviews</th>\n",
       "      <td>9.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dong Twitter</th>\n",
       "      <td>8.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Twitter</th>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTuBean</th>\n",
       "      <td>11.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Average constituency tree depth\n",
       "SemEval 14 Laptop                               10.61\n",
       "SemEval 14 Resturant                             9.73\n",
       "SemEval 15 Resturant                             9.51\n",
       "SemEval 16 Resturant                             9.00\n",
       "Product Reviews                                  9.95\n",
       "Dong Twitter                                     8.34\n",
       "Election Twitter                                 9.67\n",
       "YouTuBean                                       11.72"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_ling_stats = pd.DataFrame(dataset_ling_dict, index=index, columns=columns)\n",
    "dataset_ling_stats.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above interestingly the Election dataset that had the 2nd largest average sentence length and by far the largest number of targets per sentence does not have the largest average tree depth. The YouTuBean dataset does which may suggest that spoken text is syntactically more complex then written text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
