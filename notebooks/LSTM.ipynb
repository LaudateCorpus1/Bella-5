{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from multiprocessing import Pool\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import time\n",
    "import tempfile\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath(os.pardir))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Notebook helper methods\n",
    "from tdparse import notebook_helper\n",
    "# Models\n",
    "from tdparse.models.tdlstm import LSTM, TDLSTM, TCLSTM\n",
    "# Tokenisers\n",
    "from tdparse.tokenisers import whitespace, ark_twokenize, stanford\n",
    "# Word Vectors\n",
    "from tdparse.word_vectors import PreTrained, GloveTwitterVectors, GloveCommonCrawl\n",
    "# Get the data\n",
    "from tdparse.helper import read_config, full_path\n",
    "from tdparse.parsers import dong, semeval_14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "dong_train = dong(full_path(read_config('dong_twit_train_data')))\n",
    "dong_test = dong(full_path(read_config('dong_twit_test_data')))\n",
    "# Load the word vectors\n",
    "sswe_path = full_path(read_config('sswe_files')['vo_zhang'])\n",
    "sswe = PreTrained(sswe_path, name='sswe')\n",
    "#glove_50 = GloveTwitterVectors(50)\n",
    "#glove_100 = GloveTwitterVectors(100)\n",
    "#glove_200 = GloveTwitterVectors(200)\n",
    "#word_vectors = [sswe, glove_50, glove_100, glove_200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_average_dataset(dataset):\n",
    "    '''\n",
    "    :param dataset: A training dataset\n",
    "    :type dataset: TargetCollection\n",
    "    :returns: Half the average sentence length of the given dataset\n",
    "    :rtype: int\n",
    "    '''\n",
    "    sentence_lengths = [len(data['text'].split()) for data in dataset.data()]\n",
    "    return math.ceil(sum(sentence_lengths) / len(sentence_lengths) / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing LSTM for the affect of validation set variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0772 - acc: 0.4992 - val_loss: 1.0614 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0533 - acc: 0.5006 - val_loss: 1.0473 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0443 - acc: 0.5006 - val_loss: 1.0421 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0410 - acc: 0.5006 - val_loss: 1.0403 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0399 - acc: 0.5006 - val_loss: 1.0397 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 4s 991us/step - loss: 1.0394 - acc: 0.5006 - val_loss: 1.0394 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0392 - acc: 0.5006 - val_loss: 1.0392 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 4s 999us/step - loss: 1.0390 - acc: 0.5006 - val_loss: 1.0390 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0387 - acc: 0.5006 - val_loss: 1.0387 - val_acc: 0.5003\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0383 - acc: 0.5006 - val_loss: 1.0383 - val_acc: 0.5003\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0377 - acc: 0.5006 - val_loss: 1.0376 - val_acc: 0.5003\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0369 - acc: 0.5006 - val_loss: 1.0368 - val_acc: 0.5003\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0358 - acc: 0.5006 - val_loss: 1.0356 - val_acc: 0.5003\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0343 - acc: 0.5006 - val_loss: 1.0340 - val_acc: 0.5003\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0322 - acc: 0.5006 - val_loss: 1.0319 - val_acc: 0.5003\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0296 - acc: 0.5006 - val_loss: 1.0292 - val_acc: 0.5003s: 1.0289 -\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0264 - acc: 0.5006 - val_loss: 1.0258 - val_acc: 0.5003\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0225 - acc: 0.5006 - val_loss: 1.0218 - val_acc: 0.5003\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0178 - acc: 0.5006 - val_loss: 1.0171 - val_acc: 0.5003\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0125 - acc: 0.5006 - val_loss: 1.0120 - val_acc: 0.5003\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0069 - acc: 0.5006 - val_loss: 1.0062 - val_acc: 0.4987\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0008 - acc: 0.5015 - val_loss: 1.0002 - val_acc: 0.4997\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9946 - acc: 0.5051 - val_loss: 0.9936 - val_acc: 0.4992\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9878 - acc: 0.5072 - val_loss: 0.9864 - val_acc: 0.5029\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9809 - acc: 0.5072 - val_loss: 0.9785 - val_acc: 0.5088\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9742 - acc: 0.5106 - val_loss: 0.9698 - val_acc: 0.5195\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9657 - acc: 0.5161 - val_loss: 0.9616 - val_acc: 0.5227\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9576 - acc: 0.5186 - val_loss: 0.9630 - val_acc: 0.5280\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9551 - acc: 0.5202 - val_loss: 0.9474 - val_acc: 0.5301\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9496 - acc: 0.5237 - val_loss: 0.9510 - val_acc: 0.5307\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9462 - acc: 0.5321 - val_loss: 0.9610 - val_acc: 0.5285\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9417 - acc: 0.5287 - val_loss: 0.9335 - val_acc: 0.5392\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9395 - acc: 0.5346 - val_loss: 0.9298 - val_acc: 0.5435\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9356 - acc: 0.5340 - val_loss: 0.9508 - val_acc: 0.5408\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9336 - acc: 0.5449 - val_loss: 0.9707 - val_acc: 0.5184\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9323 - acc: 0.5401 - val_loss: 0.9407 - val_acc: 0.5291\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9259 - acc: 0.5420 - val_loss: 0.9185 - val_acc: 0.5408\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 4s 988us/step - loss: 0.9273 - acc: 0.5426 - val_loss: 0.9209 - val_acc: 0.5424\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9224 - acc: 0.5447 - val_loss: 0.9154 - val_acc: 0.5477\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 4s 998us/step - loss: 0.9205 - acc: 0.5511 - val_loss: 1.0638 - val_acc: 0.4629\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9186 - acc: 0.5507 - val_loss: 0.9182 - val_acc: 0.5520\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9168 - acc: 0.5545 - val_loss: 0.9093 - val_acc: 0.5488\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9126 - acc: 0.5559 - val_loss: 0.9373 - val_acc: 0.5504\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9100 - acc: 0.5605 - val_loss: 0.9052 - val_acc: 0.5653\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 4s 997us/step - loss: 0.9066 - acc: 0.5657 - val_loss: 0.9185 - val_acc: 0.5467\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9078 - acc: 0.5635 - val_loss: 0.9005 - val_acc: 0.5653\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 4s 985us/step - loss: 0.9053 - acc: 0.5726 - val_loss: 0.9200 - val_acc: 0.5483\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9049 - acc: 0.5719 - val_loss: 0.9141 - val_acc: 0.5643\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8985 - acc: 0.5797 - val_loss: 0.8955 - val_acc: 0.5701\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8945 - acc: 0.5808 - val_loss: 0.8944 - val_acc: 0.5787\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8945 - acc: 0.5765 - val_loss: 0.8920 - val_acc: 0.5760\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8943 - acc: 0.5838 - val_loss: 0.9351 - val_acc: 0.5429\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8919 - acc: 0.5808 - val_loss: 0.8973 - val_acc: 0.5744\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8877 - acc: 0.5834 - val_loss: 0.8882 - val_acc: 0.5829\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8857 - acc: 0.5861 - val_loss: 0.9495 - val_acc: 0.5467\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8877 - acc: 0.5888 - val_loss: 0.8844 - val_acc: 0.5888\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8831 - acc: 0.5884 - val_loss: 0.8853 - val_acc: 0.5813\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8809 - acc: 0.5884 - val_loss: 0.8884 - val_acc: 0.5883\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8802 - acc: 0.5927 - val_loss: 0.8837 - val_acc: 0.5861\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8761 - acc: 0.5923 - val_loss: 0.8761 - val_acc: 0.5909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8738 - acc: 0.6005 - val_loss: 0.8889 - val_acc: 0.5888\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8725 - acc: 0.5888 - val_loss: 0.9010 - val_acc: 0.5792\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 4s 998us/step - loss: 0.8703 - acc: 0.6014 - val_loss: 0.9236 - val_acc: 0.5536\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8681 - acc: 0.5943 - val_loss: 0.9169 - val_acc: 0.5520\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8666 - acc: 0.5959 - val_loss: 0.8824 - val_acc: 0.5813\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8663 - acc: 0.6000 - val_loss: 0.8704 - val_acc: 0.5941\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8617 - acc: 0.5978 - val_loss: 0.9005 - val_acc: 0.5744\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8639 - acc: 0.5934 - val_loss: 0.8671 - val_acc: 0.5957\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8576 - acc: 0.5957 - val_loss: 0.8723 - val_acc: 0.6053\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8559 - acc: 0.6035 - val_loss: 0.8659 - val_acc: 0.5968\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8515 - acc: 0.6012 - val_loss: 0.9191 - val_acc: 0.5589\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8543 - acc: 0.6007 - val_loss: 0.9237 - val_acc: 0.5733\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8474 - acc: 0.6094 - val_loss: 0.8846 - val_acc: 0.5765\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8501 - acc: 0.6067 - val_loss: 0.8674 - val_acc: 0.5925\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 4s 966us/step - loss: 0.8493 - acc: 0.6069 - val_loss: 0.8879 - val_acc: 0.5675\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 4s 985us/step - loss: 0.8454 - acc: 0.6071 - val_loss: 0.8791 - val_acc: 0.5872\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 4s 981us/step - loss: 0.8455 - acc: 0.6110 - val_loss: 0.8877 - val_acc: 0.5856\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 4s 997us/step - loss: 0.8451 - acc: 0.6042 - val_loss: 0.8690 - val_acc: 0.5920\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 4s 986us/step - loss: 0.8423 - acc: 0.6113 - val_loss: 0.8654 - val_acc: 0.6064\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8395 - acc: 0.6163 - val_loss: 0.8676 - val_acc: 0.6043\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 4s 990us/step - loss: 0.8384 - acc: 0.6147 - val_loss: 0.8601 - val_acc: 0.5984\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8379 - acc: 0.6122 - val_loss: 0.8596 - val_acc: 0.5995\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8352 - acc: 0.6142 - val_loss: 0.8705 - val_acc: 0.5915\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8325 - acc: 0.6126 - val_loss: 0.8757 - val_acc: 0.5904\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 4s 983us/step - loss: 0.8316 - acc: 0.6129 - val_loss: 0.8618 - val_acc: 0.6032\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8294 - acc: 0.6140 - val_loss: 0.8637 - val_acc: 0.5973\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 4s 983us/step - loss: 0.8273 - acc: 0.6165 - val_loss: 0.8656 - val_acc: 0.5957\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 4s 978us/step - loss: 0.8268 - acc: 0.6199 - val_loss: 0.8600 - val_acc: 0.5952\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 4s 987us/step - loss: 0.8212 - acc: 0.6266 - val_loss: 0.8639 - val_acc: 0.6000\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8204 - acc: 0.6206 - val_loss: 0.8582 - val_acc: 0.5984\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8148 - acc: 0.6259 - val_loss: 0.8831 - val_acc: 0.5915\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8184 - acc: 0.6234 - val_loss: 0.8665 - val_acc: 0.5947\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8134 - acc: 0.6268 - val_loss: 0.8579 - val_acc: 0.6037\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 4s 998us/step - loss: 0.8137 - acc: 0.6300 - val_loss: 0.8589 - val_acc: 0.5995\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8120 - acc: 0.6259 - val_loss: 0.8624 - val_acc: 0.5941\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8113 - acc: 0.6305 - val_loss: 0.8682 - val_acc: 0.5941\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8109 - acc: 0.6279 - val_loss: 0.8611 - val_acc: 0.6027\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 4s 1000us/step - loss: 0.8072 - acc: 0.6298 - val_loss: 0.8679 - val_acc: 0.5963\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8075 - acc: 0.6332 - val_loss: 0.8856 - val_acc: 0.5909\n",
      "Epoch 100/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8054 - acc: 0.6282 - val_loss: 0.8567 - val_acc: 0.6091\n",
      "Epoch 101/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8023 - acc: 0.6302 - val_loss: 0.8712 - val_acc: 0.5984\n",
      "Epoch 102/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.8035 - acc: 0.6343 - val_loss: 0.8618 - val_acc: 0.6005\n",
      "Epoch 103/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.8002 - acc: 0.6346 - val_loss: 0.8580 - val_acc: 0.6016\n",
      "Epoch 104/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.7983 - acc: 0.6394 - val_loss: 0.8660 - val_acc: 0.5968\n",
      "Epoch 105/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7977 - acc: 0.6380 - val_loss: 0.9053 - val_acc: 0.5765\n",
      "Epoch 106/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.7959 - acc: 0.6366 - val_loss: 0.8582 - val_acc: 0.5989\n",
      "Epoch 107/300\n",
      "4373/4373 [==============================] - 4s 988us/step - loss: 0.7970 - acc: 0.6378 - val_loss: 0.8719 - val_acc: 0.5989\n",
      "Epoch 108/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7959 - acc: 0.6419 - val_loss: 0.8619 - val_acc: 0.6011\n",
      "Epoch 109/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.7900 - acc: 0.6499 - val_loss: 0.8617 - val_acc: 0.6069\n",
      "Epoch 110/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7890 - acc: 0.6481 - val_loss: 0.8546 - val_acc: 0.6021\n",
      "Epoch 111/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7901 - acc: 0.6440 - val_loss: 0.8574 - val_acc: 0.6053\n",
      "Epoch 112/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7866 - acc: 0.6405 - val_loss: 0.8663 - val_acc: 0.5984\n",
      "Epoch 113/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.7846 - acc: 0.6520 - val_loss: 0.8628 - val_acc: 0.5904\n",
      "Epoch 114/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.7858 - acc: 0.6506 - val_loss: 0.8836 - val_acc: 0.5904\n",
      "Epoch 115/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7837 - acc: 0.6449 - val_loss: 0.8574 - val_acc: 0.6048\n",
      "Epoch 116/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7815 - acc: 0.6485 - val_loss: 0.9257 - val_acc: 0.5744\n",
      "Epoch 117/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7839 - acc: 0.6476 - val_loss: 0.8609 - val_acc: 0.5957\n",
      "Epoch 118/300\n",
      "4373/4373 [==============================] - 4s 993us/step - loss: 0.7804 - acc: 0.6552 - val_loss: 0.8643 - val_acc: 0.6000\n",
      "Epoch 119/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.7767 - acc: 0.6476 - val_loss: 0.8728 - val_acc: 0.6048\n",
      "Epoch 120/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.7741 - acc: 0.6458 - val_loss: 0.8682 - val_acc: 0.5893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.603265716495\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0773 - acc: 0.4981 - val_loss: 1.0612 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0531 - acc: 0.5006 - val_loss: 1.0472 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0442 - acc: 0.5006 - val_loss: 1.0421 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0410 - acc: 0.5006 - val_loss: 1.0403 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0399 - acc: 0.5006 - val_loss: 1.0397 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 4s 970us/step - loss: 1.0395 - acc: 0.5006 - val_loss: 1.0395 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0393 - acc: 0.5006 - val_loss: 1.0393 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0391 - acc: 0.5006 - val_loss: 1.0391 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 4s 995us/step - loss: 1.0388 - acc: 0.5006 - val_loss: 1.0388 - val_acc: 0.5003\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 4s 977us/step - loss: 1.0384 - acc: 0.5006 - val_loss: 1.0385 - val_acc: 0.5003\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 4s 984us/step - loss: 1.0379 - acc: 0.5006 - val_loss: 1.0379 - val_acc: 0.5003\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 4s 982us/step - loss: 1.0372 - acc: 0.5006 - val_loss: 1.0372 - val_acc: 0.5003\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 4s 998us/step - loss: 1.0361 - acc: 0.5006 - val_loss: 1.0361 - val_acc: 0.5003\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 4s 994us/step - loss: 1.0347 - acc: 0.5006 - val_loss: 1.0347 - val_acc: 0.5003\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0328 - acc: 0.5006 - val_loss: 1.0328 - val_acc: 0.5003\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0303 - acc: 0.5006 - val_loss: 1.0303 - val_acc: 0.5003\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0270 - acc: 0.5006 - val_loss: 1.0272 - val_acc: 0.5003\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0231 - acc: 0.5006 - val_loss: 1.0235 - val_acc: 0.5003\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0185 - acc: 0.5006 - val_loss: 1.0191 - val_acc: 0.5003\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0131 - acc: 0.5006 - val_loss: 1.0142 - val_acc: 0.5003\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0072 - acc: 0.5010 - val_loss: 1.0087 - val_acc: 0.4992\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 1.0009 - acc: 0.5015 - val_loss: 1.0029 - val_acc: 0.5003\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9943 - acc: 0.5042 - val_loss: 0.9973 - val_acc: 0.5035\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9875 - acc: 0.5063 - val_loss: 0.9904 - val_acc: 0.5013\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9799 - acc: 0.5104 - val_loss: 0.9833 - val_acc: 0.5051\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 4s 983us/step - loss: 0.9721 - acc: 0.5154 - val_loss: 0.9811 - val_acc: 0.5115\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9639 - acc: 0.5214 - val_loss: 0.9675 - val_acc: 0.5131\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9541 - acc: 0.5221 - val_loss: 0.9603 - val_acc: 0.5227\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9497 - acc: 0.5340 - val_loss: 0.9562 - val_acc: 0.5232\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9432 - acc: 0.5356 - val_loss: 0.9615 - val_acc: 0.5280\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9374 - acc: 0.5365 - val_loss: 0.9635 - val_acc: 0.5280\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9373 - acc: 0.5388 - val_loss: 0.9464 - val_acc: 0.5344\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9288 - acc: 0.5376 - val_loss: 1.0490 - val_acc: 0.4869\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9277 - acc: 0.5378 - val_loss: 0.9537 - val_acc: 0.5328\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9249 - acc: 0.5408 - val_loss: 0.9375 - val_acc: 0.5360\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9205 - acc: 0.5440 - val_loss: 0.9426 - val_acc: 0.5440\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 4s 1ms/step - loss: 0.9191 - acc: 0.5436 - val_loss: 0.9362 - val_acc: 0.5467\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 0.9125 - acc: 0.5495 - val_loss: 0.9799 - val_acc: 0.5264\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 4s 987us/step - loss: 0.9141 - acc: 0.5536 - val_loss: 0.9286 - val_acc: 0.5429\n",
      "Epoch 40/300\n",
      "3744/4373 [========================>.....] - ETA: 0s - loss: 0.9099 - acc: 0.5545"
     ]
    }
   ],
   "source": [
    "result_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results', 'TDLstm'))\n",
    "lstm_result_folder = os.path.join(result_folder, 'lstm')\n",
    "os.makedirs(lstm_result_folder, exist_ok=True)\n",
    "repeated_params = {'reproducible' : False, 'validation_size' : 0.3, \n",
    "                   'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                   'org_initialisers' : True}\n",
    "score_kwargs = {'average' : 'macro'}\n",
    "for word_vector in word_vectors:\n",
    "    lstm_repeated_results = os.path.join(lstm_result_folder, 'LSTM {} Repeated Results.json'.format(word_vector))\n",
    "    lstm = LSTM(ark_twokenize, word_vector, lower=True, pad_size=-1)\n",
    "    lstm_rep_results = lstm.repeated_results(dong_train, dong_test, 60, f1_score,\n",
    "                                             'Dong Twitter', results_file=lstm_repeated_results,\n",
    "                                             re_write=False, score_kwargs=score_kwargs, **repeated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0.5974044716136527, 0.5758951460280506, 0.5834808923713788, 0.5880956380870128, 0.5748413173906847, 0.5824670113529876, 0.6030205056933168, 0.5756893361959213, 0.5866119368151163, 0.5907036057588758, 0.5825191634004082, 0.5690845221004573, 0.5818107498587409, 0.5888063242762731, 0.5714344734839623, 0.5924360437332433, 0.5968500211307116, 0.5694929379966395, 0.5861284433666658, 0.5853628814003565, 0.5962713200048756, 0.5760815316256681, 0.5748266983561101, 0.6080294661122525, 0.570554396562961, 0.5810423447941923, 0.5873197264185556, 0.5910243946048029, 0.6011359602413915, 0.5854452448063472, 0.600364421071725, 0.5748506489960393, 0.585056934516326, 0.5740118526747588, 0.5789586492771207, 0.6011301764705156, 0.5941195603027576, 0.5949358469506157, 0.5535759141559932, 0.5912041086549715, 0.5821617167461671, 0.59820126617065, 0.5720002324519653, 0.6123774451782977, 0.5806423774228348, 0.5683724135255336, 0.5808532923059956, 0.587075542181959, 0.5699581722500495, 0.5653119027914876, 0.5650628030150685, 0.5798660496591531, 0.5782777701195343, 0.5913329490406702, 0.5831095327300803, 0.5758428108197983, 0.5679694092827003, 0.6045176001526791, 0.597254201155876, 0.5838267161299151]\n",
      "10\n",
      "[0.6062585128622864, 0.6118217767228452, 0.5927421687683597, 0.6094287812760822, 0.5782500606585402, 0.601592618680793, 0.6221048229228724, 0.5931288113331458, 0.5977514849636392, 0.6198461168060929, 0.5909335161555975, 0.5988516273416841, 0.6037477270084558, 0.6048721246183831, 0.6142490042778698, 0.6333855980952735, 0.5915628734025964, 0.6154687000230924, 0.6130594043637522, 0.605448253503955, 0.597482003735966, 0.5940742378822873, 0.6071014264418939, 0.5880469684172911, 0.6007006625100818, 0.6313574585611677, 0.5967065185501729, 0.5919842838485998, 0.6031059862241617, 0.6100772573488885, 0.63622279678866, 0.6036924243925448, 0.5850022038701285, 0.6109909136675039, 0.5940447069586142, 0.6014680258172526, 0.6010944092827004, 0.6128267689675972, 0.6100587876272501, 0.6196567829201483, 0.5958409835782962, 0.6024316314613416, 0.6228491992446009, 0.5918990611556143, 0.6096459403029356, 0.6097118049499002, 0.6093753423823286, 0.6143411380210713, 0.621077377187434, 0.6133922134721213, 0.5945592739666052, 0.6004816074806487, 0.6098623866826318, 0.6056162722360346, 0.6262481477071261, 0.6157841091298398, 0.5988182530240045, 0.6112187901725729, 0.6029044423272407, 0.5792389242215731]\n",
      "9\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 2s 504us/step - loss: 1.0522 - acc: 0.4990 - val_loss: 1.0395 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0365 - acc: 0.5006 - val_loss: 1.0346 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 1.0320 - acc: 0.5006 - val_loss: 1.0305 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 1.0283 - acc: 0.5006 - val_loss: 1.0257 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 1.0235 - acc: 0.5006 - val_loss: 1.0210 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 1.0189 - acc: 0.5006 - val_loss: 1.0156 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 1.0137 - acc: 0.5003 - val_loss: 1.0099 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 1.0081 - acc: 0.5013 - val_loss: 1.0039 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 1.0021 - acc: 0.5040 - val_loss: 0.9972 - val_acc: 0.5051\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9953 - acc: 0.5067 - val_loss: 0.9894 - val_acc: 0.5115\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9884 - acc: 0.5106 - val_loss: 0.9816 - val_acc: 0.5179\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.9812 - acc: 0.5177 - val_loss: 0.9728 - val_acc: 0.5200\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9731 - acc: 0.5214 - val_loss: 0.9647 - val_acc: 0.5248\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9645 - acc: 0.5310 - val_loss: 0.9552 - val_acc: 0.5312\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9564 - acc: 0.5358 - val_loss: 0.9458 - val_acc: 0.5413\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9479 - acc: 0.5458 - val_loss: 0.9375 - val_acc: 0.5477\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.9397 - acc: 0.5532 - val_loss: 0.9290 - val_acc: 0.5520\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9308 - acc: 0.5589 - val_loss: 0.9196 - val_acc: 0.5627\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.9224 - acc: 0.5701 - val_loss: 0.9136 - val_acc: 0.5653\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9146 - acc: 0.5699 - val_loss: 0.9038 - val_acc: 0.5696\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9071 - acc: 0.5772 - val_loss: 0.8967 - val_acc: 0.5797\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.8982 - acc: 0.5799 - val_loss: 0.8992 - val_acc: 0.5840\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.8923 - acc: 0.5875 - val_loss: 0.8866 - val_acc: 0.5856\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8834 - acc: 0.5861 - val_loss: 0.8796 - val_acc: 0.5952\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8775 - acc: 0.5939 - val_loss: 0.8710 - val_acc: 0.5989\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.8705 - acc: 0.6055 - val_loss: 0.8743 - val_acc: 0.6048\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8641 - acc: 0.6030 - val_loss: 0.8643 - val_acc: 0.6080\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8564 - acc: 0.6124 - val_loss: 0.8583 - val_acc: 0.6080\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8503 - acc: 0.6124 - val_loss: 0.8531 - val_acc: 0.6085\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8464 - acc: 0.6190 - val_loss: 0.8540 - val_acc: 0.6112\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.8416 - acc: 0.6211 - val_loss: 0.8617 - val_acc: 0.6080\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8376 - acc: 0.6206 - val_loss: 0.8523 - val_acc: 0.6085\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.8324 - acc: 0.6259 - val_loss: 0.8571 - val_acc: 0.5979\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8280 - acc: 0.6282 - val_loss: 0.8444 - val_acc: 0.6171\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8235 - acc: 0.6339 - val_loss: 0.8435 - val_acc: 0.6123\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.8191 - acc: 0.6357 - val_loss: 0.8568 - val_acc: 0.6075\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8171 - acc: 0.6362 - val_loss: 0.8386 - val_acc: 0.6192\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8116 - acc: 0.6394 - val_loss: 0.8352 - val_acc: 0.6187\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8111 - acc: 0.6446 - val_loss: 0.8351 - val_acc: 0.6299\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8045 - acc: 0.6444 - val_loss: 0.8432 - val_acc: 0.6192\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.8022 - acc: 0.6458 - val_loss: 0.8344 - val_acc: 0.6341\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.7997 - acc: 0.6472 - val_loss: 0.8388 - val_acc: 0.6272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7948 - acc: 0.6513 - val_loss: 0.8432 - val_acc: 0.6240\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.7937 - acc: 0.6501 - val_loss: 0.8399 - val_acc: 0.6245\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7888 - acc: 0.6542 - val_loss: 0.8295 - val_acc: 0.6357\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7882 - acc: 0.6574 - val_loss: 0.8293 - val_acc: 0.6411\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7820 - acc: 0.6549 - val_loss: 0.8329 - val_acc: 0.6320\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7819 - acc: 0.6613 - val_loss: 0.8395 - val_acc: 0.6256\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7785 - acc: 0.6604 - val_loss: 0.8215 - val_acc: 0.6411\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7745 - acc: 0.6627 - val_loss: 0.8198 - val_acc: 0.6357\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7744 - acc: 0.6625 - val_loss: 0.8287 - val_acc: 0.6331\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7701 - acc: 0.6680 - val_loss: 0.8233 - val_acc: 0.6363\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7664 - acc: 0.6638 - val_loss: 0.8213 - val_acc: 0.6373\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7641 - acc: 0.6670 - val_loss: 0.8199 - val_acc: 0.6405\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7637 - acc: 0.6689 - val_loss: 0.8411 - val_acc: 0.6320\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7612 - acc: 0.6725 - val_loss: 0.8178 - val_acc: 0.6405\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7557 - acc: 0.6753 - val_loss: 0.8206 - val_acc: 0.6368\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7551 - acc: 0.6746 - val_loss: 0.8411 - val_acc: 0.6213\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7551 - acc: 0.6764 - val_loss: 0.8189 - val_acc: 0.6411\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7498 - acc: 0.6748 - val_loss: 0.8143 - val_acc: 0.6416\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7483 - acc: 0.6780 - val_loss: 0.8211 - val_acc: 0.6379\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7444 - acc: 0.6803 - val_loss: 0.8165 - val_acc: 0.6405\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7431 - acc: 0.6769 - val_loss: 0.8328 - val_acc: 0.6320\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7387 - acc: 0.6835 - val_loss: 0.8193 - val_acc: 0.6400\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7373 - acc: 0.6860 - val_loss: 0.8143 - val_acc: 0.6421\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7364 - acc: 0.6860 - val_loss: 0.8091 - val_acc: 0.6517\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7321 - acc: 0.6826 - val_loss: 0.8073 - val_acc: 0.6491\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7331 - acc: 0.6913 - val_loss: 0.8098 - val_acc: 0.6443\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7265 - acc: 0.6872 - val_loss: 0.8387 - val_acc: 0.6261\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7257 - acc: 0.6908 - val_loss: 0.8062 - val_acc: 0.6475\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7232 - acc: 0.6879 - val_loss: 0.8060 - val_acc: 0.6517\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7181 - acc: 0.6920 - val_loss: 0.8089 - val_acc: 0.6517\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.7177 - acc: 0.6885 - val_loss: 0.8231 - val_acc: 0.6373\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7150 - acc: 0.6911 - val_loss: 0.8060 - val_acc: 0.6523\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7132 - acc: 0.6947 - val_loss: 0.8102 - val_acc: 0.6459\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7138 - acc: 0.6915 - val_loss: 0.8104 - val_acc: 0.6459\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7070 - acc: 0.7018 - val_loss: 0.8165 - val_acc: 0.6405\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7076 - acc: 0.6972 - val_loss: 0.8093 - val_acc: 0.6448\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7025 - acc: 0.6952 - val_loss: 0.8323 - val_acc: 0.6368\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7005 - acc: 0.7041 - val_loss: 0.8134 - val_acc: 0.6464\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6979 - acc: 0.7048 - val_loss: 0.8436 - val_acc: 0.6293\n",
      "0.603777295501\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 2s 528us/step - loss: 1.0508 - acc: 0.4990 - val_loss: 1.0367 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 1.0348 - acc: 0.5006 - val_loss: 1.0326 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 1.0300 - acc: 0.5006 - val_loss: 1.0286 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 1.0252 - acc: 0.5006 - val_loss: 1.0245 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 1.0199 - acc: 0.5006 - val_loss: 1.0200 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0142 - acc: 0.5006 - val_loss: 1.0151 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 1.0079 - acc: 0.5008 - val_loss: 1.0097 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 1.0008 - acc: 0.5010 - val_loss: 1.0040 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9931 - acc: 0.5024 - val_loss: 0.9972 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.9843 - acc: 0.5051 - val_loss: 0.9903 - val_acc: 0.5051\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9746 - acc: 0.5093 - val_loss: 0.9823 - val_acc: 0.5104\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.9640 - acc: 0.5191 - val_loss: 0.9740 - val_acc: 0.5147\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.9539 - acc: 0.5257 - val_loss: 0.9680 - val_acc: 0.5211\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.9438 - acc: 0.5319 - val_loss: 0.9598 - val_acc: 0.5349\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.9348 - acc: 0.5433 - val_loss: 0.9549 - val_acc: 0.5328\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.9260 - acc: 0.5520 - val_loss: 0.9458 - val_acc: 0.5387\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9185 - acc: 0.5607 - val_loss: 0.9401 - val_acc: 0.5429\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9091 - acc: 0.5724 - val_loss: 0.9342 - val_acc: 0.5472\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9008 - acc: 0.5781 - val_loss: 0.9275 - val_acc: 0.5552\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8939 - acc: 0.5822 - val_loss: 0.9218 - val_acc: 0.5579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.8866 - acc: 0.5898 - val_loss: 0.9180 - val_acc: 0.5653\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8789 - acc: 0.5973 - val_loss: 0.9124 - val_acc: 0.5568\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8729 - acc: 0.5989 - val_loss: 0.9100 - val_acc: 0.5712\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8665 - acc: 0.6032 - val_loss: 0.9024 - val_acc: 0.5680\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8601 - acc: 0.6101 - val_loss: 0.8981 - val_acc: 0.5733\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 361us/step - loss: 0.8540 - acc: 0.6103 - val_loss: 0.8897 - val_acc: 0.5749\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.8493 - acc: 0.6131 - val_loss: 0.8871 - val_acc: 0.5728\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8452 - acc: 0.6129 - val_loss: 0.8916 - val_acc: 0.5813\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8412 - acc: 0.6199 - val_loss: 0.8885 - val_acc: 0.5840\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8341 - acc: 0.6225 - val_loss: 0.8793 - val_acc: 0.5861\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8308 - acc: 0.6234 - val_loss: 0.8751 - val_acc: 0.5899\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8241 - acc: 0.6289 - val_loss: 0.8731 - val_acc: 0.5941\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8223 - acc: 0.6318 - val_loss: 0.8775 - val_acc: 0.5925\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8176 - acc: 0.6359 - val_loss: 0.8711 - val_acc: 0.5888\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.8147 - acc: 0.6350 - val_loss: 0.8730 - val_acc: 0.5968\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8103 - acc: 0.6325 - val_loss: 0.8617 - val_acc: 0.5995\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8067 - acc: 0.6408 - val_loss: 0.8643 - val_acc: 0.5995\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8019 - acc: 0.6401 - val_loss: 0.8591 - val_acc: 0.6005\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 351us/step - loss: 0.7984 - acc: 0.6410 - val_loss: 0.8625 - val_acc: 0.5920\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7961 - acc: 0.6430 - val_loss: 0.8551 - val_acc: 0.5984\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7934 - acc: 0.6478 - val_loss: 0.8647 - val_acc: 0.5979\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7892 - acc: 0.6453 - val_loss: 0.8532 - val_acc: 0.6016\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7853 - acc: 0.6488 - val_loss: 0.8478 - val_acc: 0.6085\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7798 - acc: 0.6510 - val_loss: 0.8503 - val_acc: 0.6107\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7798 - acc: 0.6508 - val_loss: 0.8477 - val_acc: 0.6005\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 376us/step - loss: 0.7772 - acc: 0.6540 - val_loss: 0.8552 - val_acc: 0.6043\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7712 - acc: 0.6616 - val_loss: 0.8441 - val_acc: 0.6091\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7683 - acc: 0.6620 - val_loss: 0.8487 - val_acc: 0.6123\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7652 - acc: 0.6552 - val_loss: 0.8578 - val_acc: 0.6112\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.7643 - acc: 0.6645 - val_loss: 0.8418 - val_acc: 0.6112\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.7619 - acc: 0.6611 - val_loss: 0.8461 - val_acc: 0.6144\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.7579 - acc: 0.6659 - val_loss: 0.8405 - val_acc: 0.6112\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7545 - acc: 0.6707 - val_loss: 0.8513 - val_acc: 0.6139\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7521 - acc: 0.6716 - val_loss: 0.8439 - val_acc: 0.6171\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7489 - acc: 0.6707 - val_loss: 0.8398 - val_acc: 0.6235\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7445 - acc: 0.6732 - val_loss: 0.8619 - val_acc: 0.6021\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7438 - acc: 0.6753 - val_loss: 0.8360 - val_acc: 0.6267\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7394 - acc: 0.6773 - val_loss: 0.8535 - val_acc: 0.6133\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7379 - acc: 0.6716 - val_loss: 0.8421 - val_acc: 0.6123\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7343 - acc: 0.6826 - val_loss: 0.8541 - val_acc: 0.6091\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.7354 - acc: 0.6764 - val_loss: 0.8451 - val_acc: 0.6213\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7297 - acc: 0.6799 - val_loss: 0.8966 - val_acc: 0.5883\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7283 - acc: 0.6863 - val_loss: 0.8509 - val_acc: 0.6160\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7217 - acc: 0.6860 - val_loss: 0.8357 - val_acc: 0.6203\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7201 - acc: 0.6872 - val_loss: 0.8512 - val_acc: 0.6219\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7211 - acc: 0.6885 - val_loss: 0.8374 - val_acc: 0.6251\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7169 - acc: 0.6885 - val_loss: 0.8512 - val_acc: 0.6187\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7124 - acc: 0.6888 - val_loss: 0.8390 - val_acc: 0.6176\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.7107 - acc: 0.6883 - val_loss: 0.8374 - val_acc: 0.6251\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7082 - acc: 0.6940 - val_loss: 0.8439 - val_acc: 0.6245\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7062 - acc: 0.6933 - val_loss: 0.8560 - val_acc: 0.6165\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7012 - acc: 0.6922 - val_loss: 0.8433 - val_acc: 0.6267\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6975 - acc: 0.7009 - val_loss: 0.8369 - val_acc: 0.6261\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6961 - acc: 0.6986 - val_loss: 0.8354 - val_acc: 0.6304\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.6932 - acc: 0.7032 - val_loss: 0.8606 - val_acc: 0.6128\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.6939 - acc: 0.7027 - val_loss: 0.8363 - val_acc: 0.6283\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6917 - acc: 0.7013 - val_loss: 0.8617 - val_acc: 0.6144\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6910 - acc: 0.7000 - val_loss: 0.8410 - val_acc: 0.6283\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.6841 - acc: 0.7013 - val_loss: 0.8348 - val_acc: 0.6309\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.6772 - acc: 0.7100 - val_loss: 0.8379 - val_acc: 0.6256\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6784 - acc: 0.7059 - val_loss: 0.8340 - val_acc: 0.6304\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6762 - acc: 0.7089 - val_loss: 0.8351 - val_acc: 0.6229\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6737 - acc: 0.7167 - val_loss: 0.8460 - val_acc: 0.6357\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 369us/step - loss: 0.6691 - acc: 0.7107 - val_loss: 0.8479 - val_acc: 0.6261\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.6669 - acc: 0.7171 - val_loss: 0.8381 - val_acc: 0.6277\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.6652 - acc: 0.7158 - val_loss: 0.8453 - val_acc: 0.6155\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.6607 - acc: 0.7180 - val_loss: 0.8479 - val_acc: 0.6277\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6608 - acc: 0.7158 - val_loss: 0.8937 - val_acc: 0.6160\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6580 - acc: 0.7244 - val_loss: 0.8636 - val_acc: 0.6197\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 374us/step - loss: 0.6559 - acc: 0.7215 - val_loss: 0.8440 - val_acc: 0.6240\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.6495 - acc: 0.7247 - val_loss: 0.8583 - val_acc: 0.6144\n",
      "0.608865428604\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 3s 575us/step - loss: 1.0496 - acc: 0.4978 - val_loss: 1.0376 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 1.0337 - acc: 0.5006 - val_loss: 1.0327 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 1.0282 - acc: 0.5006 - val_loss: 1.0280 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 1.0225 - acc: 0.5006 - val_loss: 1.0232 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 1.0164 - acc: 0.5006 - val_loss: 1.0181 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 1.0099 - acc: 0.5008 - val_loss: 1.0127 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 1.0032 - acc: 0.5010 - val_loss: 1.0070 - val_acc: 0.5035\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9958 - acc: 0.5033 - val_loss: 1.0002 - val_acc: 0.5040\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.9878 - acc: 0.5074 - val_loss: 0.9935 - val_acc: 0.5083\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.9790 - acc: 0.5157 - val_loss: 0.9868 - val_acc: 0.5141\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9706 - acc: 0.5223 - val_loss: 0.9789 - val_acc: 0.5237\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9615 - acc: 0.5337 - val_loss: 0.9713 - val_acc: 0.5360\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9523 - acc: 0.5431 - val_loss: 0.9634 - val_acc: 0.5376\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9435 - acc: 0.5470 - val_loss: 0.9561 - val_acc: 0.5488\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9336 - acc: 0.5571 - val_loss: 0.9486 - val_acc: 0.5472\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9253 - acc: 0.5628 - val_loss: 0.9441 - val_acc: 0.5563\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9170 - acc: 0.5731 - val_loss: 0.9355 - val_acc: 0.5611\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9089 - acc: 0.5747 - val_loss: 0.9304 - val_acc: 0.5605\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9007 - acc: 0.5820 - val_loss: 0.9226 - val_acc: 0.5691\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8931 - acc: 0.5879 - val_loss: 0.9184 - val_acc: 0.5856\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8852 - acc: 0.5907 - val_loss: 0.9127 - val_acc: 0.5781\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8774 - acc: 0.5962 - val_loss: 0.9054 - val_acc: 0.5760\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.8701 - acc: 0.6028 - val_loss: 0.9000 - val_acc: 0.5851\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8631 - acc: 0.6030 - val_loss: 0.8957 - val_acc: 0.5904\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8568 - acc: 0.6076 - val_loss: 0.8914 - val_acc: 0.5877\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8517 - acc: 0.6179 - val_loss: 0.8875 - val_acc: 0.5941\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8450 - acc: 0.6124 - val_loss: 0.8862 - val_acc: 0.5920\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8404 - acc: 0.6186 - val_loss: 0.8872 - val_acc: 0.5888\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8354 - acc: 0.6215 - val_loss: 0.8794 - val_acc: 0.5984\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8306 - acc: 0.6209 - val_loss: 0.8768 - val_acc: 0.5989\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8273 - acc: 0.6282 - val_loss: 0.8722 - val_acc: 0.5995\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8230 - acc: 0.6314 - val_loss: 0.9013 - val_acc: 0.5765\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8179 - acc: 0.6314 - val_loss: 0.8742 - val_acc: 0.5893\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8126 - acc: 0.6371 - val_loss: 0.8651 - val_acc: 0.6064\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8112 - acc: 0.6348 - val_loss: 0.8635 - val_acc: 0.6043\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.8081 - acc: 0.6408 - val_loss: 0.8638 - val_acc: 0.6107\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8027 - acc: 0.6410 - val_loss: 0.8797 - val_acc: 0.5883\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7998 - acc: 0.6446 - val_loss: 0.8797 - val_acc: 0.5845\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7960 - acc: 0.6453 - val_loss: 0.8612 - val_acc: 0.6080\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7932 - acc: 0.6456 - val_loss: 0.8615 - val_acc: 0.6080\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7909 - acc: 0.6522 - val_loss: 0.8519 - val_acc: 0.6155\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7853 - acc: 0.6526 - val_loss: 0.8551 - val_acc: 0.6128\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7825 - acc: 0.6526 - val_loss: 0.8508 - val_acc: 0.6080\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7804 - acc: 0.6604 - val_loss: 0.8553 - val_acc: 0.6139\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7775 - acc: 0.6552 - val_loss: 0.8509 - val_acc: 0.6107\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7731 - acc: 0.6618 - val_loss: 0.8557 - val_acc: 0.6107\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7715 - acc: 0.6616 - val_loss: 0.8462 - val_acc: 0.6176\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7673 - acc: 0.6629 - val_loss: 0.8437 - val_acc: 0.6219\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7681 - acc: 0.6606 - val_loss: 0.8483 - val_acc: 0.6085\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 370us/step - loss: 0.7630 - acc: 0.6670 - val_loss: 0.8533 - val_acc: 0.6192\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.7595 - acc: 0.6698 - val_loss: 0.8666 - val_acc: 0.5968\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7588 - acc: 0.6661 - val_loss: 0.8411 - val_acc: 0.6181\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7542 - acc: 0.6723 - val_loss: 0.8430 - val_acc: 0.6149\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7536 - acc: 0.6682 - val_loss: 0.8443 - val_acc: 0.6320\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7494 - acc: 0.6732 - val_loss: 0.8531 - val_acc: 0.6059\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7473 - acc: 0.6767 - val_loss: 0.8403 - val_acc: 0.6123\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7455 - acc: 0.6753 - val_loss: 0.8554 - val_acc: 0.6203\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 354us/step - loss: 0.7436 - acc: 0.6746 - val_loss: 0.8465 - val_acc: 0.6059\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7402 - acc: 0.6760 - val_loss: 0.8381 - val_acc: 0.6336\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7406 - acc: 0.6746 - val_loss: 0.8538 - val_acc: 0.6171\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7369 - acc: 0.6764 - val_loss: 0.8375 - val_acc: 0.6197\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.7327 - acc: 0.6835 - val_loss: 0.8501 - val_acc: 0.6139\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7327 - acc: 0.6799 - val_loss: 0.8435 - val_acc: 0.6277\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7284 - acc: 0.6837 - val_loss: 0.8383 - val_acc: 0.6176\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7269 - acc: 0.6824 - val_loss: 0.8378 - val_acc: 0.6171\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7230 - acc: 0.6858 - val_loss: 0.8378 - val_acc: 0.6149\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7195 - acc: 0.6885 - val_loss: 0.8432 - val_acc: 0.6160\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7199 - acc: 0.6906 - val_loss: 0.8352 - val_acc: 0.6219\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7151 - acc: 0.6865 - val_loss: 0.8414 - val_acc: 0.6176\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7148 - acc: 0.6844 - val_loss: 0.8351 - val_acc: 0.6336\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7109 - acc: 0.6913 - val_loss: 0.8354 - val_acc: 0.6293\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7106 - acc: 0.6938 - val_loss: 0.8432 - val_acc: 0.6229\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7063 - acc: 0.6906 - val_loss: 0.8448 - val_acc: 0.6192\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7056 - acc: 0.6943 - val_loss: 0.8395 - val_acc: 0.6261\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7023 - acc: 0.6981 - val_loss: 0.8348 - val_acc: 0.6293\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7026 - acc: 0.6975 - val_loss: 0.8365 - val_acc: 0.6341\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7001 - acc: 0.6993 - val_loss: 0.8320 - val_acc: 0.6261\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.6937 - acc: 0.6995 - val_loss: 0.8345 - val_acc: 0.6283\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.6922 - acc: 0.7013 - val_loss: 0.8332 - val_acc: 0.6352\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6906 - acc: 0.7048 - val_loss: 0.8308 - val_acc: 0.6352\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.6877 - acc: 0.7036 - val_loss: 0.8320 - val_acc: 0.6272\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6857 - acc: 0.7078 - val_loss: 0.8655 - val_acc: 0.6112\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6848 - acc: 0.7032 - val_loss: 0.8280 - val_acc: 0.6357\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6789 - acc: 0.7128 - val_loss: 0.8413 - val_acc: 0.6293\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 359us/step - loss: 0.6759 - acc: 0.7148 - val_loss: 0.8464 - val_acc: 0.6352\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6766 - acc: 0.7080 - val_loss: 0.8412 - val_acc: 0.6267\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.6733 - acc: 0.7094 - val_loss: 0.8302 - val_acc: 0.6341\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 362us/step - loss: 0.6704 - acc: 0.7144 - val_loss: 0.8404 - val_acc: 0.6341\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.6675 - acc: 0.7139 - val_loss: 0.8328 - val_acc: 0.6325\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6658 - acc: 0.7164 - val_loss: 0.8352 - val_acc: 0.6315\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6647 - acc: 0.7199 - val_loss: 0.8476 - val_acc: 0.6309\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 370us/step - loss: 0.6588 - acc: 0.7183 - val_loss: 0.8504 - val_acc: 0.6325\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6568 - acc: 0.7244 - val_loss: 0.8432 - val_acc: 0.6336\n",
      "0.59163696213\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 2s 543us/step - loss: 1.0504 - acc: 0.4985 - val_loss: 1.0383 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0354 - acc: 0.5006 - val_loss: 1.0340 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 1.0305 - acc: 0.5006 - val_loss: 1.0295 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 1.0251 - acc: 0.5006 - val_loss: 1.0249 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0195 - acc: 0.5006 - val_loss: 1.0201 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 1.0134 - acc: 0.5006 - val_loss: 1.0146 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 1.0065 - acc: 0.5024 - val_loss: 1.0086 - val_acc: 0.5024\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9988 - acc: 0.5063 - val_loss: 1.0019 - val_acc: 0.5072\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 367us/step - loss: 0.9902 - acc: 0.5152 - val_loss: 0.9949 - val_acc: 0.5136\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.9817 - acc: 0.5230 - val_loss: 0.9868 - val_acc: 0.5147\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.9721 - acc: 0.5298 - val_loss: 0.9784 - val_acc: 0.5200\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.9616 - acc: 0.5356 - val_loss: 0.9703 - val_acc: 0.5280\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9510 - acc: 0.5452 - val_loss: 0.9609 - val_acc: 0.5317\n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9401 - acc: 0.5607 - val_loss: 0.9508 - val_acc: 0.5349\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.9290 - acc: 0.5637 - val_loss: 0.9420 - val_acc: 0.5419\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9192 - acc: 0.5717 - val_loss: 0.9335 - val_acc: 0.5445\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 364us/step - loss: 0.9091 - acc: 0.5710 - val_loss: 0.9249 - val_acc: 0.5563\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8987 - acc: 0.5806 - val_loss: 0.9236 - val_acc: 0.5611\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8911 - acc: 0.5863 - val_loss: 0.9124 - val_acc: 0.5568\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.8810 - acc: 0.5920 - val_loss: 0.9044 - val_acc: 0.5781\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8755 - acc: 0.5989 - val_loss: 0.9016 - val_acc: 0.5749\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 370us/step - loss: 0.8686 - acc: 0.6010 - val_loss: 0.9027 - val_acc: 0.5755\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8627 - acc: 0.6039 - val_loss: 0.8919 - val_acc: 0.5653\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8592 - acc: 0.6060 - val_loss: 0.8914 - val_acc: 0.5835\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8518 - acc: 0.6117 - val_loss: 0.8811 - val_acc: 0.5904\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8467 - acc: 0.6145 - val_loss: 0.8766 - val_acc: 0.5931\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8427 - acc: 0.6145 - val_loss: 0.8736 - val_acc: 0.5963\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8386 - acc: 0.6135 - val_loss: 0.8714 - val_acc: 0.5968\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8342 - acc: 0.6213 - val_loss: 0.8693 - val_acc: 0.6000\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8287 - acc: 0.6241 - val_loss: 0.8880 - val_acc: 0.5760\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.8253 - acc: 0.6273 - val_loss: 0.8642 - val_acc: 0.6075\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.8224 - acc: 0.6291 - val_loss: 0.8679 - val_acc: 0.6064\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8183 - acc: 0.6316 - val_loss: 0.8644 - val_acc: 0.6101\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8148 - acc: 0.6291 - val_loss: 0.8594 - val_acc: 0.6085\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8106 - acc: 0.6357 - val_loss: 0.8570 - val_acc: 0.6139\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8060 - acc: 0.6314 - val_loss: 0.8593 - val_acc: 0.6112\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8033 - acc: 0.6353 - val_loss: 0.8531 - val_acc: 0.6133\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7998 - acc: 0.6408 - val_loss: 0.8514 - val_acc: 0.6213\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7940 - acc: 0.6472 - val_loss: 0.8615 - val_acc: 0.6117\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7925 - acc: 0.6458 - val_loss: 0.8519 - val_acc: 0.6144\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7897 - acc: 0.6529 - val_loss: 0.8532 - val_acc: 0.6187\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7850 - acc: 0.6453 - val_loss: 0.8594 - val_acc: 0.6133\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7838 - acc: 0.6556 - val_loss: 0.8466 - val_acc: 0.6219\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7772 - acc: 0.6574 - val_loss: 0.8533 - val_acc: 0.6160\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7745 - acc: 0.6572 - val_loss: 0.8521 - val_acc: 0.6219\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.7748 - acc: 0.6590 - val_loss: 0.8569 - val_acc: 0.6139\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7737 - acc: 0.6629 - val_loss: 0.8432 - val_acc: 0.6224\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7680 - acc: 0.6634 - val_loss: 0.8404 - val_acc: 0.6245\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7641 - acc: 0.6622 - val_loss: 0.8476 - val_acc: 0.6160\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7605 - acc: 0.6664 - val_loss: 0.8456 - val_acc: 0.6277\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 368us/step - loss: 0.7602 - acc: 0.6682 - val_loss: 0.8516 - val_acc: 0.6128\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7550 - acc: 0.6664 - val_loss: 0.8430 - val_acc: 0.6267\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7533 - acc: 0.6670 - val_loss: 0.8507 - val_acc: 0.6283\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7515 - acc: 0.6737 - val_loss: 0.8424 - val_acc: 0.6224\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7480 - acc: 0.6751 - val_loss: 0.8401 - val_acc: 0.6251\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7449 - acc: 0.6746 - val_loss: 0.8374 - val_acc: 0.6299\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7430 - acc: 0.6796 - val_loss: 0.8437 - val_acc: 0.6283\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7418 - acc: 0.6801 - val_loss: 0.8349 - val_acc: 0.6336\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.7408 - acc: 0.6776 - val_loss: 0.8513 - val_acc: 0.6245\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.7365 - acc: 0.6844 - val_loss: 0.8428 - val_acc: 0.6235\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7341 - acc: 0.6787 - val_loss: 0.8318 - val_acc: 0.6363\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7300 - acc: 0.6833 - val_loss: 0.8307 - val_acc: 0.6368\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.7303 - acc: 0.6847 - val_loss: 0.8343 - val_acc: 0.6309\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7271 - acc: 0.6860 - val_loss: 0.8334 - val_acc: 0.6341\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.7245 - acc: 0.6895 - val_loss: 0.8353 - val_acc: 0.6357\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7209 - acc: 0.6922 - val_loss: 0.8363 - val_acc: 0.6363\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7191 - acc: 0.6895 - val_loss: 0.8276 - val_acc: 0.6373\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7168 - acc: 0.6908 - val_loss: 0.8376 - val_acc: 0.6277\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7109 - acc: 0.6890 - val_loss: 0.8611 - val_acc: 0.6267\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7123 - acc: 0.6949 - val_loss: 0.8337 - val_acc: 0.6373\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.7105 - acc: 0.6963 - val_loss: 0.8353 - val_acc: 0.6384\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7051 - acc: 0.6991 - val_loss: 0.8393 - val_acc: 0.6293\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7042 - acc: 0.6954 - val_loss: 0.8390 - val_acc: 0.6325\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7017 - acc: 0.7041 - val_loss: 0.8291 - val_acc: 0.6469\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6945 - acc: 0.7082 - val_loss: 0.8345 - val_acc: 0.6373\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6950 - acc: 0.7068 - val_loss: 0.8282 - val_acc: 0.6347\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.6958 - acc: 0.7013 - val_loss: 0.8343 - val_acc: 0.6368\n",
      "0.615798108269\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 2s 559us/step - loss: 1.0517 - acc: 0.4990 - val_loss: 1.0383 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 1.0352 - acc: 0.5006 - val_loss: 1.0339 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 1.0296 - acc: 0.5006 - val_loss: 1.0292 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 1.0240 - acc: 0.5006 - val_loss: 1.0243 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 1.0181 - acc: 0.5006 - val_loss: 1.0190 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 1.0116 - acc: 0.5006 - val_loss: 1.0134 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 1.0044 - acc: 0.5006 - val_loss: 1.0071 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.9965 - acc: 0.5024 - val_loss: 1.0002 - val_acc: 0.5029\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.9882 - acc: 0.5065 - val_loss: 0.9927 - val_acc: 0.5029\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.9789 - acc: 0.5159 - val_loss: 0.9849 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.9697 - acc: 0.5212 - val_loss: 0.9762 - val_acc: 0.5173\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.9595 - acc: 0.5319 - val_loss: 0.9679 - val_acc: 0.5237\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9498 - acc: 0.5381 - val_loss: 0.9613 - val_acc: 0.5296\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9398 - acc: 0.5479 - val_loss: 0.9522 - val_acc: 0.5296\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9304 - acc: 0.5500 - val_loss: 0.9445 - val_acc: 0.5461\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9214 - acc: 0.5609 - val_loss: 0.9374 - val_acc: 0.5488\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.9140 - acc: 0.5625 - val_loss: 0.9317 - val_acc: 0.5531\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9054 - acc: 0.5712 - val_loss: 0.9264 - val_acc: 0.5525\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8976 - acc: 0.5751 - val_loss: 0.9205 - val_acc: 0.5616\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8912 - acc: 0.5783 - val_loss: 0.9146 - val_acc: 0.5675\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8837 - acc: 0.5879 - val_loss: 0.9091 - val_acc: 0.5739\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8772 - acc: 0.5916 - val_loss: 0.9048 - val_acc: 0.5744\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8719 - acc: 0.5918 - val_loss: 0.8993 - val_acc: 0.5835\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8653 - acc: 0.5994 - val_loss: 0.8947 - val_acc: 0.5931\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8590 - acc: 0.6019 - val_loss: 0.8938 - val_acc: 0.5813\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8534 - acc: 0.6039 - val_loss: 0.8883 - val_acc: 0.5877\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8480 - acc: 0.6085 - val_loss: 0.8887 - val_acc: 0.5867\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8435 - acc: 0.6122 - val_loss: 0.8790 - val_acc: 0.6027\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8389 - acc: 0.6161 - val_loss: 0.8857 - val_acc: 0.5851\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8334 - acc: 0.6154 - val_loss: 0.8734 - val_acc: 0.6069\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8288 - acc: 0.6211 - val_loss: 0.8743 - val_acc: 0.5963\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8246 - acc: 0.6204 - val_loss: 0.8720 - val_acc: 0.6117\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8207 - acc: 0.6222 - val_loss: 0.8727 - val_acc: 0.6000\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8160 - acc: 0.6268 - val_loss: 0.8722 - val_acc: 0.5936\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8132 - acc: 0.6293 - val_loss: 0.8627 - val_acc: 0.6005\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8084 - acc: 0.6373 - val_loss: 0.8622 - val_acc: 0.6037\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8038 - acc: 0.6357 - val_loss: 0.8598 - val_acc: 0.6139\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8026 - acc: 0.6316 - val_loss: 0.8525 - val_acc: 0.6155\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7979 - acc: 0.6414 - val_loss: 0.8694 - val_acc: 0.5968\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 362us/step - loss: 0.7966 - acc: 0.6391 - val_loss: 0.8554 - val_acc: 0.6091\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7911 - acc: 0.6414 - val_loss: 0.8606 - val_acc: 0.6117\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7893 - acc: 0.6446 - val_loss: 0.8503 - val_acc: 0.6203\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 374us/step - loss: 0.7853 - acc: 0.6499 - val_loss: 0.8682 - val_acc: 0.5968\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7796 - acc: 0.6492 - val_loss: 0.8676 - val_acc: 0.6037\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7784 - acc: 0.6515 - val_loss: 0.8506 - val_acc: 0.6176\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7750 - acc: 0.6536 - val_loss: 0.8636 - val_acc: 0.6064\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7728 - acc: 0.6574 - val_loss: 0.8426 - val_acc: 0.6251\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7694 - acc: 0.6572 - val_loss: 0.8415 - val_acc: 0.6144\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7671 - acc: 0.6609 - val_loss: 0.8484 - val_acc: 0.6192\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7653 - acc: 0.6584 - val_loss: 0.8421 - val_acc: 0.6245\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7635 - acc: 0.6602 - val_loss: 0.8442 - val_acc: 0.6261\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 358us/step - loss: 0.7578 - acc: 0.6593 - val_loss: 0.8481 - val_acc: 0.6171\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7548 - acc: 0.6664 - val_loss: 0.8397 - val_acc: 0.6277\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7523 - acc: 0.6707 - val_loss: 0.8426 - val_acc: 0.6133\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7491 - acc: 0.6693 - val_loss: 0.8432 - val_acc: 0.6245\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7476 - acc: 0.6689 - val_loss: 0.8708 - val_acc: 0.6160\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7469 - acc: 0.6705 - val_loss: 0.8555 - val_acc: 0.6144\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 1s 332us/step - loss: 0.7425 - acc: 0.6702 - val_loss: 0.8362 - val_acc: 0.6192\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7390 - acc: 0.6762 - val_loss: 0.8438 - val_acc: 0.6213\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7369 - acc: 0.6767 - val_loss: 0.8456 - val_acc: 0.6160\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7345 - acc: 0.6757 - val_loss: 0.8339 - val_acc: 0.6219\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7308 - acc: 0.6801 - val_loss: 0.8673 - val_acc: 0.6085\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7280 - acc: 0.6853 - val_loss: 0.8560 - val_acc: 0.6123\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7235 - acc: 0.6867 - val_loss: 0.8397 - val_acc: 0.6272\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.7230 - acc: 0.6872 - val_loss: 0.8379 - val_acc: 0.6315\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 361us/step - loss: 0.7184 - acc: 0.6863 - val_loss: 0.8608 - val_acc: 0.6203\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7179 - acc: 0.6908 - val_loss: 0.8309 - val_acc: 0.6267\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7163 - acc: 0.6901 - val_loss: 0.8350 - val_acc: 0.6331\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7158 - acc: 0.6917 - val_loss: 0.8291 - val_acc: 0.6208\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7107 - acc: 0.6895 - val_loss: 0.8351 - val_acc: 0.6187\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7041 - acc: 0.6952 - val_loss: 0.8424 - val_acc: 0.6171\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7080 - acc: 0.6904 - val_loss: 0.8372 - val_acc: 0.6277\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7021 - acc: 0.6988 - val_loss: 0.8325 - val_acc: 0.6272\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7018 - acc: 0.6963 - val_loss: 0.8408 - val_acc: 0.6331\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6983 - acc: 0.7009 - val_loss: 0.8289 - val_acc: 0.6197\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 370us/step - loss: 0.6957 - acc: 0.6984 - val_loss: 0.8375 - val_acc: 0.6219\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.6920 - acc: 0.7089 - val_loss: 0.8311 - val_acc: 0.6293\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.6889 - acc: 0.7011 - val_loss: 0.8291 - val_acc: 0.6251\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6837 - acc: 0.7089 - val_loss: 0.8936 - val_acc: 0.6075\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6854 - acc: 0.7032 - val_loss: 0.8354 - val_acc: 0.6272\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 362us/step - loss: 0.6801 - acc: 0.7110 - val_loss: 0.8374 - val_acc: 0.6208\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.6777 - acc: 0.7105 - val_loss: 0.8444 - val_acc: 0.6347\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.6754 - acc: 0.7098 - val_loss: 0.8692 - val_acc: 0.6256\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.6740 - acc: 0.7078 - val_loss: 0.8329 - val_acc: 0.6251\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6695 - acc: 0.7158 - val_loss: 0.8338 - val_acc: 0.6299\n",
      "0.603905380549\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 1.0518 - acc: 0.5006 - val_loss: 1.0374 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 1.0360 - acc: 0.5006 - val_loss: 1.0307 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0303 - acc: 0.5006 - val_loss: 1.0244 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 1.0243 - acc: 0.5006 - val_loss: 1.0184 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 1.0182 - acc: 0.5006 - val_loss: 1.0119 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 1.0114 - acc: 0.5006 - val_loss: 1.0053 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 1.0042 - acc: 0.5017 - val_loss: 0.9979 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9963 - acc: 0.5040 - val_loss: 0.9905 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9879 - acc: 0.5083 - val_loss: 0.9830 - val_acc: 0.5120\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9788 - acc: 0.5170 - val_loss: 0.9722 - val_acc: 0.5152\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.9686 - acc: 0.5271 - val_loss: 0.9626 - val_acc: 0.5248\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.9587 - acc: 0.5326 - val_loss: 0.9531 - val_acc: 0.5392\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9486 - acc: 0.5431 - val_loss: 0.9444 - val_acc: 0.5429\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9392 - acc: 0.5527 - val_loss: 0.9360 - val_acc: 0.5451\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9294 - acc: 0.5543 - val_loss: 0.9328 - val_acc: 0.5547\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9206 - acc: 0.5646 - val_loss: 0.9207 - val_acc: 0.5616\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.9147 - acc: 0.5644 - val_loss: 0.9126 - val_acc: 0.5664\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9066 - acc: 0.5710 - val_loss: 0.9236 - val_acc: 0.5595\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8994 - acc: 0.5763 - val_loss: 0.9017 - val_acc: 0.5637\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 363us/step - loss: 0.8917 - acc: 0.5850 - val_loss: 0.9082 - val_acc: 0.5696\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8877 - acc: 0.5843 - val_loss: 0.8927 - val_acc: 0.5829\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8808 - acc: 0.5909 - val_loss: 0.8870 - val_acc: 0.5845\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8766 - acc: 0.5927 - val_loss: 0.8815 - val_acc: 0.5835\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8702 - acc: 0.5966 - val_loss: 0.8852 - val_acc: 0.5797\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8659 - acc: 0.6030 - val_loss: 0.8720 - val_acc: 0.5883\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.8586 - acc: 0.6032 - val_loss: 0.8779 - val_acc: 0.5851\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8536 - acc: 0.6106 - val_loss: 0.8837 - val_acc: 0.6021\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8528 - acc: 0.6103 - val_loss: 0.8628 - val_acc: 0.5931\n",
      "Epoch 29/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8477 - acc: 0.6126 - val_loss: 0.8620 - val_acc: 0.5995\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8433 - acc: 0.6154 - val_loss: 0.8654 - val_acc: 0.5915\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8388 - acc: 0.6115 - val_loss: 0.8590 - val_acc: 0.6085\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8357 - acc: 0.6165 - val_loss: 0.8521 - val_acc: 0.6059\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8306 - acc: 0.6215 - val_loss: 0.8485 - val_acc: 0.5979\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8274 - acc: 0.6177 - val_loss: 0.8492 - val_acc: 0.6101\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8217 - acc: 0.6259 - val_loss: 0.8525 - val_acc: 0.5968\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8206 - acc: 0.6243 - val_loss: 0.8434 - val_acc: 0.6139\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.8149 - acc: 0.6295 - val_loss: 0.8504 - val_acc: 0.6032\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8138 - acc: 0.6332 - val_loss: 0.8708 - val_acc: 0.6144\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.8105 - acc: 0.6327 - val_loss: 0.8413 - val_acc: 0.6123\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8071 - acc: 0.6327 - val_loss: 0.8378 - val_acc: 0.6235\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8010 - acc: 0.6373 - val_loss: 0.8380 - val_acc: 0.6176\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7991 - acc: 0.6394 - val_loss: 0.8618 - val_acc: 0.5947\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7998 - acc: 0.6382 - val_loss: 0.8321 - val_acc: 0.6251\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7948 - acc: 0.6428 - val_loss: 0.8374 - val_acc: 0.6197\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7932 - acc: 0.6433 - val_loss: 0.8282 - val_acc: 0.6261\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7898 - acc: 0.6456 - val_loss: 0.8335 - val_acc: 0.6256\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7869 - acc: 0.6449 - val_loss: 0.8380 - val_acc: 0.6283\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7829 - acc: 0.6465 - val_loss: 0.8250 - val_acc: 0.6293\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7812 - acc: 0.6504 - val_loss: 0.8262 - val_acc: 0.6373\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7772 - acc: 0.6504 - val_loss: 0.8257 - val_acc: 0.6304\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 1s 343us/step - loss: 0.7741 - acc: 0.6547 - val_loss: 0.8264 - val_acc: 0.6261\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7730 - acc: 0.6606 - val_loss: 0.8232 - val_acc: 0.6347\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7694 - acc: 0.6538 - val_loss: 0.8267 - val_acc: 0.6224\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7670 - acc: 0.6606 - val_loss: 0.8467 - val_acc: 0.6192\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7678 - acc: 0.6629 - val_loss: 0.8195 - val_acc: 0.6288\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7625 - acc: 0.6629 - val_loss: 0.8356 - val_acc: 0.6315\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7618 - acc: 0.6586 - val_loss: 0.8149 - val_acc: 0.6373\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7566 - acc: 0.6645 - val_loss: 0.8119 - val_acc: 0.6379\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7567 - acc: 0.6636 - val_loss: 0.8159 - val_acc: 0.6341\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7541 - acc: 0.6648 - val_loss: 0.8241 - val_acc: 0.6304\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7488 - acc: 0.6755 - val_loss: 0.8147 - val_acc: 0.6347\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7498 - acc: 0.6721 - val_loss: 0.8095 - val_acc: 0.6341\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7446 - acc: 0.6732 - val_loss: 0.8133 - val_acc: 0.6331\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7433 - acc: 0.6712 - val_loss: 0.8311 - val_acc: 0.6299\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7390 - acc: 0.6799 - val_loss: 0.8128 - val_acc: 0.6336\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7376 - acc: 0.6785 - val_loss: 0.8186 - val_acc: 0.6240\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.7343 - acc: 0.6780 - val_loss: 0.8414 - val_acc: 0.6107\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7315 - acc: 0.6799 - val_loss: 0.8110 - val_acc: 0.6432\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7272 - acc: 0.6833 - val_loss: 0.8240 - val_acc: 0.6181\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7263 - acc: 0.6824 - val_loss: 0.8107 - val_acc: 0.6389\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7227 - acc: 0.6863 - val_loss: 0.8038 - val_acc: 0.6400\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7217 - acc: 0.6890 - val_loss: 0.8099 - val_acc: 0.6427\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7205 - acc: 0.6879 - val_loss: 0.8056 - val_acc: 0.6437\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7182 - acc: 0.6863 - val_loss: 0.8037 - val_acc: 0.6427\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7149 - acc: 0.6931 - val_loss: 0.8017 - val_acc: 0.6512\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7117 - acc: 0.6965 - val_loss: 0.8107 - val_acc: 0.6384\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7099 - acc: 0.6933 - val_loss: 0.8107 - val_acc: 0.6389\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7059 - acc: 0.6984 - val_loss: 0.8003 - val_acc: 0.6389\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7035 - acc: 0.6954 - val_loss: 0.8091 - val_acc: 0.6432\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7008 - acc: 0.6970 - val_loss: 0.8089 - val_acc: 0.6288\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.6986 - acc: 0.6965 - val_loss: 0.8285 - val_acc: 0.6347\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6960 - acc: 0.7025 - val_loss: 0.8068 - val_acc: 0.6453\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6941 - acc: 0.7066 - val_loss: 0.8033 - val_acc: 0.6384\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6902 - acc: 0.7041 - val_loss: 0.8008 - val_acc: 0.6416\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.6874 - acc: 0.7103 - val_loss: 0.8006 - val_acc: 0.6389\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6863 - acc: 0.7016 - val_loss: 0.8050 - val_acc: 0.6347\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6842 - acc: 0.7043 - val_loss: 0.8160 - val_acc: 0.6315\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6775 - acc: 0.7121 - val_loss: 0.8003 - val_acc: 0.6443\n",
      "0.605526171802\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 1.0509 - acc: 0.4981 - val_loss: 1.0376 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 1.0366 - acc: 0.5006 - val_loss: 1.0331 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0318 - acc: 0.5006 - val_loss: 1.0290 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 1.0269 - acc: 0.5006 - val_loss: 1.0248 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0217 - acc: 0.5006 - val_loss: 1.0208 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 1.0164 - acc: 0.5008 - val_loss: 1.0164 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 1.0111 - acc: 0.5008 - val_loss: 1.0110 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 1.0048 - acc: 0.5013 - val_loss: 1.0058 - val_acc: 0.5029\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.9985 - acc: 0.5042 - val_loss: 1.0001 - val_acc: 0.5045\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9915 - acc: 0.5115 - val_loss: 0.9939 - val_acc: 0.5115\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9841 - acc: 0.5182 - val_loss: 0.9873 - val_acc: 0.5184\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.9764 - acc: 0.5239 - val_loss: 0.9804 - val_acc: 0.5173\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.9677 - acc: 0.5276 - val_loss: 0.9738 - val_acc: 0.5275\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9584 - acc: 0.5349 - val_loss: 0.9663 - val_acc: 0.5200\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9497 - acc: 0.5383 - val_loss: 0.9574 - val_acc: 0.5371\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.9404 - acc: 0.5488 - val_loss: 0.9504 - val_acc: 0.5467\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9310 - acc: 0.5568 - val_loss: 0.9421 - val_acc: 0.5520\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9207 - acc: 0.5635 - val_loss: 0.9345 - val_acc: 0.5536\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9118 - acc: 0.5737 - val_loss: 0.9289 - val_acc: 0.5552\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9035 - acc: 0.5818 - val_loss: 0.9204 - val_acc: 0.5589\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8946 - acc: 0.5797 - val_loss: 0.9152 - val_acc: 0.5595\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8859 - acc: 0.5966 - val_loss: 0.9107 - val_acc: 0.5621\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8782 - acc: 0.5982 - val_loss: 0.9087 - val_acc: 0.5563\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8711 - acc: 0.6087 - val_loss: 0.8983 - val_acc: 0.5675\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8642 - acc: 0.6101 - val_loss: 0.8945 - val_acc: 0.5691\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8563 - acc: 0.6179 - val_loss: 0.8889 - val_acc: 0.5723\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8503 - acc: 0.6156 - val_loss: 0.8859 - val_acc: 0.5728\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8438 - acc: 0.6220 - val_loss: 0.8818 - val_acc: 0.5776\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8372 - acc: 0.6236 - val_loss: 0.8777 - val_acc: 0.5835\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8318 - acc: 0.6307 - val_loss: 0.8792 - val_acc: 0.5771\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.8269 - acc: 0.6321 - val_loss: 0.8726 - val_acc: 0.5808\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8205 - acc: 0.6385 - val_loss: 0.8719 - val_acc: 0.5877\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8157 - acc: 0.6380 - val_loss: 0.8673 - val_acc: 0.5861\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.8120 - acc: 0.6396 - val_loss: 0.8756 - val_acc: 0.5707\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.8084 - acc: 0.6382 - val_loss: 0.8674 - val_acc: 0.5941\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8041 - acc: 0.6435 - val_loss: 0.8729 - val_acc: 0.5749\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.8011 - acc: 0.6403 - val_loss: 0.8589 - val_acc: 0.5973\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7960 - acc: 0.6453 - val_loss: 0.8592 - val_acc: 0.5920\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7898 - acc: 0.6476 - val_loss: 0.8637 - val_acc: 0.5963\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7879 - acc: 0.6526 - val_loss: 0.8623 - val_acc: 0.5909\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 374us/step - loss: 0.7845 - acc: 0.6529 - val_loss: 0.8540 - val_acc: 0.6043\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.7801 - acc: 0.6577 - val_loss: 0.8590 - val_acc: 0.5941\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 363us/step - loss: 0.7795 - acc: 0.6545 - val_loss: 0.8660 - val_acc: 0.5888\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7753 - acc: 0.6572 - val_loss: 0.8521 - val_acc: 0.6069\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7714 - acc: 0.6634 - val_loss: 0.8493 - val_acc: 0.6101\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7668 - acc: 0.6602 - val_loss: 0.8780 - val_acc: 0.5819\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7652 - acc: 0.6625 - val_loss: 0.8505 - val_acc: 0.6043\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7599 - acc: 0.6668 - val_loss: 0.8492 - val_acc: 0.6096\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 368us/step - loss: 0.7600 - acc: 0.6618 - val_loss: 0.8677 - val_acc: 0.5968\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7550 - acc: 0.6616 - val_loss: 0.8537 - val_acc: 0.6053\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7516 - acc: 0.6709 - val_loss: 0.8615 - val_acc: 0.6096\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7514 - acc: 0.6739 - val_loss: 0.8579 - val_acc: 0.6075\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7477 - acc: 0.6702 - val_loss: 0.8443 - val_acc: 0.6160\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7445 - acc: 0.6753 - val_loss: 0.8444 - val_acc: 0.6176\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7427 - acc: 0.6716 - val_loss: 0.8440 - val_acc: 0.6181\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7381 - acc: 0.6771 - val_loss: 0.8456 - val_acc: 0.6160\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7386 - acc: 0.6737 - val_loss: 0.8503 - val_acc: 0.6133\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7324 - acc: 0.6794 - val_loss: 0.8470 - val_acc: 0.6144\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.7304 - acc: 0.6785 - val_loss: 0.8458 - val_acc: 0.6171\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7272 - acc: 0.6847 - val_loss: 0.8449 - val_acc: 0.6181\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7258 - acc: 0.6842 - val_loss: 0.8568 - val_acc: 0.6133\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7234 - acc: 0.6863 - val_loss: 0.8462 - val_acc: 0.6160\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7208 - acc: 0.6824 - val_loss: 0.8473 - val_acc: 0.6187\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7173 - acc: 0.6879 - val_loss: 0.8434 - val_acc: 0.6192\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7139 - acc: 0.6938 - val_loss: 0.9033 - val_acc: 0.5755\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7124 - acc: 0.6920 - val_loss: 0.8844 - val_acc: 0.5909\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7098 - acc: 0.6920 - val_loss: 0.8413 - val_acc: 0.6203\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 371us/step - loss: 0.7095 - acc: 0.6920 - val_loss: 0.8683 - val_acc: 0.6011\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7030 - acc: 0.6968 - val_loss: 0.8410 - val_acc: 0.6240\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7014 - acc: 0.6986 - val_loss: 0.8439 - val_acc: 0.6219\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6980 - acc: 0.7011 - val_loss: 0.8416 - val_acc: 0.6277\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.6974 - acc: 0.6959 - val_loss: 0.8484 - val_acc: 0.6192\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6946 - acc: 0.7052 - val_loss: 0.8394 - val_acc: 0.6283\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.6893 - acc: 0.7029 - val_loss: 0.8510 - val_acc: 0.6160\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6903 - acc: 0.7062 - val_loss: 0.8369 - val_acc: 0.6224\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6848 - acc: 0.7064 - val_loss: 0.8492 - val_acc: 0.6272\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6817 - acc: 0.7055 - val_loss: 0.8680 - val_acc: 0.6192\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6808 - acc: 0.7064 - val_loss: 0.8453 - val_acc: 0.6299\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.6771 - acc: 0.7055 - val_loss: 0.8380 - val_acc: 0.6331\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6759 - acc: 0.7119 - val_loss: 0.8365 - val_acc: 0.6245\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.6739 - acc: 0.7132 - val_loss: 0.8383 - val_acc: 0.6203\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.6694 - acc: 0.7174 - val_loss: 0.8402 - val_acc: 0.6267\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6677 - acc: 0.7121 - val_loss: 0.8360 - val_acc: 0.6251\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.6679 - acc: 0.7139 - val_loss: 0.8428 - val_acc: 0.6315\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.6626 - acc: 0.7199 - val_loss: 0.8602 - val_acc: 0.6325\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.6643 - acc: 0.7171 - val_loss: 0.8437 - val_acc: 0.6341\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6560 - acc: 0.7185 - val_loss: 0.8715 - val_acc: 0.6101\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 1s 334us/step - loss: 0.6552 - acc: 0.7290 - val_loss: 0.8379 - val_acc: 0.6336\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 363us/step - loss: 0.6559 - acc: 0.7190 - val_loss: 0.8451 - val_acc: 0.6267\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6517 - acc: 0.7217 - val_loss: 0.8618 - val_acc: 0.6219\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6477 - acc: 0.7249 - val_loss: 0.8373 - val_acc: 0.6357\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.6464 - acc: 0.7270 - val_loss: 0.8433 - val_acc: 0.6272\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.6439 - acc: 0.7324 - val_loss: 0.8494 - val_acc: 0.6267\n",
      "0.622219456218\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 1.0495 - acc: 0.5001 - val_loss: 1.0357 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 1.0350 - acc: 0.5006 - val_loss: 1.0306 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0295 - acc: 0.5006 - val_loss: 1.0254 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 1.0238 - acc: 0.5006 - val_loss: 1.0199 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0177 - acc: 0.5006 - val_loss: 1.0141 - val_acc: 0.5013\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 1.0111 - acc: 0.5003 - val_loss: 1.0079 - val_acc: 0.5024\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 1.0042 - acc: 0.5013 - val_loss: 1.0010 - val_acc: 0.5045\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9968 - acc: 0.5063 - val_loss: 0.9935 - val_acc: 0.5072\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9886 - acc: 0.5129 - val_loss: 0.9858 - val_acc: 0.5131\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9802 - acc: 0.5207 - val_loss: 0.9778 - val_acc: 0.5211\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9711 - acc: 0.5264 - val_loss: 0.9707 - val_acc: 0.5387\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9619 - acc: 0.5335 - val_loss: 0.9618 - val_acc: 0.5435\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.9525 - acc: 0.5424 - val_loss: 0.9550 - val_acc: 0.5536\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.9438 - acc: 0.5481 - val_loss: 0.9469 - val_acc: 0.5488\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9349 - acc: 0.5504 - val_loss: 0.9385 - val_acc: 0.5675\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.9264 - acc: 0.5630 - val_loss: 0.9310 - val_acc: 0.5696\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9175 - acc: 0.5694 - val_loss: 0.9269 - val_acc: 0.5771\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9090 - acc: 0.5737 - val_loss: 0.9206 - val_acc: 0.5696\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.9011 - acc: 0.5795 - val_loss: 0.9117 - val_acc: 0.5781\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8936 - acc: 0.5831 - val_loss: 0.9059 - val_acc: 0.5749\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.8859 - acc: 0.5918 - val_loss: 0.9120 - val_acc: 0.5723\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8790 - acc: 0.5925 - val_loss: 0.9038 - val_acc: 0.5840\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8722 - acc: 0.6026 - val_loss: 0.8917 - val_acc: 0.5845\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8660 - acc: 0.6051 - val_loss: 0.8908 - val_acc: 0.5872\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8604 - acc: 0.6110 - val_loss: 0.8866 - val_acc: 0.5883\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8542 - acc: 0.6085 - val_loss: 0.8822 - val_acc: 0.5893\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8467 - acc: 0.6199 - val_loss: 0.8930 - val_acc: 0.5829\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8437 - acc: 0.6167 - val_loss: 0.8777 - val_acc: 0.5968\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.8389 - acc: 0.6245 - val_loss: 0.8722 - val_acc: 0.6032\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.8343 - acc: 0.6206 - val_loss: 0.8723 - val_acc: 0.6032\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8288 - acc: 0.6279 - val_loss: 0.8673 - val_acc: 0.6048\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.8273 - acc: 0.6305 - val_loss: 0.8649 - val_acc: 0.6016\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8207 - acc: 0.6289 - val_loss: 0.8774 - val_acc: 0.6027\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8194 - acc: 0.6284 - val_loss: 0.8648 - val_acc: 0.6000\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8144 - acc: 0.6362 - val_loss: 0.8618 - val_acc: 0.6032\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8101 - acc: 0.6373 - val_loss: 0.8563 - val_acc: 0.6091\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8081 - acc: 0.6380 - val_loss: 0.8539 - val_acc: 0.6144\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8032 - acc: 0.6378 - val_loss: 0.8678 - val_acc: 0.5989\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8012 - acc: 0.6385 - val_loss: 0.8713 - val_acc: 0.6016\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7943 - acc: 0.6536 - val_loss: 0.8515 - val_acc: 0.6155\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7939 - acc: 0.6501 - val_loss: 0.8748 - val_acc: 0.6085\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7905 - acc: 0.6524 - val_loss: 0.8482 - val_acc: 0.6165\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7880 - acc: 0.6506 - val_loss: 0.8539 - val_acc: 0.6096\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7840 - acc: 0.6554 - val_loss: 0.8583 - val_acc: 0.6123\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7795 - acc: 0.6556 - val_loss: 0.8526 - val_acc: 0.6133\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7773 - acc: 0.6622 - val_loss: 0.8594 - val_acc: 0.6128\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7738 - acc: 0.6531 - val_loss: 0.8447 - val_acc: 0.6240\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7703 - acc: 0.6616 - val_loss: 0.8498 - val_acc: 0.6155\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7711 - acc: 0.6652 - val_loss: 0.8432 - val_acc: 0.6112\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7658 - acc: 0.6689 - val_loss: 0.8417 - val_acc: 0.6219\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7648 - acc: 0.6636 - val_loss: 0.8441 - val_acc: 0.6181\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7618 - acc: 0.6668 - val_loss: 0.8521 - val_acc: 0.6203\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7584 - acc: 0.6659 - val_loss: 0.8338 - val_acc: 0.6288\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7539 - acc: 0.6744 - val_loss: 0.8402 - val_acc: 0.6181\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7496 - acc: 0.6718 - val_loss: 0.8454 - val_acc: 0.6197\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7509 - acc: 0.6764 - val_loss: 0.8382 - val_acc: 0.6293\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7472 - acc: 0.6755 - val_loss: 0.8637 - val_acc: 0.6053\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7449 - acc: 0.6751 - val_loss: 0.8297 - val_acc: 0.6331\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7437 - acc: 0.6778 - val_loss: 0.8484 - val_acc: 0.6277\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7400 - acc: 0.6805 - val_loss: 0.8533 - val_acc: 0.6224\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7385 - acc: 0.6718 - val_loss: 0.8304 - val_acc: 0.6325\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7324 - acc: 0.6826 - val_loss: 0.8272 - val_acc: 0.6336\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7321 - acc: 0.6831 - val_loss: 0.8308 - val_acc: 0.6325\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7276 - acc: 0.6819 - val_loss: 0.8260 - val_acc: 0.6304\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7242 - acc: 0.6860 - val_loss: 0.8248 - val_acc: 0.6336\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7224 - acc: 0.6913 - val_loss: 0.8354 - val_acc: 0.6325\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 359us/step - loss: 0.7224 - acc: 0.6869 - val_loss: 0.8347 - val_acc: 0.6240\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7188 - acc: 0.6890 - val_loss: 0.8380 - val_acc: 0.6240\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7150 - acc: 0.6963 - val_loss: 0.8360 - val_acc: 0.6256\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7094 - acc: 0.6956 - val_loss: 0.8383 - val_acc: 0.6171\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7108 - acc: 0.6938 - val_loss: 0.8355 - val_acc: 0.6341\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7068 - acc: 0.6949 - val_loss: 0.8313 - val_acc: 0.6240\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.7069 - acc: 0.7011 - val_loss: 0.8194 - val_acc: 0.6411\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7058 - acc: 0.6947 - val_loss: 0.8421 - val_acc: 0.6176\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7013 - acc: 0.7018 - val_loss: 0.8310 - val_acc: 0.6379\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7018 - acc: 0.6975 - val_loss: 0.8286 - val_acc: 0.6245\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6955 - acc: 0.7039 - val_loss: 0.8207 - val_acc: 0.6272\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.6937 - acc: 0.7078 - val_loss: 0.8198 - val_acc: 0.6352\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.6902 - acc: 0.7043 - val_loss: 0.8576 - val_acc: 0.6181\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6873 - acc: 0.7057 - val_loss: 0.8264 - val_acc: 0.6400\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6846 - acc: 0.7084 - val_loss: 0.8442 - val_acc: 0.6203\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.6840 - acc: 0.7155 - val_loss: 0.8190 - val_acc: 0.6389\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6786 - acc: 0.7059 - val_loss: 0.8328 - val_acc: 0.6373\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6784 - acc: 0.7137 - val_loss: 0.8242 - val_acc: 0.6448\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.6776 - acc: 0.7146 - val_loss: 0.8458 - val_acc: 0.6144\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.6727 - acc: 0.7162 - val_loss: 0.8275 - val_acc: 0.6272\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6691 - acc: 0.7148 - val_loss: 0.8320 - val_acc: 0.6352\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.6627 - acc: 0.7180 - val_loss: 0.8523 - val_acc: 0.6187\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.6668 - acc: 0.7160 - val_loss: 0.8263 - val_acc: 0.6405\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.6644 - acc: 0.7228 - val_loss: 0.8191 - val_acc: 0.6331\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6601 - acc: 0.7201 - val_loss: 0.8296 - val_acc: 0.6368\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 374us/step - loss: 0.6551 - acc: 0.7247 - val_loss: 0.8435 - val_acc: 0.6368\n",
      "0.601100337761\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 1.0523 - acc: 0.4978 - val_loss: 1.0381 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 1.0359 - acc: 0.5006 - val_loss: 1.0332 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 1.0314 - acc: 0.5006 - val_loss: 1.0290 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 1.0266 - acc: 0.5006 - val_loss: 1.0246 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 1.0217 - acc: 0.5006 - val_loss: 1.0199 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0165 - acc: 0.5006 - val_loss: 1.0146 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 1.0108 - acc: 0.5006 - val_loss: 1.0089 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0045 - acc: 0.5019 - val_loss: 1.0027 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9976 - acc: 0.5031 - val_loss: 0.9958 - val_acc: 0.5045\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9901 - acc: 0.5097 - val_loss: 0.9881 - val_acc: 0.5104\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9820 - acc: 0.5150 - val_loss: 0.9802 - val_acc: 0.5163\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9734 - acc: 0.5198 - val_loss: 0.9715 - val_acc: 0.5227\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.9645 - acc: 0.5269 - val_loss: 0.9624 - val_acc: 0.5253\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9550 - acc: 0.5326 - val_loss: 0.9539 - val_acc: 0.5264\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9462 - acc: 0.5374 - val_loss: 0.9447 - val_acc: 0.5445\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9371 - acc: 0.5465 - val_loss: 0.9363 - val_acc: 0.5525\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9274 - acc: 0.5525 - val_loss: 0.9295 - val_acc: 0.5765\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9195 - acc: 0.5644 - val_loss: 0.9201 - val_acc: 0.5675\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9123 - acc: 0.5687 - val_loss: 0.9194 - val_acc: 0.5856\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9046 - acc: 0.5715 - val_loss: 0.9065 - val_acc: 0.5845\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.8990 - acc: 0.5795 - val_loss: 0.9027 - val_acc: 0.5893\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8921 - acc: 0.5854 - val_loss: 0.8975 - val_acc: 0.5925\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8842 - acc: 0.5879 - val_loss: 0.8924 - val_acc: 0.5856\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.8800 - acc: 0.5866 - val_loss: 0.8891 - val_acc: 0.5984\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.8733 - acc: 0.5925 - val_loss: 0.8847 - val_acc: 0.5973\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8665 - acc: 0.5952 - val_loss: 0.8824 - val_acc: 0.6037\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8626 - acc: 0.5996 - val_loss: 0.8738 - val_acc: 0.6011\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8578 - acc: 0.6064 - val_loss: 0.8746 - val_acc: 0.5957\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8524 - acc: 0.6080 - val_loss: 0.8680 - val_acc: 0.6043\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8470 - acc: 0.6108 - val_loss: 0.8677 - val_acc: 0.6053\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8439 - acc: 0.6142 - val_loss: 0.8637 - val_acc: 0.5963\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8371 - acc: 0.6154 - val_loss: 0.8610 - val_acc: 0.6112\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8367 - acc: 0.6195 - val_loss: 0.8563 - val_acc: 0.6069\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.8317 - acc: 0.6245 - val_loss: 0.8603 - val_acc: 0.6075\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8248 - acc: 0.6289 - val_loss: 0.8512 - val_acc: 0.6160\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8220 - acc: 0.6332 - val_loss: 0.8531 - val_acc: 0.6251\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8168 - acc: 0.6362 - val_loss: 0.8457 - val_acc: 0.6112\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.8148 - acc: 0.6332 - val_loss: 0.8528 - val_acc: 0.6085\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8089 - acc: 0.6339 - val_loss: 0.8454 - val_acc: 0.6069\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8071 - acc: 0.6357 - val_loss: 0.8511 - val_acc: 0.6064\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8046 - acc: 0.6394 - val_loss: 0.8431 - val_acc: 0.6117\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8003 - acc: 0.6414 - val_loss: 0.8372 - val_acc: 0.6165\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7962 - acc: 0.6414 - val_loss: 0.8346 - val_acc: 0.6213\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7955 - acc: 0.6398 - val_loss: 0.8407 - val_acc: 0.6267\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7908 - acc: 0.6442 - val_loss: 0.8387 - val_acc: 0.6219\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7894 - acc: 0.6472 - val_loss: 0.8309 - val_acc: 0.6219\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 362us/step - loss: 0.7863 - acc: 0.6449 - val_loss: 0.8329 - val_acc: 0.6299\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7828 - acc: 0.6499 - val_loss: 0.8303 - val_acc: 0.6176\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7790 - acc: 0.6538 - val_loss: 0.8287 - val_acc: 0.6235\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7743 - acc: 0.6552 - val_loss: 0.8335 - val_acc: 0.6267\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.7716 - acc: 0.6547 - val_loss: 0.8382 - val_acc: 0.6176\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7708 - acc: 0.6552 - val_loss: 0.8224 - val_acc: 0.6299\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7654 - acc: 0.6574 - val_loss: 0.8285 - val_acc: 0.6251\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.7630 - acc: 0.6597 - val_loss: 0.8342 - val_acc: 0.6229\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7629 - acc: 0.6643 - val_loss: 0.8394 - val_acc: 0.6155\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7575 - acc: 0.6661 - val_loss: 0.8256 - val_acc: 0.6235\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7553 - acc: 0.6705 - val_loss: 0.8219 - val_acc: 0.6315\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7532 - acc: 0.6689 - val_loss: 0.8203 - val_acc: 0.6245\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7506 - acc: 0.6705 - val_loss: 0.8226 - val_acc: 0.6309\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7483 - acc: 0.6728 - val_loss: 0.8206 - val_acc: 0.6288\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7444 - acc: 0.6723 - val_loss: 0.8161 - val_acc: 0.6304\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7452 - acc: 0.6721 - val_loss: 0.8582 - val_acc: 0.6016\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7396 - acc: 0.6744 - val_loss: 0.8202 - val_acc: 0.6272\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7414 - acc: 0.6680 - val_loss: 0.8207 - val_acc: 0.6320\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7360 - acc: 0.6819 - val_loss: 0.8212 - val_acc: 0.6277\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7361 - acc: 0.6767 - val_loss: 0.8206 - val_acc: 0.6283\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7291 - acc: 0.6860 - val_loss: 0.8175 - val_acc: 0.6379\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7286 - acc: 0.6824 - val_loss: 0.8236 - val_acc: 0.6309\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7276 - acc: 0.6831 - val_loss: 0.8312 - val_acc: 0.6229\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7237 - acc: 0.6826 - val_loss: 0.8109 - val_acc: 0.6357\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7204 - acc: 0.6872 - val_loss: 0.8164 - val_acc: 0.6336\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7196 - acc: 0.6858 - val_loss: 0.8167 - val_acc: 0.6288\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.7175 - acc: 0.6917 - val_loss: 0.8236 - val_acc: 0.6315\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7127 - acc: 0.6885 - val_loss: 0.8100 - val_acc: 0.6411\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7112 - acc: 0.6865 - val_loss: 0.8109 - val_acc: 0.6379\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7076 - acc: 0.6895 - val_loss: 0.8099 - val_acc: 0.6416\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7083 - acc: 0.6938 - val_loss: 0.8176 - val_acc: 0.6379\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7018 - acc: 0.6956 - val_loss: 0.8331 - val_acc: 0.6245\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7018 - acc: 0.6972 - val_loss: 0.8059 - val_acc: 0.6395\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6996 - acc: 0.6949 - val_loss: 0.8133 - val_acc: 0.6416\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6973 - acc: 0.6933 - val_loss: 0.8209 - val_acc: 0.6341\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6922 - acc: 0.7039 - val_loss: 0.8045 - val_acc: 0.6469\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6907 - acc: 0.6970 - val_loss: 0.8334 - val_acc: 0.6368\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6891 - acc: 0.7023 - val_loss: 0.8074 - val_acc: 0.6416\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6858 - acc: 0.7119 - val_loss: 0.8087 - val_acc: 0.6480\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6844 - acc: 0.7023 - val_loss: 0.8060 - val_acc: 0.6437\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6785 - acc: 0.7116 - val_loss: 0.8295 - val_acc: 0.6347\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6796 - acc: 0.7043 - val_loss: 0.8242 - val_acc: 0.6405\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6767 - acc: 0.7110 - val_loss: 0.8265 - val_acc: 0.6368\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.6745 - acc: 0.7071 - val_loss: 0.8076 - val_acc: 0.6496\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6717 - acc: 0.7137 - val_loss: 0.8551 - val_acc: 0.6160\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6706 - acc: 0.7128 - val_loss: 0.8206 - val_acc: 0.6405\n",
      "0.606531547748\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 3s 743us/step - loss: 1.0505 - acc: 0.4992 - val_loss: 1.0357 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 1.0361 - acc: 0.5006 - val_loss: 1.0315 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 1.0314 - acc: 0.5006 - val_loss: 1.0277 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0266 - acc: 0.5006 - val_loss: 1.0233 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 1.0220 - acc: 0.5006 - val_loss: 1.0188 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 1.0166 - acc: 0.5006 - val_loss: 1.0138 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 1.0113 - acc: 0.5010 - val_loss: 1.0086 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0053 - acc: 0.5017 - val_loss: 1.0029 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9988 - acc: 0.5038 - val_loss: 0.9970 - val_acc: 0.5019\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.9922 - acc: 0.5067 - val_loss: 0.9900 - val_acc: 0.5056\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9846 - acc: 0.5134 - val_loss: 0.9833 - val_acc: 0.5088\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.9767 - acc: 0.5161 - val_loss: 0.9762 - val_acc: 0.5227\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.9683 - acc: 0.5244 - val_loss: 0.9678 - val_acc: 0.5280\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9598 - acc: 0.5328 - val_loss: 0.9606 - val_acc: 0.5291\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9509 - acc: 0.5390 - val_loss: 0.9521 - val_acc: 0.5371\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9420 - acc: 0.5509 - val_loss: 0.9419 - val_acc: 0.5365\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.9337 - acc: 0.5543 - val_loss: 0.9338 - val_acc: 0.5424\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9262 - acc: 0.5625 - val_loss: 0.9265 - val_acc: 0.5461\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9173 - acc: 0.5593 - val_loss: 0.9246 - val_acc: 0.5525\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9106 - acc: 0.5712 - val_loss: 0.9147 - val_acc: 0.5515\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9036 - acc: 0.5692 - val_loss: 0.9116 - val_acc: 0.5691\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8961 - acc: 0.5827 - val_loss: 0.9056 - val_acc: 0.5504\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8905 - acc: 0.5818 - val_loss: 0.9052 - val_acc: 0.5765\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8841 - acc: 0.5914 - val_loss: 0.8931 - val_acc: 0.5733\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8786 - acc: 0.5893 - val_loss: 0.8902 - val_acc: 0.5669\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8723 - acc: 0.5966 - val_loss: 0.8829 - val_acc: 0.5845\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 368us/step - loss: 0.8656 - acc: 0.5959 - val_loss: 0.8842 - val_acc: 0.5760\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.8611 - acc: 0.5989 - val_loss: 0.8787 - val_acc: 0.5824\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8570 - acc: 0.6030 - val_loss: 0.8748 - val_acc: 0.5947\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8520 - acc: 0.6097 - val_loss: 0.8778 - val_acc: 0.5877\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8473 - acc: 0.6129 - val_loss: 0.8677 - val_acc: 0.5915\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8437 - acc: 0.6131 - val_loss: 0.8642 - val_acc: 0.6011\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.8389 - acc: 0.6172 - val_loss: 0.8652 - val_acc: 0.5957\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8366 - acc: 0.6167 - val_loss: 0.8624 - val_acc: 0.5995\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8304 - acc: 0.6227 - val_loss: 0.8591 - val_acc: 0.6096\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 0.8263 - acc: 0.6254 - val_loss: 0.8580 - val_acc: 0.6069\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.8234 - acc: 0.6302 - val_loss: 0.8558 - val_acc: 0.6080\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8202 - acc: 0.6298 - val_loss: 0.8664 - val_acc: 0.6096\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8160 - acc: 0.6311 - val_loss: 0.8618 - val_acc: 0.6123\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8128 - acc: 0.6318 - val_loss: 0.8572 - val_acc: 0.6096\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8101 - acc: 0.6396 - val_loss: 0.8482 - val_acc: 0.6128\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8083 - acc: 0.6401 - val_loss: 0.8491 - val_acc: 0.6069\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8043 - acc: 0.6417 - val_loss: 0.8497 - val_acc: 0.6085\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7990 - acc: 0.6456 - val_loss: 0.8488 - val_acc: 0.6171\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7984 - acc: 0.6437 - val_loss: 0.8487 - val_acc: 0.6160\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7925 - acc: 0.6451 - val_loss: 0.8777 - val_acc: 0.5957\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7932 - acc: 0.6481 - val_loss: 0.8407 - val_acc: 0.6197\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7879 - acc: 0.6540 - val_loss: 0.8431 - val_acc: 0.6229\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7867 - acc: 0.6524 - val_loss: 0.8378 - val_acc: 0.6181\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7844 - acc: 0.6515 - val_loss: 0.8488 - val_acc: 0.6219\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7799 - acc: 0.6549 - val_loss: 0.8427 - val_acc: 0.6171\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7800 - acc: 0.6554 - val_loss: 0.8382 - val_acc: 0.6256\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7774 - acc: 0.6556 - val_loss: 0.8422 - val_acc: 0.6240\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7726 - acc: 0.6673 - val_loss: 0.8415 - val_acc: 0.6176\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7705 - acc: 0.6602 - val_loss: 0.8345 - val_acc: 0.6261\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7677 - acc: 0.6613 - val_loss: 0.8418 - val_acc: 0.6219\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7643 - acc: 0.6641 - val_loss: 0.8376 - val_acc: 0.6192\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7635 - acc: 0.6689 - val_loss: 0.8441 - val_acc: 0.6123\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7630 - acc: 0.6716 - val_loss: 0.8290 - val_acc: 0.6240\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7583 - acc: 0.6677 - val_loss: 0.8322 - val_acc: 0.6256\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7561 - acc: 0.6712 - val_loss: 0.8271 - val_acc: 0.6245\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7531 - acc: 0.6718 - val_loss: 0.8249 - val_acc: 0.6325\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7503 - acc: 0.6760 - val_loss: 0.8263 - val_acc: 0.6363\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7496 - acc: 0.6757 - val_loss: 0.8265 - val_acc: 0.6309\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7471 - acc: 0.6702 - val_loss: 0.8223 - val_acc: 0.6325\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7437 - acc: 0.6748 - val_loss: 0.8275 - val_acc: 0.6336\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7404 - acc: 0.6785 - val_loss: 0.8275 - val_acc: 0.6331\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7397 - acc: 0.6776 - val_loss: 0.8233 - val_acc: 0.6357\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7346 - acc: 0.6805 - val_loss: 0.8401 - val_acc: 0.6251\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7345 - acc: 0.6869 - val_loss: 0.8230 - val_acc: 0.6347\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7315 - acc: 0.6847 - val_loss: 0.8237 - val_acc: 0.6352\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7275 - acc: 0.6869 - val_loss: 0.8312 - val_acc: 0.6277\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7275 - acc: 0.6879 - val_loss: 0.8183 - val_acc: 0.6400\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 359us/step - loss: 0.7227 - acc: 0.6888 - val_loss: 0.8372 - val_acc: 0.6224\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7225 - acc: 0.6881 - val_loss: 0.8319 - val_acc: 0.6219\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7185 - acc: 0.6895 - val_loss: 0.8188 - val_acc: 0.6427\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.7192 - acc: 0.6899 - val_loss: 0.8199 - val_acc: 0.6245\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7139 - acc: 0.6945 - val_loss: 0.8312 - val_acc: 0.6277\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7132 - acc: 0.6963 - val_loss: 0.8190 - val_acc: 0.6373\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7112 - acc: 0.7000 - val_loss: 0.8445 - val_acc: 0.6336\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7086 - acc: 0.6975 - val_loss: 0.8377 - val_acc: 0.6213\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7041 - acc: 0.6977 - val_loss: 0.8228 - val_acc: 0.6357\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7008 - acc: 0.7016 - val_loss: 0.8508 - val_acc: 0.6229\n",
      "0.574013981458\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 4s 830us/step - loss: 1.0509 - acc: 0.5006 - val_loss: 1.0375 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 1.0372 - acc: 0.5006 - val_loss: 1.0329 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 1.0323 - acc: 0.5006 - val_loss: 1.0283 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 1.0272 - acc: 0.5006 - val_loss: 1.0235 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 1.0217 - acc: 0.5006 - val_loss: 1.0183 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 1.0156 - acc: 0.5006 - val_loss: 1.0134 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 1.0098 - acc: 0.5008 - val_loss: 1.0073 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 1.0033 - acc: 0.5008 - val_loss: 1.0015 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9963 - acc: 0.5040 - val_loss: 0.9955 - val_acc: 0.5056\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9890 - acc: 0.5086 - val_loss: 0.9885 - val_acc: 0.5173\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9810 - acc: 0.5147 - val_loss: 0.9810 - val_acc: 0.5227\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9727 - acc: 0.5212 - val_loss: 0.9736 - val_acc: 0.5232\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9638 - acc: 0.5285 - val_loss: 0.9661 - val_acc: 0.5333\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9545 - acc: 0.5372 - val_loss: 0.9582 - val_acc: 0.5387\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.9449 - acc: 0.5422 - val_loss: 0.9496 - val_acc: 0.5403\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.9352 - acc: 0.5513 - val_loss: 0.9415 - val_acc: 0.5456\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9253 - acc: 0.5584 - val_loss: 0.9358 - val_acc: 0.5541\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9160 - acc: 0.5680 - val_loss: 0.9268 - val_acc: 0.5595\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9067 - acc: 0.5792 - val_loss: 0.9214 - val_acc: 0.5605\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.8982 - acc: 0.5813 - val_loss: 0.9121 - val_acc: 0.5611\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8893 - acc: 0.5936 - val_loss: 0.9063 - val_acc: 0.5632\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.8816 - acc: 0.5994 - val_loss: 0.9021 - val_acc: 0.5659\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.8737 - acc: 0.6021 - val_loss: 0.8973 - val_acc: 0.5787\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.8672 - acc: 0.6078 - val_loss: 0.8931 - val_acc: 0.5776\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8606 - acc: 0.6042 - val_loss: 0.8873 - val_acc: 0.5765\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.8536 - acc: 0.6106 - val_loss: 0.8846 - val_acc: 0.5845\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.8482 - acc: 0.6183 - val_loss: 0.8819 - val_acc: 0.5829\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8438 - acc: 0.6202 - val_loss: 0.8770 - val_acc: 0.5824\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.8352 - acc: 0.6293 - val_loss: 0.8849 - val_acc: 0.5829\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8308 - acc: 0.6282 - val_loss: 0.8707 - val_acc: 0.5893\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.8259 - acc: 0.6284 - val_loss: 0.8777 - val_acc: 0.5765\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.8229 - acc: 0.6318 - val_loss: 0.8840 - val_acc: 0.5835\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8196 - acc: 0.6337 - val_loss: 0.8645 - val_acc: 0.5957\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.8131 - acc: 0.6394 - val_loss: 0.8775 - val_acc: 0.5909\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8108 - acc: 0.6398 - val_loss: 0.8626 - val_acc: 0.5957\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.8075 - acc: 0.6446 - val_loss: 0.8657 - val_acc: 0.5973\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8039 - acc: 0.6403 - val_loss: 0.8571 - val_acc: 0.6080\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7987 - acc: 0.6476 - val_loss: 0.8618 - val_acc: 0.5952\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7961 - acc: 0.6460 - val_loss: 0.8561 - val_acc: 0.6032\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7913 - acc: 0.6472 - val_loss: 0.8574 - val_acc: 0.6032\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7895 - acc: 0.6501 - val_loss: 0.8558 - val_acc: 0.6037\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7857 - acc: 0.6572 - val_loss: 0.8657 - val_acc: 0.5963\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7842 - acc: 0.6572 - val_loss: 0.8521 - val_acc: 0.6080\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7785 - acc: 0.6536 - val_loss: 0.8478 - val_acc: 0.6117\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7757 - acc: 0.6536 - val_loss: 0.8548 - val_acc: 0.6096\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.7769 - acc: 0.6593 - val_loss: 0.8483 - val_acc: 0.6123\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7696 - acc: 0.6595 - val_loss: 0.8562 - val_acc: 0.6069\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7671 - acc: 0.6597 - val_loss: 0.8514 - val_acc: 0.6085\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7664 - acc: 0.6629 - val_loss: 0.8457 - val_acc: 0.6123\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7620 - acc: 0.6627 - val_loss: 0.8445 - val_acc: 0.6133\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7591 - acc: 0.6680 - val_loss: 0.8425 - val_acc: 0.6133\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.7552 - acc: 0.6691 - val_loss: 0.8523 - val_acc: 0.6064\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.7555 - acc: 0.6700 - val_loss: 0.8396 - val_acc: 0.6176\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7512 - acc: 0.6721 - val_loss: 0.8451 - val_acc: 0.6139\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7490 - acc: 0.6716 - val_loss: 0.8406 - val_acc: 0.6171\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7457 - acc: 0.6751 - val_loss: 0.8381 - val_acc: 0.6160\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7443 - acc: 0.6757 - val_loss: 0.8403 - val_acc: 0.6219\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7409 - acc: 0.6780 - val_loss: 0.8464 - val_acc: 0.6160\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7390 - acc: 0.6764 - val_loss: 0.8416 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7358 - acc: 0.6741 - val_loss: 0.8372 - val_acc: 0.6165\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7304 - acc: 0.6815 - val_loss: 0.8437 - val_acc: 0.6187\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7261 - acc: 0.6847 - val_loss: 0.8567 - val_acc: 0.6075\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7281 - acc: 0.6826 - val_loss: 0.8506 - val_acc: 0.6101\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7238 - acc: 0.6787 - val_loss: 0.8367 - val_acc: 0.6213\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7210 - acc: 0.6890 - val_loss: 0.8509 - val_acc: 0.6165\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7188 - acc: 0.6831 - val_loss: 0.8335 - val_acc: 0.6267\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 368us/step - loss: 0.7161 - acc: 0.6908 - val_loss: 0.8478 - val_acc: 0.6192\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7143 - acc: 0.6901 - val_loss: 0.8564 - val_acc: 0.6075\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7132 - acc: 0.6885 - val_loss: 0.8407 - val_acc: 0.6235\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7095 - acc: 0.6945 - val_loss: 0.8326 - val_acc: 0.6277\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7085 - acc: 0.6945 - val_loss: 0.8419 - val_acc: 0.6272\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 366us/step - loss: 0.7000 - acc: 0.6972 - val_loss: 0.8331 - val_acc: 0.6272\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.6998 - acc: 0.6968 - val_loss: 0.8375 - val_acc: 0.6277\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.6996 - acc: 0.6940 - val_loss: 0.8562 - val_acc: 0.6139\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.6959 - acc: 0.6936 - val_loss: 0.8264 - val_acc: 0.6299\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.6931 - acc: 0.7020 - val_loss: 0.8369 - val_acc: 0.6261\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6900 - acc: 0.7013 - val_loss: 0.8308 - val_acc: 0.6352\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.6896 - acc: 0.7091 - val_loss: 0.8375 - val_acc: 0.6251\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6864 - acc: 0.7066 - val_loss: 0.8501 - val_acc: 0.6251\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6838 - acc: 0.7032 - val_loss: 0.8618 - val_acc: 0.6144\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.6845 - acc: 0.7098 - val_loss: 0.8478 - val_acc: 0.6219\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.6767 - acc: 0.7137 - val_loss: 0.8423 - val_acc: 0.6283\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 359us/step - loss: 0.6778 - acc: 0.7011 - val_loss: 0.8310 - val_acc: 0.6299\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.6740 - acc: 0.7123 - val_loss: 0.8571 - val_acc: 0.6256\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.6726 - acc: 0.7103 - val_loss: 0.8384 - val_acc: 0.6299\n",
      "0.609635049684\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 4s 842us/step - loss: 1.0513 - acc: 0.4997 - val_loss: 1.0396 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0357 - acc: 0.5006 - val_loss: 1.0356 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 1.0310 - acc: 0.5006 - val_loss: 1.0317 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0262 - acc: 0.5006 - val_loss: 1.0276 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0210 - acc: 0.5006 - val_loss: 1.0234 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 1.0154 - acc: 0.5006 - val_loss: 1.0184 - val_acc: 0.4997\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 1.0096 - acc: 0.5008 - val_loss: 1.0128 - val_acc: 0.4997\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 1.0028 - acc: 0.5024 - val_loss: 1.0066 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9958 - acc: 0.5054 - val_loss: 1.0001 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9882 - acc: 0.5090 - val_loss: 0.9936 - val_acc: 0.5051\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9795 - acc: 0.5152 - val_loss: 0.9873 - val_acc: 0.5056\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9712 - acc: 0.5212 - val_loss: 0.9784 - val_acc: 0.5168\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9618 - acc: 0.5298 - val_loss: 0.9715 - val_acc: 0.5312\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9524 - acc: 0.5381 - val_loss: 0.9628 - val_acc: 0.5280\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9431 - acc: 0.5438 - val_loss: 0.9555 - val_acc: 0.5408\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.9341 - acc: 0.5511 - val_loss: 0.9475 - val_acc: 0.5493\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9254 - acc: 0.5591 - val_loss: 0.9415 - val_acc: 0.5483\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9161 - acc: 0.5637 - val_loss: 0.9346 - val_acc: 0.5600\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9075 - acc: 0.5731 - val_loss: 0.9362 - val_acc: 0.5477\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9002 - acc: 0.5742 - val_loss: 0.9220 - val_acc: 0.5616\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8928 - acc: 0.5769 - val_loss: 0.9166 - val_acc: 0.5792\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8853 - acc: 0.5840 - val_loss: 0.9096 - val_acc: 0.5856\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8784 - acc: 0.5847 - val_loss: 0.9064 - val_acc: 0.5755\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8725 - acc: 0.5943 - val_loss: 0.9039 - val_acc: 0.5653\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8671 - acc: 0.6007 - val_loss: 0.8929 - val_acc: 0.5941\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8598 - acc: 0.6076 - val_loss: 0.8896 - val_acc: 0.5947\n",
      "Epoch 27/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8534 - acc: 0.6080 - val_loss: 0.8925 - val_acc: 0.5893\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8500 - acc: 0.6124 - val_loss: 0.8840 - val_acc: 0.5931\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8433 - acc: 0.6183 - val_loss: 0.8783 - val_acc: 0.5989\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8401 - acc: 0.6188 - val_loss: 0.8753 - val_acc: 0.6027\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8346 - acc: 0.6177 - val_loss: 0.8733 - val_acc: 0.6000\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.8293 - acc: 0.6261 - val_loss: 0.8688 - val_acc: 0.6053\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.8249 - acc: 0.6241 - val_loss: 0.8641 - val_acc: 0.6128\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8187 - acc: 0.6291 - val_loss: 0.8644 - val_acc: 0.6096\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8173 - acc: 0.6298 - val_loss: 0.8774 - val_acc: 0.5968\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.8139 - acc: 0.6314 - val_loss: 0.8592 - val_acc: 0.6096\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.8093 - acc: 0.6311 - val_loss: 0.8549 - val_acc: 0.6176\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8046 - acc: 0.6343 - val_loss: 0.8552 - val_acc: 0.6133\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8020 - acc: 0.6359 - val_loss: 0.8573 - val_acc: 0.6101\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7983 - acc: 0.6458 - val_loss: 0.8640 - val_acc: 0.6043\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7963 - acc: 0.6433 - val_loss: 0.8462 - val_acc: 0.6224\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7923 - acc: 0.6433 - val_loss: 0.8474 - val_acc: 0.6176\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7884 - acc: 0.6442 - val_loss: 0.8853 - val_acc: 0.5952\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7863 - acc: 0.6465 - val_loss: 0.8413 - val_acc: 0.6309\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7818 - acc: 0.6476 - val_loss: 0.8485 - val_acc: 0.6261\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7796 - acc: 0.6515 - val_loss: 0.8416 - val_acc: 0.6245\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7769 - acc: 0.6556 - val_loss: 0.8433 - val_acc: 0.6192\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7725 - acc: 0.6542 - val_loss: 0.8428 - val_acc: 0.6219\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7714 - acc: 0.6622 - val_loss: 0.8450 - val_acc: 0.6208\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7651 - acc: 0.6629 - val_loss: 0.8499 - val_acc: 0.6187\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7641 - acc: 0.6586 - val_loss: 0.8349 - val_acc: 0.6315\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7610 - acc: 0.6668 - val_loss: 0.8505 - val_acc: 0.6176\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7556 - acc: 0.6680 - val_loss: 0.8354 - val_acc: 0.6325\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7539 - acc: 0.6698 - val_loss: 0.8381 - val_acc: 0.6304\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7533 - acc: 0.6657 - val_loss: 0.8525 - val_acc: 0.6219\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.7512 - acc: 0.6670 - val_loss: 0.8482 - val_acc: 0.6203\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7448 - acc: 0.6702 - val_loss: 0.8348 - val_acc: 0.6272\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7415 - acc: 0.6748 - val_loss: 0.8292 - val_acc: 0.6341\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 369us/step - loss: 0.7415 - acc: 0.6762 - val_loss: 0.8313 - val_acc: 0.6309\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 370us/step - loss: 0.7397 - acc: 0.6755 - val_loss: 0.8357 - val_acc: 0.6256\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7348 - acc: 0.6771 - val_loss: 0.8419 - val_acc: 0.6283\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7357 - acc: 0.6780 - val_loss: 0.8303 - val_acc: 0.6384\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7283 - acc: 0.6778 - val_loss: 0.8360 - val_acc: 0.6272\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7293 - acc: 0.6810 - val_loss: 0.8417 - val_acc: 0.6272\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7264 - acc: 0.6831 - val_loss: 0.8244 - val_acc: 0.6405\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7218 - acc: 0.6853 - val_loss: 0.8368 - val_acc: 0.6245\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7224 - acc: 0.6881 - val_loss: 0.8363 - val_acc: 0.6277\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7163 - acc: 0.6892 - val_loss: 0.8294 - val_acc: 0.6357\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7105 - acc: 0.6936 - val_loss: 0.8513 - val_acc: 0.6176\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7071 - acc: 0.6943 - val_loss: 0.8481 - val_acc: 0.6256\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7089 - acc: 0.6924 - val_loss: 0.8332 - val_acc: 0.6363\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7062 - acc: 0.6945 - val_loss: 0.8398 - val_acc: 0.6277\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7009 - acc: 0.6913 - val_loss: 0.8365 - val_acc: 0.6379\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6984 - acc: 0.6963 - val_loss: 0.8475 - val_acc: 0.6309\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6954 - acc: 0.6991 - val_loss: 0.8375 - val_acc: 0.6352\n",
      "0.597976426063\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 4s 878us/step - loss: 1.0499 - acc: 0.4983 - val_loss: 1.0371 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 1.0345 - acc: 0.5006 - val_loss: 1.0314 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 1.0278 - acc: 0.5006 - val_loss: 1.0266 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 1.0216 - acc: 0.5006 - val_loss: 1.0215 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 1.0148 - acc: 0.5006 - val_loss: 1.0161 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0074 - acc: 0.5008 - val_loss: 1.0103 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9994 - acc: 0.5024 - val_loss: 1.0041 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9911 - acc: 0.5079 - val_loss: 0.9980 - val_acc: 0.5067\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9824 - acc: 0.5159 - val_loss: 0.9909 - val_acc: 0.5136\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9733 - acc: 0.5244 - val_loss: 0.9839 - val_acc: 0.5237\n",
      "Epoch 11/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9638 - acc: 0.5344 - val_loss: 0.9770 - val_acc: 0.5296\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.9543 - acc: 0.5433 - val_loss: 0.9701 - val_acc: 0.5296\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9447 - acc: 0.5520 - val_loss: 0.9634 - val_acc: 0.5301\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9357 - acc: 0.5580 - val_loss: 0.9568 - val_acc: 0.5424\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9268 - acc: 0.5657 - val_loss: 0.9510 - val_acc: 0.5525\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9188 - acc: 0.5726 - val_loss: 0.9441 - val_acc: 0.5504\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9106 - acc: 0.5753 - val_loss: 0.9392 - val_acc: 0.5547\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9013 - acc: 0.5877 - val_loss: 0.9372 - val_acc: 0.5557\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8946 - acc: 0.5920 - val_loss: 0.9286 - val_acc: 0.5563\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8886 - acc: 0.5941 - val_loss: 0.9256 - val_acc: 0.5621\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8812 - acc: 0.6003 - val_loss: 0.9216 - val_acc: 0.5675\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8748 - acc: 0.5973 - val_loss: 0.9146 - val_acc: 0.5691\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8690 - acc: 0.6032 - val_loss: 0.9188 - val_acc: 0.5616\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8626 - acc: 0.6035 - val_loss: 0.9120 - val_acc: 0.5723\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8568 - acc: 0.6085 - val_loss: 0.9056 - val_acc: 0.5733\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8517 - acc: 0.6108 - val_loss: 0.9004 - val_acc: 0.5808\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.8474 - acc: 0.6140 - val_loss: 0.8955 - val_acc: 0.5819\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8410 - acc: 0.6158 - val_loss: 0.8959 - val_acc: 0.5787\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8372 - acc: 0.6174 - val_loss: 0.8899 - val_acc: 0.5717\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8315 - acc: 0.6229 - val_loss: 0.8852 - val_acc: 0.5755\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8270 - acc: 0.6199 - val_loss: 0.8887 - val_acc: 0.5696\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8229 - acc: 0.6275 - val_loss: 0.8804 - val_acc: 0.5845\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.8191 - acc: 0.6284 - val_loss: 0.8812 - val_acc: 0.5813\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8157 - acc: 0.6330 - val_loss: 0.8817 - val_acc: 0.5909\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8107 - acc: 0.6330 - val_loss: 0.8809 - val_acc: 0.5861\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8056 - acc: 0.6369 - val_loss: 0.8719 - val_acc: 0.5861\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8022 - acc: 0.6417 - val_loss: 0.8705 - val_acc: 0.5952\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.7994 - acc: 0.6433 - val_loss: 0.8756 - val_acc: 0.5915\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7945 - acc: 0.6483 - val_loss: 0.8665 - val_acc: 0.5904\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.7906 - acc: 0.6497 - val_loss: 0.8816 - val_acc: 0.5829\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7898 - acc: 0.6478 - val_loss: 0.8651 - val_acc: 0.5915\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7837 - acc: 0.6506 - val_loss: 0.8760 - val_acc: 0.5984\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7825 - acc: 0.6538 - val_loss: 0.8621 - val_acc: 0.6005\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7793 - acc: 0.6588 - val_loss: 0.8700 - val_acc: 0.5984\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7756 - acc: 0.6563 - val_loss: 0.8662 - val_acc: 0.5915\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7725 - acc: 0.6586 - val_loss: 0.8646 - val_acc: 0.5941\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7689 - acc: 0.6595 - val_loss: 0.8581 - val_acc: 0.6000\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7675 - acc: 0.6600 - val_loss: 0.8578 - val_acc: 0.5963\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7630 - acc: 0.6632 - val_loss: 0.8552 - val_acc: 0.6053\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7589 - acc: 0.6652 - val_loss: 0.8565 - val_acc: 0.5979\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7575 - acc: 0.6609 - val_loss: 0.8681 - val_acc: 0.6080\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7531 - acc: 0.6686 - val_loss: 0.8550 - val_acc: 0.6005\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7534 - acc: 0.6689 - val_loss: 0.8551 - val_acc: 0.5947\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7483 - acc: 0.6705 - val_loss: 0.8580 - val_acc: 0.5931\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7472 - acc: 0.6716 - val_loss: 0.8606 - val_acc: 0.6075\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 368us/step - loss: 0.7425 - acc: 0.6723 - val_loss: 0.8700 - val_acc: 0.6107\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7390 - acc: 0.6783 - val_loss: 0.8527 - val_acc: 0.6005\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7386 - acc: 0.6735 - val_loss: 0.8574 - val_acc: 0.5925\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7341 - acc: 0.6751 - val_loss: 0.8499 - val_acc: 0.6037\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7317 - acc: 0.6808 - val_loss: 0.8717 - val_acc: 0.6165\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.7292 - acc: 0.6778 - val_loss: 0.8499 - val_acc: 0.6123\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7268 - acc: 0.6828 - val_loss: 0.8528 - val_acc: 0.6043\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7246 - acc: 0.6876 - val_loss: 0.8627 - val_acc: 0.6149\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7197 - acc: 0.6847 - val_loss: 0.8500 - val_acc: 0.6160\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7193 - acc: 0.6856 - val_loss: 0.8615 - val_acc: 0.6187\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7172 - acc: 0.6888 - val_loss: 0.8435 - val_acc: 0.6181\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7110 - acc: 0.6890 - val_loss: 0.8424 - val_acc: 0.6117\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7093 - acc: 0.6906 - val_loss: 0.8466 - val_acc: 0.6117\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7079 - acc: 0.6943 - val_loss: 0.8442 - val_acc: 0.6197\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7061 - acc: 0.7007 - val_loss: 0.8475 - val_acc: 0.6128\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7034 - acc: 0.6949 - val_loss: 0.8448 - val_acc: 0.6139\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7031 - acc: 0.6968 - val_loss: 0.8704 - val_acc: 0.5989\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.6983 - acc: 0.7000 - val_loss: 0.8402 - val_acc: 0.6123\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6990 - acc: 0.7057 - val_loss: 0.8429 - val_acc: 0.6155\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6922 - acc: 0.7013 - val_loss: 0.8508 - val_acc: 0.6096\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6885 - acc: 0.7068 - val_loss: 0.8424 - val_acc: 0.6213\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.6868 - acc: 0.7027 - val_loss: 0.8500 - val_acc: 0.6181\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.6837 - acc: 0.7052 - val_loss: 0.8482 - val_acc: 0.6240\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6818 - acc: 0.7078 - val_loss: 0.8527 - val_acc: 0.6096\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6797 - acc: 0.7071 - val_loss: 0.8471 - val_acc: 0.6144\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6743 - acc: 0.7094 - val_loss: 0.8419 - val_acc: 0.6171\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6732 - acc: 0.7107 - val_loss: 0.8437 - val_acc: 0.6181\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.6710 - acc: 0.7114 - val_loss: 0.8396 - val_acc: 0.6224\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6637 - acc: 0.7231 - val_loss: 0.8519 - val_acc: 0.6128\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.6686 - acc: 0.7123 - val_loss: 0.8574 - val_acc: 0.6309\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6656 - acc: 0.7142 - val_loss: 0.8612 - val_acc: 0.6107\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6607 - acc: 0.7171 - val_loss: 0.8427 - val_acc: 0.6144\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6584 - acc: 0.7206 - val_loss: 0.8440 - val_acc: 0.6224\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.6554 - acc: 0.7183 - val_loss: 0.8528 - val_acc: 0.6117\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6545 - acc: 0.7224 - val_loss: 0.8907 - val_acc: 0.6144\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.6526 - acc: 0.7286 - val_loss: 0.8508 - val_acc: 0.6315\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.6470 - acc: 0.7249 - val_loss: 0.8737 - val_acc: 0.6000\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6433 - acc: 0.7254 - val_loss: 0.8488 - val_acc: 0.6224\n",
      "0.60785961094\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 4s 921us/step - loss: 1.0493 - acc: 0.5006 - val_loss: 1.0383 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0360 - acc: 0.5006 - val_loss: 1.0329 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 1.0312 - acc: 0.5006 - val_loss: 1.0280 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 1.0265 - acc: 0.5006 - val_loss: 1.0226 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 1.0215 - acc: 0.5006 - val_loss: 1.0171 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 1.0164 - acc: 0.5006 - val_loss: 1.0111 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0108 - acc: 0.5006 - val_loss: 1.0047 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 1.0047 - acc: 0.5008 - val_loss: 0.9979 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9983 - acc: 0.5013 - val_loss: 0.9908 - val_acc: 0.5045\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9914 - acc: 0.5042 - val_loss: 0.9829 - val_acc: 0.5056\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.9842 - acc: 0.5072 - val_loss: 0.9752 - val_acc: 0.5136\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.9768 - acc: 0.5152 - val_loss: 0.9661 - val_acc: 0.5163\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.9685 - acc: 0.5218 - val_loss: 0.9581 - val_acc: 0.5232\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9600 - acc: 0.5305 - val_loss: 0.9515 - val_acc: 0.5269\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.9524 - acc: 0.5344 - val_loss: 0.9404 - val_acc: 0.5488\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.9445 - acc: 0.5436 - val_loss: 0.9334 - val_acc: 0.5600\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9354 - acc: 0.5500 - val_loss: 0.9267 - val_acc: 0.5627\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9291 - acc: 0.5545 - val_loss: 0.9160 - val_acc: 0.5659\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.9212 - acc: 0.5607 - val_loss: 0.9083 - val_acc: 0.5755\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9136 - acc: 0.5646 - val_loss: 0.9017 - val_acc: 0.5744\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9061 - acc: 0.5683 - val_loss: 0.9005 - val_acc: 0.5744\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8994 - acc: 0.5767 - val_loss: 0.8882 - val_acc: 0.5856\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8910 - acc: 0.5822 - val_loss: 0.8831 - val_acc: 0.5867\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8855 - acc: 0.5882 - val_loss: 0.8808 - val_acc: 0.5803\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.8789 - acc: 0.5911 - val_loss: 0.8726 - val_acc: 0.5989\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8728 - acc: 0.5932 - val_loss: 0.8736 - val_acc: 0.5909\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.8682 - acc: 0.5980 - val_loss: 0.8653 - val_acc: 0.5941\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8618 - acc: 0.5989 - val_loss: 0.8569 - val_acc: 0.6080\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8567 - acc: 0.5987 - val_loss: 0.8550 - val_acc: 0.6101\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.8518 - acc: 0.6126 - val_loss: 0.8506 - val_acc: 0.6117\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8467 - acc: 0.6151 - val_loss: 0.8461 - val_acc: 0.6112\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.8404 - acc: 0.6161 - val_loss: 0.8473 - val_acc: 0.6187\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.8379 - acc: 0.6170 - val_loss: 0.8506 - val_acc: 0.6096\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8312 - acc: 0.6218 - val_loss: 0.8384 - val_acc: 0.6080\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8281 - acc: 0.6238 - val_loss: 0.8366 - val_acc: 0.6203\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8247 - acc: 0.6197 - val_loss: 0.8333 - val_acc: 0.6203\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8210 - acc: 0.6307 - val_loss: 0.8336 - val_acc: 0.6128\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.8161 - acc: 0.6325 - val_loss: 0.8276 - val_acc: 0.6256\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.8152 - acc: 0.6359 - val_loss: 0.8343 - val_acc: 0.6107\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8104 - acc: 0.6435 - val_loss: 0.8257 - val_acc: 0.6171\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8074 - acc: 0.6396 - val_loss: 0.8239 - val_acc: 0.6235\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.8042 - acc: 0.6403 - val_loss: 0.8300 - val_acc: 0.6192\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8015 - acc: 0.6408 - val_loss: 0.8209 - val_acc: 0.6224\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7981 - acc: 0.6437 - val_loss: 0.8197 - val_acc: 0.6267\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7957 - acc: 0.6467 - val_loss: 0.8150 - val_acc: 0.6368\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7921 - acc: 0.6488 - val_loss: 0.8189 - val_acc: 0.6251\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7897 - acc: 0.6433 - val_loss: 0.8124 - val_acc: 0.6341\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7851 - acc: 0.6552 - val_loss: 0.8123 - val_acc: 0.6336\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7843 - acc: 0.6492 - val_loss: 0.8166 - val_acc: 0.6379\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7798 - acc: 0.6556 - val_loss: 0.8182 - val_acc: 0.6357\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7781 - acc: 0.6593 - val_loss: 0.8145 - val_acc: 0.6299\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7745 - acc: 0.6593 - val_loss: 0.8085 - val_acc: 0.6363\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7727 - acc: 0.6581 - val_loss: 0.8060 - val_acc: 0.6469\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7677 - acc: 0.6606 - val_loss: 0.8035 - val_acc: 0.6507\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7657 - acc: 0.6654 - val_loss: 0.8092 - val_acc: 0.6411\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7638 - acc: 0.6666 - val_loss: 0.8044 - val_acc: 0.6437\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7622 - acc: 0.6673 - val_loss: 0.8073 - val_acc: 0.6411\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7595 - acc: 0.6668 - val_loss: 0.8050 - val_acc: 0.6421\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7558 - acc: 0.6689 - val_loss: 0.7992 - val_acc: 0.6453\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7533 - acc: 0.6718 - val_loss: 0.8093 - val_acc: 0.6421\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7499 - acc: 0.6769 - val_loss: 0.8029 - val_acc: 0.6400\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7496 - acc: 0.6732 - val_loss: 0.7980 - val_acc: 0.6491\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7465 - acc: 0.6696 - val_loss: 0.7969 - val_acc: 0.6517\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7436 - acc: 0.6714 - val_loss: 0.8131 - val_acc: 0.6373\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7411 - acc: 0.6792 - val_loss: 0.7976 - val_acc: 0.6480\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7394 - acc: 0.6783 - val_loss: 0.7940 - val_acc: 0.6571\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7369 - acc: 0.6799 - val_loss: 0.7994 - val_acc: 0.6533\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7340 - acc: 0.6805 - val_loss: 0.8046 - val_acc: 0.6453\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7345 - acc: 0.6803 - val_loss: 0.8045 - val_acc: 0.6427\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7302 - acc: 0.6847 - val_loss: 0.8029 - val_acc: 0.6400\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7306 - acc: 0.6853 - val_loss: 0.8008 - val_acc: 0.6501\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7232 - acc: 0.6867 - val_loss: 0.7882 - val_acc: 0.6629\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7241 - acc: 0.6876 - val_loss: 0.7902 - val_acc: 0.6624\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7196 - acc: 0.6888 - val_loss: 0.7888 - val_acc: 0.6571\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7177 - acc: 0.6943 - val_loss: 0.7870 - val_acc: 0.6603\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7168 - acc: 0.6915 - val_loss: 0.8028 - val_acc: 0.6437\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7131 - acc: 0.6872 - val_loss: 0.8183 - val_acc: 0.6235\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7135 - acc: 0.6954 - val_loss: 0.7854 - val_acc: 0.6683\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7089 - acc: 0.6895 - val_loss: 0.7855 - val_acc: 0.6693\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7046 - acc: 0.6952 - val_loss: 0.7968 - val_acc: 0.6507\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 369us/step - loss: 0.7023 - acc: 0.6993 - val_loss: 0.7909 - val_acc: 0.6597\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7058 - acc: 0.6936 - val_loss: 0.7847 - val_acc: 0.6619\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6982 - acc: 0.7009 - val_loss: 0.8164 - val_acc: 0.6485\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6986 - acc: 0.7039 - val_loss: 0.8134 - val_acc: 0.6427\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6935 - acc: 0.7032 - val_loss: 0.7847 - val_acc: 0.6651\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6940 - acc: 0.7020 - val_loss: 0.7976 - val_acc: 0.6523\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.6881 - acc: 0.7107 - val_loss: 0.7889 - val_acc: 0.6693\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6863 - acc: 0.7087 - val_loss: 0.8223 - val_acc: 0.6416\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6860 - acc: 0.7091 - val_loss: 0.7842 - val_acc: 0.6645\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6821 - acc: 0.7100 - val_loss: 0.7825 - val_acc: 0.6709\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.6792 - acc: 0.7096 - val_loss: 0.8703 - val_acc: 0.6112\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.6808 - acc: 0.7100 - val_loss: 0.7935 - val_acc: 0.6683\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6780 - acc: 0.7119 - val_loss: 0.8041 - val_acc: 0.6453\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 356us/step - loss: 0.6714 - acc: 0.7126 - val_loss: 0.7842 - val_acc: 0.6699\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 356us/step - loss: 0.6709 - acc: 0.7144 - val_loss: 0.8352 - val_acc: 0.6501\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6698 - acc: 0.7121 - val_loss: 0.7886 - val_acc: 0.6720\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.6657 - acc: 0.7196 - val_loss: 0.7939 - val_acc: 0.6651\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6649 - acc: 0.7160 - val_loss: 0.7952 - val_acc: 0.6608\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.6593 - acc: 0.7217 - val_loss: 0.8489 - val_acc: 0.6384\n",
      "Epoch 100/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6631 - acc: 0.7178 - val_loss: 0.8035 - val_acc: 0.6501\n",
      "0.622325399697\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 4s 965us/step - loss: 1.0493 - acc: 0.4983 - val_loss: 1.0381 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0344 - acc: 0.5006 - val_loss: 1.0333 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0294 - acc: 0.5006 - val_loss: 1.0283 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0241 - acc: 0.5006 - val_loss: 1.0231 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0181 - acc: 0.5006 - val_loss: 1.0176 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 1.0118 - acc: 0.5006 - val_loss: 1.0114 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 1.0049 - acc: 0.5008 - val_loss: 1.0048 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9972 - acc: 0.5017 - val_loss: 0.9974 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9890 - acc: 0.5031 - val_loss: 0.9892 - val_acc: 0.5035\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9801 - acc: 0.5093 - val_loss: 0.9814 - val_acc: 0.5099\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9705 - acc: 0.5184 - val_loss: 0.9729 - val_acc: 0.5163\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9616 - acc: 0.5248 - val_loss: 0.9648 - val_acc: 0.5248\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9521 - acc: 0.5324 - val_loss: 0.9571 - val_acc: 0.5355\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9423 - acc: 0.5442 - val_loss: 0.9500 - val_acc: 0.5419\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.9339 - acc: 0.5543 - val_loss: 0.9419 - val_acc: 0.5408\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9254 - acc: 0.5669 - val_loss: 0.9355 - val_acc: 0.5520\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9155 - acc: 0.5671 - val_loss: 0.9293 - val_acc: 0.5493\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9074 - acc: 0.5769 - val_loss: 0.9235 - val_acc: 0.5595\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8980 - acc: 0.5852 - val_loss: 0.9196 - val_acc: 0.5637\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8901 - acc: 0.5827 - val_loss: 0.9124 - val_acc: 0.5813\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8806 - acc: 0.5955 - val_loss: 0.9100 - val_acc: 0.5744\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8752 - acc: 0.5966 - val_loss: 0.9011 - val_acc: 0.5765\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8671 - acc: 0.6032 - val_loss: 0.8961 - val_acc: 0.5808\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8600 - acc: 0.6037 - val_loss: 0.8909 - val_acc: 0.5840\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8521 - acc: 0.6078 - val_loss: 0.8903 - val_acc: 0.5851\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8464 - acc: 0.6133 - val_loss: 0.8874 - val_acc: 0.5840\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8404 - acc: 0.6158 - val_loss: 0.8790 - val_acc: 0.5904\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8346 - acc: 0.6218 - val_loss: 0.8838 - val_acc: 0.5888\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.8298 - acc: 0.6234 - val_loss: 0.8737 - val_acc: 0.5973\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8221 - acc: 0.6263 - val_loss: 0.8712 - val_acc: 0.5973\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.8212 - acc: 0.6259 - val_loss: 0.8743 - val_acc: 0.5936\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8155 - acc: 0.6339 - val_loss: 0.8728 - val_acc: 0.5904\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8106 - acc: 0.6302 - val_loss: 0.8682 - val_acc: 0.5941\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8072 - acc: 0.6373 - val_loss: 0.8719 - val_acc: 0.5925\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8021 - acc: 0.6401 - val_loss: 0.8643 - val_acc: 0.5984\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7982 - acc: 0.6424 - val_loss: 0.8627 - val_acc: 0.6016\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7953 - acc: 0.6421 - val_loss: 0.8592 - val_acc: 0.6053\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7897 - acc: 0.6488 - val_loss: 0.8563 - val_acc: 0.6043\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7887 - acc: 0.6440 - val_loss: 0.8719 - val_acc: 0.5957\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7808 - acc: 0.6542 - val_loss: 0.8679 - val_acc: 0.6064\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7797 - acc: 0.6531 - val_loss: 0.8598 - val_acc: 0.6069\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7749 - acc: 0.6572 - val_loss: 0.8557 - val_acc: 0.6053\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7738 - acc: 0.6536 - val_loss: 0.8559 - val_acc: 0.6069\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7708 - acc: 0.6611 - val_loss: 0.8577 - val_acc: 0.6107\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7677 - acc: 0.6609 - val_loss: 0.8479 - val_acc: 0.6165\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7669 - acc: 0.6638 - val_loss: 0.8642 - val_acc: 0.6075\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7623 - acc: 0.6616 - val_loss: 0.8468 - val_acc: 0.6181\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7578 - acc: 0.6680 - val_loss: 0.8516 - val_acc: 0.6117\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7549 - acc: 0.6702 - val_loss: 0.8478 - val_acc: 0.6112\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7525 - acc: 0.6716 - val_loss: 0.8563 - val_acc: 0.6117\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7506 - acc: 0.6725 - val_loss: 0.8487 - val_acc: 0.6155\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7451 - acc: 0.6751 - val_loss: 0.8477 - val_acc: 0.6208\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7430 - acc: 0.6771 - val_loss: 0.8452 - val_acc: 0.6112\n",
      "Epoch 54/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7412 - acc: 0.6757 - val_loss: 0.8413 - val_acc: 0.6251\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7384 - acc: 0.6833 - val_loss: 0.8642 - val_acc: 0.6005\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7354 - acc: 0.6796 - val_loss: 0.8660 - val_acc: 0.6085\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.7336 - acc: 0.6833 - val_loss: 0.8527 - val_acc: 0.6123\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7302 - acc: 0.6796 - val_loss: 0.8589 - val_acc: 0.6112\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7279 - acc: 0.6881 - val_loss: 0.8626 - val_acc: 0.6032\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7225 - acc: 0.6876 - val_loss: 0.8452 - val_acc: 0.6112\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7213 - acc: 0.6945 - val_loss: 0.8593 - val_acc: 0.6165\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7183 - acc: 0.6920 - val_loss: 0.8539 - val_acc: 0.6123\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7170 - acc: 0.6874 - val_loss: 0.8505 - val_acc: 0.6251\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7144 - acc: 0.6911 - val_loss: 0.8436 - val_acc: 0.6176\n",
      "0.584476796311\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0503 - acc: 0.4981 - val_loss: 1.0395 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 1.0366 - acc: 0.5006 - val_loss: 1.0358 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 1.0327 - acc: 0.5006 - val_loss: 1.0315 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0284 - acc: 0.5006 - val_loss: 1.0270 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 1.0238 - acc: 0.5006 - val_loss: 1.0223 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 1.0189 - acc: 0.5006 - val_loss: 1.0173 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0139 - acc: 0.5006 - val_loss: 1.0120 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0081 - acc: 0.5008 - val_loss: 1.0063 - val_acc: 0.5024\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 1.0024 - acc: 0.5019 - val_loss: 1.0000 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9961 - acc: 0.5024 - val_loss: 0.9934 - val_acc: 0.5083\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9894 - acc: 0.5063 - val_loss: 0.9865 - val_acc: 0.5147\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.9820 - acc: 0.5154 - val_loss: 0.9789 - val_acc: 0.5237\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9744 - acc: 0.5228 - val_loss: 0.9711 - val_acc: 0.5259\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9663 - acc: 0.5301 - val_loss: 0.9629 - val_acc: 0.5376\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9578 - acc: 0.5378 - val_loss: 0.9547 - val_acc: 0.5339\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.9490 - acc: 0.5426 - val_loss: 0.9465 - val_acc: 0.5424\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9406 - acc: 0.5481 - val_loss: 0.9371 - val_acc: 0.5504\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9319 - acc: 0.5550 - val_loss: 0.9295 - val_acc: 0.5568\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9236 - acc: 0.5623 - val_loss: 0.9204 - val_acc: 0.5568\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.9147 - acc: 0.5667 - val_loss: 0.9128 - val_acc: 0.5664\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9076 - acc: 0.5769 - val_loss: 0.9076 - val_acc: 0.5664\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8996 - acc: 0.5795 - val_loss: 0.9007 - val_acc: 0.5680\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8930 - acc: 0.5822 - val_loss: 0.8932 - val_acc: 0.5749\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8853 - acc: 0.5920 - val_loss: 0.8879 - val_acc: 0.5755\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8788 - acc: 0.5907 - val_loss: 0.8809 - val_acc: 0.5845\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8726 - acc: 0.5914 - val_loss: 0.8858 - val_acc: 0.5851\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8667 - acc: 0.5955 - val_loss: 0.8706 - val_acc: 0.5920\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8606 - acc: 0.6028 - val_loss: 0.8687 - val_acc: 0.5931\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8557 - acc: 0.6051 - val_loss: 0.8623 - val_acc: 0.5995\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8502 - acc: 0.6071 - val_loss: 0.8711 - val_acc: 0.5947\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8446 - acc: 0.6064 - val_loss: 0.8533 - val_acc: 0.6085\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8403 - acc: 0.6110 - val_loss: 0.8518 - val_acc: 0.6032\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8361 - acc: 0.6106 - val_loss: 0.8512 - val_acc: 0.6053\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.8312 - acc: 0.6206 - val_loss: 0.8531 - val_acc: 0.6000\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8278 - acc: 0.6238 - val_loss: 0.8464 - val_acc: 0.6053\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8243 - acc: 0.6186 - val_loss: 0.8421 - val_acc: 0.6043\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8202 - acc: 0.6275 - val_loss: 0.8397 - val_acc: 0.6128\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8171 - acc: 0.6318 - val_loss: 0.8387 - val_acc: 0.6032\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.8146 - acc: 0.6334 - val_loss: 0.8333 - val_acc: 0.6059\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8104 - acc: 0.6364 - val_loss: 0.8312 - val_acc: 0.6101\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.8058 - acc: 0.6359 - val_loss: 0.8393 - val_acc: 0.6027\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8030 - acc: 0.6385 - val_loss: 0.8322 - val_acc: 0.6139\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7982 - acc: 0.6385 - val_loss: 0.8492 - val_acc: 0.6011\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 358us/step - loss: 0.7982 - acc: 0.6405 - val_loss: 0.8575 - val_acc: 0.5979\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7962 - acc: 0.6446 - val_loss: 0.8247 - val_acc: 0.6139\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7909 - acc: 0.6469 - val_loss: 0.8236 - val_acc: 0.6187\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7882 - acc: 0.6460 - val_loss: 0.8221 - val_acc: 0.6085\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7845 - acc: 0.6467 - val_loss: 0.8294 - val_acc: 0.6251\n",
      "Epoch 49/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7833 - acc: 0.6517 - val_loss: 0.8272 - val_acc: 0.6091\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7812 - acc: 0.6545 - val_loss: 0.8199 - val_acc: 0.6144\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7770 - acc: 0.6565 - val_loss: 0.8347 - val_acc: 0.6123\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7720 - acc: 0.6616 - val_loss: 0.8166 - val_acc: 0.6213\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7715 - acc: 0.6600 - val_loss: 0.8229 - val_acc: 0.6176\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7679 - acc: 0.6588 - val_loss: 0.8190 - val_acc: 0.6197\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7649 - acc: 0.6620 - val_loss: 0.8208 - val_acc: 0.6235\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7622 - acc: 0.6684 - val_loss: 0.8138 - val_acc: 0.6235\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7604 - acc: 0.6707 - val_loss: 0.8199 - val_acc: 0.6203\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7585 - acc: 0.6677 - val_loss: 0.8136 - val_acc: 0.6229\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7541 - acc: 0.6684 - val_loss: 0.8247 - val_acc: 0.6293\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7519 - acc: 0.6684 - val_loss: 0.8109 - val_acc: 0.6219\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7523 - acc: 0.6755 - val_loss: 0.8172 - val_acc: 0.6192\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7481 - acc: 0.6773 - val_loss: 0.8077 - val_acc: 0.6235\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7460 - acc: 0.6767 - val_loss: 0.8118 - val_acc: 0.6357\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7423 - acc: 0.6792 - val_loss: 0.8089 - val_acc: 0.6240\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7402 - acc: 0.6808 - val_loss: 0.8046 - val_acc: 0.6309\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7394 - acc: 0.6810 - val_loss: 0.8172 - val_acc: 0.6251\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7359 - acc: 0.6837 - val_loss: 0.8118 - val_acc: 0.6347\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7311 - acc: 0.6824 - val_loss: 0.8036 - val_acc: 0.6277\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7305 - acc: 0.6828 - val_loss: 0.8116 - val_acc: 0.6219\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7266 - acc: 0.6863 - val_loss: 0.8091 - val_acc: 0.6320\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7254 - acc: 0.6885 - val_loss: 0.8025 - val_acc: 0.6384\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7249 - acc: 0.6851 - val_loss: 0.8028 - val_acc: 0.6352\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7176 - acc: 0.6890 - val_loss: 0.8183 - val_acc: 0.6288\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7174 - acc: 0.6901 - val_loss: 0.7992 - val_acc: 0.6320\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7172 - acc: 0.6995 - val_loss: 0.8015 - val_acc: 0.6304\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 360us/step - loss: 0.7157 - acc: 0.6911 - val_loss: 0.8078 - val_acc: 0.6363\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7127 - acc: 0.6917 - val_loss: 0.8009 - val_acc: 0.6373\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7087 - acc: 0.6961 - val_loss: 0.8097 - val_acc: 0.6315\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7058 - acc: 0.7029 - val_loss: 0.8021 - val_acc: 0.6384\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7047 - acc: 0.7002 - val_loss: 0.8041 - val_acc: 0.6421\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7017 - acc: 0.7018 - val_loss: 0.7985 - val_acc: 0.6432\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6978 - acc: 0.7023 - val_loss: 0.7957 - val_acc: 0.6400\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6949 - acc: 0.7091 - val_loss: 0.8025 - val_acc: 0.6437\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.6923 - acc: 0.7048 - val_loss: 0.8079 - val_acc: 0.6421\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6909 - acc: 0.7055 - val_loss: 0.7972 - val_acc: 0.6453\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.6901 - acc: 0.7135 - val_loss: 0.8161 - val_acc: 0.6331\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.6877 - acc: 0.7153 - val_loss: 0.8088 - val_acc: 0.6373\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6846 - acc: 0.7107 - val_loss: 0.8118 - val_acc: 0.6341\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.6835 - acc: 0.7080 - val_loss: 0.8063 - val_acc: 0.6416\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6797 - acc: 0.7139 - val_loss: 0.8158 - val_acc: 0.6288\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.6788 - acc: 0.7087 - val_loss: 0.8120 - val_acc: 0.6405\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 376us/step - loss: 0.6758 - acc: 0.7135 - val_loss: 0.8005 - val_acc: 0.6464\n",
      "0.607444658125\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0512 - acc: 0.4999 - val_loss: 1.0384 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0353 - acc: 0.5006 - val_loss: 1.0340 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0306 - acc: 0.5006 - val_loss: 1.0294 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 1.0258 - acc: 0.5006 - val_loss: 1.0248 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 1.0208 - acc: 0.5006 - val_loss: 1.0197 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 1.0152 - acc: 0.5006 - val_loss: 1.0144 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 1.0093 - acc: 0.5006 - val_loss: 1.0085 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 1.0029 - acc: 0.5013 - val_loss: 1.0018 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9957 - acc: 0.5042 - val_loss: 0.9945 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9876 - acc: 0.5088 - val_loss: 0.9870 - val_acc: 0.5040\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.9791 - acc: 0.5161 - val_loss: 0.9775 - val_acc: 0.5125\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.9694 - acc: 0.5223 - val_loss: 0.9680 - val_acc: 0.5205\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.9595 - acc: 0.5326 - val_loss: 0.9575 - val_acc: 0.5317\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9495 - acc: 0.5438 - val_loss: 0.9479 - val_acc: 0.5360\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.9394 - acc: 0.5481 - val_loss: 0.9383 - val_acc: 0.5392\n",
      "Epoch 16/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9293 - acc: 0.5536 - val_loss: 0.9268 - val_acc: 0.5536\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9206 - acc: 0.5662 - val_loss: 0.9193 - val_acc: 0.5637\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9109 - acc: 0.5747 - val_loss: 0.9106 - val_acc: 0.5723\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9030 - acc: 0.5797 - val_loss: 0.9067 - val_acc: 0.5675\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8961 - acc: 0.5868 - val_loss: 0.8975 - val_acc: 0.5813\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8868 - acc: 0.5920 - val_loss: 0.8901 - val_acc: 0.5893\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8787 - acc: 0.5980 - val_loss: 0.8864 - val_acc: 0.5840\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8721 - acc: 0.6023 - val_loss: 0.8788 - val_acc: 0.5888\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8652 - acc: 0.6080 - val_loss: 0.8779 - val_acc: 0.5915\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8587 - acc: 0.6113 - val_loss: 0.8840 - val_acc: 0.5989\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8537 - acc: 0.6156 - val_loss: 0.8666 - val_acc: 0.6021\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8474 - acc: 0.6229 - val_loss: 0.8599 - val_acc: 0.6011\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8415 - acc: 0.6309 - val_loss: 0.8613 - val_acc: 0.6091\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.8378 - acc: 0.6245 - val_loss: 0.8554 - val_acc: 0.6027\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8331 - acc: 0.6309 - val_loss: 0.8636 - val_acc: 0.5931\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8291 - acc: 0.6318 - val_loss: 0.8562 - val_acc: 0.6027\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8244 - acc: 0.6369 - val_loss: 0.8533 - val_acc: 0.6032\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8204 - acc: 0.6375 - val_loss: 0.8552 - val_acc: 0.5989\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8150 - acc: 0.6382 - val_loss: 0.8420 - val_acc: 0.6085\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8111 - acc: 0.6446 - val_loss: 0.8640 - val_acc: 0.5931\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8089 - acc: 0.6456 - val_loss: 0.8470 - val_acc: 0.6085\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8045 - acc: 0.6465 - val_loss: 0.8399 - val_acc: 0.6101\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8002 - acc: 0.6474 - val_loss: 0.8356 - val_acc: 0.6176\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7972 - acc: 0.6501 - val_loss: 0.8352 - val_acc: 0.6213\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7934 - acc: 0.6554 - val_loss: 0.8323 - val_acc: 0.6181\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7891 - acc: 0.6620 - val_loss: 0.8346 - val_acc: 0.6171\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 371us/step - loss: 0.7883 - acc: 0.6565 - val_loss: 0.8285 - val_acc: 0.6203\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7835 - acc: 0.6574 - val_loss: 0.8341 - val_acc: 0.6176\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7811 - acc: 0.6602 - val_loss: 0.8311 - val_acc: 0.6267\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7766 - acc: 0.6652 - val_loss: 0.8436 - val_acc: 0.6101\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7751 - acc: 0.6616 - val_loss: 0.8497 - val_acc: 0.6048\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7731 - acc: 0.6632 - val_loss: 0.8271 - val_acc: 0.6235\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7696 - acc: 0.6664 - val_loss: 0.8313 - val_acc: 0.6213\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7664 - acc: 0.6664 - val_loss: 0.8512 - val_acc: 0.6059\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7621 - acc: 0.6705 - val_loss: 0.8221 - val_acc: 0.6288\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 363us/step - loss: 0.7589 - acc: 0.6757 - val_loss: 0.8386 - val_acc: 0.6187\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7556 - acc: 0.6755 - val_loss: 0.8205 - val_acc: 0.6336\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7555 - acc: 0.6789 - val_loss: 0.8224 - val_acc: 0.6293\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7510 - acc: 0.6769 - val_loss: 0.8528 - val_acc: 0.6080\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.7484 - acc: 0.6799 - val_loss: 0.8149 - val_acc: 0.6384\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7452 - acc: 0.6828 - val_loss: 0.8317 - val_acc: 0.6245\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7433 - acc: 0.6835 - val_loss: 0.8168 - val_acc: 0.6395\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7425 - acc: 0.6833 - val_loss: 0.8281 - val_acc: 0.6299\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7371 - acc: 0.6869 - val_loss: 0.8290 - val_acc: 0.6304\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7369 - acc: 0.6849 - val_loss: 0.8115 - val_acc: 0.6325\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7312 - acc: 0.6895 - val_loss: 0.8201 - val_acc: 0.6240\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7287 - acc: 0.6876 - val_loss: 0.8103 - val_acc: 0.6453\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7261 - acc: 0.6865 - val_loss: 0.8131 - val_acc: 0.6357\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 346us/step - loss: 0.7225 - acc: 0.6936 - val_loss: 0.8127 - val_acc: 0.6336\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7194 - acc: 0.6920 - val_loss: 0.8156 - val_acc: 0.6261\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7153 - acc: 0.6975 - val_loss: 0.8192 - val_acc: 0.6347\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7172 - acc: 0.6972 - val_loss: 0.8186 - val_acc: 0.6325\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7155 - acc: 0.7007 - val_loss: 0.8233 - val_acc: 0.6336\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7119 - acc: 0.6968 - val_loss: 0.8184 - val_acc: 0.6309\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7083 - acc: 0.7027 - val_loss: 0.8368 - val_acc: 0.6229\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7061 - acc: 0.7039 - val_loss: 0.8564 - val_acc: 0.6165\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7063 - acc: 0.7025 - val_loss: 0.8104 - val_acc: 0.6459\n",
      "0.604694850838\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0511 - acc: 0.4994 - val_loss: 1.0370 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 1.0347 - acc: 0.5006 - val_loss: 1.0309 - val_acc: 0.5003\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0286 - acc: 0.5006 - val_loss: 1.0246 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 1.0224 - acc: 0.5006 - val_loss: 1.0175 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0155 - acc: 0.5006 - val_loss: 1.0102 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0082 - acc: 0.5003 - val_loss: 1.0020 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 1.0004 - acc: 0.5024 - val_loss: 0.9949 - val_acc: 0.5024\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.9925 - acc: 0.5065 - val_loss: 0.9875 - val_acc: 0.5035\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9834 - acc: 0.5090 - val_loss: 0.9776 - val_acc: 0.5168\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.9759 - acc: 0.5154 - val_loss: 0.9811 - val_acc: 0.5173\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9688 - acc: 0.5209 - val_loss: 0.9636 - val_acc: 0.5205\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.9612 - acc: 0.5280 - val_loss: 0.9569 - val_acc: 0.5285\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.9536 - acc: 0.5353 - val_loss: 0.9489 - val_acc: 0.5403\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9467 - acc: 0.5392 - val_loss: 0.9503 - val_acc: 0.5440\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9400 - acc: 0.5413 - val_loss: 0.9370 - val_acc: 0.5525\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 368us/step - loss: 0.9316 - acc: 0.5486 - val_loss: 0.9311 - val_acc: 0.5477\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9269 - acc: 0.5511 - val_loss: 0.9267 - val_acc: 0.5627\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9199 - acc: 0.5603 - val_loss: 0.9225 - val_acc: 0.5696\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9138 - acc: 0.5598 - val_loss: 0.9241 - val_acc: 0.5723\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9070 - acc: 0.5667 - val_loss: 0.9105 - val_acc: 0.5840\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8994 - acc: 0.5765 - val_loss: 0.9028 - val_acc: 0.5749\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8963 - acc: 0.5753 - val_loss: 0.9030 - val_acc: 0.5883\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8882 - acc: 0.5786 - val_loss: 0.8970 - val_acc: 0.5925\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8826 - acc: 0.5854 - val_loss: 0.8948 - val_acc: 0.5765\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8774 - acc: 0.5891 - val_loss: 0.8869 - val_acc: 0.5979\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8706 - acc: 0.5941 - val_loss: 0.8839 - val_acc: 0.5920\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8663 - acc: 0.5980 - val_loss: 0.8808 - val_acc: 0.5979\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8607 - acc: 0.6016 - val_loss: 0.8742 - val_acc: 0.6064\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8556 - acc: 0.5971 - val_loss: 0.8784 - val_acc: 0.6048\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8521 - acc: 0.6067 - val_loss: 0.8679 - val_acc: 0.6005\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8469 - acc: 0.6087 - val_loss: 0.8682 - val_acc: 0.6128\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8405 - acc: 0.6097 - val_loss: 0.8612 - val_acc: 0.6075\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.8380 - acc: 0.6167 - val_loss: 0.8597 - val_acc: 0.6197\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8338 - acc: 0.6181 - val_loss: 0.8645 - val_acc: 0.6101\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8288 - acc: 0.6126 - val_loss: 0.8769 - val_acc: 0.6011\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8252 - acc: 0.6181 - val_loss: 0.8589 - val_acc: 0.6123\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8206 - acc: 0.6241 - val_loss: 0.8791 - val_acc: 0.5936\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8196 - acc: 0.6218 - val_loss: 0.8469 - val_acc: 0.6176\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8168 - acc: 0.6215 - val_loss: 0.8452 - val_acc: 0.6283\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8104 - acc: 0.6284 - val_loss: 0.8486 - val_acc: 0.6224\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8081 - acc: 0.6284 - val_loss: 0.8384 - val_acc: 0.6341\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8049 - acc: 0.6348 - val_loss: 0.8384 - val_acc: 0.6288\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8004 - acc: 0.6339 - val_loss: 0.8489 - val_acc: 0.6192\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7990 - acc: 0.6353 - val_loss: 0.8337 - val_acc: 0.6384\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7935 - acc: 0.6424 - val_loss: 0.8352 - val_acc: 0.6304\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7908 - acc: 0.6446 - val_loss: 0.8366 - val_acc: 0.6357\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7889 - acc: 0.6391 - val_loss: 0.8330 - val_acc: 0.6352\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7858 - acc: 0.6442 - val_loss: 0.8305 - val_acc: 0.6368\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7826 - acc: 0.6472 - val_loss: 0.8267 - val_acc: 0.6395\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7783 - acc: 0.6515 - val_loss: 0.8245 - val_acc: 0.6352\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7754 - acc: 0.6538 - val_loss: 0.8296 - val_acc: 0.6309\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7731 - acc: 0.6556 - val_loss: 0.8226 - val_acc: 0.6373\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7697 - acc: 0.6558 - val_loss: 0.8339 - val_acc: 0.6240\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7688 - acc: 0.6602 - val_loss: 0.8255 - val_acc: 0.6368\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7640 - acc: 0.6620 - val_loss: 0.8302 - val_acc: 0.6389\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7630 - acc: 0.6616 - val_loss: 0.8170 - val_acc: 0.6421\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7599 - acc: 0.6654 - val_loss: 0.8164 - val_acc: 0.6405\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7550 - acc: 0.6677 - val_loss: 0.8235 - val_acc: 0.6336\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7544 - acc: 0.6659 - val_loss: 0.8198 - val_acc: 0.6459\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7525 - acc: 0.6682 - val_loss: 0.8179 - val_acc: 0.6491\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7496 - acc: 0.6716 - val_loss: 0.8204 - val_acc: 0.6480\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7474 - acc: 0.6718 - val_loss: 0.8155 - val_acc: 0.6427\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7438 - acc: 0.6760 - val_loss: 0.8277 - val_acc: 0.6389\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7425 - acc: 0.6714 - val_loss: 0.8197 - val_acc: 0.6459\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7412 - acc: 0.6764 - val_loss: 0.8091 - val_acc: 0.6480\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7359 - acc: 0.6780 - val_loss: 0.8133 - val_acc: 0.6517\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7349 - acc: 0.6773 - val_loss: 0.8129 - val_acc: 0.6512\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7312 - acc: 0.6858 - val_loss: 0.8285 - val_acc: 0.6480\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7302 - acc: 0.6833 - val_loss: 0.8056 - val_acc: 0.6517\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7285 - acc: 0.6801 - val_loss: 0.8148 - val_acc: 0.6539\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7267 - acc: 0.6805 - val_loss: 0.8082 - val_acc: 0.6512\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7211 - acc: 0.6844 - val_loss: 0.8074 - val_acc: 0.6491\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7189 - acc: 0.6867 - val_loss: 0.8025 - val_acc: 0.6597\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7160 - acc: 0.6899 - val_loss: 0.8012 - val_acc: 0.6581\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 356us/step - loss: 0.7151 - acc: 0.6831 - val_loss: 0.8056 - val_acc: 0.6560\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7113 - acc: 0.6901 - val_loss: 0.8369 - val_acc: 0.6357\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7084 - acc: 0.6943 - val_loss: 0.8031 - val_acc: 0.6597\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7084 - acc: 0.6936 - val_loss: 0.8272 - val_acc: 0.6475\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7053 - acc: 0.6956 - val_loss: 0.8035 - val_acc: 0.6608\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7003 - acc: 0.6991 - val_loss: 0.8111 - val_acc: 0.6517\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7002 - acc: 0.6965 - val_loss: 0.8004 - val_acc: 0.6555\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.6968 - acc: 0.6965 - val_loss: 0.8040 - val_acc: 0.6581\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6951 - acc: 0.6981 - val_loss: 0.8074 - val_acc: 0.6475\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6915 - acc: 0.7050 - val_loss: 0.8283 - val_acc: 0.6405\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6863 - acc: 0.7055 - val_loss: 0.8042 - val_acc: 0.6587\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6891 - acc: 0.7055 - val_loss: 0.7980 - val_acc: 0.6592\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6847 - acc: 0.7043 - val_loss: 0.7997 - val_acc: 0.6587\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.6829 - acc: 0.6991 - val_loss: 0.8070 - val_acc: 0.6517\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.6793 - acc: 0.7103 - val_loss: 0.8118 - val_acc: 0.6517\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6761 - acc: 0.7103 - val_loss: 0.7973 - val_acc: 0.6587\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.6733 - acc: 0.7110 - val_loss: 0.8011 - val_acc: 0.6597\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.6727 - acc: 0.7119 - val_loss: 0.8229 - val_acc: 0.6427\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.6679 - acc: 0.7144 - val_loss: 0.8060 - val_acc: 0.6507\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.6656 - acc: 0.7144 - val_loss: 0.8036 - val_acc: 0.6533\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.6651 - acc: 0.7153 - val_loss: 0.8039 - val_acc: 0.6555\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6659 - acc: 0.7126 - val_loss: 0.8119 - val_acc: 0.6464\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6568 - acc: 0.7251 - val_loss: 0.8073 - val_acc: 0.6555\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6571 - acc: 0.7180 - val_loss: 0.8124 - val_acc: 0.6512\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.6546 - acc: 0.7178 - val_loss: 0.8067 - val_acc: 0.6592\n",
      "Epoch 100/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6510 - acc: 0.7256 - val_loss: 0.8181 - val_acc: 0.6597\n",
      "0.630456251234\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0512 - acc: 0.4987 - val_loss: 1.0389 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 1.0358 - acc: 0.5006 - val_loss: 1.0349 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 1.0315 - acc: 0.5006 - val_loss: 1.0311 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0272 - acc: 0.5006 - val_loss: 1.0268 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 1.0229 - acc: 0.5006 - val_loss: 1.0224 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0181 - acc: 0.5006 - val_loss: 1.0179 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0132 - acc: 0.5008 - val_loss: 1.0129 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 1.0079 - acc: 0.5015 - val_loss: 1.0075 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0019 - acc: 0.5022 - val_loss: 1.0016 - val_acc: 0.5029\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9955 - acc: 0.5040 - val_loss: 0.9954 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9887 - acc: 0.5065 - val_loss: 0.9884 - val_acc: 0.5104\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9810 - acc: 0.5177 - val_loss: 0.9828 - val_acc: 0.5147\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.9733 - acc: 0.5200 - val_loss: 0.9734 - val_acc: 0.5275\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9650 - acc: 0.5292 - val_loss: 0.9648 - val_acc: 0.5312\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9561 - acc: 0.5344 - val_loss: 0.9562 - val_acc: 0.5339\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.9472 - acc: 0.5401 - val_loss: 0.9479 - val_acc: 0.5424\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9377 - acc: 0.5481 - val_loss: 0.9399 - val_acc: 0.5579\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9286 - acc: 0.5552 - val_loss: 0.9356 - val_acc: 0.5595\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9202 - acc: 0.5657 - val_loss: 0.9238 - val_acc: 0.5685\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9121 - acc: 0.5667 - val_loss: 0.9156 - val_acc: 0.5691\n",
      "Epoch 21/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9044 - acc: 0.5765 - val_loss: 0.9143 - val_acc: 0.5755\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.8959 - acc: 0.5822 - val_loss: 0.9045 - val_acc: 0.5824\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8895 - acc: 0.5856 - val_loss: 0.8996 - val_acc: 0.5680\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8828 - acc: 0.5914 - val_loss: 0.8918 - val_acc: 0.5867\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8757 - acc: 0.6012 - val_loss: 0.8915 - val_acc: 0.5883\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8689 - acc: 0.5994 - val_loss: 0.8825 - val_acc: 0.5893\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8635 - acc: 0.6037 - val_loss: 0.8782 - val_acc: 0.5963\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8569 - acc: 0.6117 - val_loss: 0.8789 - val_acc: 0.5797\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8522 - acc: 0.6133 - val_loss: 0.8679 - val_acc: 0.5973\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8455 - acc: 0.6138 - val_loss: 0.8716 - val_acc: 0.5920\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8405 - acc: 0.6167 - val_loss: 0.8655 - val_acc: 0.5968\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8347 - acc: 0.6257 - val_loss: 0.8615 - val_acc: 0.5963\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8309 - acc: 0.6225 - val_loss: 0.8637 - val_acc: 0.6016\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8267 - acc: 0.6204 - val_loss: 0.8580 - val_acc: 0.6059\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8238 - acc: 0.6241 - val_loss: 0.8554 - val_acc: 0.6133\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8204 - acc: 0.6273 - val_loss: 0.8574 - val_acc: 0.6016\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8134 - acc: 0.6357 - val_loss: 0.8692 - val_acc: 0.5979\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8117 - acc: 0.6309 - val_loss: 0.8530 - val_acc: 0.6160\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8075 - acc: 0.6412 - val_loss: 0.8476 - val_acc: 0.6149\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8045 - acc: 0.6373 - val_loss: 0.8477 - val_acc: 0.6117\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8026 - acc: 0.6366 - val_loss: 0.8488 - val_acc: 0.6240\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7979 - acc: 0.6391 - val_loss: 0.8424 - val_acc: 0.6171\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7941 - acc: 0.6440 - val_loss: 0.8408 - val_acc: 0.6240\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7918 - acc: 0.6446 - val_loss: 0.8443 - val_acc: 0.6160\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7882 - acc: 0.6474 - val_loss: 0.8412 - val_acc: 0.6229\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7836 - acc: 0.6497 - val_loss: 0.8483 - val_acc: 0.6203\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7823 - acc: 0.6472 - val_loss: 0.8487 - val_acc: 0.6149\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7792 - acc: 0.6506 - val_loss: 0.8380 - val_acc: 0.6261\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7770 - acc: 0.6513 - val_loss: 0.8365 - val_acc: 0.6224\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7730 - acc: 0.6542 - val_loss: 0.8344 - val_acc: 0.6235\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7687 - acc: 0.6565 - val_loss: 0.8370 - val_acc: 0.6288\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7675 - acc: 0.6629 - val_loss: 0.8638 - val_acc: 0.6107\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7656 - acc: 0.6604 - val_loss: 0.8305 - val_acc: 0.6293\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7613 - acc: 0.6609 - val_loss: 0.8364 - val_acc: 0.6288\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7600 - acc: 0.6641 - val_loss: 0.8354 - val_acc: 0.6309\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7563 - acc: 0.6659 - val_loss: 0.8304 - val_acc: 0.6331\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7533 - acc: 0.6698 - val_loss: 0.8505 - val_acc: 0.6139\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7504 - acc: 0.6657 - val_loss: 0.8342 - val_acc: 0.6240\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7450 - acc: 0.6698 - val_loss: 0.8435 - val_acc: 0.6224\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7423 - acc: 0.6764 - val_loss: 0.8359 - val_acc: 0.6235\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7421 - acc: 0.6805 - val_loss: 0.8360 - val_acc: 0.6283\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7396 - acc: 0.6762 - val_loss: 0.8321 - val_acc: 0.6261\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7400 - acc: 0.6762 - val_loss: 0.8423 - val_acc: 0.6213\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7365 - acc: 0.6741 - val_loss: 0.8293 - val_acc: 0.6315\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7298 - acc: 0.6844 - val_loss: 0.8331 - val_acc: 0.6208\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7283 - acc: 0.6810 - val_loss: 0.8298 - val_acc: 0.6309\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7269 - acc: 0.6817 - val_loss: 0.8617 - val_acc: 0.6171\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7240 - acc: 0.6803 - val_loss: 0.8341 - val_acc: 0.6288\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7223 - acc: 0.6867 - val_loss: 0.8309 - val_acc: 0.6277\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7190 - acc: 0.6883 - val_loss: 0.8439 - val_acc: 0.6213\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7152 - acc: 0.6883 - val_loss: 0.8499 - val_acc: 0.6203\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7150 - acc: 0.6924 - val_loss: 0.8288 - val_acc: 0.6379\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7109 - acc: 0.6931 - val_loss: 0.8362 - val_acc: 0.6293\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7078 - acc: 0.6908 - val_loss: 0.8340 - val_acc: 0.6288\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7075 - acc: 0.6988 - val_loss: 0.8282 - val_acc: 0.6336\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7030 - acc: 0.6945 - val_loss: 0.8279 - val_acc: 0.6315\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7017 - acc: 0.6984 - val_loss: 0.8325 - val_acc: 0.6357\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6960 - acc: 0.7002 - val_loss: 0.8284 - val_acc: 0.6379\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6937 - acc: 0.6988 - val_loss: 0.8316 - val_acc: 0.6261\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.6945 - acc: 0.7036 - val_loss: 0.8351 - val_acc: 0.6304\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6875 - acc: 0.7050 - val_loss: 0.8544 - val_acc: 0.6240\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6861 - acc: 0.7055 - val_loss: 0.8947 - val_acc: 0.6021\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6867 - acc: 0.7068 - val_loss: 0.8337 - val_acc: 0.6283\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.6792 - acc: 0.7059 - val_loss: 0.8351 - val_acc: 0.6320\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6784 - acc: 0.7071 - val_loss: 0.8417 - val_acc: 0.6272\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.6735 - acc: 0.7112 - val_loss: 0.8332 - val_acc: 0.6368\n",
      "0.594385740005\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0533 - acc: 0.4985 - val_loss: 1.0394 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 1.0353 - acc: 0.5006 - val_loss: 1.0348 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 1.0297 - acc: 0.5006 - val_loss: 1.0310 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0242 - acc: 0.5006 - val_loss: 1.0271 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 1.0185 - acc: 0.5006 - val_loss: 1.0230 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 1.0127 - acc: 0.5006 - val_loss: 1.0187 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 1.0063 - acc: 0.5008 - val_loss: 1.0142 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9996 - acc: 0.5015 - val_loss: 1.0095 - val_acc: 0.4997\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.9926 - acc: 0.5035 - val_loss: 1.0042 - val_acc: 0.5035\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9849 - acc: 0.5099 - val_loss: 0.9986 - val_acc: 0.5061\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9772 - acc: 0.5180 - val_loss: 0.9925 - val_acc: 0.5120\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9688 - acc: 0.5262 - val_loss: 0.9858 - val_acc: 0.5147\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9602 - acc: 0.5301 - val_loss: 0.9792 - val_acc: 0.5211\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9512 - acc: 0.5392 - val_loss: 0.9725 - val_acc: 0.5269\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9418 - acc: 0.5456 - val_loss: 0.9655 - val_acc: 0.5355\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9323 - acc: 0.5516 - val_loss: 0.9586 - val_acc: 0.5483\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9235 - acc: 0.5603 - val_loss: 0.9513 - val_acc: 0.5488\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9143 - acc: 0.5694 - val_loss: 0.9466 - val_acc: 0.5477\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9052 - acc: 0.5799 - val_loss: 0.9399 - val_acc: 0.5509\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8959 - acc: 0.5799 - val_loss: 0.9342 - val_acc: 0.5547\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8880 - acc: 0.5845 - val_loss: 0.9260 - val_acc: 0.5573\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8801 - acc: 0.5925 - val_loss: 0.9204 - val_acc: 0.5616\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8729 - acc: 0.5980 - val_loss: 0.9149 - val_acc: 0.5637\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8646 - acc: 0.6037 - val_loss: 0.9148 - val_acc: 0.5701\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8591 - acc: 0.6078 - val_loss: 0.9060 - val_acc: 0.5707\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8523 - acc: 0.6106 - val_loss: 0.9011 - val_acc: 0.5717\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8473 - acc: 0.6172 - val_loss: 0.9003 - val_acc: 0.5723\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8405 - acc: 0.6199 - val_loss: 0.8937 - val_acc: 0.5744\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.8356 - acc: 0.6222 - val_loss: 0.8908 - val_acc: 0.5776\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8313 - acc: 0.6259 - val_loss: 0.8897 - val_acc: 0.5813\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8258 - acc: 0.6268 - val_loss: 0.8867 - val_acc: 0.5776\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8220 - acc: 0.6307 - val_loss: 0.8920 - val_acc: 0.5771\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8191 - acc: 0.6371 - val_loss: 0.8805 - val_acc: 0.5829\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8143 - acc: 0.6311 - val_loss: 0.8772 - val_acc: 0.5904\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 521us/step - loss: 0.8111 - acc: 0.6300 - val_loss: 0.8759 - val_acc: 0.5835\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8076 - acc: 0.6380 - val_loss: 0.8781 - val_acc: 0.5883\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8039 - acc: 0.6398 - val_loss: 0.8718 - val_acc: 0.5877\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8005 - acc: 0.6449 - val_loss: 0.8702 - val_acc: 0.5893\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.7960 - acc: 0.6456 - val_loss: 0.8695 - val_acc: 0.5952\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7937 - acc: 0.6472 - val_loss: 0.8728 - val_acc: 0.5861\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7900 - acc: 0.6549 - val_loss: 0.8727 - val_acc: 0.5968\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7881 - acc: 0.6515 - val_loss: 0.8611 - val_acc: 0.5920\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7857 - acc: 0.6533 - val_loss: 0.8607 - val_acc: 0.6053\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7813 - acc: 0.6517 - val_loss: 0.8575 - val_acc: 0.5973\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7782 - acc: 0.6565 - val_loss: 0.8599 - val_acc: 0.6005\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7760 - acc: 0.6506 - val_loss: 0.8592 - val_acc: 0.5968\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7730 - acc: 0.6563 - val_loss: 0.8546 - val_acc: 0.6075\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7692 - acc: 0.6602 - val_loss: 0.8581 - val_acc: 0.6037\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7683 - acc: 0.6618 - val_loss: 0.8571 - val_acc: 0.6064\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7640 - acc: 0.6661 - val_loss: 0.8501 - val_acc: 0.6080\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7605 - acc: 0.6709 - val_loss: 0.8578 - val_acc: 0.6048\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7585 - acc: 0.6636 - val_loss: 0.8523 - val_acc: 0.6053\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7552 - acc: 0.6700 - val_loss: 0.8528 - val_acc: 0.6096\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7519 - acc: 0.6696 - val_loss: 0.8859 - val_acc: 0.5829\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7527 - acc: 0.6744 - val_loss: 0.8471 - val_acc: 0.6155\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7481 - acc: 0.6735 - val_loss: 0.8477 - val_acc: 0.6171\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7448 - acc: 0.6760 - val_loss: 0.8471 - val_acc: 0.6176\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7442 - acc: 0.6762 - val_loss: 0.8436 - val_acc: 0.6213\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7409 - acc: 0.6783 - val_loss: 0.8470 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7357 - acc: 0.6778 - val_loss: 0.8442 - val_acc: 0.6171\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7332 - acc: 0.6831 - val_loss: 0.8445 - val_acc: 0.6133\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7325 - acc: 0.6808 - val_loss: 0.8436 - val_acc: 0.6187\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7290 - acc: 0.6831 - val_loss: 0.8459 - val_acc: 0.6197\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7264 - acc: 0.6869 - val_loss: 0.8427 - val_acc: 0.6176\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7233 - acc: 0.6856 - val_loss: 0.8436 - val_acc: 0.6149\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7197 - acc: 0.6906 - val_loss: 0.8539 - val_acc: 0.6005\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7197 - acc: 0.6897 - val_loss: 0.8644 - val_acc: 0.6171\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7159 - acc: 0.6888 - val_loss: 0.8394 - val_acc: 0.6197\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7151 - acc: 0.6931 - val_loss: 0.8576 - val_acc: 0.6032\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7132 - acc: 0.6917 - val_loss: 0.8456 - val_acc: 0.6219\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7090 - acc: 0.6911 - val_loss: 0.8442 - val_acc: 0.6229\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7064 - acc: 0.6959 - val_loss: 0.8431 - val_acc: 0.6219\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7063 - acc: 0.6993 - val_loss: 0.8440 - val_acc: 0.6224\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7032 - acc: 0.6936 - val_loss: 0.8413 - val_acc: 0.6208\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.6999 - acc: 0.6965 - val_loss: 0.8445 - val_acc: 0.6181\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.6966 - acc: 0.6993 - val_loss: 0.8589 - val_acc: 0.6155\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6936 - acc: 0.7027 - val_loss: 0.8613 - val_acc: 0.5995\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6918 - acc: 0.7041 - val_loss: 0.8569 - val_acc: 0.6155\n",
      "0.596312237632\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0520 - acc: 0.5006 - val_loss: 1.0396 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0361 - acc: 0.5006 - val_loss: 1.0337 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 1.0312 - acc: 0.5006 - val_loss: 1.0291 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 1.0265 - acc: 0.5006 - val_loss: 1.0248 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 1.0219 - acc: 0.5006 - val_loss: 1.0191 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 1.0168 - acc: 0.5008 - val_loss: 1.0139 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0114 - acc: 0.5010 - val_loss: 1.0084 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 1.0058 - acc: 0.5019 - val_loss: 1.0027 - val_acc: 0.5024\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 1.0001 - acc: 0.5049 - val_loss: 0.9964 - val_acc: 0.5099\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9938 - acc: 0.5099 - val_loss: 0.9900 - val_acc: 0.5189\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9873 - acc: 0.5152 - val_loss: 0.9829 - val_acc: 0.5221\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9802 - acc: 0.5205 - val_loss: 0.9757 - val_acc: 0.5253\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9733 - acc: 0.5239 - val_loss: 0.9681 - val_acc: 0.5253\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9652 - acc: 0.5305 - val_loss: 0.9602 - val_acc: 0.5339\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9578 - acc: 0.5312 - val_loss: 0.9525 - val_acc: 0.5403\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9502 - acc: 0.5401 - val_loss: 0.9443 - val_acc: 0.5397\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.9423 - acc: 0.5420 - val_loss: 0.9365 - val_acc: 0.5445\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.9349 - acc: 0.5475 - val_loss: 0.9292 - val_acc: 0.5579\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9269 - acc: 0.5564 - val_loss: 0.9230 - val_acc: 0.5488\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.9206 - acc: 0.5587 - val_loss: 0.9147 - val_acc: 0.5797\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.9125 - acc: 0.5635 - val_loss: 0.9111 - val_acc: 0.5637\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9056 - acc: 0.5651 - val_loss: 0.9045 - val_acc: 0.5845\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9006 - acc: 0.5644 - val_loss: 0.8954 - val_acc: 0.5845\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8937 - acc: 0.5747 - val_loss: 0.8889 - val_acc: 0.5883\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8871 - acc: 0.5804 - val_loss: 0.8872 - val_acc: 0.5840\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8810 - acc: 0.5772 - val_loss: 0.8815 - val_acc: 0.5840\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8754 - acc: 0.5904 - val_loss: 0.8770 - val_acc: 0.6032\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8708 - acc: 0.5891 - val_loss: 0.8693 - val_acc: 0.6037\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8651 - acc: 0.5996 - val_loss: 0.8660 - val_acc: 0.6011\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.8605 - acc: 0.5957 - val_loss: 0.8663 - val_acc: 0.5909\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8547 - acc: 0.5980 - val_loss: 0.8571 - val_acc: 0.6128\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8489 - acc: 0.6094 - val_loss: 0.8508 - val_acc: 0.6091\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.8466 - acc: 0.6003 - val_loss: 0.8524 - val_acc: 0.6160\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8406 - acc: 0.6090 - val_loss: 0.8462 - val_acc: 0.6256\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8375 - acc: 0.6110 - val_loss: 0.8438 - val_acc: 0.6165\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8327 - acc: 0.6149 - val_loss: 0.8437 - val_acc: 0.6224\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8311 - acc: 0.6172 - val_loss: 0.8422 - val_acc: 0.6235\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8246 - acc: 0.6190 - val_loss: 0.8424 - val_acc: 0.6016\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 371us/step - loss: 0.8202 - acc: 0.6222 - val_loss: 0.8318 - val_acc: 0.6261\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8186 - acc: 0.6275 - val_loss: 0.8248 - val_acc: 0.6256\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8137 - acc: 0.6268 - val_loss: 0.8246 - val_acc: 0.6272\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.8114 - acc: 0.6321 - val_loss: 0.8306 - val_acc: 0.6139\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8082 - acc: 0.6346 - val_loss: 0.8247 - val_acc: 0.6224\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8067 - acc: 0.6373 - val_loss: 0.8316 - val_acc: 0.6304\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8030 - acc: 0.6353 - val_loss: 0.8206 - val_acc: 0.6277\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7979 - acc: 0.6389 - val_loss: 0.8495 - val_acc: 0.5963\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7946 - acc: 0.6437 - val_loss: 0.8083 - val_acc: 0.6352\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7915 - acc: 0.6414 - val_loss: 0.8076 - val_acc: 0.6352\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7892 - acc: 0.6469 - val_loss: 0.8047 - val_acc: 0.6373\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7854 - acc: 0.6467 - val_loss: 0.8118 - val_acc: 0.6469\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7841 - acc: 0.6497 - val_loss: 0.8046 - val_acc: 0.6325\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7788 - acc: 0.6602 - val_loss: 0.8149 - val_acc: 0.6448\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7754 - acc: 0.6600 - val_loss: 0.8128 - val_acc: 0.6395\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7762 - acc: 0.6590 - val_loss: 0.8128 - val_acc: 0.6421\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7703 - acc: 0.6602 - val_loss: 0.7986 - val_acc: 0.6384\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7670 - acc: 0.6643 - val_loss: 0.7985 - val_acc: 0.6341\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7659 - acc: 0.6645 - val_loss: 0.8024 - val_acc: 0.6288\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7639 - acc: 0.6691 - val_loss: 0.7975 - val_acc: 0.6469\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7596 - acc: 0.6636 - val_loss: 0.8055 - val_acc: 0.6304\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7590 - acc: 0.6636 - val_loss: 0.7906 - val_acc: 0.6469\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7585 - acc: 0.6652 - val_loss: 0.7966 - val_acc: 0.6523\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7534 - acc: 0.6696 - val_loss: 0.7935 - val_acc: 0.6437\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7501 - acc: 0.6693 - val_loss: 0.7967 - val_acc: 0.6363\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7470 - acc: 0.6686 - val_loss: 0.7906 - val_acc: 0.6421\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7449 - acc: 0.6725 - val_loss: 0.7861 - val_acc: 0.6475\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.7416 - acc: 0.6801 - val_loss: 0.8028 - val_acc: 0.6299\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7397 - acc: 0.6785 - val_loss: 0.8029 - val_acc: 0.6437\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7387 - acc: 0.6815 - val_loss: 0.7840 - val_acc: 0.6555\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7366 - acc: 0.6767 - val_loss: 0.7848 - val_acc: 0.6485\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7338 - acc: 0.6792 - val_loss: 0.7850 - val_acc: 0.6443\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7285 - acc: 0.6815 - val_loss: 0.7985 - val_acc: 0.6432\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.7271 - acc: 0.6837 - val_loss: 0.8047 - val_acc: 0.6432\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7229 - acc: 0.6808 - val_loss: 0.7903 - val_acc: 0.6528\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7210 - acc: 0.6874 - val_loss: 0.7784 - val_acc: 0.6565\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7210 - acc: 0.6895 - val_loss: 0.8639 - val_acc: 0.5941\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7150 - acc: 0.6869 - val_loss: 0.7781 - val_acc: 0.6549\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7150 - acc: 0.6952 - val_loss: 0.7857 - val_acc: 0.6528\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7121 - acc: 0.6915 - val_loss: 0.7834 - val_acc: 0.6544\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7109 - acc: 0.6892 - val_loss: 0.7779 - val_acc: 0.6485\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7067 - acc: 0.6938 - val_loss: 0.7848 - val_acc: 0.6395\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7063 - acc: 0.6929 - val_loss: 0.8009 - val_acc: 0.6331\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7037 - acc: 0.6965 - val_loss: 0.7752 - val_acc: 0.6421\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6999 - acc: 0.7023 - val_loss: 0.7842 - val_acc: 0.6480\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.6957 - acc: 0.6995 - val_loss: 0.7767 - val_acc: 0.6475\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6963 - acc: 0.7025 - val_loss: 0.7871 - val_acc: 0.6512\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.6951 - acc: 0.7023 - val_loss: 0.7785 - val_acc: 0.6523\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6884 - acc: 0.7080 - val_loss: 0.7857 - val_acc: 0.6512\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6856 - acc: 0.7007 - val_loss: 0.7812 - val_acc: 0.6507\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6821 - acc: 0.7087 - val_loss: 0.8208 - val_acc: 0.6368\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6815 - acc: 0.7034 - val_loss: 0.7779 - val_acc: 0.6544\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6795 - acc: 0.7073 - val_loss: 0.7766 - val_acc: 0.6555\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6818 - acc: 0.7103 - val_loss: 0.7777 - val_acc: 0.6565\n",
      "0.618400295465\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 5s 1ms/step - loss: 1.0503 - acc: 0.4985 - val_loss: 1.0370 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0343 - acc: 0.5006 - val_loss: 1.0323 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 1.0293 - acc: 0.5006 - val_loss: 1.0275 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 1.0245 - acc: 0.5006 - val_loss: 1.0226 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 1.0191 - acc: 0.5006 - val_loss: 1.0176 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0134 - acc: 0.5006 - val_loss: 1.0122 - val_acc: 0.5013\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 1.0073 - acc: 0.5006 - val_loss: 1.0063 - val_acc: 0.5024\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0007 - acc: 0.5015 - val_loss: 1.0000 - val_acc: 0.5045\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9936 - acc: 0.5051 - val_loss: 0.9934 - val_acc: 0.5067\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9858 - acc: 0.5088 - val_loss: 0.9865 - val_acc: 0.5141\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9775 - acc: 0.5161 - val_loss: 0.9785 - val_acc: 0.5136\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9685 - acc: 0.5218 - val_loss: 0.9710 - val_acc: 0.5216\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9594 - acc: 0.5330 - val_loss: 0.9629 - val_acc: 0.5264\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9504 - acc: 0.5376 - val_loss: 0.9539 - val_acc: 0.5451\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9415 - acc: 0.5486 - val_loss: 0.9484 - val_acc: 0.5499\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9330 - acc: 0.5548 - val_loss: 0.9394 - val_acc: 0.5520\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9246 - acc: 0.5607 - val_loss: 0.9311 - val_acc: 0.5568\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 374us/step - loss: 0.9180 - acc: 0.5680 - val_loss: 0.9250 - val_acc: 0.5541\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.9101 - acc: 0.5740 - val_loss: 0.9194 - val_acc: 0.5573\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9016 - acc: 0.5751 - val_loss: 0.9177 - val_acc: 0.5637\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8963 - acc: 0.5838 - val_loss: 0.9101 - val_acc: 0.5643\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8896 - acc: 0.5886 - val_loss: 0.9011 - val_acc: 0.5616\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8846 - acc: 0.5900 - val_loss: 0.8965 - val_acc: 0.5717\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8781 - acc: 0.5975 - val_loss: 0.8915 - val_acc: 0.5733\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8721 - acc: 0.5966 - val_loss: 0.8873 - val_acc: 0.5771\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8673 - acc: 0.6023 - val_loss: 0.8874 - val_acc: 0.5840\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8607 - acc: 0.6069 - val_loss: 0.8811 - val_acc: 0.5989\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8554 - acc: 0.6069 - val_loss: 0.8736 - val_acc: 0.5861\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8504 - acc: 0.6165 - val_loss: 0.8692 - val_acc: 0.5872\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8451 - acc: 0.6126 - val_loss: 0.8683 - val_acc: 0.5915\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8416 - acc: 0.6199 - val_loss: 0.8637 - val_acc: 0.5947\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8359 - acc: 0.6234 - val_loss: 0.8593 - val_acc: 0.6021\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.8318 - acc: 0.6270 - val_loss: 0.8531 - val_acc: 0.6075\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8269 - acc: 0.6227 - val_loss: 0.8500 - val_acc: 0.6123\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.8230 - acc: 0.6318 - val_loss: 0.8555 - val_acc: 0.6091\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8192 - acc: 0.6362 - val_loss: 0.8552 - val_acc: 0.6101\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.8153 - acc: 0.6327 - val_loss: 0.8521 - val_acc: 0.6043\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8120 - acc: 0.6348 - val_loss: 0.8419 - val_acc: 0.6219\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 526us/step - loss: 0.8074 - acc: 0.6380 - val_loss: 0.8396 - val_acc: 0.6187\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.8039 - acc: 0.6430 - val_loss: 0.8389 - val_acc: 0.6149\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7998 - acc: 0.6451 - val_loss: 0.8477 - val_acc: 0.6229\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7969 - acc: 0.6476 - val_loss: 0.8329 - val_acc: 0.6144\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7947 - acc: 0.6510 - val_loss: 0.8324 - val_acc: 0.6213\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7909 - acc: 0.6563 - val_loss: 0.8303 - val_acc: 0.6219\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7876 - acc: 0.6504 - val_loss: 0.8317 - val_acc: 0.6229\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7830 - acc: 0.6572 - val_loss: 0.8306 - val_acc: 0.6293\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7814 - acc: 0.6563 - val_loss: 0.8278 - val_acc: 0.6256\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7785 - acc: 0.6588 - val_loss: 0.8261 - val_acc: 0.6283\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7761 - acc: 0.6572 - val_loss: 0.8307 - val_acc: 0.6331\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 367us/step - loss: 0.7703 - acc: 0.6632 - val_loss: 0.8280 - val_acc: 0.6272\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7699 - acc: 0.6604 - val_loss: 0.8251 - val_acc: 0.6315\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7662 - acc: 0.6579 - val_loss: 0.8374 - val_acc: 0.6187\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 365us/step - loss: 0.7653 - acc: 0.6593 - val_loss: 0.8348 - val_acc: 0.6251\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7608 - acc: 0.6641 - val_loss: 0.8235 - val_acc: 0.6309\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7567 - acc: 0.6700 - val_loss: 0.8202 - val_acc: 0.6320\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7529 - acc: 0.6748 - val_loss: 0.8196 - val_acc: 0.6309\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7519 - acc: 0.6652 - val_loss: 0.8179 - val_acc: 0.6336\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7485 - acc: 0.6677 - val_loss: 0.8237 - val_acc: 0.6331\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.7480 - acc: 0.6728 - val_loss: 0.8205 - val_acc: 0.6320\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7416 - acc: 0.6739 - val_loss: 0.8227 - val_acc: 0.6352\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7401 - acc: 0.6744 - val_loss: 0.8257 - val_acc: 0.6288\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7368 - acc: 0.6783 - val_loss: 0.8206 - val_acc: 0.6384\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7351 - acc: 0.6808 - val_loss: 0.8194 - val_acc: 0.6384\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7327 - acc: 0.6835 - val_loss: 0.8171 - val_acc: 0.6373\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7285 - acc: 0.6821 - val_loss: 0.8240 - val_acc: 0.6352\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7283 - acc: 0.6913 - val_loss: 0.8218 - val_acc: 0.6293\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7239 - acc: 0.6872 - val_loss: 0.8269 - val_acc: 0.6363\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7239 - acc: 0.6819 - val_loss: 0.8204 - val_acc: 0.6352\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7183 - acc: 0.6858 - val_loss: 0.8147 - val_acc: 0.6421\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7182 - acc: 0.6835 - val_loss: 0.8228 - val_acc: 0.6347\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7116 - acc: 0.6908 - val_loss: 0.8145 - val_acc: 0.6421\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7098 - acc: 0.6892 - val_loss: 0.8120 - val_acc: 0.6416\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7099 - acc: 0.6947 - val_loss: 0.8124 - val_acc: 0.6389\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7069 - acc: 0.6901 - val_loss: 0.8100 - val_acc: 0.6379\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7021 - acc: 0.6943 - val_loss: 0.8117 - val_acc: 0.6448\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7016 - acc: 0.6938 - val_loss: 0.8212 - val_acc: 0.6453\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7009 - acc: 0.7007 - val_loss: 0.8128 - val_acc: 0.6389\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.6971 - acc: 0.6961 - val_loss: 0.8181 - val_acc: 0.6357\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6941 - acc: 0.6975 - val_loss: 0.8125 - val_acc: 0.6395\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6929 - acc: 0.6940 - val_loss: 0.8343 - val_acc: 0.6357\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6906 - acc: 0.7048 - val_loss: 0.8160 - val_acc: 0.6475\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6861 - acc: 0.7036 - val_loss: 0.8319 - val_acc: 0.6507\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6821 - acc: 0.7041 - val_loss: 0.8354 - val_acc: 0.6400\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.6821 - acc: 0.7080 - val_loss: 0.8117 - val_acc: 0.6475\n",
      "0.621706989247\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0501 - acc: 0.4983 - val_loss: 1.0391 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0370 - acc: 0.5006 - val_loss: 1.0349 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 1.0318 - acc: 0.5006 - val_loss: 1.0310 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0273 - acc: 0.5006 - val_loss: 1.0263 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 1.0221 - acc: 0.5006 - val_loss: 1.0217 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0164 - acc: 0.5006 - val_loss: 1.0183 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 1.0116 - acc: 0.5006 - val_loss: 1.0112 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 1.0052 - acc: 0.5006 - val_loss: 1.0057 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9983 - acc: 0.5022 - val_loss: 0.9996 - val_acc: 0.5040\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9914 - acc: 0.5056 - val_loss: 0.9920 - val_acc: 0.5109\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9840 - acc: 0.5097 - val_loss: 0.9852 - val_acc: 0.5163\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.9762 - acc: 0.5207 - val_loss: 0.9800 - val_acc: 0.5189\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.9684 - acc: 0.5278 - val_loss: 0.9711 - val_acc: 0.5195\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9608 - acc: 0.5333 - val_loss: 0.9643 - val_acc: 0.5312\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9523 - acc: 0.5436 - val_loss: 0.9566 - val_acc: 0.5312\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9448 - acc: 0.5468 - val_loss: 0.9491 - val_acc: 0.5355\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9359 - acc: 0.5568 - val_loss: 0.9427 - val_acc: 0.5408\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9290 - acc: 0.5628 - val_loss: 0.9343 - val_acc: 0.5440\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9214 - acc: 0.5673 - val_loss: 0.9339 - val_acc: 0.5419\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9131 - acc: 0.5726 - val_loss: 0.9210 - val_acc: 0.5515\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.9059 - acc: 0.5756 - val_loss: 0.9180 - val_acc: 0.5595\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8983 - acc: 0.5813 - val_loss: 0.9113 - val_acc: 0.5579\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8925 - acc: 0.5866 - val_loss: 0.9054 - val_acc: 0.5685\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.8859 - acc: 0.5946 - val_loss: 0.9027 - val_acc: 0.5744\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8802 - acc: 0.5943 - val_loss: 0.8953 - val_acc: 0.5744\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8729 - acc: 0.5989 - val_loss: 0.8906 - val_acc: 0.5819\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8682 - acc: 0.6021 - val_loss: 0.8829 - val_acc: 0.5787\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.8635 - acc: 0.6071 - val_loss: 0.8862 - val_acc: 0.5808\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.8577 - acc: 0.6135 - val_loss: 0.8914 - val_acc: 0.5813\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8526 - acc: 0.6106 - val_loss: 0.8924 - val_acc: 0.5808\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8464 - acc: 0.6211 - val_loss: 0.8700 - val_acc: 0.5883\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8439 - acc: 0.6229 - val_loss: 0.8658 - val_acc: 0.5904\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8378 - acc: 0.6225 - val_loss: 0.8622 - val_acc: 0.5931\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 366us/step - loss: 0.8349 - acc: 0.6211 - val_loss: 0.8583 - val_acc: 0.5957\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8292 - acc: 0.6284 - val_loss: 0.8550 - val_acc: 0.6021\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8244 - acc: 0.6348 - val_loss: 0.8602 - val_acc: 0.5915\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8211 - acc: 0.6339 - val_loss: 0.8546 - val_acc: 0.6085\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8175 - acc: 0.6357 - val_loss: 0.8485 - val_acc: 0.6064\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.8132 - acc: 0.6401 - val_loss: 0.8483 - val_acc: 0.6101\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8105 - acc: 0.6451 - val_loss: 0.8540 - val_acc: 0.6032\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8052 - acc: 0.6472 - val_loss: 0.8415 - val_acc: 0.6091\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8024 - acc: 0.6398 - val_loss: 0.8623 - val_acc: 0.6027\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7996 - acc: 0.6444 - val_loss: 0.8437 - val_acc: 0.6123\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7945 - acc: 0.6522 - val_loss: 0.8627 - val_acc: 0.6032\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7920 - acc: 0.6469 - val_loss: 0.8485 - val_acc: 0.6139\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7895 - acc: 0.6529 - val_loss: 0.8654 - val_acc: 0.6069\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7871 - acc: 0.6533 - val_loss: 0.8288 - val_acc: 0.6203\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7825 - acc: 0.6526 - val_loss: 0.8461 - val_acc: 0.6160\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7846 - acc: 0.6536 - val_loss: 0.8423 - val_acc: 0.6197\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7802 - acc: 0.6627 - val_loss: 0.8518 - val_acc: 0.6133\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7763 - acc: 0.6538 - val_loss: 0.8311 - val_acc: 0.6197\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7707 - acc: 0.6629 - val_loss: 0.8273 - val_acc: 0.6299\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7693 - acc: 0.6638 - val_loss: 0.8328 - val_acc: 0.6277\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.7650 - acc: 0.6675 - val_loss: 0.8340 - val_acc: 0.6219\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7659 - acc: 0.6657 - val_loss: 0.8198 - val_acc: 0.6325\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7610 - acc: 0.6709 - val_loss: 0.8195 - val_acc: 0.6304\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7583 - acc: 0.6645 - val_loss: 0.8151 - val_acc: 0.6341\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7529 - acc: 0.6730 - val_loss: 0.8291 - val_acc: 0.6240\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7518 - acc: 0.6721 - val_loss: 0.8237 - val_acc: 0.6331\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7497 - acc: 0.6698 - val_loss: 0.8159 - val_acc: 0.6309\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7474 - acc: 0.6757 - val_loss: 0.8251 - val_acc: 0.6336\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7448 - acc: 0.6751 - val_loss: 0.8239 - val_acc: 0.6331\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.7397 - acc: 0.6773 - val_loss: 0.8110 - val_acc: 0.6373\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7369 - acc: 0.6817 - val_loss: 0.8300 - val_acc: 0.6315\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7366 - acc: 0.6844 - val_loss: 0.8135 - val_acc: 0.6400\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7296 - acc: 0.6817 - val_loss: 0.8149 - val_acc: 0.6400\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7307 - acc: 0.6851 - val_loss: 0.8284 - val_acc: 0.6357\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7258 - acc: 0.6853 - val_loss: 0.8146 - val_acc: 0.6384\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7237 - acc: 0.6828 - val_loss: 0.8255 - val_acc: 0.6341\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7238 - acc: 0.6833 - val_loss: 0.8144 - val_acc: 0.6395\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7202 - acc: 0.6929 - val_loss: 0.8220 - val_acc: 0.6336\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.7151 - acc: 0.6874 - val_loss: 0.8130 - val_acc: 0.6421\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7137 - acc: 0.6936 - val_loss: 0.8202 - val_acc: 0.6315\n",
      "0.582022372776\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0502 - acc: 0.5001 - val_loss: 1.0374 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 1.0347 - acc: 0.5006 - val_loss: 1.0325 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 1.0294 - acc: 0.5006 - val_loss: 1.0272 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 1.0239 - acc: 0.5006 - val_loss: 1.0219 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 1.0182 - acc: 0.5006 - val_loss: 1.0165 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 1.0121 - acc: 0.5006 - val_loss: 1.0107 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0057 - acc: 0.5013 - val_loss: 1.0047 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9992 - acc: 0.5035 - val_loss: 0.9984 - val_acc: 0.5024\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9925 - acc: 0.5049 - val_loss: 0.9912 - val_acc: 0.5077\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9849 - acc: 0.5088 - val_loss: 0.9843 - val_acc: 0.5104\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.9769 - acc: 0.5152 - val_loss: 0.9771 - val_acc: 0.5237\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.9693 - acc: 0.5228 - val_loss: 0.9695 - val_acc: 0.5227\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.9608 - acc: 0.5278 - val_loss: 0.9617 - val_acc: 0.5360\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9528 - acc: 0.5383 - val_loss: 0.9538 - val_acc: 0.5413\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.9446 - acc: 0.5431 - val_loss: 0.9455 - val_acc: 0.5472\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9364 - acc: 0.5568 - val_loss: 0.9397 - val_acc: 0.5435\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.9286 - acc: 0.5630 - val_loss: 0.9317 - val_acc: 0.5531\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9206 - acc: 0.5680 - val_loss: 0.9243 - val_acc: 0.5584\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.9135 - acc: 0.5724 - val_loss: 0.9181 - val_acc: 0.5600\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.9057 - acc: 0.5779 - val_loss: 0.9123 - val_acc: 0.5584\n",
      "Epoch 21/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.8983 - acc: 0.5806 - val_loss: 0.9060 - val_acc: 0.5611\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8917 - acc: 0.5868 - val_loss: 0.9016 - val_acc: 0.5691\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8847 - acc: 0.5925 - val_loss: 0.8961 - val_acc: 0.5653\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8794 - acc: 0.5891 - val_loss: 0.8899 - val_acc: 0.5637\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8731 - acc: 0.5932 - val_loss: 0.8849 - val_acc: 0.5760\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8665 - acc: 0.6053 - val_loss: 0.8817 - val_acc: 0.5691\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8609 - acc: 0.6067 - val_loss: 0.8817 - val_acc: 0.5659\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.8557 - acc: 0.6106 - val_loss: 0.8725 - val_acc: 0.5781\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8499 - acc: 0.6122 - val_loss: 0.8684 - val_acc: 0.5803\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8434 - acc: 0.6161 - val_loss: 0.8849 - val_acc: 0.5819\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8386 - acc: 0.6195 - val_loss: 0.8643 - val_acc: 0.5845\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8345 - acc: 0.6220 - val_loss: 0.8597 - val_acc: 0.5835\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.8292 - acc: 0.6247 - val_loss: 0.8607 - val_acc: 0.5861\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8233 - acc: 0.6314 - val_loss: 0.8567 - val_acc: 0.6053\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8228 - acc: 0.6275 - val_loss: 0.8506 - val_acc: 0.5973\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8182 - acc: 0.6268 - val_loss: 0.8506 - val_acc: 0.6032\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8136 - acc: 0.6380 - val_loss: 0.8461 - val_acc: 0.5957\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8103 - acc: 0.6357 - val_loss: 0.8438 - val_acc: 0.6011\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8053 - acc: 0.6412 - val_loss: 0.8453 - val_acc: 0.5973\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8020 - acc: 0.6437 - val_loss: 0.8417 - val_acc: 0.6016\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7991 - acc: 0.6446 - val_loss: 0.8421 - val_acc: 0.6005\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7960 - acc: 0.6451 - val_loss: 0.8386 - val_acc: 0.6021\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7925 - acc: 0.6467 - val_loss: 0.8410 - val_acc: 0.6123\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.7902 - acc: 0.6476 - val_loss: 0.8344 - val_acc: 0.6027\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7855 - acc: 0.6522 - val_loss: 0.8439 - val_acc: 0.6139\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7835 - acc: 0.6538 - val_loss: 0.8367 - val_acc: 0.6069\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7827 - acc: 0.6508 - val_loss: 0.8306 - val_acc: 0.6144\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7796 - acc: 0.6529 - val_loss: 0.8294 - val_acc: 0.6139\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7743 - acc: 0.6602 - val_loss: 0.8351 - val_acc: 0.6144\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7728 - acc: 0.6574 - val_loss: 0.8287 - val_acc: 0.6128\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7696 - acc: 0.6602 - val_loss: 0.8277 - val_acc: 0.6128\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7670 - acc: 0.6645 - val_loss: 0.8336 - val_acc: 0.6075\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7657 - acc: 0.6616 - val_loss: 0.8245 - val_acc: 0.6165\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7629 - acc: 0.6629 - val_loss: 0.8281 - val_acc: 0.6149\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7607 - acc: 0.6689 - val_loss: 0.8306 - val_acc: 0.6053\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7572 - acc: 0.6712 - val_loss: 0.8203 - val_acc: 0.6112\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7556 - acc: 0.6632 - val_loss: 0.8197 - val_acc: 0.6160\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7506 - acc: 0.6648 - val_loss: 0.8575 - val_acc: 0.6053\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7477 - acc: 0.6741 - val_loss: 0.8226 - val_acc: 0.6197\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7464 - acc: 0.6714 - val_loss: 0.8223 - val_acc: 0.6091\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7444 - acc: 0.6755 - val_loss: 0.8269 - val_acc: 0.6021\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7426 - acc: 0.6785 - val_loss: 0.8269 - val_acc: 0.6181\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7402 - acc: 0.6773 - val_loss: 0.8164 - val_acc: 0.6197\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7337 - acc: 0.6796 - val_loss: 0.8295 - val_acc: 0.6059\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7332 - acc: 0.6757 - val_loss: 0.8179 - val_acc: 0.6176\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7299 - acc: 0.6760 - val_loss: 0.8315 - val_acc: 0.6096\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7279 - acc: 0.6833 - val_loss: 0.8339 - val_acc: 0.6133\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7245 - acc: 0.6913 - val_loss: 0.8213 - val_acc: 0.6107\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7210 - acc: 0.6835 - val_loss: 0.8154 - val_acc: 0.6187\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7170 - acc: 0.6890 - val_loss: 0.8321 - val_acc: 0.6123\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7174 - acc: 0.6901 - val_loss: 0.8170 - val_acc: 0.6245\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7182 - acc: 0.6833 - val_loss: 0.8155 - val_acc: 0.6208\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7129 - acc: 0.6904 - val_loss: 0.8266 - val_acc: 0.6149\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7083 - acc: 0.7013 - val_loss: 0.8129 - val_acc: 0.6240\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7068 - acc: 0.6972 - val_loss: 0.8133 - val_acc: 0.6197\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7076 - acc: 0.6938 - val_loss: 0.8270 - val_acc: 0.6181\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7020 - acc: 0.6949 - val_loss: 0.8157 - val_acc: 0.6208\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7017 - acc: 0.6965 - val_loss: 0.8245 - val_acc: 0.6085\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6978 - acc: 0.7027 - val_loss: 0.8227 - val_acc: 0.6091\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.6938 - acc: 0.7020 - val_loss: 0.8165 - val_acc: 0.6256\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6923 - acc: 0.6995 - val_loss: 0.8107 - val_acc: 0.6256\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6920 - acc: 0.6995 - val_loss: 0.8637 - val_acc: 0.6123\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6890 - acc: 0.7041 - val_loss: 0.8212 - val_acc: 0.6075\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.6842 - acc: 0.7046 - val_loss: 0.8266 - val_acc: 0.6080\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6830 - acc: 0.7066 - val_loss: 0.8251 - val_acc: 0.6272\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6757 - acc: 0.7059 - val_loss: 0.8129 - val_acc: 0.6240\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6740 - acc: 0.7137 - val_loss: 0.8237 - val_acc: 0.6123\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.6732 - acc: 0.7110 - val_loss: 0.8131 - val_acc: 0.6181\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6706 - acc: 0.7185 - val_loss: 0.8208 - val_acc: 0.6304\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6681 - acc: 0.7094 - val_loss: 0.8250 - val_acc: 0.6283\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6680 - acc: 0.7142 - val_loss: 0.8107 - val_acc: 0.6272\n",
      "0.605088654046\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0507 - acc: 0.4997 - val_loss: 1.0367 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0356 - acc: 0.5006 - val_loss: 1.0320 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 1.0308 - acc: 0.5006 - val_loss: 1.0274 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 1.0257 - acc: 0.5006 - val_loss: 1.0225 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 1.0203 - acc: 0.5006 - val_loss: 1.0173 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 1.0143 - acc: 0.5008 - val_loss: 1.0118 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 1.0081 - acc: 0.5008 - val_loss: 1.0058 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 1.0012 - acc: 0.5019 - val_loss: 0.9992 - val_acc: 0.5067\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9932 - acc: 0.5070 - val_loss: 0.9926 - val_acc: 0.5056\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9856 - acc: 0.5122 - val_loss: 0.9845 - val_acc: 0.5216\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9770 - acc: 0.5182 - val_loss: 0.9762 - val_acc: 0.5216\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.9687 - acc: 0.5257 - val_loss: 0.9675 - val_acc: 0.5333\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9585 - acc: 0.5378 - val_loss: 0.9654 - val_acc: 0.5349\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9499 - acc: 0.5438 - val_loss: 0.9523 - val_acc: 0.5349\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9415 - acc: 0.5461 - val_loss: 0.9431 - val_acc: 0.5392\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9334 - acc: 0.5543 - val_loss: 0.9398 - val_acc: 0.5579\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9264 - acc: 0.5605 - val_loss: 0.9267 - val_acc: 0.5653\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9190 - acc: 0.5678 - val_loss: 0.9213 - val_acc: 0.5573\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9104 - acc: 0.5719 - val_loss: 0.9175 - val_acc: 0.5648\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9034 - acc: 0.5767 - val_loss: 0.9144 - val_acc: 0.5621\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8958 - acc: 0.5786 - val_loss: 0.9063 - val_acc: 0.5611\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8905 - acc: 0.5799 - val_loss: 0.8989 - val_acc: 0.5835\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8850 - acc: 0.5872 - val_loss: 0.9031 - val_acc: 0.5728\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8790 - acc: 0.5852 - val_loss: 0.8960 - val_acc: 0.5792\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8739 - acc: 0.5982 - val_loss: 0.8868 - val_acc: 0.5867\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8674 - acc: 0.6005 - val_loss: 0.8843 - val_acc: 0.5936\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8658 - acc: 0.6016 - val_loss: 0.8764 - val_acc: 0.5915\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8590 - acc: 0.6030 - val_loss: 0.8715 - val_acc: 0.5963\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.8540 - acc: 0.6094 - val_loss: 0.8722 - val_acc: 0.5952\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8511 - acc: 0.6062 - val_loss: 0.8861 - val_acc: 0.5931\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8498 - acc: 0.6051 - val_loss: 0.8679 - val_acc: 0.6000\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8401 - acc: 0.6140 - val_loss: 0.8805 - val_acc: 0.6005\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.8371 - acc: 0.6199 - val_loss: 0.8587 - val_acc: 0.6000\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8320 - acc: 0.6247 - val_loss: 0.8617 - val_acc: 0.6037\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8318 - acc: 0.6231 - val_loss: 0.8553 - val_acc: 0.6048\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 504us/step - loss: 0.8285 - acc: 0.6241 - val_loss: 0.8551 - val_acc: 0.6096\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8241 - acc: 0.6151 - val_loss: 0.8498 - val_acc: 0.6096\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.8189 - acc: 0.6316 - val_loss: 0.8683 - val_acc: 0.6005\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8175 - acc: 0.6284 - val_loss: 0.8508 - val_acc: 0.6059\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8128 - acc: 0.6307 - val_loss: 0.8437 - val_acc: 0.6192\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.8104 - acc: 0.6373 - val_loss: 0.8563 - val_acc: 0.6139\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8089 - acc: 0.6353 - val_loss: 0.8412 - val_acc: 0.6208\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8029 - acc: 0.6378 - val_loss: 0.8600 - val_acc: 0.6091\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8020 - acc: 0.6366 - val_loss: 0.8355 - val_acc: 0.6208\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7987 - acc: 0.6378 - val_loss: 0.8389 - val_acc: 0.6133\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7970 - acc: 0.6421 - val_loss: 0.8334 - val_acc: 0.6261\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7907 - acc: 0.6474 - val_loss: 0.8344 - val_acc: 0.6224\n",
      "Epoch 48/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7885 - acc: 0.6490 - val_loss: 0.8314 - val_acc: 0.6181\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7855 - acc: 0.6510 - val_loss: 0.8399 - val_acc: 0.6192\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7813 - acc: 0.6524 - val_loss: 0.8316 - val_acc: 0.6336\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7797 - acc: 0.6499 - val_loss: 0.8263 - val_acc: 0.6240\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7769 - acc: 0.6515 - val_loss: 0.8268 - val_acc: 0.6315\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7735 - acc: 0.6515 - val_loss: 0.8249 - val_acc: 0.6309\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7703 - acc: 0.6545 - val_loss: 0.8457 - val_acc: 0.6251\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7675 - acc: 0.6574 - val_loss: 0.8217 - val_acc: 0.6283\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7635 - acc: 0.6595 - val_loss: 0.8274 - val_acc: 0.6267\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7590 - acc: 0.6677 - val_loss: 0.8255 - val_acc: 0.6363\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7608 - acc: 0.6645 - val_loss: 0.8225 - val_acc: 0.6315\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7557 - acc: 0.6645 - val_loss: 0.8335 - val_acc: 0.6219\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7498 - acc: 0.6728 - val_loss: 0.8421 - val_acc: 0.6272\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7514 - acc: 0.6652 - val_loss: 0.8140 - val_acc: 0.6368\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7455 - acc: 0.6769 - val_loss: 0.8226 - val_acc: 0.6405\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7454 - acc: 0.6705 - val_loss: 0.8134 - val_acc: 0.6416\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7389 - acc: 0.6780 - val_loss: 0.8240 - val_acc: 0.6389\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7366 - acc: 0.6751 - val_loss: 0.8263 - val_acc: 0.6421\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7356 - acc: 0.6725 - val_loss: 0.8135 - val_acc: 0.6416\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7329 - acc: 0.6831 - val_loss: 0.8417 - val_acc: 0.6304\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7275 - acc: 0.6837 - val_loss: 0.8100 - val_acc: 0.6448\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7249 - acc: 0.6826 - val_loss: 0.8101 - val_acc: 0.6512\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7232 - acc: 0.6883 - val_loss: 0.8087 - val_acc: 0.6432\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7197 - acc: 0.6869 - val_loss: 0.8691 - val_acc: 0.6155\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7170 - acc: 0.6879 - val_loss: 0.8297 - val_acc: 0.6437\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7192 - acc: 0.6849 - val_loss: 0.8349 - val_acc: 0.6379\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7125 - acc: 0.6899 - val_loss: 0.8108 - val_acc: 0.6507\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7082 - acc: 0.6988 - val_loss: 0.8091 - val_acc: 0.6512\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7065 - acc: 0.6988 - val_loss: 0.8273 - val_acc: 0.6475\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7012 - acc: 0.7034 - val_loss: 0.8141 - val_acc: 0.6448\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7006 - acc: 0.7018 - val_loss: 0.8266 - val_acc: 0.6352\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6937 - acc: 0.7075 - val_loss: 0.8288 - val_acc: 0.6427\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6952 - acc: 0.6970 - val_loss: 0.8033 - val_acc: 0.6555\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6934 - acc: 0.7000 - val_loss: 0.8300 - val_acc: 0.6336\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.6903 - acc: 0.7016 - val_loss: 0.8303 - val_acc: 0.6400\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6879 - acc: 0.7011 - val_loss: 0.8098 - val_acc: 0.6549\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.6839 - acc: 0.7078 - val_loss: 0.8069 - val_acc: 0.6581\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.6773 - acc: 0.7064 - val_loss: 0.8156 - val_acc: 0.6491\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.6742 - acc: 0.7158 - val_loss: 0.8069 - val_acc: 0.6533\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6729 - acc: 0.7190 - val_loss: 0.8282 - val_acc: 0.6459\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6700 - acc: 0.7132 - val_loss: 0.8126 - val_acc: 0.6533\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.6698 - acc: 0.7151 - val_loss: 0.8109 - val_acc: 0.6587\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6616 - acc: 0.7174 - val_loss: 0.8134 - val_acc: 0.6512\n",
      "0.597594463817\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0530 - acc: 0.4994 - val_loss: 1.0396 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0377 - acc: 0.5006 - val_loss: 1.0360 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 1.0338 - acc: 0.5006 - val_loss: 1.0325 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0301 - acc: 0.5006 - val_loss: 1.0289 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0260 - acc: 0.5006 - val_loss: 1.0251 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0217 - acc: 0.5006 - val_loss: 1.0210 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 1.0169 - acc: 0.5006 - val_loss: 1.0165 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 1.0119 - acc: 0.5006 - val_loss: 1.0116 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0061 - acc: 0.5013 - val_loss: 1.0062 - val_acc: 0.5019\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9999 - acc: 0.5033 - val_loss: 1.0003 - val_acc: 0.5029\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9930 - acc: 0.5056 - val_loss: 0.9942 - val_acc: 0.5051\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9857 - acc: 0.5106 - val_loss: 0.9870 - val_acc: 0.5083\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9779 - acc: 0.5157 - val_loss: 0.9797 - val_acc: 0.5141\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9694 - acc: 0.5255 - val_loss: 0.9725 - val_acc: 0.5253\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9612 - acc: 0.5303 - val_loss: 0.9643 - val_acc: 0.5387\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9525 - acc: 0.5381 - val_loss: 0.9564 - val_acc: 0.5445\n",
      "Epoch 17/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9432 - acc: 0.5447 - val_loss: 0.9493 - val_acc: 0.5493\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.9349 - acc: 0.5502 - val_loss: 0.9414 - val_acc: 0.5472\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9256 - acc: 0.5616 - val_loss: 0.9377 - val_acc: 0.5525\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.9181 - acc: 0.5639 - val_loss: 0.9272 - val_acc: 0.5723\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.9107 - acc: 0.5651 - val_loss: 0.9197 - val_acc: 0.5771\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.9028 - acc: 0.5765 - val_loss: 0.9147 - val_acc: 0.5813\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8951 - acc: 0.5802 - val_loss: 0.9066 - val_acc: 0.5813\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8884 - acc: 0.5859 - val_loss: 0.9012 - val_acc: 0.5765\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8827 - acc: 0.5861 - val_loss: 0.8965 - val_acc: 0.5771\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8761 - acc: 0.5920 - val_loss: 0.8897 - val_acc: 0.5883\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8701 - acc: 0.5934 - val_loss: 0.8881 - val_acc: 0.5909\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8655 - acc: 0.6058 - val_loss: 0.8821 - val_acc: 0.5931\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8605 - acc: 0.6000 - val_loss: 0.8922 - val_acc: 0.5989\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8559 - acc: 0.6053 - val_loss: 0.8724 - val_acc: 0.5899\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8505 - acc: 0.6080 - val_loss: 0.8685 - val_acc: 0.5984\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8459 - acc: 0.6124 - val_loss: 0.8686 - val_acc: 0.6016\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8421 - acc: 0.6154 - val_loss: 0.8675 - val_acc: 0.5925\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8375 - acc: 0.6197 - val_loss: 0.8596 - val_acc: 0.5989\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.8338 - acc: 0.6170 - val_loss: 0.8814 - val_acc: 0.5829\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8302 - acc: 0.6241 - val_loss: 0.8537 - val_acc: 0.6091\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8277 - acc: 0.6284 - val_loss: 0.8651 - val_acc: 0.5931\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8228 - acc: 0.6229 - val_loss: 0.8587 - val_acc: 0.6144\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8219 - acc: 0.6311 - val_loss: 0.8473 - val_acc: 0.6176\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8183 - acc: 0.6275 - val_loss: 0.8452 - val_acc: 0.6128\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.8140 - acc: 0.6339 - val_loss: 0.8505 - val_acc: 0.6043\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8122 - acc: 0.6353 - val_loss: 0.8466 - val_acc: 0.6021\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.8086 - acc: 0.6357 - val_loss: 0.8406 - val_acc: 0.6256\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8043 - acc: 0.6325 - val_loss: 0.8392 - val_acc: 0.6203\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8006 - acc: 0.6398 - val_loss: 0.8487 - val_acc: 0.6032\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7984 - acc: 0.6412 - val_loss: 0.8354 - val_acc: 0.6165\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7966 - acc: 0.6437 - val_loss: 0.8404 - val_acc: 0.6219\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7919 - acc: 0.6485 - val_loss: 0.8326 - val_acc: 0.6309\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7900 - acc: 0.6444 - val_loss: 0.8391 - val_acc: 0.6181\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7881 - acc: 0.6435 - val_loss: 0.8372 - val_acc: 0.6277\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7856 - acc: 0.6533 - val_loss: 0.8302 - val_acc: 0.6277\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7815 - acc: 0.6499 - val_loss: 0.8358 - val_acc: 0.6133\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 513us/step - loss: 0.7788 - acc: 0.6529 - val_loss: 0.8272 - val_acc: 0.6288\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7768 - acc: 0.6602 - val_loss: 0.8266 - val_acc: 0.6267\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.7727 - acc: 0.6547 - val_loss: 0.8274 - val_acc: 0.6203\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7702 - acc: 0.6600 - val_loss: 0.8275 - val_acc: 0.6240\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7688 - acc: 0.6604 - val_loss: 0.8320 - val_acc: 0.6299\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7666 - acc: 0.6611 - val_loss: 0.8617 - val_acc: 0.6000\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.7650 - acc: 0.6611 - val_loss: 0.8199 - val_acc: 0.6373\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7619 - acc: 0.6659 - val_loss: 0.8275 - val_acc: 0.6229\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7564 - acc: 0.6654 - val_loss: 0.8273 - val_acc: 0.6240\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7574 - acc: 0.6677 - val_loss: 0.8440 - val_acc: 0.6261\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7543 - acc: 0.6670 - val_loss: 0.8167 - val_acc: 0.6411\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7527 - acc: 0.6682 - val_loss: 0.8144 - val_acc: 0.6421\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7465 - acc: 0.6755 - val_loss: 0.8202 - val_acc: 0.6283\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.7488 - acc: 0.6707 - val_loss: 0.8159 - val_acc: 0.6363\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7448 - acc: 0.6732 - val_loss: 0.8150 - val_acc: 0.6405\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7405 - acc: 0.6755 - val_loss: 0.8222 - val_acc: 0.6288\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7365 - acc: 0.6746 - val_loss: 0.8166 - val_acc: 0.6389\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7371 - acc: 0.6803 - val_loss: 0.8137 - val_acc: 0.6395\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.7329 - acc: 0.6833 - val_loss: 0.8115 - val_acc: 0.6400\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7307 - acc: 0.6831 - val_loss: 0.8261 - val_acc: 0.6384\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7300 - acc: 0.6831 - val_loss: 0.8089 - val_acc: 0.6400\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7294 - acc: 0.6895 - val_loss: 0.8440 - val_acc: 0.6176\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7255 - acc: 0.6890 - val_loss: 0.8241 - val_acc: 0.6256\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7202 - acc: 0.6851 - val_loss: 0.8113 - val_acc: 0.6432\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7171 - acc: 0.6977 - val_loss: 0.8262 - val_acc: 0.6320\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7167 - acc: 0.6952 - val_loss: 0.8086 - val_acc: 0.6453\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7167 - acc: 0.6947 - val_loss: 0.8100 - val_acc: 0.6400\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7138 - acc: 0.6993 - val_loss: 0.8103 - val_acc: 0.6432\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7093 - acc: 0.6981 - val_loss: 0.8136 - val_acc: 0.6341\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7073 - acc: 0.6970 - val_loss: 0.8090 - val_acc: 0.6395\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7032 - acc: 0.7039 - val_loss: 0.8060 - val_acc: 0.6469\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7021 - acc: 0.7043 - val_loss: 0.8073 - val_acc: 0.6384\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7005 - acc: 0.6984 - val_loss: 0.8107 - val_acc: 0.6421\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.6987 - acc: 0.7048 - val_loss: 0.8302 - val_acc: 0.6235\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.6930 - acc: 0.7055 - val_loss: 0.8069 - val_acc: 0.6432\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6928 - acc: 0.7062 - val_loss: 0.8172 - val_acc: 0.6373\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6860 - acc: 0.7089 - val_loss: 0.8201 - val_acc: 0.6352\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6866 - acc: 0.7110 - val_loss: 0.8304 - val_acc: 0.6368\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6877 - acc: 0.7091 - val_loss: 0.8040 - val_acc: 0.6464\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6809 - acc: 0.7137 - val_loss: 0.8221 - val_acc: 0.6384\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6778 - acc: 0.7151 - val_loss: 0.8050 - val_acc: 0.6485\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6769 - acc: 0.7206 - val_loss: 0.8402 - val_acc: 0.6309\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6718 - acc: 0.7242 - val_loss: 0.8165 - val_acc: 0.6448\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6696 - acc: 0.7199 - val_loss: 0.8195 - val_acc: 0.6389\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 373us/step - loss: 0.6681 - acc: 0.7210 - val_loss: 0.8263 - val_acc: 0.6411\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6675 - acc: 0.7183 - val_loss: 0.8175 - val_acc: 0.6384\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.6627 - acc: 0.7212 - val_loss: 0.8078 - val_acc: 0.6395\n",
      "Epoch 100/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6610 - acc: 0.7272 - val_loss: 0.8716 - val_acc: 0.6075\n",
      "Epoch 101/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6597 - acc: 0.7292 - val_loss: 0.8415 - val_acc: 0.6240\n",
      "0.611518042005\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0524 - acc: 0.4990 - val_loss: 1.0390 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 1.0356 - acc: 0.5006 - val_loss: 1.0340 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 1.0308 - acc: 0.5006 - val_loss: 1.0300 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 1.0268 - acc: 0.5006 - val_loss: 1.0251 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 1.0221 - acc: 0.5006 - val_loss: 1.0204 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 1.0174 - acc: 0.5006 - val_loss: 1.0154 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 1.0122 - acc: 0.5006 - val_loss: 1.0100 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 1.0068 - acc: 0.5008 - val_loss: 1.0042 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 1.0006 - acc: 0.5022 - val_loss: 0.9979 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9943 - acc: 0.5049 - val_loss: 0.9911 - val_acc: 0.5083\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9871 - acc: 0.5104 - val_loss: 0.9840 - val_acc: 0.5104\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.9789 - acc: 0.5157 - val_loss: 0.9766 - val_acc: 0.5205\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9714 - acc: 0.5246 - val_loss: 0.9679 - val_acc: 0.5221\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9632 - acc: 0.5301 - val_loss: 0.9598 - val_acc: 0.5269\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9537 - acc: 0.5337 - val_loss: 0.9512 - val_acc: 0.5344\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9450 - acc: 0.5399 - val_loss: 0.9430 - val_acc: 0.5365\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9359 - acc: 0.5475 - val_loss: 0.9351 - val_acc: 0.5541\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9279 - acc: 0.5580 - val_loss: 0.9276 - val_acc: 0.5632\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9196 - acc: 0.5639 - val_loss: 0.9227 - val_acc: 0.5616\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.9118 - acc: 0.5710 - val_loss: 0.9130 - val_acc: 0.5659\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9036 - acc: 0.5788 - val_loss: 0.9066 - val_acc: 0.5648\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8956 - acc: 0.5788 - val_loss: 0.9006 - val_acc: 0.5877\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8886 - acc: 0.5875 - val_loss: 0.8940 - val_acc: 0.5792\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.8816 - acc: 0.5916 - val_loss: 0.8918 - val_acc: 0.5824\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8750 - acc: 0.6030 - val_loss: 0.8902 - val_acc: 0.5819\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8690 - acc: 0.5998 - val_loss: 0.8891 - val_acc: 0.5813\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8625 - acc: 0.6092 - val_loss: 0.8771 - val_acc: 0.5867\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8570 - acc: 0.6058 - val_loss: 0.8786 - val_acc: 0.5867\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8509 - acc: 0.6126 - val_loss: 0.8688 - val_acc: 0.5947\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8476 - acc: 0.6135 - val_loss: 0.8657 - val_acc: 0.6011\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8418 - acc: 0.6209 - val_loss: 0.8701 - val_acc: 0.5915\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8387 - acc: 0.6179 - val_loss: 0.8647 - val_acc: 0.6000\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8321 - acc: 0.6218 - val_loss: 0.8785 - val_acc: 0.5883\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8291 - acc: 0.6161 - val_loss: 0.8697 - val_acc: 0.6037\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8244 - acc: 0.6254 - val_loss: 0.8595 - val_acc: 0.6123\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8212 - acc: 0.6282 - val_loss: 0.8726 - val_acc: 0.5925\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8181 - acc: 0.6273 - val_loss: 0.8645 - val_acc: 0.5995\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8173 - acc: 0.6321 - val_loss: 0.8502 - val_acc: 0.6128\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8116 - acc: 0.6321 - val_loss: 0.8509 - val_acc: 0.6133\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8066 - acc: 0.6426 - val_loss: 0.8550 - val_acc: 0.6101\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8041 - acc: 0.6449 - val_loss: 0.8956 - val_acc: 0.5813\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8037 - acc: 0.6424 - val_loss: 0.8432 - val_acc: 0.6235\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7984 - acc: 0.6405 - val_loss: 0.8569 - val_acc: 0.6059\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7958 - acc: 0.6426 - val_loss: 0.8437 - val_acc: 0.6149\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7940 - acc: 0.6428 - val_loss: 0.8432 - val_acc: 0.6171\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7896 - acc: 0.6483 - val_loss: 0.8424 - val_acc: 0.6181\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7872 - acc: 0.6490 - val_loss: 0.8368 - val_acc: 0.6245\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7855 - acc: 0.6538 - val_loss: 0.8367 - val_acc: 0.6309\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7803 - acc: 0.6545 - val_loss: 0.8388 - val_acc: 0.6203\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7762 - acc: 0.6581 - val_loss: 0.8422 - val_acc: 0.6283\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7751 - acc: 0.6526 - val_loss: 0.8320 - val_acc: 0.6251\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.7733 - acc: 0.6572 - val_loss: 0.8354 - val_acc: 0.6309\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7698 - acc: 0.6593 - val_loss: 0.8299 - val_acc: 0.6283\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7701 - acc: 0.6558 - val_loss: 0.8310 - val_acc: 0.6283\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7676 - acc: 0.6602 - val_loss: 0.8452 - val_acc: 0.6213\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7628 - acc: 0.6641 - val_loss: 0.8302 - val_acc: 0.6235\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7601 - acc: 0.6691 - val_loss: 0.8257 - val_acc: 0.6288\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7562 - acc: 0.6675 - val_loss: 0.8248 - val_acc: 0.6283\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7558 - acc: 0.6709 - val_loss: 0.8291 - val_acc: 0.6283\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7540 - acc: 0.6670 - val_loss: 0.8435 - val_acc: 0.6224\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.7522 - acc: 0.6721 - val_loss: 0.8344 - val_acc: 0.6245\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7481 - acc: 0.6718 - val_loss: 0.8371 - val_acc: 0.6224\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7453 - acc: 0.6780 - val_loss: 0.8289 - val_acc: 0.6277\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7415 - acc: 0.6785 - val_loss: 0.8374 - val_acc: 0.6192\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7414 - acc: 0.6819 - val_loss: 0.8900 - val_acc: 0.5909\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7402 - acc: 0.6762 - val_loss: 0.8204 - val_acc: 0.6315\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7376 - acc: 0.6831 - val_loss: 0.8360 - val_acc: 0.6261\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7329 - acc: 0.6776 - val_loss: 0.8198 - val_acc: 0.6315\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7316 - acc: 0.6776 - val_loss: 0.8267 - val_acc: 0.6283\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7301 - acc: 0.6785 - val_loss: 0.8349 - val_acc: 0.6309\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7284 - acc: 0.6831 - val_loss: 0.8167 - val_acc: 0.6347\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7241 - acc: 0.6895 - val_loss: 0.8381 - val_acc: 0.6171\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7206 - acc: 0.6863 - val_loss: 0.8181 - val_acc: 0.6363\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 377us/step - loss: 0.7196 - acc: 0.6872 - val_loss: 0.8226 - val_acc: 0.6256\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7190 - acc: 0.6874 - val_loss: 0.8182 - val_acc: 0.6427\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7167 - acc: 0.6879 - val_loss: 0.8259 - val_acc: 0.6309\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7137 - acc: 0.6890 - val_loss: 0.8224 - val_acc: 0.6320\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7104 - acc: 0.6922 - val_loss: 0.8155 - val_acc: 0.6368\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7089 - acc: 0.6952 - val_loss: 0.8197 - val_acc: 0.6304\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7044 - acc: 0.6938 - val_loss: 0.8273 - val_acc: 0.6261\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7055 - acc: 0.6933 - val_loss: 0.8333 - val_acc: 0.6299\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7006 - acc: 0.6940 - val_loss: 0.8135 - val_acc: 0.6379\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6986 - acc: 0.6968 - val_loss: 0.8162 - val_acc: 0.6384\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.6976 - acc: 0.6972 - val_loss: 0.8317 - val_acc: 0.6277\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6927 - acc: 0.7080 - val_loss: 0.8265 - val_acc: 0.6347\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6905 - acc: 0.6984 - val_loss: 0.9091 - val_acc: 0.5936\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6882 - acc: 0.7064 - val_loss: 0.8473 - val_acc: 0.6176\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.6874 - acc: 0.6977 - val_loss: 0.8146 - val_acc: 0.6405\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6851 - acc: 0.7032 - val_loss: 0.8346 - val_acc: 0.6357\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6799 - acc: 0.7130 - val_loss: 0.8217 - val_acc: 0.6389\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.6775 - acc: 0.7039 - val_loss: 0.8220 - val_acc: 0.6384\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6777 - acc: 0.7073 - val_loss: 0.8192 - val_acc: 0.6336\n",
      "0.588657094259\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 6s 1ms/step - loss: 1.0531 - acc: 0.4978 - val_loss: 1.0390 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 1.0362 - acc: 0.5006 - val_loss: 1.0344 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0312 - acc: 0.5006 - val_loss: 1.0303 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 1.0260 - acc: 0.5006 - val_loss: 1.0258 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 1.0202 - acc: 0.5006 - val_loss: 1.0209 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0139 - acc: 0.5006 - val_loss: 1.0156 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 1.0070 - acc: 0.5003 - val_loss: 1.0096 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.9993 - acc: 0.5013 - val_loss: 1.0031 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9908 - acc: 0.5047 - val_loss: 0.9964 - val_acc: 0.5029\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.9817 - acc: 0.5079 - val_loss: 0.9891 - val_acc: 0.5061\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9719 - acc: 0.5159 - val_loss: 0.9841 - val_acc: 0.5077\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9633 - acc: 0.5246 - val_loss: 0.9745 - val_acc: 0.5157\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.9535 - acc: 0.5308 - val_loss: 0.9675 - val_acc: 0.5253\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9436 - acc: 0.5362 - val_loss: 0.9609 - val_acc: 0.5461\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9349 - acc: 0.5532 - val_loss: 0.9537 - val_acc: 0.5355\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9253 - acc: 0.5580 - val_loss: 0.9477 - val_acc: 0.5419\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9175 - acc: 0.5655 - val_loss: 0.9443 - val_acc: 0.5536\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9092 - acc: 0.5747 - val_loss: 0.9392 - val_acc: 0.5509\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9021 - acc: 0.5795 - val_loss: 0.9353 - val_acc: 0.5589\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8940 - acc: 0.5891 - val_loss: 0.9381 - val_acc: 0.5509\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8868 - acc: 0.5911 - val_loss: 0.9198 - val_acc: 0.5531\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8803 - acc: 0.5916 - val_loss: 0.9172 - val_acc: 0.5584\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8728 - acc: 0.6021 - val_loss: 0.9089 - val_acc: 0.5627\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8681 - acc: 0.5989 - val_loss: 0.9026 - val_acc: 0.5643\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.8609 - acc: 0.6053 - val_loss: 0.9056 - val_acc: 0.5728\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8561 - acc: 0.6048 - val_loss: 0.8957 - val_acc: 0.5685\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8507 - acc: 0.6113 - val_loss: 0.8916 - val_acc: 0.5664\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8460 - acc: 0.6106 - val_loss: 0.9067 - val_acc: 0.5643\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8425 - acc: 0.6186 - val_loss: 0.8868 - val_acc: 0.5835\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8353 - acc: 0.6213 - val_loss: 0.8827 - val_acc: 0.5840\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.8336 - acc: 0.6227 - val_loss: 0.8839 - val_acc: 0.5712\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8282 - acc: 0.6241 - val_loss: 0.8806 - val_acc: 0.5840\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8238 - acc: 0.6263 - val_loss: 0.8753 - val_acc: 0.5856\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.8195 - acc: 0.6270 - val_loss: 0.8703 - val_acc: 0.5829\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8182 - acc: 0.6325 - val_loss: 0.8746 - val_acc: 0.5829\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8138 - acc: 0.6353 - val_loss: 0.8755 - val_acc: 0.5819\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8107 - acc: 0.6348 - val_loss: 0.8626 - val_acc: 0.5957\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8086 - acc: 0.6325 - val_loss: 0.8587 - val_acc: 0.5973\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8027 - acc: 0.6396 - val_loss: 0.8611 - val_acc: 0.5952\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.7983 - acc: 0.6385 - val_loss: 0.8775 - val_acc: 0.5792\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7961 - acc: 0.6398 - val_loss: 0.8536 - val_acc: 0.5968\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7923 - acc: 0.6428 - val_loss: 0.8569 - val_acc: 0.6069\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7879 - acc: 0.6467 - val_loss: 0.8573 - val_acc: 0.6080\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7861 - acc: 0.6510 - val_loss: 0.8516 - val_acc: 0.6037\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7840 - acc: 0.6497 - val_loss: 0.8523 - val_acc: 0.6048\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7828 - acc: 0.6531 - val_loss: 0.8525 - val_acc: 0.6096\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7779 - acc: 0.6565 - val_loss: 0.8456 - val_acc: 0.6101\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7738 - acc: 0.6552 - val_loss: 0.8559 - val_acc: 0.6139\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7744 - acc: 0.6604 - val_loss: 0.8578 - val_acc: 0.6176\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7692 - acc: 0.6622 - val_loss: 0.8504 - val_acc: 0.6144\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7657 - acc: 0.6602 - val_loss: 0.8439 - val_acc: 0.6160\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7645 - acc: 0.6634 - val_loss: 0.8403 - val_acc: 0.6171\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7594 - acc: 0.6636 - val_loss: 0.8412 - val_acc: 0.6107\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7588 - acc: 0.6675 - val_loss: 0.8598 - val_acc: 0.6123\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7542 - acc: 0.6709 - val_loss: 0.8447 - val_acc: 0.6203\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7525 - acc: 0.6725 - val_loss: 0.8412 - val_acc: 0.6203\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7510 - acc: 0.6718 - val_loss: 0.8367 - val_acc: 0.6144\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7465 - acc: 0.6753 - val_loss: 0.8589 - val_acc: 0.6075\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7445 - acc: 0.6837 - val_loss: 0.8488 - val_acc: 0.6123\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7419 - acc: 0.6780 - val_loss: 0.8353 - val_acc: 0.6229\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7387 - acc: 0.6780 - val_loss: 0.8390 - val_acc: 0.6112\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.7363 - acc: 0.6789 - val_loss: 0.8387 - val_acc: 0.6149\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7341 - acc: 0.6856 - val_loss: 0.8646 - val_acc: 0.6091\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7319 - acc: 0.6840 - val_loss: 0.8593 - val_acc: 0.6112\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7289 - acc: 0.6835 - val_loss: 0.8336 - val_acc: 0.6219\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7256 - acc: 0.6872 - val_loss: 0.8347 - val_acc: 0.6176\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7223 - acc: 0.6847 - val_loss: 0.8405 - val_acc: 0.6197\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7199 - acc: 0.6954 - val_loss: 0.8404 - val_acc: 0.6171\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7170 - acc: 0.6906 - val_loss: 0.8744 - val_acc: 0.6091\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7156 - acc: 0.6901 - val_loss: 0.8409 - val_acc: 0.6219\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7129 - acc: 0.6931 - val_loss: 0.8340 - val_acc: 0.6219\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7110 - acc: 0.6929 - val_loss: 0.8839 - val_acc: 0.5952\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7061 - acc: 0.6972 - val_loss: 0.8461 - val_acc: 0.6139\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7059 - acc: 0.6947 - val_loss: 0.8491 - val_acc: 0.6123\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6985 - acc: 0.6997 - val_loss: 0.8445 - val_acc: 0.6181\n",
      "0.611516199632\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 7s 2ms/step - loss: 1.0523 - acc: 0.4981 - val_loss: 1.0378 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0336 - acc: 0.5006 - val_loss: 1.0314 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0275 - acc: 0.5006 - val_loss: 1.0259 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 1.0212 - acc: 0.5006 - val_loss: 1.0198 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0143 - acc: 0.5006 - val_loss: 1.0133 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 1.0069 - acc: 0.5006 - val_loss: 1.0064 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9989 - acc: 0.5015 - val_loss: 0.9987 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.9905 - acc: 0.5024 - val_loss: 0.9904 - val_acc: 0.5040\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9814 - acc: 0.5051 - val_loss: 0.9824 - val_acc: 0.5093\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9719 - acc: 0.5134 - val_loss: 0.9732 - val_acc: 0.5157\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9628 - acc: 0.5262 - val_loss: 0.9665 - val_acc: 0.5248\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9541 - acc: 0.5342 - val_loss: 0.9594 - val_acc: 0.5360\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9444 - acc: 0.5461 - val_loss: 0.9485 - val_acc: 0.5381\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.9360 - acc: 0.5518 - val_loss: 0.9419 - val_acc: 0.5472\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.9281 - acc: 0.5625 - val_loss: 0.9345 - val_acc: 0.5568\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 505us/step - loss: 0.9200 - acc: 0.5701 - val_loss: 0.9303 - val_acc: 0.5563\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.9120 - acc: 0.5749 - val_loss: 0.9206 - val_acc: 0.5685\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 366us/step - loss: 0.9052 - acc: 0.5824 - val_loss: 0.9156 - val_acc: 0.5653\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8977 - acc: 0.5884 - val_loss: 0.9098 - val_acc: 0.5744\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8918 - acc: 0.5952 - val_loss: 0.9040 - val_acc: 0.5792\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8854 - acc: 0.6023 - val_loss: 0.8980 - val_acc: 0.5819\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8772 - acc: 0.6055 - val_loss: 0.8946 - val_acc: 0.5776\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8730 - acc: 0.6058 - val_loss: 0.8880 - val_acc: 0.5851\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8674 - acc: 0.6097 - val_loss: 0.8844 - val_acc: 0.5915\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8624 - acc: 0.6092 - val_loss: 0.8828 - val_acc: 0.5797\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8563 - acc: 0.6140 - val_loss: 0.8755 - val_acc: 0.5968\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8508 - acc: 0.6147 - val_loss: 0.8749 - val_acc: 0.5995\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8453 - acc: 0.6174 - val_loss: 0.8699 - val_acc: 0.5947\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8403 - acc: 0.6202 - val_loss: 0.8648 - val_acc: 0.6016\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8371 - acc: 0.6245 - val_loss: 0.8650 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8340 - acc: 0.6254 - val_loss: 0.8618 - val_acc: 0.6069\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8271 - acc: 0.6298 - val_loss: 0.8622 - val_acc: 0.6091\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8248 - acc: 0.6284 - val_loss: 0.8560 - val_acc: 0.6075\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8181 - acc: 0.6387 - val_loss: 0.8612 - val_acc: 0.6101\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8147 - acc: 0.6382 - val_loss: 0.8533 - val_acc: 0.6080\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8125 - acc: 0.6405 - val_loss: 0.8487 - val_acc: 0.6160\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8097 - acc: 0.6375 - val_loss: 0.8493 - val_acc: 0.6069\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.8049 - acc: 0.6435 - val_loss: 0.8461 - val_acc: 0.6128\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8025 - acc: 0.6398 - val_loss: 0.8606 - val_acc: 0.6032\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7998 - acc: 0.6474 - val_loss: 0.8525 - val_acc: 0.6101\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7979 - acc: 0.6453 - val_loss: 0.8464 - val_acc: 0.6123\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7938 - acc: 0.6460 - val_loss: 0.8419 - val_acc: 0.6176\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7915 - acc: 0.6517 - val_loss: 0.8424 - val_acc: 0.6224\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7871 - acc: 0.6526 - val_loss: 0.8425 - val_acc: 0.6208\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.7856 - acc: 0.6506 - val_loss: 0.8338 - val_acc: 0.6293\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7837 - acc: 0.6565 - val_loss: 0.9024 - val_acc: 0.5621\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.7796 - acc: 0.6586 - val_loss: 0.8308 - val_acc: 0.6235\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7774 - acc: 0.6563 - val_loss: 0.8313 - val_acc: 0.6272\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7735 - acc: 0.6627 - val_loss: 0.8319 - val_acc: 0.6272\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7703 - acc: 0.6597 - val_loss: 0.8351 - val_acc: 0.6267\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7673 - acc: 0.6650 - val_loss: 0.8322 - val_acc: 0.6197\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7672 - acc: 0.6659 - val_loss: 0.8523 - val_acc: 0.6149\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7643 - acc: 0.6661 - val_loss: 0.8353 - val_acc: 0.6235\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7596 - acc: 0.6670 - val_loss: 0.8291 - val_acc: 0.6331\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7576 - acc: 0.6700 - val_loss: 0.8468 - val_acc: 0.6096\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7553 - acc: 0.6650 - val_loss: 0.8310 - val_acc: 0.6245\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7534 - acc: 0.6691 - val_loss: 0.8215 - val_acc: 0.6325\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7512 - acc: 0.6725 - val_loss: 0.8200 - val_acc: 0.6277\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7493 - acc: 0.6702 - val_loss: 0.8193 - val_acc: 0.6304\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7466 - acc: 0.6815 - val_loss: 0.8188 - val_acc: 0.6309\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7418 - acc: 0.6785 - val_loss: 0.8355 - val_acc: 0.6160\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7389 - acc: 0.6732 - val_loss: 0.8203 - val_acc: 0.6304\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7357 - acc: 0.6741 - val_loss: 0.8185 - val_acc: 0.6352\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7370 - acc: 0.6746 - val_loss: 0.8236 - val_acc: 0.6256\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7317 - acc: 0.6842 - val_loss: 0.8393 - val_acc: 0.6165\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7306 - acc: 0.6789 - val_loss: 0.8329 - val_acc: 0.6219\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7265 - acc: 0.6860 - val_loss: 0.8187 - val_acc: 0.6389\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7260 - acc: 0.6773 - val_loss: 0.8120 - val_acc: 0.6384\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7232 - acc: 0.6851 - val_loss: 0.8199 - val_acc: 0.6251\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7197 - acc: 0.6837 - val_loss: 0.8122 - val_acc: 0.6352\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7185 - acc: 0.6917 - val_loss: 0.8257 - val_acc: 0.6373\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7141 - acc: 0.6872 - val_loss: 0.8209 - val_acc: 0.6336\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7144 - acc: 0.6865 - val_loss: 0.8252 - val_acc: 0.6331\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7111 - acc: 0.6927 - val_loss: 0.8139 - val_acc: 0.6373\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7065 - acc: 0.6933 - val_loss: 0.8457 - val_acc: 0.6373\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7107 - acc: 0.6890 - val_loss: 0.8137 - val_acc: 0.6373\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7041 - acc: 0.6979 - val_loss: 0.8047 - val_acc: 0.6437\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7007 - acc: 0.6970 - val_loss: 0.8285 - val_acc: 0.6272\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6987 - acc: 0.6954 - val_loss: 0.8057 - val_acc: 0.6357\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6929 - acc: 0.7009 - val_loss: 0.8076 - val_acc: 0.6395\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.6920 - acc: 0.7025 - val_loss: 0.8049 - val_acc: 0.6400\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.6921 - acc: 0.7004 - val_loss: 0.8297 - val_acc: 0.6283\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.6892 - acc: 0.7032 - val_loss: 0.8072 - val_acc: 0.6437\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6880 - acc: 0.7055 - val_loss: 0.8023 - val_acc: 0.6411\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.6853 - acc: 0.7075 - val_loss: 0.8525 - val_acc: 0.6373\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6805 - acc: 0.7068 - val_loss: 0.8215 - val_acc: 0.6395\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6768 - acc: 0.7082 - val_loss: 0.8238 - val_acc: 0.6357\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.6753 - acc: 0.7078 - val_loss: 0.8390 - val_acc: 0.6384\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.6744 - acc: 0.7068 - val_loss: 0.8274 - val_acc: 0.6395\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6688 - acc: 0.7171 - val_loss: 0.8143 - val_acc: 0.6400\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6676 - acc: 0.7146 - val_loss: 0.8059 - val_acc: 0.6459\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6624 - acc: 0.7199 - val_loss: 0.8057 - val_acc: 0.6432\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6647 - acc: 0.7171 - val_loss: 0.8068 - val_acc: 0.6453\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6607 - acc: 0.7169 - val_loss: 0.8124 - val_acc: 0.6485\n",
      "0.591369319624\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 7s 1ms/step - loss: 1.0496 - acc: 0.4983 - val_loss: 1.0389 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 1.0363 - acc: 0.5006 - val_loss: 1.0347 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 1.0318 - acc: 0.5006 - val_loss: 1.0304 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 1.0269 - acc: 0.5006 - val_loss: 1.0264 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0225 - acc: 0.5006 - val_loss: 1.0212 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0173 - acc: 0.5006 - val_loss: 1.0157 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0114 - acc: 0.5008 - val_loss: 1.0100 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0054 - acc: 0.5029 - val_loss: 1.0037 - val_acc: 0.5008\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9987 - acc: 0.5065 - val_loss: 0.9967 - val_acc: 0.5072\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.9908 - acc: 0.5134 - val_loss: 0.9901 - val_acc: 0.5093\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9833 - acc: 0.5173 - val_loss: 0.9808 - val_acc: 0.5125\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.9747 - acc: 0.5218 - val_loss: 0.9732 - val_acc: 0.5205\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9661 - acc: 0.5285 - val_loss: 0.9634 - val_acc: 0.5285\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.9565 - acc: 0.5360 - val_loss: 0.9555 - val_acc: 0.5435\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9476 - acc: 0.5445 - val_loss: 0.9459 - val_acc: 0.5504\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.9384 - acc: 0.5529 - val_loss: 0.9388 - val_acc: 0.5456\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.9282 - acc: 0.5591 - val_loss: 0.9305 - val_acc: 0.5627\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.9189 - acc: 0.5687 - val_loss: 0.9206 - val_acc: 0.5696\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9098 - acc: 0.5749 - val_loss: 0.9170 - val_acc: 0.5819\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9021 - acc: 0.5802 - val_loss: 0.9093 - val_acc: 0.5803\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8914 - acc: 0.5888 - val_loss: 0.9041 - val_acc: 0.5824\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8842 - acc: 0.5943 - val_loss: 0.8957 - val_acc: 0.5867\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8776 - acc: 0.5904 - val_loss: 0.8892 - val_acc: 0.5893\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8710 - acc: 0.6019 - val_loss: 0.8856 - val_acc: 0.5899\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8648 - acc: 0.6021 - val_loss: 0.8910 - val_acc: 0.5819\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8596 - acc: 0.6042 - val_loss: 0.8807 - val_acc: 0.5931\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8539 - acc: 0.6103 - val_loss: 0.8789 - val_acc: 0.5968\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8501 - acc: 0.6060 - val_loss: 0.8718 - val_acc: 0.5989\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8450 - acc: 0.6087 - val_loss: 0.8731 - val_acc: 0.6011\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8369 - acc: 0.6117 - val_loss: 0.8693 - val_acc: 0.5995\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8351 - acc: 0.6199 - val_loss: 0.8614 - val_acc: 0.6075\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8314 - acc: 0.6213 - val_loss: 0.8693 - val_acc: 0.5989\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8285 - acc: 0.6252 - val_loss: 0.8959 - val_acc: 0.5829\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8236 - acc: 0.6261 - val_loss: 0.8554 - val_acc: 0.6139\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8193 - acc: 0.6277 - val_loss: 0.8593 - val_acc: 0.6128\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8145 - acc: 0.6293 - val_loss: 0.8551 - val_acc: 0.6053\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.8116 - acc: 0.6238 - val_loss: 0.8623 - val_acc: 0.6043\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 382us/step - loss: 0.8103 - acc: 0.6332 - val_loss: 0.8570 - val_acc: 0.6053\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.8052 - acc: 0.6387 - val_loss: 0.8564 - val_acc: 0.6096\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.8012 - acc: 0.6437 - val_loss: 0.8533 - val_acc: 0.6165\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8008 - acc: 0.6408 - val_loss: 0.8451 - val_acc: 0.6187\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7975 - acc: 0.6467 - val_loss: 0.8473 - val_acc: 0.6187\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7930 - acc: 0.6442 - val_loss: 0.8453 - val_acc: 0.6219\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7900 - acc: 0.6462 - val_loss: 0.8554 - val_acc: 0.6101\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7891 - acc: 0.6485 - val_loss: 0.8474 - val_acc: 0.6123\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7846 - acc: 0.6492 - val_loss: 0.8446 - val_acc: 0.6240\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7820 - acc: 0.6517 - val_loss: 0.8422 - val_acc: 0.6229\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7799 - acc: 0.6552 - val_loss: 0.8385 - val_acc: 0.6219\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7737 - acc: 0.6547 - val_loss: 0.8510 - val_acc: 0.6069\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7736 - acc: 0.6565 - val_loss: 0.8358 - val_acc: 0.6229\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7716 - acc: 0.6602 - val_loss: 0.8380 - val_acc: 0.6208\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7685 - acc: 0.6618 - val_loss: 0.8342 - val_acc: 0.6277\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7666 - acc: 0.6568 - val_loss: 0.8346 - val_acc: 0.6293\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7629 - acc: 0.6622 - val_loss: 0.8356 - val_acc: 0.6261\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7593 - acc: 0.6618 - val_loss: 0.8405 - val_acc: 0.6144\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7577 - acc: 0.6659 - val_loss: 0.8337 - val_acc: 0.6251\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7567 - acc: 0.6650 - val_loss: 0.8354 - val_acc: 0.6240\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7527 - acc: 0.6691 - val_loss: 0.8550 - val_acc: 0.6197\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7501 - acc: 0.6673 - val_loss: 0.8375 - val_acc: 0.6256\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7470 - acc: 0.6760 - val_loss: 0.8280 - val_acc: 0.6363\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7449 - acc: 0.6753 - val_loss: 0.8265 - val_acc: 0.6325\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7417 - acc: 0.6732 - val_loss: 0.8815 - val_acc: 0.5963\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7388 - acc: 0.6799 - val_loss: 0.8474 - val_acc: 0.6128\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7371 - acc: 0.6778 - val_loss: 0.8254 - val_acc: 0.6368\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7337 - acc: 0.6851 - val_loss: 0.8284 - val_acc: 0.6325\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7316 - acc: 0.6789 - val_loss: 0.8520 - val_acc: 0.6107\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7303 - acc: 0.6815 - val_loss: 0.8231 - val_acc: 0.6352\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7284 - acc: 0.6856 - val_loss: 0.8251 - val_acc: 0.6363\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 357us/step - loss: 0.7241 - acc: 0.6874 - val_loss: 0.8446 - val_acc: 0.6208\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7232 - acc: 0.6874 - val_loss: 0.8250 - val_acc: 0.6363\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7226 - acc: 0.6872 - val_loss: 0.8323 - val_acc: 0.6256\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.7194 - acc: 0.6890 - val_loss: 0.8219 - val_acc: 0.6368\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7150 - acc: 0.6924 - val_loss: 0.8242 - val_acc: 0.6379\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7113 - acc: 0.6940 - val_loss: 0.8210 - val_acc: 0.6357\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7140 - acc: 0.6920 - val_loss: 0.8335 - val_acc: 0.6277\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7096 - acc: 0.6922 - val_loss: 0.8242 - val_acc: 0.6389\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 365us/step - loss: 0.7052 - acc: 0.6979 - val_loss: 0.8212 - val_acc: 0.6379\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7025 - acc: 0.7057 - val_loss: 0.8630 - val_acc: 0.6181\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7013 - acc: 0.7009 - val_loss: 0.8410 - val_acc: 0.6283\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 372us/step - loss: 0.7002 - acc: 0.6963 - val_loss: 0.8241 - val_acc: 0.6373\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6962 - acc: 0.7000 - val_loss: 0.8187 - val_acc: 0.6459\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6950 - acc: 0.7023 - val_loss: 0.8513 - val_acc: 0.6219\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6926 - acc: 0.7016 - val_loss: 0.8220 - val_acc: 0.6357\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6900 - acc: 0.7073 - val_loss: 0.8157 - val_acc: 0.6421\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6857 - acc: 0.7087 - val_loss: 0.8208 - val_acc: 0.6448\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6839 - acc: 0.7116 - val_loss: 0.8219 - val_acc: 0.6400\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6838 - acc: 0.7082 - val_loss: 0.8257 - val_acc: 0.6368\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.6788 - acc: 0.7158 - val_loss: 0.8583 - val_acc: 0.6187\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.6802 - acc: 0.7119 - val_loss: 0.8250 - val_acc: 0.6427\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6754 - acc: 0.7128 - val_loss: 0.8226 - val_acc: 0.6357\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6738 - acc: 0.7174 - val_loss: 0.8253 - val_acc: 0.6437\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.6702 - acc: 0.7155 - val_loss: 0.8421 - val_acc: 0.6373\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6696 - acc: 0.7178 - val_loss: 0.8522 - val_acc: 0.6283\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.6682 - acc: 0.7132 - val_loss: 0.8259 - val_acc: 0.6437\n",
      "0.602764032147\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 7s 2ms/step - loss: 1.0516 - acc: 0.5001 - val_loss: 1.0370 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 1.0355 - acc: 0.5006 - val_loss: 1.0319 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0305 - acc: 0.5006 - val_loss: 1.0267 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 1.0252 - acc: 0.5006 - val_loss: 1.0214 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0200 - acc: 0.5006 - val_loss: 1.0157 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0143 - acc: 0.5006 - val_loss: 1.0093 - val_acc: 0.5013\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 1.0080 - acc: 0.5010 - val_loss: 1.0030 - val_acc: 0.5029\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 1.0016 - acc: 0.5022 - val_loss: 0.9955 - val_acc: 0.5035\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9949 - acc: 0.5031 - val_loss: 0.9878 - val_acc: 0.5051\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.9874 - acc: 0.5072 - val_loss: 0.9800 - val_acc: 0.5093\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9799 - acc: 0.5120 - val_loss: 0.9715 - val_acc: 0.5168\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9722 - acc: 0.5209 - val_loss: 0.9648 - val_acc: 0.5243\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9651 - acc: 0.5255 - val_loss: 0.9557 - val_acc: 0.5296\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.9572 - acc: 0.5340 - val_loss: 0.9505 - val_acc: 0.5285\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.9505 - acc: 0.5376 - val_loss: 0.9416 - val_acc: 0.5371\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9443 - acc: 0.5454 - val_loss: 0.9334 - val_acc: 0.5515\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9367 - acc: 0.5559 - val_loss: 0.9381 - val_acc: 0.5643\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9300 - acc: 0.5541 - val_loss: 0.9372 - val_acc: 0.5669\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9236 - acc: 0.5619 - val_loss: 0.9180 - val_acc: 0.5525\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9163 - acc: 0.5689 - val_loss: 0.9154 - val_acc: 0.5765\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9093 - acc: 0.5721 - val_loss: 0.9068 - val_acc: 0.5648\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9028 - acc: 0.5726 - val_loss: 0.8953 - val_acc: 0.5808\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8957 - acc: 0.5790 - val_loss: 0.8922 - val_acc: 0.5776\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8896 - acc: 0.5875 - val_loss: 0.8926 - val_acc: 0.5888\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8828 - acc: 0.5911 - val_loss: 0.8786 - val_acc: 0.5931\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.8751 - acc: 0.5946 - val_loss: 0.8802 - val_acc: 0.5899\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8698 - acc: 0.5982 - val_loss: 0.8672 - val_acc: 0.5883\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8643 - acc: 0.6051 - val_loss: 0.8662 - val_acc: 0.6032\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8551 - acc: 0.6119 - val_loss: 0.8606 - val_acc: 0.5936\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8526 - acc: 0.6032 - val_loss: 0.8682 - val_acc: 0.5984\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8462 - acc: 0.6138 - val_loss: 0.8531 - val_acc: 0.6075\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8398 - acc: 0.6204 - val_loss: 0.8550 - val_acc: 0.6048\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8357 - acc: 0.6206 - val_loss: 0.8504 - val_acc: 0.6069\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8327 - acc: 0.6188 - val_loss: 0.8505 - val_acc: 0.6123\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8294 - acc: 0.6270 - val_loss: 0.8422 - val_acc: 0.6085\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8226 - acc: 0.6273 - val_loss: 0.8410 - val_acc: 0.6101\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8196 - acc: 0.6277 - val_loss: 0.8534 - val_acc: 0.6000\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8194 - acc: 0.6284 - val_loss: 0.8479 - val_acc: 0.6011\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8140 - acc: 0.6286 - val_loss: 0.8405 - val_acc: 0.6059\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8083 - acc: 0.6300 - val_loss: 0.8429 - val_acc: 0.6091\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8065 - acc: 0.6398 - val_loss: 0.8324 - val_acc: 0.6139\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8037 - acc: 0.6396 - val_loss: 0.8344 - val_acc: 0.6176\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.8001 - acc: 0.6444 - val_loss: 0.8343 - val_acc: 0.6123\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.7998 - acc: 0.6410 - val_loss: 0.8331 - val_acc: 0.6144\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7950 - acc: 0.6440 - val_loss: 0.8301 - val_acc: 0.6165\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7940 - acc: 0.6428 - val_loss: 0.8322 - val_acc: 0.6251\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7888 - acc: 0.6492 - val_loss: 0.8268 - val_acc: 0.6155\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7881 - acc: 0.6465 - val_loss: 0.8276 - val_acc: 0.6139\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7829 - acc: 0.6467 - val_loss: 0.8264 - val_acc: 0.6160\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7802 - acc: 0.6554 - val_loss: 0.8284 - val_acc: 0.6171\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7784 - acc: 0.6536 - val_loss: 0.8270 - val_acc: 0.6155\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7764 - acc: 0.6540 - val_loss: 0.8355 - val_acc: 0.6181\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7735 - acc: 0.6520 - val_loss: 0.8335 - val_acc: 0.6128\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7704 - acc: 0.6568 - val_loss: 0.8204 - val_acc: 0.6197\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7690 - acc: 0.6581 - val_loss: 0.8283 - val_acc: 0.6251\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7663 - acc: 0.6549 - val_loss: 0.8303 - val_acc: 0.6256\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7610 - acc: 0.6680 - val_loss: 0.8224 - val_acc: 0.6176\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7596 - acc: 0.6645 - val_loss: 0.8265 - val_acc: 0.6229\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7593 - acc: 0.6645 - val_loss: 0.8258 - val_acc: 0.6245\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7558 - acc: 0.6680 - val_loss: 0.8319 - val_acc: 0.6219\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7554 - acc: 0.6686 - val_loss: 0.8338 - val_acc: 0.6213\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7503 - acc: 0.6744 - val_loss: 0.8272 - val_acc: 0.6197\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7510 - acc: 0.6673 - val_loss: 0.8176 - val_acc: 0.6203\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7457 - acc: 0.6785 - val_loss: 0.8143 - val_acc: 0.6251\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7432 - acc: 0.6712 - val_loss: 0.8143 - val_acc: 0.6240\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7405 - acc: 0.6744 - val_loss: 0.8217 - val_acc: 0.6171\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7397 - acc: 0.6773 - val_loss: 0.8277 - val_acc: 0.6096\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7377 - acc: 0.6799 - val_loss: 0.8149 - val_acc: 0.6256\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7316 - acc: 0.6812 - val_loss: 0.8403 - val_acc: 0.6091\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7312 - acc: 0.6856 - val_loss: 0.8139 - val_acc: 0.6229\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7276 - acc: 0.6810 - val_loss: 0.8152 - val_acc: 0.6245\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7253 - acc: 0.6847 - val_loss: 0.8128 - val_acc: 0.6224\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.7278 - acc: 0.6833 - val_loss: 0.8107 - val_acc: 0.6267\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.7240 - acc: 0.6872 - val_loss: 0.8390 - val_acc: 0.6128\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7196 - acc: 0.6899 - val_loss: 0.8140 - val_acc: 0.6245\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7209 - acc: 0.6874 - val_loss: 0.8116 - val_acc: 0.6219\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7133 - acc: 0.6908 - val_loss: 0.8202 - val_acc: 0.6176\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7122 - acc: 0.6943 - val_loss: 0.8179 - val_acc: 0.6267\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7107 - acc: 0.6858 - val_loss: 0.8245 - val_acc: 0.6176\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7111 - acc: 0.6947 - val_loss: 0.8079 - val_acc: 0.6283\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7060 - acc: 0.6913 - val_loss: 0.8074 - val_acc: 0.6309\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7056 - acc: 0.6965 - val_loss: 0.8208 - val_acc: 0.6229\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7025 - acc: 0.6947 - val_loss: 0.8130 - val_acc: 0.6288\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6991 - acc: 0.6956 - val_loss: 0.8170 - val_acc: 0.6283\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6968 - acc: 0.6931 - val_loss: 0.8386 - val_acc: 0.6277\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6937 - acc: 0.7027 - val_loss: 0.8058 - val_acc: 0.6309\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.6932 - acc: 0.6949 - val_loss: 0.8046 - val_acc: 0.6325\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6902 - acc: 0.7018 - val_loss: 0.8108 - val_acc: 0.6352\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 378us/step - loss: 0.6894 - acc: 0.7000 - val_loss: 0.8145 - val_acc: 0.6336\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.6855 - acc: 0.7052 - val_loss: 0.8228 - val_acc: 0.6379\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.6853 - acc: 0.6997 - val_loss: 0.8128 - val_acc: 0.6288\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.6830 - acc: 0.7002 - val_loss: 0.8087 - val_acc: 0.6347\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 387us/step - loss: 0.6781 - acc: 0.7087 - val_loss: 0.8271 - val_acc: 0.6384\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 358us/step - loss: 0.6743 - acc: 0.7126 - val_loss: 0.8267 - val_acc: 0.6235\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6755 - acc: 0.7084 - val_loss: 0.8050 - val_acc: 0.6363\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6709 - acc: 0.7144 - val_loss: 0.8081 - val_acc: 0.6347\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6694 - acc: 0.7139 - val_loss: 0.8083 - val_acc: 0.6357\n",
      "0.608610554705\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 7s 2ms/step - loss: 1.0509 - acc: 0.4990 - val_loss: 1.0376 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 1.0358 - acc: 0.5006 - val_loss: 1.0329 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0310 - acc: 0.5006 - val_loss: 1.0281 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 1.0261 - acc: 0.5006 - val_loss: 1.0231 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0207 - acc: 0.5006 - val_loss: 1.0181 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 1.0150 - acc: 0.5008 - val_loss: 1.0114 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 1.0080 - acc: 0.5008 - val_loss: 1.0054 - val_acc: 0.5040\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0010 - acc: 0.5033 - val_loss: 0.9969 - val_acc: 0.5061\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9933 - acc: 0.5051 - val_loss: 0.9886 - val_acc: 0.5077\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9847 - acc: 0.5079 - val_loss: 0.9798 - val_acc: 0.5136\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9761 - acc: 0.5180 - val_loss: 0.9695 - val_acc: 0.5168\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9667 - acc: 0.5214 - val_loss: 0.9613 - val_acc: 0.5216\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9577 - acc: 0.5319 - val_loss: 0.9503 - val_acc: 0.5355\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9491 - acc: 0.5381 - val_loss: 0.9412 - val_acc: 0.5333\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9405 - acc: 0.5431 - val_loss: 0.9332 - val_acc: 0.5408\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.9323 - acc: 0.5523 - val_loss: 0.9252 - val_acc: 0.5653\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9236 - acc: 0.5637 - val_loss: 0.9188 - val_acc: 0.5717\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9170 - acc: 0.5600 - val_loss: 0.9119 - val_acc: 0.5627\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9092 - acc: 0.5657 - val_loss: 0.9074 - val_acc: 0.5760\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.9029 - acc: 0.5744 - val_loss: 0.9028 - val_acc: 0.5909\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8959 - acc: 0.5783 - val_loss: 0.8966 - val_acc: 0.5867\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8883 - acc: 0.5872 - val_loss: 0.8901 - val_acc: 0.5909\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.8835 - acc: 0.5856 - val_loss: 0.8868 - val_acc: 0.5968\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.8762 - acc: 0.5925 - val_loss: 0.8852 - val_acc: 0.5936\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.8691 - acc: 0.5984 - val_loss: 0.8777 - val_acc: 0.5968\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8622 - acc: 0.6014 - val_loss: 0.8760 - val_acc: 0.5915\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8599 - acc: 0.5996 - val_loss: 0.8740 - val_acc: 0.6101\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8523 - acc: 0.6080 - val_loss: 0.8705 - val_acc: 0.5952\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8483 - acc: 0.6106 - val_loss: 0.8671 - val_acc: 0.6075\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8420 - acc: 0.6147 - val_loss: 0.8896 - val_acc: 0.5813\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8380 - acc: 0.6165 - val_loss: 0.8648 - val_acc: 0.6059\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8343 - acc: 0.6186 - val_loss: 0.8633 - val_acc: 0.5973\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8311 - acc: 0.6222 - val_loss: 0.8604 - val_acc: 0.6027\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8250 - acc: 0.6250 - val_loss: 0.8598 - val_acc: 0.6064\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8206 - acc: 0.6295 - val_loss: 0.8611 - val_acc: 0.6021\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8180 - acc: 0.6334 - val_loss: 0.8483 - val_acc: 0.6101\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8153 - acc: 0.6323 - val_loss: 0.8459 - val_acc: 0.6096\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8091 - acc: 0.6364 - val_loss: 0.8443 - val_acc: 0.6123\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8065 - acc: 0.6357 - val_loss: 0.8469 - val_acc: 0.6139\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.8031 - acc: 0.6412 - val_loss: 0.8621 - val_acc: 0.6021\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7994 - acc: 0.6410 - val_loss: 0.8477 - val_acc: 0.6107\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7985 - acc: 0.6440 - val_loss: 0.8410 - val_acc: 0.6091\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7942 - acc: 0.6380 - val_loss: 0.8499 - val_acc: 0.6112\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.7911 - acc: 0.6474 - val_loss: 0.8399 - val_acc: 0.6171\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7893 - acc: 0.6440 - val_loss: 0.8377 - val_acc: 0.6069\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7850 - acc: 0.6513 - val_loss: 0.8680 - val_acc: 0.5968\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7828 - acc: 0.6558 - val_loss: 0.8402 - val_acc: 0.6176\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7785 - acc: 0.6549 - val_loss: 0.8525 - val_acc: 0.6027\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7759 - acc: 0.6552 - val_loss: 0.8357 - val_acc: 0.6187\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7716 - acc: 0.6568 - val_loss: 0.8405 - val_acc: 0.6208\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.7706 - acc: 0.6632 - val_loss: 0.8268 - val_acc: 0.6208\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7672 - acc: 0.6581 - val_loss: 0.8527 - val_acc: 0.6107\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7653 - acc: 0.6638 - val_loss: 0.8261 - val_acc: 0.6240\n",
      "Epoch 54/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7635 - acc: 0.6597 - val_loss: 0.8300 - val_acc: 0.6219\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7580 - acc: 0.6725 - val_loss: 0.8295 - val_acc: 0.6197\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7574 - acc: 0.6705 - val_loss: 0.8401 - val_acc: 0.6144\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7553 - acc: 0.6657 - val_loss: 0.8287 - val_acc: 0.6155\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7542 - acc: 0.6668 - val_loss: 0.8227 - val_acc: 0.6229\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7521 - acc: 0.6723 - val_loss: 0.8225 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7477 - acc: 0.6723 - val_loss: 0.8250 - val_acc: 0.6325\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7475 - acc: 0.6700 - val_loss: 0.8272 - val_acc: 0.6197\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7422 - acc: 0.6789 - val_loss: 0.8288 - val_acc: 0.6229\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7398 - acc: 0.6760 - val_loss: 0.8238 - val_acc: 0.6325\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7372 - acc: 0.6810 - val_loss: 0.8299 - val_acc: 0.6251\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7354 - acc: 0.6783 - val_loss: 0.8386 - val_acc: 0.6208\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7319 - acc: 0.6794 - val_loss: 0.8153 - val_acc: 0.6283\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7301 - acc: 0.6801 - val_loss: 0.8599 - val_acc: 0.6075\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7284 - acc: 0.6787 - val_loss: 0.8389 - val_acc: 0.6229\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7246 - acc: 0.6847 - val_loss: 0.8347 - val_acc: 0.6283\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7252 - acc: 0.6824 - val_loss: 0.8095 - val_acc: 0.6336\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7209 - acc: 0.6858 - val_loss: 0.8282 - val_acc: 0.6299\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7173 - acc: 0.6899 - val_loss: 0.8221 - val_acc: 0.6357\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7153 - acc: 0.6947 - val_loss: 0.8358 - val_acc: 0.6187\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7151 - acc: 0.6984 - val_loss: 0.8160 - val_acc: 0.6384\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7112 - acc: 0.6908 - val_loss: 0.8205 - val_acc: 0.6384\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7095 - acc: 0.6924 - val_loss: 0.8155 - val_acc: 0.6341\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7055 - acc: 0.6917 - val_loss: 0.8190 - val_acc: 0.6368\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7011 - acc: 0.7018 - val_loss: 0.8177 - val_acc: 0.6331\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7028 - acc: 0.6931 - val_loss: 0.8248 - val_acc: 0.6363\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.6968 - acc: 0.7043 - val_loss: 0.8117 - val_acc: 0.6341\n",
      "0.574234932277\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 7s 2ms/step - loss: 1.0520 - acc: 0.4976 - val_loss: 1.0382 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 1.0366 - acc: 0.5006 - val_loss: 1.0338 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 1.0317 - acc: 0.5006 - val_loss: 1.0295 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0268 - acc: 0.5006 - val_loss: 1.0253 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 1.0219 - acc: 0.5006 - val_loss: 1.0206 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0166 - acc: 0.5006 - val_loss: 1.0156 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 1.0108 - acc: 0.5010 - val_loss: 1.0102 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 1.0048 - acc: 0.5017 - val_loss: 1.0043 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9980 - acc: 0.5042 - val_loss: 0.9977 - val_acc: 0.5035\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.9904 - acc: 0.5088 - val_loss: 0.9907 - val_acc: 0.5088\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.9823 - acc: 0.5150 - val_loss: 0.9826 - val_acc: 0.5099\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9734 - acc: 0.5198 - val_loss: 0.9738 - val_acc: 0.5157\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.9636 - acc: 0.5264 - val_loss: 0.9648 - val_acc: 0.5227\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9529 - acc: 0.5324 - val_loss: 0.9565 - val_acc: 0.5445\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9424 - acc: 0.5484 - val_loss: 0.9471 - val_acc: 0.5413\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9326 - acc: 0.5527 - val_loss: 0.9484 - val_acc: 0.5621\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9247 - acc: 0.5605 - val_loss: 0.9372 - val_acc: 0.5611\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.9166 - acc: 0.5639 - val_loss: 0.9284 - val_acc: 0.5712\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9099 - acc: 0.5758 - val_loss: 0.9192 - val_acc: 0.5675\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9042 - acc: 0.5765 - val_loss: 0.9111 - val_acc: 0.5760\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8969 - acc: 0.5808 - val_loss: 0.9056 - val_acc: 0.5755\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8893 - acc: 0.5827 - val_loss: 0.8981 - val_acc: 0.5723\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8828 - acc: 0.5902 - val_loss: 0.9022 - val_acc: 0.5776\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8766 - acc: 0.5991 - val_loss: 0.8946 - val_acc: 0.5893\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8707 - acc: 0.6042 - val_loss: 0.8795 - val_acc: 0.5899\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8649 - acc: 0.6037 - val_loss: 0.8766 - val_acc: 0.5899\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8569 - acc: 0.6085 - val_loss: 0.8722 - val_acc: 0.5931\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.8541 - acc: 0.6149 - val_loss: 0.8636 - val_acc: 0.5952\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8463 - acc: 0.6133 - val_loss: 0.8596 - val_acc: 0.5920\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8422 - acc: 0.6177 - val_loss: 0.8639 - val_acc: 0.5984\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8369 - acc: 0.6275 - val_loss: 0.8559 - val_acc: 0.5979\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8319 - acc: 0.6277 - val_loss: 0.8509 - val_acc: 0.6016\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8277 - acc: 0.6325 - val_loss: 0.8821 - val_acc: 0.5899\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8238 - acc: 0.6350 - val_loss: 0.8510 - val_acc: 0.5947\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8190 - acc: 0.6334 - val_loss: 0.8508 - val_acc: 0.5995\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8140 - acc: 0.6350 - val_loss: 0.8747 - val_acc: 0.5963\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8122 - acc: 0.6357 - val_loss: 0.8386 - val_acc: 0.6080\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8044 - acc: 0.6449 - val_loss: 0.8339 - val_acc: 0.6144\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8063 - acc: 0.6451 - val_loss: 0.8335 - val_acc: 0.6144\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8010 - acc: 0.6435 - val_loss: 0.8308 - val_acc: 0.6133\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7993 - acc: 0.6462 - val_loss: 0.8351 - val_acc: 0.6208\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7957 - acc: 0.6526 - val_loss: 0.8408 - val_acc: 0.6096\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7914 - acc: 0.6497 - val_loss: 0.8214 - val_acc: 0.6192\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7874 - acc: 0.6483 - val_loss: 0.8234 - val_acc: 0.6165\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7865 - acc: 0.6542 - val_loss: 0.8186 - val_acc: 0.6240\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7816 - acc: 0.6586 - val_loss: 0.8199 - val_acc: 0.6203\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 367us/step - loss: 0.7816 - acc: 0.6540 - val_loss: 0.8319 - val_acc: 0.6203\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7775 - acc: 0.6565 - val_loss: 0.8150 - val_acc: 0.6293\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7719 - acc: 0.6638 - val_loss: 0.8277 - val_acc: 0.6176\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7722 - acc: 0.6597 - val_loss: 0.8167 - val_acc: 0.6293\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7657 - acc: 0.6654 - val_loss: 0.8300 - val_acc: 0.6219\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7675 - acc: 0.6609 - val_loss: 0.8215 - val_acc: 0.6208\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7647 - acc: 0.6645 - val_loss: 0.8395 - val_acc: 0.6192\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7582 - acc: 0.6666 - val_loss: 0.8313 - val_acc: 0.6133\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7589 - acc: 0.6659 - val_loss: 0.8431 - val_acc: 0.6160\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7550 - acc: 0.6751 - val_loss: 0.8185 - val_acc: 0.6267\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7490 - acc: 0.6668 - val_loss: 0.8093 - val_acc: 0.6357\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7492 - acc: 0.6721 - val_loss: 0.8181 - val_acc: 0.6304\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7455 - acc: 0.6746 - val_loss: 0.8126 - val_acc: 0.6347\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7457 - acc: 0.6728 - val_loss: 0.8146 - val_acc: 0.6347\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7420 - acc: 0.6744 - val_loss: 0.8090 - val_acc: 0.6368\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7366 - acc: 0.6837 - val_loss: 0.8174 - val_acc: 0.6373\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7329 - acc: 0.6812 - val_loss: 0.8125 - val_acc: 0.6373\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7351 - acc: 0.6792 - val_loss: 0.8096 - val_acc: 0.6320\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7296 - acc: 0.6815 - val_loss: 0.8515 - val_acc: 0.6144\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7259 - acc: 0.6805 - val_loss: 0.8214 - val_acc: 0.6315\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7263 - acc: 0.6821 - val_loss: 0.8126 - val_acc: 0.6320\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7240 - acc: 0.6826 - val_loss: 0.8115 - val_acc: 0.6336\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7220 - acc: 0.6858 - val_loss: 0.8042 - val_acc: 0.6437\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7164 - acc: 0.6913 - val_loss: 0.8220 - val_acc: 0.6299\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7173 - acc: 0.6940 - val_loss: 0.8155 - val_acc: 0.6304\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7113 - acc: 0.6901 - val_loss: 0.8309 - val_acc: 0.6229\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7117 - acc: 0.6940 - val_loss: 0.8096 - val_acc: 0.6395\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7086 - acc: 0.6984 - val_loss: 0.8044 - val_acc: 0.6373\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7072 - acc: 0.6952 - val_loss: 0.8282 - val_acc: 0.6160\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.6998 - acc: 0.6993 - val_loss: 0.8130 - val_acc: 0.6288\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7010 - acc: 0.7002 - val_loss: 0.8160 - val_acc: 0.6309\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6962 - acc: 0.7004 - val_loss: 0.8020 - val_acc: 0.6432\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6966 - acc: 0.7062 - val_loss: 0.8077 - val_acc: 0.6437\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.6897 - acc: 0.7075 - val_loss: 0.8186 - val_acc: 0.6245\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6891 - acc: 0.7034 - val_loss: 0.8200 - val_acc: 0.6309\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6856 - acc: 0.7123 - val_loss: 0.8089 - val_acc: 0.6469\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.6866 - acc: 0.7057 - val_loss: 0.8010 - val_acc: 0.6485\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.6838 - acc: 0.7078 - val_loss: 0.8278 - val_acc: 0.6331\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6830 - acc: 0.7103 - val_loss: 0.8706 - val_acc: 0.6272\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.6795 - acc: 0.7148 - val_loss: 0.8691 - val_acc: 0.6187\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.6731 - acc: 0.7183 - val_loss: 0.8244 - val_acc: 0.6224\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6731 - acc: 0.7174 - val_loss: 0.8196 - val_acc: 0.6315\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6696 - acc: 0.7171 - val_loss: 0.8079 - val_acc: 0.6421\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6683 - acc: 0.7164 - val_loss: 0.8067 - val_acc: 0.6475\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6671 - acc: 0.7231 - val_loss: 0.8157 - val_acc: 0.6299\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6609 - acc: 0.7185 - val_loss: 0.8376 - val_acc: 0.6309\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6628 - acc: 0.7167 - val_loss: 0.8192 - val_acc: 0.6373\n",
      "0.597695876564\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 7s 2ms/step - loss: 1.0507 - acc: 0.4976 - val_loss: 1.0401 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0369 - acc: 0.5006 - val_loss: 1.0362 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 1.0326 - acc: 0.5006 - val_loss: 1.0324 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 1.0283 - acc: 0.5006 - val_loss: 1.0282 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 1.0237 - acc: 0.5006 - val_loss: 1.0238 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0187 - acc: 0.5006 - val_loss: 1.0191 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 1.0133 - acc: 0.5006 - val_loss: 1.0135 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0076 - acc: 0.5006 - val_loss: 1.0077 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 1.0012 - acc: 0.5010 - val_loss: 1.0017 - val_acc: 0.5019\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9941 - acc: 0.5029 - val_loss: 0.9945 - val_acc: 0.5077\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.9870 - acc: 0.5088 - val_loss: 0.9885 - val_acc: 0.5125\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.9793 - acc: 0.5131 - val_loss: 0.9804 - val_acc: 0.5200\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9718 - acc: 0.5214 - val_loss: 0.9736 - val_acc: 0.5269\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9638 - acc: 0.5296 - val_loss: 0.9656 - val_acc: 0.5328\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9560 - acc: 0.5296 - val_loss: 0.9581 - val_acc: 0.5435\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 353us/step - loss: 0.9483 - acc: 0.5383 - val_loss: 0.9561 - val_acc: 0.5371\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9415 - acc: 0.5413 - val_loss: 0.9508 - val_acc: 0.5435\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9341 - acc: 0.5539 - val_loss: 0.9371 - val_acc: 0.5499\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9272 - acc: 0.5550 - val_loss: 0.9325 - val_acc: 0.5520\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.9198 - acc: 0.5635 - val_loss: 0.9375 - val_acc: 0.5531\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9141 - acc: 0.5630 - val_loss: 0.9190 - val_acc: 0.5611\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9080 - acc: 0.5669 - val_loss: 0.9122 - val_acc: 0.5616\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.8990 - acc: 0.5742 - val_loss: 0.9187 - val_acc: 0.5664\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8938 - acc: 0.5779 - val_loss: 0.9050 - val_acc: 0.5787\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8874 - acc: 0.5806 - val_loss: 0.8950 - val_acc: 0.5787\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8797 - acc: 0.5856 - val_loss: 0.8914 - val_acc: 0.5845\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8751 - acc: 0.5930 - val_loss: 0.8846 - val_acc: 0.5909\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8677 - acc: 0.5950 - val_loss: 0.8831 - val_acc: 0.5840\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8649 - acc: 0.6014 - val_loss: 0.8760 - val_acc: 0.5947\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8581 - acc: 0.6021 - val_loss: 0.8907 - val_acc: 0.5824\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8525 - acc: 0.6092 - val_loss: 0.8716 - val_acc: 0.5872\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8479 - acc: 0.6055 - val_loss: 0.8756 - val_acc: 0.5904\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8423 - acc: 0.6147 - val_loss: 0.8618 - val_acc: 0.6032\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8375 - acc: 0.6186 - val_loss: 0.8582 - val_acc: 0.5984\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8366 - acc: 0.6156 - val_loss: 0.8571 - val_acc: 0.5995\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8322 - acc: 0.6241 - val_loss: 0.8576 - val_acc: 0.6016\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8273 - acc: 0.6273 - val_loss: 0.8507 - val_acc: 0.6053\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8231 - acc: 0.6291 - val_loss: 0.8495 - val_acc: 0.6021\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8193 - acc: 0.6300 - val_loss: 0.8520 - val_acc: 0.6043\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8146 - acc: 0.6353 - val_loss: 0.9166 - val_acc: 0.5829\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8123 - acc: 0.6371 - val_loss: 0.8432 - val_acc: 0.6080\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8086 - acc: 0.6337 - val_loss: 0.8573 - val_acc: 0.6021\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8073 - acc: 0.6419 - val_loss: 0.8601 - val_acc: 0.6080\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8037 - acc: 0.6424 - val_loss: 0.8661 - val_acc: 0.6096\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7949 - acc: 0.6444 - val_loss: 0.8642 - val_acc: 0.6043\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7985 - acc: 0.6469 - val_loss: 0.8537 - val_acc: 0.5989\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7927 - acc: 0.6467 - val_loss: 0.8323 - val_acc: 0.6171\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7913 - acc: 0.6533 - val_loss: 0.8529 - val_acc: 0.6075\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7864 - acc: 0.6485 - val_loss: 0.8327 - val_acc: 0.6128\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7852 - acc: 0.6561 - val_loss: 0.8314 - val_acc: 0.6176\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7803 - acc: 0.6568 - val_loss: 0.8491 - val_acc: 0.6021\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7784 - acc: 0.6581 - val_loss: 0.8435 - val_acc: 0.6149\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 0.7752 - acc: 0.6588 - val_loss: 0.8249 - val_acc: 0.6176\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7724 - acc: 0.6609 - val_loss: 0.8367 - val_acc: 0.6240\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7685 - acc: 0.6652 - val_loss: 0.8398 - val_acc: 0.6069\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7682 - acc: 0.6604 - val_loss: 0.8253 - val_acc: 0.6229\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7647 - acc: 0.6682 - val_loss: 0.8284 - val_acc: 0.6128\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7628 - acc: 0.6654 - val_loss: 0.8355 - val_acc: 0.6187\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7605 - acc: 0.6659 - val_loss: 0.8327 - val_acc: 0.6187\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7557 - acc: 0.6702 - val_loss: 0.8243 - val_acc: 0.6224\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7542 - acc: 0.6696 - val_loss: 0.8352 - val_acc: 0.6235\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7509 - acc: 0.6725 - val_loss: 0.8264 - val_acc: 0.6139\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7514 - acc: 0.6721 - val_loss: 0.8178 - val_acc: 0.6171\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7485 - acc: 0.6682 - val_loss: 0.8152 - val_acc: 0.6160\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7455 - acc: 0.6748 - val_loss: 0.8249 - val_acc: 0.6192\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7432 - acc: 0.6801 - val_loss: 0.8184 - val_acc: 0.6240\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7399 - acc: 0.6819 - val_loss: 0.8440 - val_acc: 0.6144\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7350 - acc: 0.6810 - val_loss: 0.8206 - val_acc: 0.6208\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7369 - acc: 0.6794 - val_loss: 0.8255 - val_acc: 0.6251\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7324 - acc: 0.6796 - val_loss: 0.8153 - val_acc: 0.6229\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7299 - acc: 0.6867 - val_loss: 0.8145 - val_acc: 0.6304\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.7273 - acc: 0.6808 - val_loss: 0.8455 - val_acc: 0.6069\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7283 - acc: 0.6883 - val_loss: 0.8122 - val_acc: 0.6331\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7254 - acc: 0.6892 - val_loss: 0.8196 - val_acc: 0.6245\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 384us/step - loss: 0.7223 - acc: 0.6853 - val_loss: 0.8163 - val_acc: 0.6267\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7182 - acc: 0.6940 - val_loss: 0.8080 - val_acc: 0.6272\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7147 - acc: 0.6881 - val_loss: 0.8427 - val_acc: 0.6192\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7172 - acc: 0.6899 - val_loss: 0.8079 - val_acc: 0.6336\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7131 - acc: 0.6952 - val_loss: 0.8121 - val_acc: 0.6320\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7093 - acc: 0.6965 - val_loss: 0.8335 - val_acc: 0.6165\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7056 - acc: 0.6995 - val_loss: 0.8102 - val_acc: 0.6331\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7044 - acc: 0.7002 - val_loss: 0.8125 - val_acc: 0.6277\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7025 - acc: 0.7002 - val_loss: 0.8236 - val_acc: 0.6293\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7010 - acc: 0.7043 - val_loss: 0.8201 - val_acc: 0.6304\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.6977 - acc: 0.6997 - val_loss: 0.8385 - val_acc: 0.6160\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.6941 - acc: 0.7039 - val_loss: 0.8040 - val_acc: 0.6405\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.6889 - acc: 0.7018 - val_loss: 0.8090 - val_acc: 0.6384\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.6939 - acc: 0.7041 - val_loss: 0.8101 - val_acc: 0.6315\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.6854 - acc: 0.7043 - val_loss: 0.8193 - val_acc: 0.6299\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6877 - acc: 0.7075 - val_loss: 0.8087 - val_acc: 0.6379\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6819 - acc: 0.7116 - val_loss: 0.8158 - val_acc: 0.6331\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.6798 - acc: 0.7112 - val_loss: 0.8388 - val_acc: 0.6187\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6795 - acc: 0.7103 - val_loss: 0.8314 - val_acc: 0.6272\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.6752 - acc: 0.7114 - val_loss: 0.8223 - val_acc: 0.6208\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6726 - acc: 0.7139 - val_loss: 0.8117 - val_acc: 0.6363\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6718 - acc: 0.7162 - val_loss: 0.8018 - val_acc: 0.6395\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6676 - acc: 0.7144 - val_loss: 0.8140 - val_acc: 0.6315\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6644 - acc: 0.7174 - val_loss: 0.8095 - val_acc: 0.6405\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.6648 - acc: 0.7144 - val_loss: 0.8012 - val_acc: 0.6437\n",
      "Epoch 100/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6591 - acc: 0.7199 - val_loss: 0.8056 - val_acc: 0.6416\n",
      "Epoch 101/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6559 - acc: 0.7228 - val_loss: 0.8432 - val_acc: 0.6331\n",
      "Epoch 102/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6557 - acc: 0.7212 - val_loss: 0.8090 - val_acc: 0.6405\n",
      "Epoch 103/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.6504 - acc: 0.7299 - val_loss: 0.8199 - val_acc: 0.6389\n",
      "Epoch 104/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6482 - acc: 0.7256 - val_loss: 0.8054 - val_acc: 0.6464\n",
      "Epoch 105/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.6489 - acc: 0.7192 - val_loss: 0.8242 - val_acc: 0.6368\n",
      "Epoch 106/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6439 - acc: 0.7292 - val_loss: 0.8070 - val_acc: 0.6405\n",
      "Epoch 107/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.6426 - acc: 0.7272 - val_loss: 0.8305 - val_acc: 0.6384\n",
      "Epoch 108/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6418 - acc: 0.7318 - val_loss: 0.8115 - val_acc: 0.6427\n",
      "Epoch 109/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.6373 - acc: 0.7320 - val_loss: 0.8026 - val_acc: 0.6448\n",
      "0.600628550821\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0512 - acc: 0.4976 - val_loss: 1.0381 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 1.0369 - acc: 0.5006 - val_loss: 1.0335 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 1.0326 - acc: 0.5006 - val_loss: 1.0293 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 1.0280 - acc: 0.5006 - val_loss: 1.0251 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 1.0236 - acc: 0.5006 - val_loss: 1.0200 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 1.0182 - acc: 0.5006 - val_loss: 1.0146 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 1.0123 - acc: 0.5006 - val_loss: 1.0080 - val_acc: 0.5003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 1.0058 - acc: 0.5008 - val_loss: 1.0012 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9984 - acc: 0.5019 - val_loss: 0.9939 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9909 - acc: 0.5063 - val_loss: 0.9854 - val_acc: 0.5035\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9815 - acc: 0.5093 - val_loss: 0.9764 - val_acc: 0.5131\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9729 - acc: 0.5177 - val_loss: 0.9678 - val_acc: 0.5141\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9637 - acc: 0.5216 - val_loss: 0.9581 - val_acc: 0.5275\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9546 - acc: 0.5344 - val_loss: 0.9484 - val_acc: 0.5301\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9448 - acc: 0.5429 - val_loss: 0.9395 - val_acc: 0.5435\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.9349 - acc: 0.5504 - val_loss: 0.9318 - val_acc: 0.5451\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.9263 - acc: 0.5628 - val_loss: 0.9239 - val_acc: 0.5483\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.9167 - acc: 0.5655 - val_loss: 0.9164 - val_acc: 0.5579\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9082 - acc: 0.5710 - val_loss: 0.9065 - val_acc: 0.5648\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8992 - acc: 0.5818 - val_loss: 0.8988 - val_acc: 0.5712\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8921 - acc: 0.5840 - val_loss: 0.8927 - val_acc: 0.5733\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8856 - acc: 0.5879 - val_loss: 0.8866 - val_acc: 0.5771\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8779 - acc: 0.5968 - val_loss: 0.8872 - val_acc: 0.5659\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8714 - acc: 0.6023 - val_loss: 0.8756 - val_acc: 0.5803\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8656 - acc: 0.6076 - val_loss: 0.8758 - val_acc: 0.5781\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.8586 - acc: 0.6138 - val_loss: 0.8680 - val_acc: 0.6037\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8527 - acc: 0.6097 - val_loss: 0.8704 - val_acc: 0.5952\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8503 - acc: 0.6138 - val_loss: 0.8596 - val_acc: 0.5984\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8436 - acc: 0.6195 - val_loss: 0.8579 - val_acc: 0.5931\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8378 - acc: 0.6209 - val_loss: 0.8556 - val_acc: 0.5947\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8350 - acc: 0.6218 - val_loss: 0.8550 - val_acc: 0.5925\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8317 - acc: 0.6257 - val_loss: 0.8474 - val_acc: 0.6112\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.8267 - acc: 0.6266 - val_loss: 0.8579 - val_acc: 0.6064\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8233 - acc: 0.6302 - val_loss: 0.8460 - val_acc: 0.6133\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8174 - acc: 0.6325 - val_loss: 0.8424 - val_acc: 0.6069\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8150 - acc: 0.6357 - val_loss: 0.8443 - val_acc: 0.6048\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 370us/step - loss: 0.8085 - acc: 0.6446 - val_loss: 0.8773 - val_acc: 0.5904\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.8072 - acc: 0.6366 - val_loss: 0.8588 - val_acc: 0.6048\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8044 - acc: 0.6405 - val_loss: 0.8495 - val_acc: 0.6123\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7994 - acc: 0.6472 - val_loss: 0.8335 - val_acc: 0.6192\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7973 - acc: 0.6451 - val_loss: 0.8506 - val_acc: 0.6043\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7949 - acc: 0.6469 - val_loss: 0.8410 - val_acc: 0.6219\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7910 - acc: 0.6467 - val_loss: 0.8368 - val_acc: 0.6229\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7875 - acc: 0.6440 - val_loss: 0.8356 - val_acc: 0.6176\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7871 - acc: 0.6529 - val_loss: 0.8274 - val_acc: 0.6277\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7847 - acc: 0.6526 - val_loss: 0.8263 - val_acc: 0.6235\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7781 - acc: 0.6584 - val_loss: 0.8397 - val_acc: 0.6165\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7780 - acc: 0.6577 - val_loss: 0.8261 - val_acc: 0.6224\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7740 - acc: 0.6568 - val_loss: 0.8451 - val_acc: 0.6085\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7703 - acc: 0.6629 - val_loss: 0.8235 - val_acc: 0.6208\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7696 - acc: 0.6584 - val_loss: 0.8185 - val_acc: 0.6309\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7664 - acc: 0.6634 - val_loss: 0.8293 - val_acc: 0.6256\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7635 - acc: 0.6645 - val_loss: 0.8480 - val_acc: 0.6053\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7606 - acc: 0.6677 - val_loss: 0.8186 - val_acc: 0.6389\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7566 - acc: 0.6698 - val_loss: 0.8171 - val_acc: 0.6341\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.7550 - acc: 0.6691 - val_loss: 0.8237 - val_acc: 0.6347\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7491 - acc: 0.6682 - val_loss: 0.8663 - val_acc: 0.6075\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7484 - acc: 0.6675 - val_loss: 0.8462 - val_acc: 0.6128\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7463 - acc: 0.6696 - val_loss: 0.8132 - val_acc: 0.6336\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.7439 - acc: 0.6744 - val_loss: 0.8271 - val_acc: 0.6272\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7417 - acc: 0.6812 - val_loss: 0.8103 - val_acc: 0.6389\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7402 - acc: 0.6767 - val_loss: 0.8344 - val_acc: 0.6208\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7360 - acc: 0.6778 - val_loss: 0.8149 - val_acc: 0.6315\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7338 - acc: 0.6785 - val_loss: 0.8088 - val_acc: 0.6347\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.7297 - acc: 0.6869 - val_loss: 0.8104 - val_acc: 0.6373\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7264 - acc: 0.6895 - val_loss: 0.8162 - val_acc: 0.6341\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7274 - acc: 0.6865 - val_loss: 0.8105 - val_acc: 0.6363\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7224 - acc: 0.6906 - val_loss: 0.8090 - val_acc: 0.6384\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 0.7206 - acc: 0.6874 - val_loss: 0.8094 - val_acc: 0.6427\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7184 - acc: 0.6858 - val_loss: 0.8108 - val_acc: 0.6363\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7148 - acc: 0.6911 - val_loss: 0.8251 - val_acc: 0.6277\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7143 - acc: 0.6913 - val_loss: 0.8204 - val_acc: 0.6405\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7103 - acc: 0.6933 - val_loss: 0.8121 - val_acc: 0.6331\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7066 - acc: 0.6981 - val_loss: 0.8094 - val_acc: 0.6347\n",
      "0.588248985218\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 8s 2ms/step - loss: 1.0464 - acc: 0.4985 - val_loss: 1.0369 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 1.0315 - acc: 0.5006 - val_loss: 1.0321 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 1.0259 - acc: 0.5006 - val_loss: 1.0271 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 1.0200 - acc: 0.5006 - val_loss: 1.0220 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0138 - acc: 0.5006 - val_loss: 1.0170 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0077 - acc: 0.5010 - val_loss: 1.0111 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 1.0006 - acc: 0.5031 - val_loss: 1.0054 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9935 - acc: 0.5051 - val_loss: 0.9989 - val_acc: 0.5099\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9860 - acc: 0.5086 - val_loss: 0.9924 - val_acc: 0.5147\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9778 - acc: 0.5161 - val_loss: 0.9854 - val_acc: 0.5184\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9691 - acc: 0.5234 - val_loss: 0.9781 - val_acc: 0.5211\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9600 - acc: 0.5324 - val_loss: 0.9711 - val_acc: 0.5216\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9509 - acc: 0.5378 - val_loss: 0.9637 - val_acc: 0.5317\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9410 - acc: 0.5477 - val_loss: 0.9566 - val_acc: 0.5413\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 0.9313 - acc: 0.5532 - val_loss: 0.9499 - val_acc: 0.5472\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.9224 - acc: 0.5619 - val_loss: 0.9423 - val_acc: 0.5531\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9132 - acc: 0.5680 - val_loss: 0.9359 - val_acc: 0.5504\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9044 - acc: 0.5763 - val_loss: 0.9302 - val_acc: 0.5504\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8957 - acc: 0.5790 - val_loss: 0.9236 - val_acc: 0.5568\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8879 - acc: 0.5856 - val_loss: 0.9173 - val_acc: 0.5584\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8800 - acc: 0.5962 - val_loss: 0.9115 - val_acc: 0.5573\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.8726 - acc: 0.6019 - val_loss: 0.9066 - val_acc: 0.5760\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8657 - acc: 0.6016 - val_loss: 0.9006 - val_acc: 0.5701\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8585 - acc: 0.6113 - val_loss: 0.8975 - val_acc: 0.5744\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8519 - acc: 0.6119 - val_loss: 0.8916 - val_acc: 0.5765\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8463 - acc: 0.6142 - val_loss: 0.8918 - val_acc: 0.5739\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.8407 - acc: 0.6238 - val_loss: 0.8926 - val_acc: 0.5733\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8352 - acc: 0.6245 - val_loss: 0.8862 - val_acc: 0.5808\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.8317 - acc: 0.6270 - val_loss: 0.8795 - val_acc: 0.5808\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8275 - acc: 0.6298 - val_loss: 0.8806 - val_acc: 0.5819\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8227 - acc: 0.6350 - val_loss: 0.8756 - val_acc: 0.5861\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8170 - acc: 0.6357 - val_loss: 0.9025 - val_acc: 0.5787\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8149 - acc: 0.6355 - val_loss: 0.8712 - val_acc: 0.5947\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8100 - acc: 0.6382 - val_loss: 0.8666 - val_acc: 0.5952\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8056 - acc: 0.6446 - val_loss: 0.8633 - val_acc: 0.5952\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8023 - acc: 0.6398 - val_loss: 0.8608 - val_acc: 0.6037\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7979 - acc: 0.6485 - val_loss: 0.8638 - val_acc: 0.5957\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7950 - acc: 0.6462 - val_loss: 0.8593 - val_acc: 0.6048\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7910 - acc: 0.6520 - val_loss: 0.8609 - val_acc: 0.5979\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7880 - acc: 0.6538 - val_loss: 0.8550 - val_acc: 0.6075\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7853 - acc: 0.6552 - val_loss: 0.8589 - val_acc: 0.6048\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7819 - acc: 0.6526 - val_loss: 0.8506 - val_acc: 0.6091\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7789 - acc: 0.6579 - val_loss: 0.8667 - val_acc: 0.5909\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7756 - acc: 0.6570 - val_loss: 0.8794 - val_acc: 0.5904\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7721 - acc: 0.6570 - val_loss: 0.8481 - val_acc: 0.6133\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7753 - acc: 0.6554 - val_loss: 0.8511 - val_acc: 0.6155\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7665 - acc: 0.6636 - val_loss: 0.8505 - val_acc: 0.6043\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7611 - acc: 0.6638 - val_loss: 0.8647 - val_acc: 0.6048\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7598 - acc: 0.6702 - val_loss: 0.8450 - val_acc: 0.6160\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7579 - acc: 0.6673 - val_loss: 0.8550 - val_acc: 0.6059\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7537 - acc: 0.6645 - val_loss: 0.8712 - val_acc: 0.6027\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7497 - acc: 0.6725 - val_loss: 0.8530 - val_acc: 0.6064\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7468 - acc: 0.6712 - val_loss: 0.8453 - val_acc: 0.6091\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7426 - acc: 0.6714 - val_loss: 0.8418 - val_acc: 0.6176\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7408 - acc: 0.6783 - val_loss: 0.8382 - val_acc: 0.6155\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7389 - acc: 0.6778 - val_loss: 0.8392 - val_acc: 0.6208\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7356 - acc: 0.6840 - val_loss: 0.8609 - val_acc: 0.6016\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 375us/step - loss: 0.7357 - acc: 0.6828 - val_loss: 0.8391 - val_acc: 0.6155\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7317 - acc: 0.6808 - val_loss: 0.8446 - val_acc: 0.6091\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7283 - acc: 0.6847 - val_loss: 0.8373 - val_acc: 0.6144\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7239 - acc: 0.6844 - val_loss: 0.8428 - val_acc: 0.6112\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7210 - acc: 0.6856 - val_loss: 0.8340 - val_acc: 0.6203\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.7223 - acc: 0.6865 - val_loss: 0.8514 - val_acc: 0.6203\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7180 - acc: 0.6899 - val_loss: 0.8335 - val_acc: 0.6149\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7150 - acc: 0.6945 - val_loss: 0.8434 - val_acc: 0.6144\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7118 - acc: 0.6938 - val_loss: 0.8433 - val_acc: 0.6107\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7087 - acc: 0.6949 - val_loss: 0.8342 - val_acc: 0.6176\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7063 - acc: 0.6954 - val_loss: 0.8461 - val_acc: 0.6213\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7072 - acc: 0.6954 - val_loss: 0.8297 - val_acc: 0.6197\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7024 - acc: 0.6991 - val_loss: 0.8457 - val_acc: 0.6080\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.6974 - acc: 0.7043 - val_loss: 0.8281 - val_acc: 0.6261\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6963 - acc: 0.7039 - val_loss: 0.8346 - val_acc: 0.6075\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.6962 - acc: 0.7000 - val_loss: 0.8299 - val_acc: 0.6181\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.6911 - acc: 0.7059 - val_loss: 0.8682 - val_acc: 0.6112\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6883 - acc: 0.7062 - val_loss: 0.8293 - val_acc: 0.6293\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6866 - acc: 0.7046 - val_loss: 0.8346 - val_acc: 0.6261\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.6848 - acc: 0.7073 - val_loss: 0.8392 - val_acc: 0.6341\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6813 - acc: 0.7032 - val_loss: 0.8654 - val_acc: 0.6016\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.6779 - acc: 0.7082 - val_loss: 0.8341 - val_acc: 0.6144\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6751 - acc: 0.7110 - val_loss: 0.8547 - val_acc: 0.6085\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.6742 - acc: 0.7137 - val_loss: 0.8303 - val_acc: 0.6283\n",
      "0.599478086462\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 8s 2ms/step - loss: 1.0479 - acc: 0.4981 - val_loss: 1.0395 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 1.0339 - acc: 0.5006 - val_loss: 1.0346 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 1.0284 - acc: 0.5006 - val_loss: 1.0302 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 1.0231 - acc: 0.5006 - val_loss: 1.0248 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 1.0177 - acc: 0.5006 - val_loss: 1.0197 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0119 - acc: 0.5006 - val_loss: 1.0143 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0057 - acc: 0.5022 - val_loss: 1.0088 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9993 - acc: 0.5058 - val_loss: 1.0024 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.9920 - acc: 0.5079 - val_loss: 0.9961 - val_acc: 0.5141\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9850 - acc: 0.5164 - val_loss: 0.9886 - val_acc: 0.5163\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9771 - acc: 0.5207 - val_loss: 0.9812 - val_acc: 0.5189\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9687 - acc: 0.5269 - val_loss: 0.9741 - val_acc: 0.5248\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.9602 - acc: 0.5337 - val_loss: 0.9667 - val_acc: 0.5317\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9512 - acc: 0.5440 - val_loss: 0.9616 - val_acc: 0.5328\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.9429 - acc: 0.5500 - val_loss: 0.9508 - val_acc: 0.5381\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9337 - acc: 0.5575 - val_loss: 0.9419 - val_acc: 0.5435\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9250 - acc: 0.5600 - val_loss: 0.9346 - val_acc: 0.5509\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9166 - acc: 0.5680 - val_loss: 0.9296 - val_acc: 0.5573\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9081 - acc: 0.5721 - val_loss: 0.9257 - val_acc: 0.5723\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.9006 - acc: 0.5747 - val_loss: 0.9157 - val_acc: 0.5632\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8939 - acc: 0.5737 - val_loss: 0.9090 - val_acc: 0.5840\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8855 - acc: 0.5859 - val_loss: 0.9023 - val_acc: 0.5739\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8792 - acc: 0.5909 - val_loss: 0.8987 - val_acc: 0.5851\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8721 - acc: 0.5968 - val_loss: 0.8970 - val_acc: 0.5867\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8650 - acc: 0.6055 - val_loss: 0.9005 - val_acc: 0.5824\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8616 - acc: 0.6021 - val_loss: 0.8897 - val_acc: 0.5813\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8561 - acc: 0.6126 - val_loss: 0.8813 - val_acc: 0.6005\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8505 - acc: 0.6119 - val_loss: 0.8847 - val_acc: 0.5888\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8450 - acc: 0.6115 - val_loss: 0.8960 - val_acc: 0.5733\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.8416 - acc: 0.6197 - val_loss: 0.8725 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8372 - acc: 0.6204 - val_loss: 0.8828 - val_acc: 0.5877\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8325 - acc: 0.6218 - val_loss: 0.8812 - val_acc: 0.5899\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.8295 - acc: 0.6298 - val_loss: 0.8666 - val_acc: 0.6027\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.8246 - acc: 0.6284 - val_loss: 0.8731 - val_acc: 0.5877\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8219 - acc: 0.6339 - val_loss: 0.8681 - val_acc: 0.6016\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8187 - acc: 0.6332 - val_loss: 0.8607 - val_acc: 0.6075\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8137 - acc: 0.6348 - val_loss: 0.8843 - val_acc: 0.5771\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8104 - acc: 0.6364 - val_loss: 0.8678 - val_acc: 0.5957\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8082 - acc: 0.6437 - val_loss: 0.8655 - val_acc: 0.6027\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8048 - acc: 0.6419 - val_loss: 0.8665 - val_acc: 0.5973\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8011 - acc: 0.6426 - val_loss: 0.8513 - val_acc: 0.6117\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7978 - acc: 0.6490 - val_loss: 0.8533 - val_acc: 0.6080\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7957 - acc: 0.6446 - val_loss: 0.8498 - val_acc: 0.6197\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7927 - acc: 0.6499 - val_loss: 0.8534 - val_acc: 0.6085\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7890 - acc: 0.6492 - val_loss: 0.8573 - val_acc: 0.6123\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7876 - acc: 0.6549 - val_loss: 0.8590 - val_acc: 0.6085\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7842 - acc: 0.6522 - val_loss: 0.8715 - val_acc: 0.6133\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7837 - acc: 0.6524 - val_loss: 0.8479 - val_acc: 0.6139\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7789 - acc: 0.6604 - val_loss: 0.8513 - val_acc: 0.6069\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7774 - acc: 0.6574 - val_loss: 0.8649 - val_acc: 0.6016\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7747 - acc: 0.6613 - val_loss: 0.8593 - val_acc: 0.6005\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7705 - acc: 0.6620 - val_loss: 0.8526 - val_acc: 0.6080\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7687 - acc: 0.6625 - val_loss: 0.8403 - val_acc: 0.6213\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7677 - acc: 0.6620 - val_loss: 0.8408 - val_acc: 0.6229\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7627 - acc: 0.6650 - val_loss: 0.8533 - val_acc: 0.6107\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7598 - acc: 0.6691 - val_loss: 0.8589 - val_acc: 0.6085\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7584 - acc: 0.6680 - val_loss: 0.8497 - val_acc: 0.6107\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7569 - acc: 0.6648 - val_loss: 0.8335 - val_acc: 0.6235\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7527 - acc: 0.6707 - val_loss: 0.8517 - val_acc: 0.6176\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7477 - acc: 0.6698 - val_loss: 0.8316 - val_acc: 0.6229\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7496 - acc: 0.6739 - val_loss: 0.8809 - val_acc: 0.5963\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7470 - acc: 0.6746 - val_loss: 0.8435 - val_acc: 0.6224\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7424 - acc: 0.6789 - val_loss: 0.8466 - val_acc: 0.6128\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7417 - acc: 0.6751 - val_loss: 0.8433 - val_acc: 0.6208\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7387 - acc: 0.6760 - val_loss: 0.8317 - val_acc: 0.6251\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7352 - acc: 0.6751 - val_loss: 0.8378 - val_acc: 0.6213\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7325 - acc: 0.6824 - val_loss: 0.8366 - val_acc: 0.6197\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.7353 - acc: 0.6760 - val_loss: 0.8393 - val_acc: 0.6117\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7273 - acc: 0.6810 - val_loss: 0.8290 - val_acc: 0.6315\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7252 - acc: 0.6817 - val_loss: 0.8269 - val_acc: 0.6288\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7267 - acc: 0.6817 - val_loss: 0.8297 - val_acc: 0.6304\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7222 - acc: 0.6808 - val_loss: 0.8372 - val_acc: 0.6197\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7194 - acc: 0.6847 - val_loss: 0.8272 - val_acc: 0.6331\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7172 - acc: 0.6833 - val_loss: 0.8287 - val_acc: 0.6283\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7136 - acc: 0.6920 - val_loss: 0.8743 - val_acc: 0.6069\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.7130 - acc: 0.6853 - val_loss: 0.8312 - val_acc: 0.6251\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7094 - acc: 0.6901 - val_loss: 0.8221 - val_acc: 0.6347\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7055 - acc: 0.6949 - val_loss: 0.8218 - val_acc: 0.6331\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7026 - acc: 0.6963 - val_loss: 0.8542 - val_acc: 0.6139\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7030 - acc: 0.6933 - val_loss: 0.8276 - val_acc: 0.6283\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7004 - acc: 0.6943 - val_loss: 0.8361 - val_acc: 0.6235\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.6947 - acc: 0.7016 - val_loss: 0.8230 - val_acc: 0.6288\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.6926 - acc: 0.7002 - val_loss: 0.8273 - val_acc: 0.6299\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6921 - acc: 0.7000 - val_loss: 0.8263 - val_acc: 0.6283\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6875 - acc: 0.7007 - val_loss: 0.8709 - val_acc: 0.6133\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6880 - acc: 0.6975 - val_loss: 0.8364 - val_acc: 0.6224\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.6835 - acc: 0.7057 - val_loss: 0.8449 - val_acc: 0.6213\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6805 - acc: 0.7007 - val_loss: 0.8362 - val_acc: 0.6245\n",
      "0.610181090077\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0496 - acc: 0.5006 - val_loss: 1.0401 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 1.0361 - acc: 0.5006 - val_loss: 1.0353 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 1.0315 - acc: 0.5006 - val_loss: 1.0305 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 1.0269 - acc: 0.5006 - val_loss: 1.0257 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 1.0222 - acc: 0.5006 - val_loss: 1.0204 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 1.0165 - acc: 0.5006 - val_loss: 1.0153 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0114 - acc: 0.5006 - val_loss: 1.0092 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 1.0054 - acc: 0.5013 - val_loss: 1.0027 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9994 - acc: 0.5022 - val_loss: 0.9962 - val_acc: 0.5003\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 379us/step - loss: 0.9929 - acc: 0.5026 - val_loss: 0.9893 - val_acc: 0.5024\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.9857 - acc: 0.5090 - val_loss: 0.9827 - val_acc: 0.5040\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.9786 - acc: 0.5154 - val_loss: 0.9754 - val_acc: 0.5083\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.9706 - acc: 0.5200 - val_loss: 0.9669 - val_acc: 0.5259\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.9631 - acc: 0.5271 - val_loss: 0.9592 - val_acc: 0.5275\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.9555 - acc: 0.5340 - val_loss: 0.9515 - val_acc: 0.5403\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9476 - acc: 0.5399 - val_loss: 0.9446 - val_acc: 0.5435\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.9392 - acc: 0.5447 - val_loss: 0.9400 - val_acc: 0.5616\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.9322 - acc: 0.5520 - val_loss: 0.9297 - val_acc: 0.5728\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9237 - acc: 0.5603 - val_loss: 0.9220 - val_acc: 0.5728\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9156 - acc: 0.5623 - val_loss: 0.9150 - val_acc: 0.5765\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9069 - acc: 0.5744 - val_loss: 0.9073 - val_acc: 0.5840\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9008 - acc: 0.5774 - val_loss: 0.9006 - val_acc: 0.5861\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8948 - acc: 0.5790 - val_loss: 0.8955 - val_acc: 0.5856\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8871 - acc: 0.5829 - val_loss: 0.8892 - val_acc: 0.5877\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8791 - acc: 0.5875 - val_loss: 0.8818 - val_acc: 0.5941\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8746 - acc: 0.5948 - val_loss: 0.8771 - val_acc: 0.5979\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8682 - acc: 0.6010 - val_loss: 0.8735 - val_acc: 0.6000\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8595 - acc: 0.6023 - val_loss: 0.8754 - val_acc: 0.6064\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8570 - acc: 0.6042 - val_loss: 0.8648 - val_acc: 0.6069\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8506 - acc: 0.6078 - val_loss: 0.8607 - val_acc: 0.6112\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8471 - acc: 0.6094 - val_loss: 0.8613 - val_acc: 0.6080\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8412 - acc: 0.6156 - val_loss: 0.8580 - val_acc: 0.6091\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8371 - acc: 0.6163 - val_loss: 0.8631 - val_acc: 0.6085\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8323 - acc: 0.6129 - val_loss: 0.8528 - val_acc: 0.6085\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8280 - acc: 0.6245 - val_loss: 0.8838 - val_acc: 0.5957\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8263 - acc: 0.6286 - val_loss: 0.8447 - val_acc: 0.6133\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8223 - acc: 0.6275 - val_loss: 0.8425 - val_acc: 0.6107\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8179 - acc: 0.6282 - val_loss: 0.8424 - val_acc: 0.6139\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8156 - acc: 0.6270 - val_loss: 0.8395 - val_acc: 0.6176\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8121 - acc: 0.6318 - val_loss: 0.8367 - val_acc: 0.6123\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8083 - acc: 0.6323 - val_loss: 0.8369 - val_acc: 0.6165\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8029 - acc: 0.6369 - val_loss: 0.8389 - val_acc: 0.6112\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8017 - acc: 0.6371 - val_loss: 0.8335 - val_acc: 0.6240\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8001 - acc: 0.6371 - val_loss: 0.8510 - val_acc: 0.6245\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7954 - acc: 0.6408 - val_loss: 0.8344 - val_acc: 0.6171\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7924 - acc: 0.6433 - val_loss: 0.8325 - val_acc: 0.6197\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7893 - acc: 0.6440 - val_loss: 0.8476 - val_acc: 0.6197\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7866 - acc: 0.6403 - val_loss: 0.8278 - val_acc: 0.6181\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7849 - acc: 0.6490 - val_loss: 0.8226 - val_acc: 0.6245\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7836 - acc: 0.6478 - val_loss: 0.8310 - val_acc: 0.6235\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7776 - acc: 0.6504 - val_loss: 0.8378 - val_acc: 0.6149\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7747 - acc: 0.6565 - val_loss: 0.8239 - val_acc: 0.6171\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7743 - acc: 0.6588 - val_loss: 0.8271 - val_acc: 0.6144\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7696 - acc: 0.6590 - val_loss: 0.8165 - val_acc: 0.6229\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7660 - acc: 0.6597 - val_loss: 0.8369 - val_acc: 0.6181\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7655 - acc: 0.6616 - val_loss: 0.8176 - val_acc: 0.6261\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7608 - acc: 0.6593 - val_loss: 0.8114 - val_acc: 0.6331\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7571 - acc: 0.6632 - val_loss: 0.8302 - val_acc: 0.6229\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7557 - acc: 0.6680 - val_loss: 0.8417 - val_acc: 0.6059\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7537 - acc: 0.6661 - val_loss: 0.8234 - val_acc: 0.6213\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7495 - acc: 0.6718 - val_loss: 0.8201 - val_acc: 0.6187\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7512 - acc: 0.6684 - val_loss: 0.8133 - val_acc: 0.6288\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7456 - acc: 0.6721 - val_loss: 0.8065 - val_acc: 0.6389\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7430 - acc: 0.6780 - val_loss: 0.8025 - val_acc: 0.6299\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7414 - acc: 0.6755 - val_loss: 0.8014 - val_acc: 0.6347\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7372 - acc: 0.6735 - val_loss: 0.8040 - val_acc: 0.6299\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7333 - acc: 0.6799 - val_loss: 0.8020 - val_acc: 0.6363\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7312 - acc: 0.6796 - val_loss: 0.7993 - val_acc: 0.6325\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7276 - acc: 0.6849 - val_loss: 0.8184 - val_acc: 0.6229\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7259 - acc: 0.6771 - val_loss: 0.8165 - val_acc: 0.6320\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7235 - acc: 0.6853 - val_loss: 0.7999 - val_acc: 0.6373\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7200 - acc: 0.6819 - val_loss: 0.8001 - val_acc: 0.6363\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7180 - acc: 0.6835 - val_loss: 0.7955 - val_acc: 0.6416\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7156 - acc: 0.6927 - val_loss: 0.7976 - val_acc: 0.6352\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7125 - acc: 0.6872 - val_loss: 0.7965 - val_acc: 0.6357\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7105 - acc: 0.6904 - val_loss: 0.7937 - val_acc: 0.6363\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7116 - acc: 0.6899 - val_loss: 0.8629 - val_acc: 0.6016\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.7049 - acc: 0.6929 - val_loss: 0.7978 - val_acc: 0.6357\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7002 - acc: 0.6913 - val_loss: 0.7944 - val_acc: 0.6395\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7006 - acc: 0.6961 - val_loss: 0.8068 - val_acc: 0.6389\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6972 - acc: 0.6965 - val_loss: 0.8018 - val_acc: 0.6336\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6941 - acc: 0.6965 - val_loss: 0.8148 - val_acc: 0.6331\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.6948 - acc: 0.6945 - val_loss: 0.8098 - val_acc: 0.6384\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.6899 - acc: 0.6975 - val_loss: 0.8169 - val_acc: 0.6389\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.6877 - acc: 0.7011 - val_loss: 0.8039 - val_acc: 0.6475\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6857 - acc: 0.7075 - val_loss: 0.8044 - val_acc: 0.6464\n",
      "0.597831569155\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0524 - acc: 0.4983 - val_loss: 1.0375 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 1.0348 - acc: 0.5006 - val_loss: 1.0320 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 1.0296 - acc: 0.5006 - val_loss: 1.0266 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0241 - acc: 0.5006 - val_loss: 1.0213 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 1.0186 - acc: 0.5006 - val_loss: 1.0155 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 1.0127 - acc: 0.5006 - val_loss: 1.0096 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0065 - acc: 0.5015 - val_loss: 1.0033 - val_acc: 0.5035\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9995 - acc: 0.5045 - val_loss: 0.9970 - val_acc: 0.5035\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9927 - acc: 0.5063 - val_loss: 0.9897 - val_acc: 0.5056\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.9851 - acc: 0.5113 - val_loss: 0.9822 - val_acc: 0.5115\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9772 - acc: 0.5182 - val_loss: 0.9748 - val_acc: 0.5184\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9689 - acc: 0.5225 - val_loss: 0.9664 - val_acc: 0.5253\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9598 - acc: 0.5296 - val_loss: 0.9586 - val_acc: 0.5317\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9506 - acc: 0.5358 - val_loss: 0.9506 - val_acc: 0.5376\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9417 - acc: 0.5406 - val_loss: 0.9419 - val_acc: 0.5365\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9326 - acc: 0.5497 - val_loss: 0.9342 - val_acc: 0.5451\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9235 - acc: 0.5536 - val_loss: 0.9270 - val_acc: 0.5568\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9153 - acc: 0.5603 - val_loss: 0.9199 - val_acc: 0.5589\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9077 - acc: 0.5676 - val_loss: 0.9141 - val_acc: 0.5605\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9001 - acc: 0.5683 - val_loss: 0.9119 - val_acc: 0.5632\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8933 - acc: 0.5772 - val_loss: 0.9037 - val_acc: 0.5739\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8871 - acc: 0.5852 - val_loss: 0.9014 - val_acc: 0.5797\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.8806 - acc: 0.5891 - val_loss: 0.8930 - val_acc: 0.5829\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8743 - acc: 0.5891 - val_loss: 0.8930 - val_acc: 0.5957\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8677 - acc: 0.5941 - val_loss: 0.8870 - val_acc: 0.5813\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8635 - acc: 0.6003 - val_loss: 0.8838 - val_acc: 0.5845\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8579 - acc: 0.6053 - val_loss: 0.8820 - val_acc: 0.5952\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.8523 - acc: 0.6064 - val_loss: 0.8742 - val_acc: 0.6005\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8499 - acc: 0.6030 - val_loss: 0.8716 - val_acc: 0.6021\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.8437 - acc: 0.6129 - val_loss: 0.8721 - val_acc: 0.5973\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8394 - acc: 0.6099 - val_loss: 0.8694 - val_acc: 0.6080\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8346 - acc: 0.6145 - val_loss: 0.8690 - val_acc: 0.6011\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8292 - acc: 0.6170 - val_loss: 0.8800 - val_acc: 0.6032\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8269 - acc: 0.6172 - val_loss: 0.8671 - val_acc: 0.5989\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.8221 - acc: 0.6238 - val_loss: 0.8616 - val_acc: 0.6133\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8180 - acc: 0.6279 - val_loss: 0.8567 - val_acc: 0.6133\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8152 - acc: 0.6273 - val_loss: 0.8586 - val_acc: 0.6075\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8111 - acc: 0.6298 - val_loss: 0.8636 - val_acc: 0.6053\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8085 - acc: 0.6311 - val_loss: 0.8588 - val_acc: 0.6149\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8043 - acc: 0.6362 - val_loss: 0.8550 - val_acc: 0.6213\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8005 - acc: 0.6391 - val_loss: 0.8597 - val_acc: 0.6192\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7973 - acc: 0.6387 - val_loss: 0.8548 - val_acc: 0.6176\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7949 - acc: 0.6385 - val_loss: 0.8498 - val_acc: 0.6144\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7907 - acc: 0.6499 - val_loss: 0.8439 - val_acc: 0.6192\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7860 - acc: 0.6533 - val_loss: 0.8546 - val_acc: 0.6240\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7867 - acc: 0.6490 - val_loss: 0.8463 - val_acc: 0.6256\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7811 - acc: 0.6494 - val_loss: 0.8410 - val_acc: 0.6240\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 390us/step - loss: 0.7771 - acc: 0.6586 - val_loss: 0.8521 - val_acc: 0.6112\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7756 - acc: 0.6556 - val_loss: 0.8387 - val_acc: 0.6251\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7742 - acc: 0.6570 - val_loss: 0.8450 - val_acc: 0.6288\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7715 - acc: 0.6590 - val_loss: 0.8427 - val_acc: 0.6288\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7669 - acc: 0.6618 - val_loss: 0.8371 - val_acc: 0.6267\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7668 - acc: 0.6609 - val_loss: 0.8515 - val_acc: 0.6272\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7608 - acc: 0.6664 - val_loss: 0.8462 - val_acc: 0.6139\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7601 - acc: 0.6638 - val_loss: 0.8410 - val_acc: 0.6181\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7579 - acc: 0.6677 - val_loss: 0.8344 - val_acc: 0.6261\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7545 - acc: 0.6668 - val_loss: 0.8382 - val_acc: 0.6203\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7516 - acc: 0.6670 - val_loss: 0.8386 - val_acc: 0.6208\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.7509 - acc: 0.6714 - val_loss: 0.8307 - val_acc: 0.6331\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7469 - acc: 0.6707 - val_loss: 0.8542 - val_acc: 0.6155\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7454 - acc: 0.6748 - val_loss: 0.8353 - val_acc: 0.6293\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7438 - acc: 0.6757 - val_loss: 0.8411 - val_acc: 0.6373\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7387 - acc: 0.6792 - val_loss: 0.8362 - val_acc: 0.6389\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7374 - acc: 0.6792 - val_loss: 0.8306 - val_acc: 0.6331\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7339 - acc: 0.6826 - val_loss: 0.8440 - val_acc: 0.6336\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7307 - acc: 0.6821 - val_loss: 0.8406 - val_acc: 0.6187\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7341 - acc: 0.6767 - val_loss: 0.8308 - val_acc: 0.6357\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7258 - acc: 0.6881 - val_loss: 0.8334 - val_acc: 0.6251\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7226 - acc: 0.6901 - val_loss: 0.8378 - val_acc: 0.6219\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7203 - acc: 0.6883 - val_loss: 0.8288 - val_acc: 0.6288\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7193 - acc: 0.6917 - val_loss: 0.8318 - val_acc: 0.6363\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 398us/step - loss: 0.7175 - acc: 0.6890 - val_loss: 0.8329 - val_acc: 0.6336\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7153 - acc: 0.6901 - val_loss: 0.8288 - val_acc: 0.6320\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7147 - acc: 0.6954 - val_loss: 0.8265 - val_acc: 0.6315\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7071 - acc: 0.6956 - val_loss: 0.8714 - val_acc: 0.6235\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7062 - acc: 0.6963 - val_loss: 0.8260 - val_acc: 0.6336\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7042 - acc: 0.7004 - val_loss: 0.8347 - val_acc: 0.6325\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7003 - acc: 0.7009 - val_loss: 0.8370 - val_acc: 0.6272\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.6994 - acc: 0.6981 - val_loss: 0.8337 - val_acc: 0.6363\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.6971 - acc: 0.7016 - val_loss: 0.8331 - val_acc: 0.6272\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6979 - acc: 0.7046 - val_loss: 0.8532 - val_acc: 0.6235\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.6914 - acc: 0.7055 - val_loss: 0.8329 - val_acc: 0.6325\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.6870 - acc: 0.7080 - val_loss: 0.8363 - val_acc: 0.6277\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6880 - acc: 0.7018 - val_loss: 0.8327 - val_acc: 0.6304\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.6822 - acc: 0.7082 - val_loss: 0.8367 - val_acc: 0.6251\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6845 - acc: 0.7130 - val_loss: 0.8295 - val_acc: 0.6331\n",
      "0.58507746013\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 8s 2ms/step - loss: 1.0523 - acc: 0.5008 - val_loss: 1.0383 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0331 - acc: 0.5006 - val_loss: 1.0327 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 1.0272 - acc: 0.5006 - val_loss: 1.0273 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 1.0214 - acc: 0.5006 - val_loss: 1.0215 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 1.0152 - acc: 0.5006 - val_loss: 1.0154 - val_acc: 0.4997\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0084 - acc: 0.5006 - val_loss: 1.0090 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 1.0009 - acc: 0.5010 - val_loss: 1.0020 - val_acc: 0.5035\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9931 - acc: 0.5040 - val_loss: 0.9946 - val_acc: 0.5120\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 0.9851 - acc: 0.5074 - val_loss: 0.9869 - val_acc: 0.5189\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9762 - acc: 0.5186 - val_loss: 0.9809 - val_acc: 0.5152\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9680 - acc: 0.5234 - val_loss: 0.9715 - val_acc: 0.5248\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9587 - acc: 0.5337 - val_loss: 0.9667 - val_acc: 0.5237\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9493 - acc: 0.5390 - val_loss: 0.9585 - val_acc: 0.5456\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9422 - acc: 0.5465 - val_loss: 0.9495 - val_acc: 0.5451\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9336 - acc: 0.5534 - val_loss: 0.9425 - val_acc: 0.5483\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9257 - acc: 0.5548 - val_loss: 0.9349 - val_acc: 0.5552\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9165 - acc: 0.5641 - val_loss: 0.9283 - val_acc: 0.5627\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.9100 - acc: 0.5689 - val_loss: 0.9224 - val_acc: 0.5755\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9021 - acc: 0.5788 - val_loss: 0.9157 - val_acc: 0.5787\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8939 - acc: 0.5856 - val_loss: 0.9111 - val_acc: 0.5803\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8881 - acc: 0.5838 - val_loss: 0.9063 - val_acc: 0.5797\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.8806 - acc: 0.5941 - val_loss: 0.9031 - val_acc: 0.5856\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8748 - acc: 0.5946 - val_loss: 0.8948 - val_acc: 0.5920\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8683 - acc: 0.6007 - val_loss: 0.8958 - val_acc: 0.5888\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8623 - acc: 0.6069 - val_loss: 0.8874 - val_acc: 0.5952\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8556 - acc: 0.6080 - val_loss: 0.8863 - val_acc: 0.5856\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.8508 - acc: 0.6101 - val_loss: 0.8810 - val_acc: 0.5984\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8442 - acc: 0.6158 - val_loss: 0.8802 - val_acc: 0.5984\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8391 - acc: 0.6204 - val_loss: 0.8749 - val_acc: 0.5979\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8341 - acc: 0.6238 - val_loss: 0.8715 - val_acc: 0.5995\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8297 - acc: 0.6167 - val_loss: 0.8700 - val_acc: 0.5963\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8234 - acc: 0.6220 - val_loss: 0.8620 - val_acc: 0.6053\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8210 - acc: 0.6305 - val_loss: 0.8653 - val_acc: 0.5968\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8167 - acc: 0.6291 - val_loss: 0.8598 - val_acc: 0.6107\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8096 - acc: 0.6330 - val_loss: 0.8579 - val_acc: 0.6080\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8081 - acc: 0.6389 - val_loss: 0.8601 - val_acc: 0.6069\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8037 - acc: 0.6408 - val_loss: 0.8548 - val_acc: 0.6160\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8003 - acc: 0.6403 - val_loss: 0.8493 - val_acc: 0.6133\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7968 - acc: 0.6437 - val_loss: 0.8692 - val_acc: 0.6107\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7935 - acc: 0.6520 - val_loss: 0.8471 - val_acc: 0.6203\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7883 - acc: 0.6462 - val_loss: 0.8665 - val_acc: 0.5867\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7891 - acc: 0.6474 - val_loss: 0.8447 - val_acc: 0.6171\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 504us/step - loss: 0.7826 - acc: 0.6545 - val_loss: 0.8588 - val_acc: 0.6128\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7800 - acc: 0.6568 - val_loss: 0.8515 - val_acc: 0.6096\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7781 - acc: 0.6597 - val_loss: 0.8583 - val_acc: 0.5952\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7742 - acc: 0.6563 - val_loss: 0.8614 - val_acc: 0.5936\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7707 - acc: 0.6618 - val_loss: 0.8430 - val_acc: 0.6155\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7692 - acc: 0.6659 - val_loss: 0.8388 - val_acc: 0.6229\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7630 - acc: 0.6718 - val_loss: 0.8381 - val_acc: 0.6171\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7633 - acc: 0.6664 - val_loss: 0.8451 - val_acc: 0.6149\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7581 - acc: 0.6682 - val_loss: 0.8418 - val_acc: 0.6144\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7586 - acc: 0.6659 - val_loss: 0.8357 - val_acc: 0.6165\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7531 - acc: 0.6693 - val_loss: 0.8375 - val_acc: 0.6208\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7533 - acc: 0.6732 - val_loss: 0.8425 - val_acc: 0.6101\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7458 - acc: 0.6762 - val_loss: 0.8336 - val_acc: 0.6288\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7468 - acc: 0.6751 - val_loss: 0.8437 - val_acc: 0.6251\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7435 - acc: 0.6789 - val_loss: 0.8467 - val_acc: 0.6080\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7418 - acc: 0.6771 - val_loss: 0.8342 - val_acc: 0.6224\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7374 - acc: 0.6808 - val_loss: 0.8423 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7376 - acc: 0.6803 - val_loss: 0.8431 - val_acc: 0.6149\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7305 - acc: 0.6842 - val_loss: 0.8304 - val_acc: 0.6304\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7282 - acc: 0.6837 - val_loss: 0.8302 - val_acc: 0.6235\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7270 - acc: 0.6869 - val_loss: 0.8274 - val_acc: 0.6304\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7230 - acc: 0.6858 - val_loss: 0.8331 - val_acc: 0.6235\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7198 - acc: 0.6899 - val_loss: 0.8449 - val_acc: 0.6139\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7189 - acc: 0.6890 - val_loss: 0.8496 - val_acc: 0.6187\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7162 - acc: 0.6981 - val_loss: 0.8343 - val_acc: 0.6325\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 395us/step - loss: 0.7124 - acc: 0.6904 - val_loss: 0.8282 - val_acc: 0.6336\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7157 - acc: 0.6940 - val_loss: 0.8342 - val_acc: 0.6320\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7093 - acc: 0.6963 - val_loss: 0.8442 - val_acc: 0.6251\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7040 - acc: 0.6993 - val_loss: 0.8345 - val_acc: 0.6379\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7020 - acc: 0.7064 - val_loss: 0.8428 - val_acc: 0.6272\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7009 - acc: 0.7004 - val_loss: 0.8441 - val_acc: 0.6315\n",
      "0.609505435126\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0504 - acc: 0.4999 - val_loss: 1.0388 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 1.0348 - acc: 0.5006 - val_loss: 1.0344 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 1.0295 - acc: 0.5006 - val_loss: 1.0297 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 1.0239 - acc: 0.5006 - val_loss: 1.0249 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 1.0178 - acc: 0.5006 - val_loss: 1.0195 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 1.0110 - acc: 0.5006 - val_loss: 1.0136 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 1.0035 - acc: 0.5008 - val_loss: 1.0077 - val_acc: 0.5019\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.9957 - acc: 0.5022 - val_loss: 1.0001 - val_acc: 0.5051\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9869 - acc: 0.5058 - val_loss: 0.9925 - val_acc: 0.5077\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.9778 - acc: 0.5086 - val_loss: 0.9844 - val_acc: 0.5136\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.9683 - acc: 0.5164 - val_loss: 0.9761 - val_acc: 0.5205\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 0.9586 - acc: 0.5294 - val_loss: 0.9675 - val_acc: 0.5232\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.9482 - acc: 0.5365 - val_loss: 0.9591 - val_acc: 0.5312\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 512us/step - loss: 0.9383 - acc: 0.5468 - val_loss: 0.9501 - val_acc: 0.5467\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9279 - acc: 0.5584 - val_loss: 0.9411 - val_acc: 0.5488\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.9179 - acc: 0.5600 - val_loss: 0.9361 - val_acc: 0.5541\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.9100 - acc: 0.5680 - val_loss: 0.9288 - val_acc: 0.5621\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9008 - acc: 0.5753 - val_loss: 0.9198 - val_acc: 0.5701\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8931 - acc: 0.5776 - val_loss: 0.9130 - val_acc: 0.5707\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8847 - acc: 0.5838 - val_loss: 0.9075 - val_acc: 0.5797\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8786 - acc: 0.5916 - val_loss: 0.9042 - val_acc: 0.5813\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8712 - acc: 0.5920 - val_loss: 0.8983 - val_acc: 0.5888\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.8664 - acc: 0.5966 - val_loss: 0.8910 - val_acc: 0.5813\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8588 - acc: 0.5968 - val_loss: 0.8845 - val_acc: 0.5931\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8528 - acc: 0.5973 - val_loss: 0.8802 - val_acc: 0.5915\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8484 - acc: 0.6087 - val_loss: 0.8761 - val_acc: 0.5925\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8427 - acc: 0.6030 - val_loss: 0.8838 - val_acc: 0.5941\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.8404 - acc: 0.6090 - val_loss: 0.8709 - val_acc: 0.6037\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8353 - acc: 0.6131 - val_loss: 0.8708 - val_acc: 0.6032\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8307 - acc: 0.6140 - val_loss: 0.8651 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.8271 - acc: 0.6195 - val_loss: 0.8654 - val_acc: 0.6032\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8220 - acc: 0.6181 - val_loss: 0.8641 - val_acc: 0.6107\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8183 - acc: 0.6252 - val_loss: 0.8572 - val_acc: 0.6107\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8147 - acc: 0.6286 - val_loss: 0.8565 - val_acc: 0.6096\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 505us/step - loss: 0.8120 - acc: 0.6284 - val_loss: 0.8524 - val_acc: 0.6112\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8097 - acc: 0.6316 - val_loss: 0.8569 - val_acc: 0.6144\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8050 - acc: 0.6350 - val_loss: 0.8503 - val_acc: 0.6176\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8002 - acc: 0.6394 - val_loss: 0.8550 - val_acc: 0.6160\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7992 - acc: 0.6375 - val_loss: 0.8496 - val_acc: 0.6144\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7909 - acc: 0.6449 - val_loss: 0.8616 - val_acc: 0.6032\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7909 - acc: 0.6462 - val_loss: 0.8451 - val_acc: 0.6176\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7886 - acc: 0.6469 - val_loss: 0.8497 - val_acc: 0.6139\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7860 - acc: 0.6462 - val_loss: 0.8438 - val_acc: 0.6224\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7815 - acc: 0.6440 - val_loss: 0.8464 - val_acc: 0.6101\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7783 - acc: 0.6549 - val_loss: 0.8529 - val_acc: 0.6069\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7756 - acc: 0.6510 - val_loss: 0.8374 - val_acc: 0.6251\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7729 - acc: 0.6526 - val_loss: 0.8403 - val_acc: 0.6171\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7710 - acc: 0.6568 - val_loss: 0.8532 - val_acc: 0.6085\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7673 - acc: 0.6540 - val_loss: 0.8535 - val_acc: 0.6208\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7651 - acc: 0.6595 - val_loss: 0.8544 - val_acc: 0.6069\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7620 - acc: 0.6620 - val_loss: 0.8445 - val_acc: 0.6208\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7598 - acc: 0.6625 - val_loss: 0.8442 - val_acc: 0.6101\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7559 - acc: 0.6609 - val_loss: 0.8351 - val_acc: 0.6245\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7556 - acc: 0.6648 - val_loss: 0.8327 - val_acc: 0.6277\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7507 - acc: 0.6716 - val_loss: 0.8341 - val_acc: 0.6165\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7495 - acc: 0.6705 - val_loss: 0.8358 - val_acc: 0.6261\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 383us/step - loss: 0.7490 - acc: 0.6684 - val_loss: 0.8782 - val_acc: 0.5872\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7462 - acc: 0.6714 - val_loss: 0.8305 - val_acc: 0.6304\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7421 - acc: 0.6764 - val_loss: 0.8289 - val_acc: 0.6267\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7379 - acc: 0.6821 - val_loss: 0.8342 - val_acc: 0.6155\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7376 - acc: 0.6785 - val_loss: 0.8295 - val_acc: 0.6283\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7328 - acc: 0.6821 - val_loss: 0.8330 - val_acc: 0.6304\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7300 - acc: 0.6805 - val_loss: 0.8374 - val_acc: 0.6272\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7262 - acc: 0.6817 - val_loss: 0.8395 - val_acc: 0.6155\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7242 - acc: 0.6865 - val_loss: 0.8826 - val_acc: 0.5984\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7248 - acc: 0.6828 - val_loss: 0.8281 - val_acc: 0.6245\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7205 - acc: 0.6826 - val_loss: 0.8601 - val_acc: 0.6208\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7191 - acc: 0.6897 - val_loss: 0.8415 - val_acc: 0.6272\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7172 - acc: 0.6826 - val_loss: 0.8253 - val_acc: 0.6261\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7123 - acc: 0.6853 - val_loss: 0.8225 - val_acc: 0.6304\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7103 - acc: 0.6917 - val_loss: 0.8249 - val_acc: 0.6309\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7108 - acc: 0.6913 - val_loss: 0.8344 - val_acc: 0.6309\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7034 - acc: 0.6915 - val_loss: 0.8302 - val_acc: 0.6235\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7048 - acc: 0.6949 - val_loss: 0.8233 - val_acc: 0.6315\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6982 - acc: 0.6986 - val_loss: 0.8262 - val_acc: 0.6341\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6955 - acc: 0.7025 - val_loss: 0.8262 - val_acc: 0.6293\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6971 - acc: 0.6947 - val_loss: 0.8331 - val_acc: 0.6197\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.6948 - acc: 0.6965 - val_loss: 0.8366 - val_acc: 0.6331\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6873 - acc: 0.7059 - val_loss: 0.8439 - val_acc: 0.6405\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 386us/step - loss: 0.6909 - acc: 0.7032 - val_loss: 0.8273 - val_acc: 0.6421\n",
      "0.611605235091\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0506 - acc: 0.4971 - val_loss: 1.0358 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 1.0347 - acc: 0.5006 - val_loss: 1.0300 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0289 - acc: 0.5006 - val_loss: 1.0239 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 1.0231 - acc: 0.5006 - val_loss: 1.0179 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 1.0169 - acc: 0.5006 - val_loss: 1.0115 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0102 - acc: 0.5006 - val_loss: 1.0047 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 1.0032 - acc: 0.5008 - val_loss: 0.9973 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9953 - acc: 0.5017 - val_loss: 0.9890 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9870 - acc: 0.5047 - val_loss: 0.9802 - val_acc: 0.5104\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9782 - acc: 0.5106 - val_loss: 0.9712 - val_acc: 0.5141\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.9690 - acc: 0.5207 - val_loss: 0.9617 - val_acc: 0.5365\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9601 - acc: 0.5296 - val_loss: 0.9529 - val_acc: 0.5408\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9521 - acc: 0.5358 - val_loss: 0.9447 - val_acc: 0.5419\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9436 - acc: 0.5420 - val_loss: 0.9355 - val_acc: 0.5616\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9360 - acc: 0.5502 - val_loss: 0.9292 - val_acc: 0.5600\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9289 - acc: 0.5550 - val_loss: 0.9206 - val_acc: 0.5685\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9207 - acc: 0.5577 - val_loss: 0.9143 - val_acc: 0.5797\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9139 - acc: 0.5639 - val_loss: 0.9084 - val_acc: 0.5808\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9058 - acc: 0.5703 - val_loss: 0.9098 - val_acc: 0.5808\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.9007 - acc: 0.5733 - val_loss: 0.9037 - val_acc: 0.5765\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.8952 - acc: 0.5786 - val_loss: 0.8919 - val_acc: 0.5813\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.8883 - acc: 0.5840 - val_loss: 0.8927 - val_acc: 0.5893\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8831 - acc: 0.5845 - val_loss: 0.8855 - val_acc: 0.5899\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8772 - acc: 0.5888 - val_loss: 0.8760 - val_acc: 0.5989\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8717 - acc: 0.5955 - val_loss: 0.8721 - val_acc: 0.6016\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8641 - acc: 0.5998 - val_loss: 0.8818 - val_acc: 0.5877\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8612 - acc: 0.6014 - val_loss: 0.8654 - val_acc: 0.6123\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.8554 - acc: 0.6067 - val_loss: 0.8608 - val_acc: 0.6064\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 376us/step - loss: 0.8520 - acc: 0.6048 - val_loss: 0.8783 - val_acc: 0.6016\n",
      "Epoch 30/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8478 - acc: 0.6060 - val_loss: 0.8610 - val_acc: 0.6027\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8425 - acc: 0.6090 - val_loss: 0.8516 - val_acc: 0.6117\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8386 - acc: 0.6206 - val_loss: 0.8538 - val_acc: 0.6069\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8346 - acc: 0.6229 - val_loss: 0.8484 - val_acc: 0.6112\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.8296 - acc: 0.6231 - val_loss: 0.8497 - val_acc: 0.6171\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8258 - acc: 0.6284 - val_loss: 0.8580 - val_acc: 0.6005\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8239 - acc: 0.6273 - val_loss: 0.8512 - val_acc: 0.6144\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.8195 - acc: 0.6286 - val_loss: 0.8450 - val_acc: 0.6144\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8160 - acc: 0.6270 - val_loss: 0.8628 - val_acc: 0.5989\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8136 - acc: 0.6318 - val_loss: 0.8464 - val_acc: 0.6112\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8099 - acc: 0.6282 - val_loss: 0.8371 - val_acc: 0.6187\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8072 - acc: 0.6371 - val_loss: 0.8349 - val_acc: 0.6187\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8036 - acc: 0.6330 - val_loss: 0.8344 - val_acc: 0.6197\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8009 - acc: 0.6373 - val_loss: 0.8310 - val_acc: 0.6187\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7974 - acc: 0.6440 - val_loss: 0.8392 - val_acc: 0.6128\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7912 - acc: 0.6458 - val_loss: 0.8278 - val_acc: 0.6192\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7907 - acc: 0.6419 - val_loss: 0.8311 - val_acc: 0.6288\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.7870 - acc: 0.6478 - val_loss: 0.8207 - val_acc: 0.6256\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7844 - acc: 0.6510 - val_loss: 0.8438 - val_acc: 0.6213\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7851 - acc: 0.6522 - val_loss: 0.8221 - val_acc: 0.6256\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7789 - acc: 0.6545 - val_loss: 0.8358 - val_acc: 0.6139\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7800 - acc: 0.6547 - val_loss: 0.8182 - val_acc: 0.6347\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 505us/step - loss: 0.7741 - acc: 0.6611 - val_loss: 0.8302 - val_acc: 0.6277\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7705 - acc: 0.6577 - val_loss: 0.8233 - val_acc: 0.6245\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7672 - acc: 0.6613 - val_loss: 0.8133 - val_acc: 0.6331\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7641 - acc: 0.6609 - val_loss: 0.8191 - val_acc: 0.6267\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7635 - acc: 0.6618 - val_loss: 0.8133 - val_acc: 0.6352\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7592 - acc: 0.6700 - val_loss: 0.8158 - val_acc: 0.6395\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7576 - acc: 0.6670 - val_loss: 0.8138 - val_acc: 0.6341\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7533 - acc: 0.6668 - val_loss: 0.8202 - val_acc: 0.6315\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7498 - acc: 0.6693 - val_loss: 0.8142 - val_acc: 0.6336\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7486 - acc: 0.6714 - val_loss: 0.8450 - val_acc: 0.6208\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7479 - acc: 0.6748 - val_loss: 0.8136 - val_acc: 0.6384\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7422 - acc: 0.6712 - val_loss: 0.8163 - val_acc: 0.6331\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7403 - acc: 0.6744 - val_loss: 0.8138 - val_acc: 0.6389\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7413 - acc: 0.6785 - val_loss: 0.8332 - val_acc: 0.6208\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7369 - acc: 0.6794 - val_loss: 0.8126 - val_acc: 0.6352\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7325 - acc: 0.6803 - val_loss: 0.8077 - val_acc: 0.6453\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7326 - acc: 0.6751 - val_loss: 0.8060 - val_acc: 0.6469\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7295 - acc: 0.6837 - val_loss: 0.8214 - val_acc: 0.6315\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7258 - acc: 0.6844 - val_loss: 0.8070 - val_acc: 0.6384\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7237 - acc: 0.6883 - val_loss: 0.8066 - val_acc: 0.6331\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7235 - acc: 0.6819 - val_loss: 0.8207 - val_acc: 0.6363\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7191 - acc: 0.6885 - val_loss: 0.8150 - val_acc: 0.6379\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7175 - acc: 0.6872 - val_loss: 0.8211 - val_acc: 0.6389\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7133 - acc: 0.6922 - val_loss: 0.8480 - val_acc: 0.6117\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7130 - acc: 0.6876 - val_loss: 0.8002 - val_acc: 0.6517\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7101 - acc: 0.6968 - val_loss: 0.8079 - val_acc: 0.6405\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7072 - acc: 0.6901 - val_loss: 0.8069 - val_acc: 0.6427\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7037 - acc: 0.6943 - val_loss: 0.7984 - val_acc: 0.6485\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7014 - acc: 0.6936 - val_loss: 0.8065 - val_acc: 0.6368\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7007 - acc: 0.6991 - val_loss: 0.7997 - val_acc: 0.6485\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6980 - acc: 0.6936 - val_loss: 0.8010 - val_acc: 0.6421\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6920 - acc: 0.7013 - val_loss: 0.8041 - val_acc: 0.6496\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.6903 - acc: 0.7025 - val_loss: 0.7965 - val_acc: 0.6517\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6865 - acc: 0.7036 - val_loss: 0.8096 - val_acc: 0.6448\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6868 - acc: 0.7048 - val_loss: 0.8012 - val_acc: 0.6528\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6850 - acc: 0.7018 - val_loss: 0.8298 - val_acc: 0.6293\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6836 - acc: 0.7032 - val_loss: 0.8003 - val_acc: 0.6480\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.6802 - acc: 0.7068 - val_loss: 0.8006 - val_acc: 0.6512\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6734 - acc: 0.7066 - val_loss: 0.8082 - val_acc: 0.6389\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6733 - acc: 0.7059 - val_loss: 0.7981 - val_acc: 0.6485\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.6713 - acc: 0.7137 - val_loss: 0.8098 - val_acc: 0.6432\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6631 - acc: 0.7183 - val_loss: 0.8023 - val_acc: 0.6533\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.6662 - acc: 0.7158 - val_loss: 0.8032 - val_acc: 0.6512\n",
      "0.599987152253\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0505 - acc: 0.4994 - val_loss: 1.0396 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 1.0360 - acc: 0.5006 - val_loss: 1.0359 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0315 - acc: 0.5006 - val_loss: 1.0314 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 1.0265 - acc: 0.5006 - val_loss: 1.0267 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0213 - acc: 0.5006 - val_loss: 1.0226 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 1.0161 - acc: 0.5006 - val_loss: 1.0175 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 1.0106 - acc: 0.5008 - val_loss: 1.0121 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 1.0044 - acc: 0.5019 - val_loss: 1.0067 - val_acc: 0.5029\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9979 - acc: 0.5045 - val_loss: 1.0009 - val_acc: 0.5040\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9911 - acc: 0.5086 - val_loss: 0.9943 - val_acc: 0.5131\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9837 - acc: 0.5138 - val_loss: 0.9879 - val_acc: 0.5147\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9759 - acc: 0.5202 - val_loss: 0.9805 - val_acc: 0.5216\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9678 - acc: 0.5282 - val_loss: 0.9734 - val_acc: 0.5275\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9590 - acc: 0.5344 - val_loss: 0.9661 - val_acc: 0.5291\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9507 - acc: 0.5431 - val_loss: 0.9593 - val_acc: 0.5387\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9418 - acc: 0.5548 - val_loss: 0.9522 - val_acc: 0.5531\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9325 - acc: 0.5582 - val_loss: 0.9443 - val_acc: 0.5456\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.9241 - acc: 0.5657 - val_loss: 0.9342 - val_acc: 0.5579\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9143 - acc: 0.5694 - val_loss: 0.9301 - val_acc: 0.5547\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.9041 - acc: 0.5767 - val_loss: 0.9198 - val_acc: 0.5675\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8959 - acc: 0.5831 - val_loss: 0.9147 - val_acc: 0.5728\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8887 - acc: 0.5868 - val_loss: 0.9073 - val_acc: 0.5765\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8810 - acc: 0.5923 - val_loss: 0.9059 - val_acc: 0.5755\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8747 - acc: 0.5916 - val_loss: 0.9063 - val_acc: 0.5712\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.8695 - acc: 0.5987 - val_loss: 0.8935 - val_acc: 0.5899\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8642 - acc: 0.6010 - val_loss: 0.8930 - val_acc: 0.5851\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.8586 - acc: 0.6021 - val_loss: 0.8887 - val_acc: 0.5883\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.8552 - acc: 0.6085 - val_loss: 0.8951 - val_acc: 0.5840\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8495 - acc: 0.6078 - val_loss: 0.8794 - val_acc: 0.5952\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8463 - acc: 0.6161 - val_loss: 0.8756 - val_acc: 0.5984\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8408 - acc: 0.6165 - val_loss: 0.8867 - val_acc: 0.5952\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8372 - acc: 0.6183 - val_loss: 0.8957 - val_acc: 0.5797\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8319 - acc: 0.6199 - val_loss: 0.8806 - val_acc: 0.5936\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8305 - acc: 0.6247 - val_loss: 0.8684 - val_acc: 0.6053\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8270 - acc: 0.6225 - val_loss: 0.8632 - val_acc: 0.6048\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8214 - acc: 0.6314 - val_loss: 0.8633 - val_acc: 0.5995\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8200 - acc: 0.6293 - val_loss: 0.8595 - val_acc: 0.6016\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.8171 - acc: 0.6302 - val_loss: 0.8580 - val_acc: 0.6091\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8137 - acc: 0.6305 - val_loss: 0.8544 - val_acc: 0.6096\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8092 - acc: 0.6380 - val_loss: 0.8607 - val_acc: 0.5979\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.8062 - acc: 0.6378 - val_loss: 0.8515 - val_acc: 0.6128\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8025 - acc: 0.6428 - val_loss: 0.8497 - val_acc: 0.6123\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7989 - acc: 0.6440 - val_loss: 0.8517 - val_acc: 0.6187\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7995 - acc: 0.6440 - val_loss: 0.8523 - val_acc: 0.6139\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7969 - acc: 0.6414 - val_loss: 0.8463 - val_acc: 0.6123\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7915 - acc: 0.6424 - val_loss: 0.8452 - val_acc: 0.6176\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7880 - acc: 0.6469 - val_loss: 0.8454 - val_acc: 0.6160\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7854 - acc: 0.6476 - val_loss: 0.8494 - val_acc: 0.6181\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7816 - acc: 0.6492 - val_loss: 0.8394 - val_acc: 0.6219\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7822 - acc: 0.6508 - val_loss: 0.8369 - val_acc: 0.6245\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7784 - acc: 0.6501 - val_loss: 0.8346 - val_acc: 0.6229\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7715 - acc: 0.6545 - val_loss: 0.8574 - val_acc: 0.6075\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7723 - acc: 0.6538 - val_loss: 0.8367 - val_acc: 0.6325\n",
      "Epoch 54/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7686 - acc: 0.6611 - val_loss: 0.8295 - val_acc: 0.6304\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7662 - acc: 0.6609 - val_loss: 0.8302 - val_acc: 0.6315\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7642 - acc: 0.6590 - val_loss: 0.8308 - val_acc: 0.6309\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7620 - acc: 0.6622 - val_loss: 0.8395 - val_acc: 0.6208\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7590 - acc: 0.6636 - val_loss: 0.8309 - val_acc: 0.6315\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.7546 - acc: 0.6716 - val_loss: 0.8361 - val_acc: 0.6245\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7528 - acc: 0.6693 - val_loss: 0.8304 - val_acc: 0.6272\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.7518 - acc: 0.6705 - val_loss: 0.8378 - val_acc: 0.6240\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 0.7489 - acc: 0.6723 - val_loss: 0.8272 - val_acc: 0.6309\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 0.7447 - acc: 0.6712 - val_loss: 0.8434 - val_acc: 0.6368\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.7437 - acc: 0.6702 - val_loss: 0.8217 - val_acc: 0.6405\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7441 - acc: 0.6789 - val_loss: 0.8342 - val_acc: 0.6373\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 511us/step - loss: 0.7396 - acc: 0.6778 - val_loss: 0.8189 - val_acc: 0.6395\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7380 - acc: 0.6767 - val_loss: 0.8192 - val_acc: 0.6416\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7338 - acc: 0.6831 - val_loss: 0.8193 - val_acc: 0.6485\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7280 - acc: 0.6815 - val_loss: 0.8273 - val_acc: 0.6373\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7299 - acc: 0.6831 - val_loss: 0.8297 - val_acc: 0.6379\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7240 - acc: 0.6876 - val_loss: 0.8192 - val_acc: 0.6400\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7211 - acc: 0.6911 - val_loss: 0.8247 - val_acc: 0.6453\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7190 - acc: 0.6899 - val_loss: 0.8142 - val_acc: 0.6469\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7184 - acc: 0.6819 - val_loss: 0.8174 - val_acc: 0.6459\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7161 - acc: 0.6851 - val_loss: 0.8102 - val_acc: 0.6496\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7144 - acc: 0.6888 - val_loss: 0.8144 - val_acc: 0.6432\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7143 - acc: 0.6915 - val_loss: 0.8138 - val_acc: 0.6485\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7058 - acc: 0.6954 - val_loss: 0.8336 - val_acc: 0.6395\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.7053 - acc: 0.6995 - val_loss: 0.8214 - val_acc: 0.6363\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7046 - acc: 0.7016 - val_loss: 0.8327 - val_acc: 0.6352\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 0.7029 - acc: 0.6972 - val_loss: 0.8295 - val_acc: 0.6299\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7011 - acc: 0.6952 - val_loss: 0.8202 - val_acc: 0.6363\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.6989 - acc: 0.7025 - val_loss: 0.8377 - val_acc: 0.6309\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.6942 - acc: 0.7002 - val_loss: 0.8295 - val_acc: 0.6368\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6928 - acc: 0.7084 - val_loss: 0.8390 - val_acc: 0.6272\n",
      "0.610904945353\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 10s 2ms/step - loss: 1.0494 - acc: 0.4999 - val_loss: 1.0382 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 519us/step - loss: 1.0335 - acc: 0.5006 - val_loss: 1.0330 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 1.0273 - acc: 0.5006 - val_loss: 1.0283 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 1.0214 - acc: 0.5006 - val_loss: 1.0223 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 1.0148 - acc: 0.5006 - val_loss: 1.0165 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 1.0078 - acc: 0.5006 - val_loss: 1.0108 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 1.0005 - acc: 0.5017 - val_loss: 1.0033 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9921 - acc: 0.5035 - val_loss: 0.9953 - val_acc: 0.5035\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9831 - acc: 0.5086 - val_loss: 0.9870 - val_acc: 0.5061\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9737 - acc: 0.5173 - val_loss: 0.9782 - val_acc: 0.5141\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9638 - acc: 0.5260 - val_loss: 0.9688 - val_acc: 0.5163\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.9539 - acc: 0.5305 - val_loss: 0.9599 - val_acc: 0.5317\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9440 - acc: 0.5356 - val_loss: 0.9507 - val_acc: 0.5477\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9349 - acc: 0.5475 - val_loss: 0.9434 - val_acc: 0.5376\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9266 - acc: 0.5511 - val_loss: 0.9345 - val_acc: 0.5520\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9174 - acc: 0.5621 - val_loss: 0.9267 - val_acc: 0.5531\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9106 - acc: 0.5715 - val_loss: 0.9203 - val_acc: 0.5611\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9029 - acc: 0.5756 - val_loss: 0.9204 - val_acc: 0.5675\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8950 - acc: 0.5852 - val_loss: 0.9124 - val_acc: 0.5659\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8885 - acc: 0.5859 - val_loss: 0.8989 - val_acc: 0.5744\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8816 - acc: 0.5904 - val_loss: 0.8970 - val_acc: 0.5893\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8752 - acc: 0.5994 - val_loss: 0.8906 - val_acc: 0.5835\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.8686 - acc: 0.6030 - val_loss: 0.8924 - val_acc: 0.5819\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8619 - acc: 0.6044 - val_loss: 0.8777 - val_acc: 0.5861\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.8577 - acc: 0.6078 - val_loss: 0.8757 - val_acc: 0.5899\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8510 - acc: 0.6113 - val_loss: 0.8735 - val_acc: 0.5931\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8460 - acc: 0.6142 - val_loss: 0.8703 - val_acc: 0.5968\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.8412 - acc: 0.6133 - val_loss: 0.8848 - val_acc: 0.5840\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.8361 - acc: 0.6193 - val_loss: 0.8568 - val_acc: 0.6053\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.8325 - acc: 0.6234 - val_loss: 0.8552 - val_acc: 0.6048\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.8288 - acc: 0.6222 - val_loss: 0.8505 - val_acc: 0.6107\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.8245 - acc: 0.6268 - val_loss: 0.8515 - val_acc: 0.6139\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8216 - acc: 0.6229 - val_loss: 0.8459 - val_acc: 0.6075\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.8164 - acc: 0.6339 - val_loss: 0.8484 - val_acc: 0.6112\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8137 - acc: 0.6346 - val_loss: 0.8429 - val_acc: 0.6107\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8089 - acc: 0.6371 - val_loss: 0.8388 - val_acc: 0.6091\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.8080 - acc: 0.6353 - val_loss: 0.8407 - val_acc: 0.6123\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8019 - acc: 0.6364 - val_loss: 0.8400 - val_acc: 0.6101\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7992 - acc: 0.6405 - val_loss: 0.8424 - val_acc: 0.6112\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7962 - acc: 0.6444 - val_loss: 0.8443 - val_acc: 0.6139\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7931 - acc: 0.6430 - val_loss: 0.8354 - val_acc: 0.6128\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7909 - acc: 0.6430 - val_loss: 0.8299 - val_acc: 0.6096\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 399us/step - loss: 0.7873 - acc: 0.6435 - val_loss: 0.8536 - val_acc: 0.6043\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7853 - acc: 0.6465 - val_loss: 0.8240 - val_acc: 0.6208\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7809 - acc: 0.6494 - val_loss: 0.8238 - val_acc: 0.6176\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7761 - acc: 0.6504 - val_loss: 0.8234 - val_acc: 0.6229\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7743 - acc: 0.6570 - val_loss: 0.8364 - val_acc: 0.6219\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7718 - acc: 0.6552 - val_loss: 0.8367 - val_acc: 0.6283\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7695 - acc: 0.6604 - val_loss: 0.8251 - val_acc: 0.6256\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7655 - acc: 0.6588 - val_loss: 0.8226 - val_acc: 0.6283\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7640 - acc: 0.6645 - val_loss: 0.8166 - val_acc: 0.6256\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7630 - acc: 0.6602 - val_loss: 0.8304 - val_acc: 0.6187\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7567 - acc: 0.6673 - val_loss: 0.8198 - val_acc: 0.6288\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7552 - acc: 0.6650 - val_loss: 0.8128 - val_acc: 0.6325\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7544 - acc: 0.6643 - val_loss: 0.8439 - val_acc: 0.6229\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7506 - acc: 0.6641 - val_loss: 0.8236 - val_acc: 0.6283\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7488 - acc: 0.6721 - val_loss: 0.8154 - val_acc: 0.6256\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7442 - acc: 0.6707 - val_loss: 0.8228 - val_acc: 0.6171\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7426 - acc: 0.6709 - val_loss: 0.8306 - val_acc: 0.6181\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7395 - acc: 0.6751 - val_loss: 0.8338 - val_acc: 0.6325\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7378 - acc: 0.6739 - val_loss: 0.8106 - val_acc: 0.6331\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7349 - acc: 0.6783 - val_loss: 0.8173 - val_acc: 0.6256\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7337 - acc: 0.6815 - val_loss: 0.8082 - val_acc: 0.6309\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7294 - acc: 0.6796 - val_loss: 0.8156 - val_acc: 0.6272\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7273 - acc: 0.6792 - val_loss: 0.8153 - val_acc: 0.6304\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7257 - acc: 0.6794 - val_loss: 0.8225 - val_acc: 0.6235\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7222 - acc: 0.6865 - val_loss: 0.8141 - val_acc: 0.6304\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7214 - acc: 0.6865 - val_loss: 0.8307 - val_acc: 0.6267\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7178 - acc: 0.6842 - val_loss: 0.8085 - val_acc: 0.6325\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7120 - acc: 0.6892 - val_loss: 0.8356 - val_acc: 0.6203\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7122 - acc: 0.6883 - val_loss: 0.8410 - val_acc: 0.6229\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7094 - acc: 0.6885 - val_loss: 0.8394 - val_acc: 0.6213\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7073 - acc: 0.6933 - val_loss: 0.8094 - val_acc: 0.6395\n",
      "0.598554558547\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 9s 2ms/step - loss: 1.0492 - acc: 0.4990 - val_loss: 1.0350 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 1.0334 - acc: 0.5006 - val_loss: 1.0291 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 1.0269 - acc: 0.5006 - val_loss: 1.0233 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 1.0202 - acc: 0.5006 - val_loss: 1.0168 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 1.0130 - acc: 0.5006 - val_loss: 1.0098 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 1.0049 - acc: 0.5008 - val_loss: 1.0020 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.9958 - acc: 0.5022 - val_loss: 0.9938 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9857 - acc: 0.5047 - val_loss: 0.9857 - val_acc: 0.5029\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9752 - acc: 0.5145 - val_loss: 0.9752 - val_acc: 0.5088\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9646 - acc: 0.5207 - val_loss: 0.9660 - val_acc: 0.5189\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9546 - acc: 0.5282 - val_loss: 0.9582 - val_acc: 0.5307\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9466 - acc: 0.5388 - val_loss: 0.9508 - val_acc: 0.5435\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9383 - acc: 0.5454 - val_loss: 0.9448 - val_acc: 0.5552\n",
      "Epoch 14/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9312 - acc: 0.5493 - val_loss: 0.9385 - val_acc: 0.5568\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.9249 - acc: 0.5529 - val_loss: 0.9314 - val_acc: 0.5669\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9168 - acc: 0.5596 - val_loss: 0.9272 - val_acc: 0.5803\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9097 - acc: 0.5673 - val_loss: 0.9197 - val_acc: 0.5749\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 517us/step - loss: 0.9040 - acc: 0.5687 - val_loss: 0.9164 - val_acc: 0.5840\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.8979 - acc: 0.5731 - val_loss: 0.9122 - val_acc: 0.5904\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.8915 - acc: 0.5797 - val_loss: 0.9079 - val_acc: 0.5920\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.8858 - acc: 0.5850 - val_loss: 0.9058 - val_acc: 0.5792\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.8791 - acc: 0.5943 - val_loss: 0.8933 - val_acc: 0.5931\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.8753 - acc: 0.5959 - val_loss: 0.8903 - val_acc: 0.5888\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 542us/step - loss: 0.8691 - acc: 0.5996 - val_loss: 0.8846 - val_acc: 0.5952\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.8624 - acc: 0.5962 - val_loss: 0.8832 - val_acc: 0.5973\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8567 - acc: 0.6046 - val_loss: 0.8753 - val_acc: 0.6011\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8503 - acc: 0.6076 - val_loss: 0.8730 - val_acc: 0.5995\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8488 - acc: 0.6083 - val_loss: 0.8717 - val_acc: 0.6037\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8425 - acc: 0.6163 - val_loss: 0.8668 - val_acc: 0.6112\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8379 - acc: 0.6183 - val_loss: 0.8687 - val_acc: 0.5984\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.8312 - acc: 0.6213 - val_loss: 0.8696 - val_acc: 0.6091\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8286 - acc: 0.6243 - val_loss: 0.8564 - val_acc: 0.6123\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8266 - acc: 0.6231 - val_loss: 0.8953 - val_acc: 0.5957\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8219 - acc: 0.6268 - val_loss: 0.8486 - val_acc: 0.6165\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8174 - acc: 0.6270 - val_loss: 0.8592 - val_acc: 0.6181\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8133 - acc: 0.6350 - val_loss: 0.8452 - val_acc: 0.6219\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.8090 - acc: 0.6353 - val_loss: 0.8810 - val_acc: 0.5995\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8078 - acc: 0.6327 - val_loss: 0.8483 - val_acc: 0.6224\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8022 - acc: 0.6430 - val_loss: 0.8470 - val_acc: 0.6128\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8001 - acc: 0.6410 - val_loss: 0.8418 - val_acc: 0.6187\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 0.7951 - acc: 0.6428 - val_loss: 0.8409 - val_acc: 0.6144\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7931 - acc: 0.6494 - val_loss: 0.8328 - val_acc: 0.6251\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7881 - acc: 0.6453 - val_loss: 0.8347 - val_acc: 0.6187\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7889 - acc: 0.6513 - val_loss: 0.8295 - val_acc: 0.6229\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7822 - acc: 0.6513 - val_loss: 0.8344 - val_acc: 0.6219\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.7801 - acc: 0.6563 - val_loss: 0.8523 - val_acc: 0.6224\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7779 - acc: 0.6556 - val_loss: 0.8256 - val_acc: 0.6347\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7762 - acc: 0.6586 - val_loss: 0.8272 - val_acc: 0.6176\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 0.7710 - acc: 0.6622 - val_loss: 0.8375 - val_acc: 0.6149\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7697 - acc: 0.6613 - val_loss: 0.8257 - val_acc: 0.6261\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7650 - acc: 0.6616 - val_loss: 0.8369 - val_acc: 0.6261\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7614 - acc: 0.6643 - val_loss: 0.8258 - val_acc: 0.6245\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.7603 - acc: 0.6698 - val_loss: 0.8204 - val_acc: 0.6320\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7564 - acc: 0.6675 - val_loss: 0.8214 - val_acc: 0.6261\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7551 - acc: 0.6654 - val_loss: 0.8243 - val_acc: 0.6240\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7517 - acc: 0.6705 - val_loss: 0.8360 - val_acc: 0.6267\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7495 - acc: 0.6748 - val_loss: 0.8181 - val_acc: 0.6384\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7440 - acc: 0.6787 - val_loss: 0.8669 - val_acc: 0.6021\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7455 - acc: 0.6714 - val_loss: 0.8210 - val_acc: 0.6267\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7423 - acc: 0.6739 - val_loss: 0.8448 - val_acc: 0.6299\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7402 - acc: 0.6789 - val_loss: 0.8178 - val_acc: 0.6341\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.7381 - acc: 0.6787 - val_loss: 0.8167 - val_acc: 0.6341\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7339 - acc: 0.6753 - val_loss: 0.8172 - val_acc: 0.6357\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7300 - acc: 0.6858 - val_loss: 0.8128 - val_acc: 0.6341\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7298 - acc: 0.6815 - val_loss: 0.8173 - val_acc: 0.6389\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7240 - acc: 0.6853 - val_loss: 0.8191 - val_acc: 0.6395\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7233 - acc: 0.6803 - val_loss: 0.8143 - val_acc: 0.6347\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 385us/step - loss: 0.7217 - acc: 0.6876 - val_loss: 0.8188 - val_acc: 0.6357\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7160 - acc: 0.6924 - val_loss: 0.8102 - val_acc: 0.6395\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7176 - acc: 0.6858 - val_loss: 0.8256 - val_acc: 0.6320\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7122 - acc: 0.6943 - val_loss: 0.8286 - val_acc: 0.6421\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7139 - acc: 0.6897 - val_loss: 0.8154 - val_acc: 0.6421\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7056 - acc: 0.6908 - val_loss: 0.8253 - val_acc: 0.6336\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7053 - acc: 0.6952 - val_loss: 0.8104 - val_acc: 0.6416\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7050 - acc: 0.6970 - val_loss: 0.8074 - val_acc: 0.6464\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7021 - acc: 0.6917 - val_loss: 0.8140 - val_acc: 0.6448\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6988 - acc: 0.6984 - val_loss: 0.8126 - val_acc: 0.6373\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6964 - acc: 0.7011 - val_loss: 0.8075 - val_acc: 0.6363\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6948 - acc: 0.7043 - val_loss: 0.8128 - val_acc: 0.6416\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6903 - acc: 0.7025 - val_loss: 0.8545 - val_acc: 0.6224\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.6873 - acc: 0.7087 - val_loss: 0.8077 - val_acc: 0.6432\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.6858 - acc: 0.7082 - val_loss: 0.8233 - val_acc: 0.6373\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.6818 - acc: 0.7034 - val_loss: 0.8307 - val_acc: 0.6379\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.6803 - acc: 0.7087 - val_loss: 0.8085 - val_acc: 0.6432\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.6776 - acc: 0.7119 - val_loss: 0.8089 - val_acc: 0.6485\n",
      "0.606087661632\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 10s 2ms/step - loss: 1.0502 - acc: 0.4976 - val_loss: 1.0380 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 519us/step - loss: 1.0359 - acc: 0.5006 - val_loss: 1.0337 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0309 - acc: 0.5006 - val_loss: 1.0296 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 1.0255 - acc: 0.5006 - val_loss: 1.0249 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 1.0205 - acc: 0.5006 - val_loss: 1.0201 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 1.0149 - acc: 0.5006 - val_loss: 1.0153 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 1.0089 - acc: 0.5006 - val_loss: 1.0098 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 1.0025 - acc: 0.5015 - val_loss: 1.0041 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9956 - acc: 0.5024 - val_loss: 0.9979 - val_acc: 0.5035\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9881 - acc: 0.5056 - val_loss: 0.9915 - val_acc: 0.5088\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9804 - acc: 0.5136 - val_loss: 0.9852 - val_acc: 0.5093\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9727 - acc: 0.5180 - val_loss: 0.9776 - val_acc: 0.5163\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9643 - acc: 0.5271 - val_loss: 0.9704 - val_acc: 0.5275\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9553 - acc: 0.5390 - val_loss: 0.9637 - val_acc: 0.5253\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9475 - acc: 0.5408 - val_loss: 0.9556 - val_acc: 0.5323\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9385 - acc: 0.5504 - val_loss: 0.9490 - val_acc: 0.5440\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9302 - acc: 0.5566 - val_loss: 0.9458 - val_acc: 0.5333\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9227 - acc: 0.5664 - val_loss: 0.9346 - val_acc: 0.5573\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9140 - acc: 0.5687 - val_loss: 0.9294 - val_acc: 0.5563\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9065 - acc: 0.5744 - val_loss: 0.9214 - val_acc: 0.5664\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8991 - acc: 0.5772 - val_loss: 0.9158 - val_acc: 0.5739\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8917 - acc: 0.5868 - val_loss: 0.9096 - val_acc: 0.5755\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8844 - acc: 0.5904 - val_loss: 0.9088 - val_acc: 0.5899\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.8771 - acc: 0.5904 - val_loss: 0.9054 - val_acc: 0.5872\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8701 - acc: 0.5975 - val_loss: 0.8928 - val_acc: 0.5787\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8644 - acc: 0.5968 - val_loss: 0.8891 - val_acc: 0.5909\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8587 - acc: 0.5996 - val_loss: 0.8892 - val_acc: 0.5877\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.8536 - acc: 0.6012 - val_loss: 0.8824 - val_acc: 0.5840\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8487 - acc: 0.6046 - val_loss: 0.8746 - val_acc: 0.5893\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8431 - acc: 0.6092 - val_loss: 0.8727 - val_acc: 0.5979\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8395 - acc: 0.6131 - val_loss: 0.8674 - val_acc: 0.5984\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.8353 - acc: 0.6151 - val_loss: 0.8789 - val_acc: 0.6069\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8299 - acc: 0.6211 - val_loss: 0.8617 - val_acc: 0.5941\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8273 - acc: 0.6275 - val_loss: 0.8741 - val_acc: 0.6043\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8231 - acc: 0.6263 - val_loss: 0.8545 - val_acc: 0.6000\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.8189 - acc: 0.6270 - val_loss: 0.8530 - val_acc: 0.6016\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.8146 - acc: 0.6291 - val_loss: 0.8551 - val_acc: 0.6059\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8116 - acc: 0.6343 - val_loss: 0.8486 - val_acc: 0.6053\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8071 - acc: 0.6343 - val_loss: 0.8509 - val_acc: 0.6085\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.8024 - acc: 0.6430 - val_loss: 0.8576 - val_acc: 0.5925\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8014 - acc: 0.6353 - val_loss: 0.8464 - val_acc: 0.6091\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7986 - acc: 0.6426 - val_loss: 0.8426 - val_acc: 0.6160\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7949 - acc: 0.6462 - val_loss: 0.8508 - val_acc: 0.6229\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7922 - acc: 0.6449 - val_loss: 0.8381 - val_acc: 0.6069\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.7876 - acc: 0.6515 - val_loss: 0.9037 - val_acc: 0.6139\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7867 - acc: 0.6451 - val_loss: 0.8487 - val_acc: 0.5947\n",
      "Epoch 47/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7819 - acc: 0.6533 - val_loss: 0.8435 - val_acc: 0.6085\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7818 - acc: 0.6547 - val_loss: 0.8419 - val_acc: 0.6053\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7772 - acc: 0.6554 - val_loss: 0.8515 - val_acc: 0.6187\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7753 - acc: 0.6590 - val_loss: 0.8406 - val_acc: 0.6107\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7719 - acc: 0.6627 - val_loss: 0.8401 - val_acc: 0.6192\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7707 - acc: 0.6636 - val_loss: 0.8301 - val_acc: 0.6219\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7681 - acc: 0.6595 - val_loss: 0.8394 - val_acc: 0.6144\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7639 - acc: 0.6616 - val_loss: 0.8310 - val_acc: 0.6176\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7618 - acc: 0.6648 - val_loss: 0.8296 - val_acc: 0.6197\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.7601 - acc: 0.6636 - val_loss: 0.8279 - val_acc: 0.6267\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7559 - acc: 0.6677 - val_loss: 0.8461 - val_acc: 0.6240\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7527 - acc: 0.6700 - val_loss: 0.8266 - val_acc: 0.6240\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7518 - acc: 0.6739 - val_loss: 0.8347 - val_acc: 0.6288\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7504 - acc: 0.6785 - val_loss: 0.8267 - val_acc: 0.6331\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.7462 - acc: 0.6776 - val_loss: 0.8231 - val_acc: 0.6267\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7442 - acc: 0.6760 - val_loss: 0.8372 - val_acc: 0.6149\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7409 - acc: 0.6805 - val_loss: 0.8235 - val_acc: 0.6245\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7365 - acc: 0.6824 - val_loss: 0.8297 - val_acc: 0.6288\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7355 - acc: 0.6815 - val_loss: 0.8292 - val_acc: 0.6293\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7322 - acc: 0.6764 - val_loss: 0.8336 - val_acc: 0.6133\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7289 - acc: 0.6847 - val_loss: 0.8247 - val_acc: 0.6304\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7294 - acc: 0.6828 - val_loss: 0.8341 - val_acc: 0.6069\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7247 - acc: 0.6844 - val_loss: 0.8259 - val_acc: 0.6304\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7231 - acc: 0.6915 - val_loss: 0.8263 - val_acc: 0.6272\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7231 - acc: 0.6835 - val_loss: 0.8245 - val_acc: 0.6315\n",
      "0.599066619723\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 10s 2ms/step - loss: 1.0511 - acc: 0.4976 - val_loss: 1.0365 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 1.0350 - acc: 0.5006 - val_loss: 1.0306 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 1.0298 - acc: 0.5006 - val_loss: 1.0249 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 1.0242 - acc: 0.5006 - val_loss: 1.0189 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 1.0183 - acc: 0.5006 - val_loss: 1.0127 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0121 - acc: 0.5008 - val_loss: 1.0057 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 1.0057 - acc: 0.5022 - val_loss: 0.9987 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9987 - acc: 0.5051 - val_loss: 0.9906 - val_acc: 0.5093\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9910 - acc: 0.5109 - val_loss: 0.9818 - val_acc: 0.5125\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9830 - acc: 0.5170 - val_loss: 0.9729 - val_acc: 0.5152\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.9745 - acc: 0.5230 - val_loss: 0.9633 - val_acc: 0.5259\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9654 - acc: 0.5285 - val_loss: 0.9540 - val_acc: 0.5248\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.9566 - acc: 0.5333 - val_loss: 0.9441 - val_acc: 0.5408\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9478 - acc: 0.5426 - val_loss: 0.9346 - val_acc: 0.5408\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9394 - acc: 0.5479 - val_loss: 0.9250 - val_acc: 0.5605\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9312 - acc: 0.5607 - val_loss: 0.9162 - val_acc: 0.5605\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.9224 - acc: 0.5678 - val_loss: 0.9079 - val_acc: 0.5701\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.9155 - acc: 0.5710 - val_loss: 0.9005 - val_acc: 0.5701\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.9085 - acc: 0.5753 - val_loss: 0.8941 - val_acc: 0.5803\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.9007 - acc: 0.5827 - val_loss: 0.8936 - val_acc: 0.5781\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.8957 - acc: 0.5845 - val_loss: 0.8815 - val_acc: 0.5840\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.8895 - acc: 0.5888 - val_loss: 0.8792 - val_acc: 0.5883\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8835 - acc: 0.5923 - val_loss: 0.8753 - val_acc: 0.6091\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8776 - acc: 0.5930 - val_loss: 0.8699 - val_acc: 0.6096\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8729 - acc: 0.5957 - val_loss: 0.8617 - val_acc: 0.6000\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8667 - acc: 0.6023 - val_loss: 0.8666 - val_acc: 0.5920\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8625 - acc: 0.6053 - val_loss: 0.8678 - val_acc: 0.5883\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8591 - acc: 0.6087 - val_loss: 0.8532 - val_acc: 0.6139\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8547 - acc: 0.6126 - val_loss: 0.8471 - val_acc: 0.6160\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8528 - acc: 0.6110 - val_loss: 0.8444 - val_acc: 0.6085\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8469 - acc: 0.6154 - val_loss: 0.8566 - val_acc: 0.6133\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8433 - acc: 0.6204 - val_loss: 0.8410 - val_acc: 0.6144\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.8384 - acc: 0.6183 - val_loss: 0.8351 - val_acc: 0.6203\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8364 - acc: 0.6209 - val_loss: 0.8324 - val_acc: 0.6219\n",
      "Epoch 35/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8338 - acc: 0.6199 - val_loss: 0.8303 - val_acc: 0.6224\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8291 - acc: 0.6227 - val_loss: 0.8294 - val_acc: 0.6165\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8282 - acc: 0.6241 - val_loss: 0.8281 - val_acc: 0.6208\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8232 - acc: 0.6332 - val_loss: 0.8275 - val_acc: 0.6197\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8200 - acc: 0.6321 - val_loss: 0.8227 - val_acc: 0.6288\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8177 - acc: 0.6318 - val_loss: 0.8301 - val_acc: 0.6165\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8142 - acc: 0.6371 - val_loss: 0.8202 - val_acc: 0.6389\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8101 - acc: 0.6373 - val_loss: 0.8218 - val_acc: 0.6219\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8093 - acc: 0.6394 - val_loss: 0.8198 - val_acc: 0.6341\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8048 - acc: 0.6435 - val_loss: 0.8131 - val_acc: 0.6432\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8035 - acc: 0.6405 - val_loss: 0.8168 - val_acc: 0.6400\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7986 - acc: 0.6396 - val_loss: 0.8149 - val_acc: 0.6267\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7941 - acc: 0.6442 - val_loss: 0.8305 - val_acc: 0.6389\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7947 - acc: 0.6435 - val_loss: 0.8243 - val_acc: 0.6139\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.7913 - acc: 0.6522 - val_loss: 0.8073 - val_acc: 0.6416\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 508us/step - loss: 0.7884 - acc: 0.6515 - val_loss: 0.8070 - val_acc: 0.6459\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.7859 - acc: 0.6499 - val_loss: 0.8133 - val_acc: 0.6304\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7829 - acc: 0.6522 - val_loss: 0.8030 - val_acc: 0.6432\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7835 - acc: 0.6526 - val_loss: 0.8051 - val_acc: 0.6496\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7771 - acc: 0.6529 - val_loss: 0.8088 - val_acc: 0.6304\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7757 - acc: 0.6616 - val_loss: 0.8100 - val_acc: 0.6325\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7742 - acc: 0.6558 - val_loss: 0.8060 - val_acc: 0.6469\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7716 - acc: 0.6604 - val_loss: 0.8001 - val_acc: 0.6427\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7674 - acc: 0.6613 - val_loss: 0.7978 - val_acc: 0.6512\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.7638 - acc: 0.6648 - val_loss: 0.8004 - val_acc: 0.6501\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7623 - acc: 0.6689 - val_loss: 0.7968 - val_acc: 0.6432\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7569 - acc: 0.6696 - val_loss: 0.8076 - val_acc: 0.6352\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7586 - acc: 0.6666 - val_loss: 0.7984 - val_acc: 0.6485\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7524 - acc: 0.6698 - val_loss: 0.8163 - val_acc: 0.6357\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7497 - acc: 0.6753 - val_loss: 0.7941 - val_acc: 0.6443\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7483 - acc: 0.6707 - val_loss: 0.7915 - val_acc: 0.6507\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7464 - acc: 0.6714 - val_loss: 0.7946 - val_acc: 0.6427\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7458 - acc: 0.6732 - val_loss: 0.7972 - val_acc: 0.6453\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7411 - acc: 0.6760 - val_loss: 0.8113 - val_acc: 0.6299\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7405 - acc: 0.6748 - val_loss: 0.7944 - val_acc: 0.6432\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7379 - acc: 0.6824 - val_loss: 0.7985 - val_acc: 0.6453\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7336 - acc: 0.6828 - val_loss: 0.7887 - val_acc: 0.6528\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7262 - acc: 0.6856 - val_loss: 0.8363 - val_acc: 0.6251\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7317 - acc: 0.6833 - val_loss: 0.7878 - val_acc: 0.6539\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7271 - acc: 0.6851 - val_loss: 0.7907 - val_acc: 0.6464\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7253 - acc: 0.6821 - val_loss: 0.8045 - val_acc: 0.6427\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7223 - acc: 0.6911 - val_loss: 0.7958 - val_acc: 0.6507\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7164 - acc: 0.6892 - val_loss: 0.8043 - val_acc: 0.6507\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7176 - acc: 0.6899 - val_loss: 0.8386 - val_acc: 0.6160\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7135 - acc: 0.6931 - val_loss: 0.8049 - val_acc: 0.6389\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7127 - acc: 0.6943 - val_loss: 0.8057 - val_acc: 0.6405\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7114 - acc: 0.6965 - val_loss: 0.7860 - val_acc: 0.6565\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7071 - acc: 0.6981 - val_loss: 0.7939 - val_acc: 0.6427\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7024 - acc: 0.7004 - val_loss: 0.7923 - val_acc: 0.6533\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7022 - acc: 0.7009 - val_loss: 0.7826 - val_acc: 0.6517\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7022 - acc: 0.6972 - val_loss: 0.7843 - val_acc: 0.6496\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.6971 - acc: 0.7066 - val_loss: 0.8000 - val_acc: 0.6539\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.6944 - acc: 0.7029 - val_loss: 0.7940 - val_acc: 0.6528\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6953 - acc: 0.7011 - val_loss: 0.7999 - val_acc: 0.6437\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.6901 - acc: 0.7100 - val_loss: 0.7921 - val_acc: 0.6459\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6879 - acc: 0.7066 - val_loss: 0.7884 - val_acc: 0.6571\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.6874 - acc: 0.7094 - val_loss: 0.7861 - val_acc: 0.6501\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6818 - acc: 0.7123 - val_loss: 0.7972 - val_acc: 0.6512\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6792 - acc: 0.7096 - val_loss: 0.7858 - val_acc: 0.6539\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6773 - acc: 0.7169 - val_loss: 0.7886 - val_acc: 0.6560\n",
      "0.585588374676\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 10s 2ms/step - loss: 1.0529 - acc: 0.4994 - val_loss: 1.0354 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0339 - acc: 0.5006 - val_loss: 1.0299 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 1.0281 - acc: 0.5006 - val_loss: 1.0246 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 1.0218 - acc: 0.5006 - val_loss: 1.0189 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 1.0150 - acc: 0.5006 - val_loss: 1.0129 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0076 - acc: 0.5006 - val_loss: 1.0062 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9994 - acc: 0.5010 - val_loss: 0.9992 - val_acc: 0.5029\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9905 - acc: 0.5024 - val_loss: 0.9906 - val_acc: 0.5035\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9803 - acc: 0.5058 - val_loss: 0.9827 - val_acc: 0.5083\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9696 - acc: 0.5152 - val_loss: 0.9729 - val_acc: 0.5152\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.9586 - acc: 0.5264 - val_loss: 0.9637 - val_acc: 0.5253\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.9477 - acc: 0.5385 - val_loss: 0.9550 - val_acc: 0.5317\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9371 - acc: 0.5534 - val_loss: 0.9489 - val_acc: 0.5339\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.9269 - acc: 0.5596 - val_loss: 0.9386 - val_acc: 0.5493\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9179 - acc: 0.5717 - val_loss: 0.9310 - val_acc: 0.5573\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9086 - acc: 0.5786 - val_loss: 0.9259 - val_acc: 0.5541\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.9012 - acc: 0.5872 - val_loss: 0.9199 - val_acc: 0.5611\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.8934 - acc: 0.5886 - val_loss: 0.9177 - val_acc: 0.5605\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8857 - acc: 0.5920 - val_loss: 0.9064 - val_acc: 0.5669\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 523us/step - loss: 0.8783 - acc: 0.5994 - val_loss: 0.9028 - val_acc: 0.5664\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8734 - acc: 0.6060 - val_loss: 0.8994 - val_acc: 0.5712\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8661 - acc: 0.6039 - val_loss: 0.9062 - val_acc: 0.5637\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.8600 - acc: 0.6083 - val_loss: 0.8898 - val_acc: 0.5701\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.8534 - acc: 0.6142 - val_loss: 0.8859 - val_acc: 0.5760\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8494 - acc: 0.6163 - val_loss: 0.8817 - val_acc: 0.5797\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8444 - acc: 0.6154 - val_loss: 0.8798 - val_acc: 0.5856\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8369 - acc: 0.6215 - val_loss: 0.8752 - val_acc: 0.5739\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8327 - acc: 0.6302 - val_loss: 0.8711 - val_acc: 0.5819\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8296 - acc: 0.6266 - val_loss: 0.8720 - val_acc: 0.5872\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.8245 - acc: 0.6295 - val_loss: 0.8701 - val_acc: 0.5808\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8193 - acc: 0.6346 - val_loss: 0.8811 - val_acc: 0.5845\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8172 - acc: 0.6339 - val_loss: 0.8657 - val_acc: 0.5995\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8123 - acc: 0.6348 - val_loss: 0.8674 - val_acc: 0.5957\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8087 - acc: 0.6369 - val_loss: 0.8604 - val_acc: 0.5952\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8066 - acc: 0.6398 - val_loss: 0.8628 - val_acc: 0.6053\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8045 - acc: 0.6323 - val_loss: 0.8521 - val_acc: 0.5979\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 0.7984 - acc: 0.6405 - val_loss: 0.9026 - val_acc: 0.5691\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7976 - acc: 0.6456 - val_loss: 0.8810 - val_acc: 0.5819\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7917 - acc: 0.6465 - val_loss: 0.8615 - val_acc: 0.5968\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7871 - acc: 0.6474 - val_loss: 0.8503 - val_acc: 0.6165\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7847 - acc: 0.6522 - val_loss: 0.8473 - val_acc: 0.6096\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7818 - acc: 0.6442 - val_loss: 0.8479 - val_acc: 0.6069\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7830 - acc: 0.6510 - val_loss: 0.8484 - val_acc: 0.6219\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7765 - acc: 0.6572 - val_loss: 0.8422 - val_acc: 0.6171\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.7732 - acc: 0.6577 - val_loss: 0.8410 - val_acc: 0.6160\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7709 - acc: 0.6595 - val_loss: 0.8390 - val_acc: 0.6165\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7656 - acc: 0.6638 - val_loss: 0.8442 - val_acc: 0.6149\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7622 - acc: 0.6664 - val_loss: 0.8467 - val_acc: 0.6256\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7631 - acc: 0.6661 - val_loss: 0.8435 - val_acc: 0.6219\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.7549 - acc: 0.6696 - val_loss: 0.8350 - val_acc: 0.6037\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7570 - acc: 0.6682 - val_loss: 0.8375 - val_acc: 0.6267\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7530 - acc: 0.6673 - val_loss: 0.8336 - val_acc: 0.6144\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 374us/step - loss: 0.7494 - acc: 0.6718 - val_loss: 0.8375 - val_acc: 0.6091\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7480 - acc: 0.6696 - val_loss: 0.8356 - val_acc: 0.6283\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7445 - acc: 0.6725 - val_loss: 0.8286 - val_acc: 0.6213\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7414 - acc: 0.6721 - val_loss: 0.8271 - val_acc: 0.6229\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7392 - acc: 0.6783 - val_loss: 0.8497 - val_acc: 0.5989\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7360 - acc: 0.6831 - val_loss: 0.8271 - val_acc: 0.6309\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7343 - acc: 0.6801 - val_loss: 0.8314 - val_acc: 0.6123\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7305 - acc: 0.6853 - val_loss: 0.8334 - val_acc: 0.6080\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7300 - acc: 0.6828 - val_loss: 0.8294 - val_acc: 0.6224\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7276 - acc: 0.6849 - val_loss: 0.8269 - val_acc: 0.6187\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7215 - acc: 0.6901 - val_loss: 0.8342 - val_acc: 0.6389\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7202 - acc: 0.6881 - val_loss: 0.8357 - val_acc: 0.6160\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.7159 - acc: 0.6956 - val_loss: 0.8316 - val_acc: 0.6256\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7151 - acc: 0.6899 - val_loss: 0.8650 - val_acc: 0.5936\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7119 - acc: 0.6947 - val_loss: 0.8357 - val_acc: 0.6336\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7136 - acc: 0.6899 - val_loss: 0.8340 - val_acc: 0.6299\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7094 - acc: 0.6972 - val_loss: 0.8310 - val_acc: 0.6336\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7048 - acc: 0.6968 - val_loss: 0.8298 - val_acc: 0.6368\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7020 - acc: 0.7011 - val_loss: 0.8232 - val_acc: 0.6336\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6986 - acc: 0.7055 - val_loss: 0.8308 - val_acc: 0.6208\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6969 - acc: 0.7025 - val_loss: 0.8319 - val_acc: 0.6272\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.6977 - acc: 0.7016 - val_loss: 0.8253 - val_acc: 0.6304\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.6929 - acc: 0.7004 - val_loss: 0.8512 - val_acc: 0.6304\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6914 - acc: 0.7068 - val_loss: 0.8220 - val_acc: 0.6283\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.6913 - acc: 0.7043 - val_loss: 0.8982 - val_acc: 0.6192\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.6833 - acc: 0.7043 - val_loss: 0.8520 - val_acc: 0.6341\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.6830 - acc: 0.7057 - val_loss: 0.8229 - val_acc: 0.6299\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 521us/step - loss: 0.6823 - acc: 0.7105 - val_loss: 0.8213 - val_acc: 0.6320\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.6820 - acc: 0.7080 - val_loss: 0.8778 - val_acc: 0.6011\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.6766 - acc: 0.7151 - val_loss: 0.8401 - val_acc: 0.6304\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 404us/step - loss: 0.6741 - acc: 0.7121 - val_loss: 0.8223 - val_acc: 0.6309\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6737 - acc: 0.7121 - val_loss: 0.8430 - val_acc: 0.6160\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.6675 - acc: 0.7153 - val_loss: 0.8318 - val_acc: 0.6320\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.6658 - acc: 0.7171 - val_loss: 0.8286 - val_acc: 0.6213\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.6640 - acc: 0.7174 - val_loss: 0.8221 - val_acc: 0.6331\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.6626 - acc: 0.7135 - val_loss: 0.8365 - val_acc: 0.6261\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6585 - acc: 0.7199 - val_loss: 0.8372 - val_acc: 0.6229\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6571 - acc: 0.7235 - val_loss: 0.8282 - val_acc: 0.6293\n",
      "0.615578274253\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 11s 2ms/step - loss: 1.0518 - acc: 0.5003 - val_loss: 1.0380 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 1.0355 - acc: 0.5006 - val_loss: 1.0329 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 1.0297 - acc: 0.5006 - val_loss: 1.0278 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 1.0237 - acc: 0.5006 - val_loss: 1.0225 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 1.0174 - acc: 0.5006 - val_loss: 1.0169 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 1.0108 - acc: 0.5008 - val_loss: 1.0112 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 1.0038 - acc: 0.5015 - val_loss: 1.0044 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 533us/step - loss: 0.9959 - acc: 0.5035 - val_loss: 0.9983 - val_acc: 0.5083\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.9877 - acc: 0.5088 - val_loss: 0.9911 - val_acc: 0.5072\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9796 - acc: 0.5154 - val_loss: 0.9823 - val_acc: 0.5120\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9706 - acc: 0.5205 - val_loss: 0.9741 - val_acc: 0.5211\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.9611 - acc: 0.5310 - val_loss: 0.9672 - val_acc: 0.5200\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9525 - acc: 0.5362 - val_loss: 0.9582 - val_acc: 0.5397\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9432 - acc: 0.5429 - val_loss: 0.9506 - val_acc: 0.5435\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 508us/step - loss: 0.9351 - acc: 0.5468 - val_loss: 0.9431 - val_acc: 0.5456\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.9261 - acc: 0.5541 - val_loss: 0.9364 - val_acc: 0.5488\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9176 - acc: 0.5660 - val_loss: 0.9293 - val_acc: 0.5504\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9104 - acc: 0.5648 - val_loss: 0.9304 - val_acc: 0.5680\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.9036 - acc: 0.5744 - val_loss: 0.9168 - val_acc: 0.5557\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8958 - acc: 0.5776 - val_loss: 0.9119 - val_acc: 0.5717\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8889 - acc: 0.5824 - val_loss: 0.9048 - val_acc: 0.5712\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8834 - acc: 0.5875 - val_loss: 0.9013 - val_acc: 0.5728\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8766 - acc: 0.5932 - val_loss: 0.9024 - val_acc: 0.5819\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8700 - acc: 0.5957 - val_loss: 0.8905 - val_acc: 0.5792\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8662 - acc: 0.5973 - val_loss: 0.8870 - val_acc: 0.5861\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8595 - acc: 0.6003 - val_loss: 0.8812 - val_acc: 0.5915\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8535 - acc: 0.6087 - val_loss: 0.8852 - val_acc: 0.5835\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8519 - acc: 0.6062 - val_loss: 0.8732 - val_acc: 0.5989\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8439 - acc: 0.6140 - val_loss: 0.8695 - val_acc: 0.6032\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8407 - acc: 0.6124 - val_loss: 0.8694 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8348 - acc: 0.6140 - val_loss: 0.8695 - val_acc: 0.6117\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8314 - acc: 0.6163 - val_loss: 0.8649 - val_acc: 0.6160\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8297 - acc: 0.6145 - val_loss: 0.8599 - val_acc: 0.6080\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8242 - acc: 0.6190 - val_loss: 0.8741 - val_acc: 0.6075\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8211 - acc: 0.6222 - val_loss: 0.8560 - val_acc: 0.6059\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8177 - acc: 0.6220 - val_loss: 0.8583 - val_acc: 0.6069\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8147 - acc: 0.6218 - val_loss: 0.8472 - val_acc: 0.6203\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8111 - acc: 0.6284 - val_loss: 0.8505 - val_acc: 0.6155\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.8086 - acc: 0.6305 - val_loss: 0.8452 - val_acc: 0.6165\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8052 - acc: 0.6289 - val_loss: 0.8473 - val_acc: 0.6192\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8020 - acc: 0.6337 - val_loss: 0.8579 - val_acc: 0.6165\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7985 - acc: 0.6394 - val_loss: 0.8474 - val_acc: 0.6181\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7965 - acc: 0.6341 - val_loss: 0.8392 - val_acc: 0.6224\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7936 - acc: 0.6394 - val_loss: 0.8358 - val_acc: 0.6272\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7897 - acc: 0.6449 - val_loss: 0.8355 - val_acc: 0.6272\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7881 - acc: 0.6442 - val_loss: 0.8382 - val_acc: 0.6219\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7809 - acc: 0.6458 - val_loss: 0.8388 - val_acc: 0.6240\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7802 - acc: 0.6446 - val_loss: 0.8308 - val_acc: 0.6299\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7779 - acc: 0.6531 - val_loss: 0.8294 - val_acc: 0.6256\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7743 - acc: 0.6533 - val_loss: 0.8929 - val_acc: 0.5899\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7729 - acc: 0.6501 - val_loss: 0.8342 - val_acc: 0.6288\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7689 - acc: 0.6563 - val_loss: 0.8478 - val_acc: 0.6251\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7668 - acc: 0.6572 - val_loss: 0.8315 - val_acc: 0.6293\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7642 - acc: 0.6574 - val_loss: 0.8273 - val_acc: 0.6277\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7603 - acc: 0.6572 - val_loss: 0.8251 - val_acc: 0.6395\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7590 - acc: 0.6595 - val_loss: 0.8263 - val_acc: 0.6331\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 391us/step - loss: 0.7575 - acc: 0.6643 - val_loss: 0.8233 - val_acc: 0.6341\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7503 - acc: 0.6673 - val_loss: 0.8397 - val_acc: 0.6240\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 362us/step - loss: 0.7510 - acc: 0.6739 - val_loss: 0.8338 - val_acc: 0.6315\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7486 - acc: 0.6689 - val_loss: 0.8303 - val_acc: 0.6229\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7440 - acc: 0.6689 - val_loss: 0.8332 - val_acc: 0.6299\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7458 - acc: 0.6691 - val_loss: 0.8190 - val_acc: 0.6357\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7400 - acc: 0.6714 - val_loss: 0.8320 - val_acc: 0.6331\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7396 - acc: 0.6668 - val_loss: 0.8202 - val_acc: 0.6341\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7362 - acc: 0.6730 - val_loss: 0.8526 - val_acc: 0.6219\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7314 - acc: 0.6739 - val_loss: 0.8246 - val_acc: 0.6304\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7320 - acc: 0.6789 - val_loss: 0.8158 - val_acc: 0.6363\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.7262 - acc: 0.6858 - val_loss: 0.8373 - val_acc: 0.6283\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7266 - acc: 0.6792 - val_loss: 0.8133 - val_acc: 0.6400\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7201 - acc: 0.6876 - val_loss: 0.8145 - val_acc: 0.6384\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7210 - acc: 0.6821 - val_loss: 0.8112 - val_acc: 0.6459\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7178 - acc: 0.6815 - val_loss: 0.8281 - val_acc: 0.6347\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7153 - acc: 0.6920 - val_loss: 0.8156 - val_acc: 0.6448\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7134 - acc: 0.6865 - val_loss: 0.8116 - val_acc: 0.6480\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.7140 - acc: 0.6876 - val_loss: 0.8109 - val_acc: 0.6448\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7059 - acc: 0.6892 - val_loss: 0.8108 - val_acc: 0.6517\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7084 - acc: 0.6940 - val_loss: 0.8050 - val_acc: 0.6496\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7063 - acc: 0.6890 - val_loss: 0.8078 - val_acc: 0.6421\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7061 - acc: 0.6924 - val_loss: 0.8168 - val_acc: 0.6368\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7003 - acc: 0.6949 - val_loss: 0.8263 - val_acc: 0.6293\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6995 - acc: 0.6954 - val_loss: 0.8035 - val_acc: 0.6448\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.6937 - acc: 0.7043 - val_loss: 0.8077 - val_acc: 0.6496\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6917 - acc: 0.7018 - val_loss: 0.8360 - val_acc: 0.6304\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.6914 - acc: 0.7004 - val_loss: 0.8048 - val_acc: 0.6464\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.6857 - acc: 0.7050 - val_loss: 0.8139 - val_acc: 0.6459\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.6827 - acc: 0.7039 - val_loss: 0.8497 - val_acc: 0.6203\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6810 - acc: 0.7004 - val_loss: 0.8141 - val_acc: 0.6352\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.6820 - acc: 0.7046 - val_loss: 0.8358 - val_acc: 0.6293\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.6761 - acc: 0.7013 - val_loss: 0.8398 - val_acc: 0.6235\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6733 - acc: 0.7119 - val_loss: 0.8087 - val_acc: 0.6432\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.6707 - acc: 0.7098 - val_loss: 0.8384 - val_acc: 0.6304\n",
      "0.609277224157\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 10s 2ms/step - loss: 1.0508 - acc: 0.4985 - val_loss: 1.0390 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 1.0328 - acc: 0.5006 - val_loss: 1.0336 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 1.0274 - acc: 0.5006 - val_loss: 1.0281 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 1.0215 - acc: 0.5006 - val_loss: 1.0229 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 1.0156 - acc: 0.5006 - val_loss: 1.0165 - val_acc: 0.5008\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0091 - acc: 0.5006 - val_loss: 1.0100 - val_acc: 0.5013\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 1.0021 - acc: 0.5015 - val_loss: 1.0029 - val_acc: 0.5019\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.9948 - acc: 0.5033 - val_loss: 0.9954 - val_acc: 0.5040\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9866 - acc: 0.5088 - val_loss: 0.9869 - val_acc: 0.5077\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.9782 - acc: 0.5141 - val_loss: 0.9783 - val_acc: 0.5120\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9692 - acc: 0.5182 - val_loss: 0.9699 - val_acc: 0.5184\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.9600 - acc: 0.5344 - val_loss: 0.9608 - val_acc: 0.5179\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.9518 - acc: 0.5362 - val_loss: 0.9538 - val_acc: 0.5365\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.9429 - acc: 0.5481 - val_loss: 0.9466 - val_acc: 0.5403\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9352 - acc: 0.5486 - val_loss: 0.9392 - val_acc: 0.5440\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.9279 - acc: 0.5548 - val_loss: 0.9301 - val_acc: 0.5499\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.9199 - acc: 0.5598 - val_loss: 0.9228 - val_acc: 0.5515\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.9117 - acc: 0.5653 - val_loss: 0.9204 - val_acc: 0.5488\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.9054 - acc: 0.5719 - val_loss: 0.9130 - val_acc: 0.5637\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 0.8970 - acc: 0.5795 - val_loss: 0.9086 - val_acc: 0.5653\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 511us/step - loss: 0.8907 - acc: 0.5827 - val_loss: 0.8979 - val_acc: 0.5712\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8847 - acc: 0.5875 - val_loss: 0.8952 - val_acc: 0.5717\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8780 - acc: 0.5888 - val_loss: 0.8868 - val_acc: 0.5776\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8711 - acc: 0.5989 - val_loss: 0.8873 - val_acc: 0.5808\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8662 - acc: 0.6010 - val_loss: 0.8781 - val_acc: 0.5861\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8610 - acc: 0.6021 - val_loss: 0.8765 - val_acc: 0.5920\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8567 - acc: 0.6023 - val_loss: 0.8758 - val_acc: 0.5803\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8500 - acc: 0.6103 - val_loss: 0.8701 - val_acc: 0.5851\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8449 - acc: 0.6124 - val_loss: 0.8652 - val_acc: 0.5995\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8398 - acc: 0.6131 - val_loss: 0.8607 - val_acc: 0.5968\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8358 - acc: 0.6179 - val_loss: 0.8621 - val_acc: 0.6043\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8323 - acc: 0.6227 - val_loss: 0.8593 - val_acc: 0.6011\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8284 - acc: 0.6243 - val_loss: 0.8612 - val_acc: 0.6091\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8246 - acc: 0.6254 - val_loss: 0.8578 - val_acc: 0.6075\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 0.8197 - acc: 0.6309 - val_loss: 0.8513 - val_acc: 0.6139\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8173 - acc: 0.6316 - val_loss: 0.8493 - val_acc: 0.6112\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8125 - acc: 0.6366 - val_loss: 0.8537 - val_acc: 0.5963\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8088 - acc: 0.6401 - val_loss: 0.8462 - val_acc: 0.6160\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8055 - acc: 0.6433 - val_loss: 0.8448 - val_acc: 0.6192\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8031 - acc: 0.6444 - val_loss: 0.8544 - val_acc: 0.5947\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8000 - acc: 0.6483 - val_loss: 0.8479 - val_acc: 0.6107\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7971 - acc: 0.6526 - val_loss: 0.8446 - val_acc: 0.6117\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7933 - acc: 0.6478 - val_loss: 0.8487 - val_acc: 0.6101\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7910 - acc: 0.6504 - val_loss: 0.8389 - val_acc: 0.6181\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7880 - acc: 0.6522 - val_loss: 0.8533 - val_acc: 0.6133\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7861 - acc: 0.6552 - val_loss: 0.8367 - val_acc: 0.6149\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.7817 - acc: 0.6554 - val_loss: 0.8364 - val_acc: 0.6181\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7774 - acc: 0.6625 - val_loss: 0.8411 - val_acc: 0.6059\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.7749 - acc: 0.6593 - val_loss: 0.8363 - val_acc: 0.6155\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.7732 - acc: 0.6613 - val_loss: 0.8358 - val_acc: 0.6133\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7693 - acc: 0.6691 - val_loss: 0.8327 - val_acc: 0.6192\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 513us/step - loss: 0.7694 - acc: 0.6620 - val_loss: 0.8382 - val_acc: 0.6187\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7651 - acc: 0.6673 - val_loss: 0.8409 - val_acc: 0.6096\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7611 - acc: 0.6730 - val_loss: 0.8341 - val_acc: 0.6235\n",
      "Epoch 55/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7572 - acc: 0.6721 - val_loss: 0.8873 - val_acc: 0.5776\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7597 - acc: 0.6735 - val_loss: 0.8269 - val_acc: 0.6245\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7537 - acc: 0.6783 - val_loss: 0.8342 - val_acc: 0.6251\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7548 - acc: 0.6718 - val_loss: 0.8270 - val_acc: 0.6171\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7489 - acc: 0.6812 - val_loss: 0.8357 - val_acc: 0.6229\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7482 - acc: 0.6748 - val_loss: 0.8312 - val_acc: 0.6155\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7436 - acc: 0.6792 - val_loss: 0.8327 - val_acc: 0.6256\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7417 - acc: 0.6801 - val_loss: 0.8267 - val_acc: 0.6187\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7355 - acc: 0.6828 - val_loss: 0.8252 - val_acc: 0.6261\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7338 - acc: 0.6863 - val_loss: 0.8282 - val_acc: 0.6229\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7314 - acc: 0.6835 - val_loss: 0.8322 - val_acc: 0.6315\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 393us/step - loss: 0.7314 - acc: 0.6847 - val_loss: 0.8423 - val_acc: 0.6245\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7286 - acc: 0.6844 - val_loss: 0.8562 - val_acc: 0.5979\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7277 - acc: 0.6881 - val_loss: 0.8272 - val_acc: 0.6267\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7270 - acc: 0.6856 - val_loss: 0.8221 - val_acc: 0.6288\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7215 - acc: 0.6849 - val_loss: 0.8291 - val_acc: 0.6192\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7174 - acc: 0.6949 - val_loss: 0.8188 - val_acc: 0.6272\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7160 - acc: 0.6933 - val_loss: 0.8636 - val_acc: 0.6112\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.7126 - acc: 0.6920 - val_loss: 0.8380 - val_acc: 0.6128\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7109 - acc: 0.6927 - val_loss: 0.8193 - val_acc: 0.6336\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7099 - acc: 0.6940 - val_loss: 0.8245 - val_acc: 0.6219\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7055 - acc: 0.6972 - val_loss: 0.8282 - val_acc: 0.6315\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7010 - acc: 0.6927 - val_loss: 0.8258 - val_acc: 0.6379\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.6994 - acc: 0.6997 - val_loss: 0.8400 - val_acc: 0.6160\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.6967 - acc: 0.6975 - val_loss: 0.8353 - val_acc: 0.6363\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.6931 - acc: 0.7020 - val_loss: 0.8231 - val_acc: 0.6309\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6919 - acc: 0.7048 - val_loss: 0.8246 - val_acc: 0.6363\n",
      "0.597418282764\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 11s 3ms/step - loss: 1.0512 - acc: 0.5003 - val_loss: 1.0381 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 1.0363 - acc: 0.5006 - val_loss: 1.0335 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 1.0314 - acc: 0.5006 - val_loss: 1.0291 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 1.0269 - acc: 0.5006 - val_loss: 1.0244 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0217 - acc: 0.5006 - val_loss: 1.0195 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0163 - acc: 0.5006 - val_loss: 1.0143 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 1.0104 - acc: 0.5010 - val_loss: 1.0088 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0040 - acc: 0.5017 - val_loss: 1.0023 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9972 - acc: 0.5045 - val_loss: 0.9953 - val_acc: 0.5019\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.9892 - acc: 0.5056 - val_loss: 0.9880 - val_acc: 0.5019\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9811 - acc: 0.5090 - val_loss: 0.9801 - val_acc: 0.5024\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.9719 - acc: 0.5147 - val_loss: 0.9718 - val_acc: 0.5189\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9625 - acc: 0.5234 - val_loss: 0.9631 - val_acc: 0.5216\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.9522 - acc: 0.5310 - val_loss: 0.9549 - val_acc: 0.5285\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9418 - acc: 0.5399 - val_loss: 0.9484 - val_acc: 0.5301\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.9336 - acc: 0.5458 - val_loss: 0.9401 - val_acc: 0.5445\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.9240 - acc: 0.5545 - val_loss: 0.9352 - val_acc: 0.5483\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9163 - acc: 0.5584 - val_loss: 0.9260 - val_acc: 0.5456\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.9072 - acc: 0.5673 - val_loss: 0.9224 - val_acc: 0.5675\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8999 - acc: 0.5687 - val_loss: 0.9161 - val_acc: 0.5696\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8916 - acc: 0.5772 - val_loss: 0.9125 - val_acc: 0.5797\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8847 - acc: 0.5827 - val_loss: 0.9056 - val_acc: 0.5803\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8787 - acc: 0.5877 - val_loss: 0.8998 - val_acc: 0.5659\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8710 - acc: 0.5948 - val_loss: 0.8954 - val_acc: 0.5856\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8642 - acc: 0.5962 - val_loss: 0.8888 - val_acc: 0.5856\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8588 - acc: 0.6058 - val_loss: 0.8853 - val_acc: 0.5824\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8516 - acc: 0.6101 - val_loss: 0.8876 - val_acc: 0.5824\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.8453 - acc: 0.6124 - val_loss: 0.8775 - val_acc: 0.5947\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8412 - acc: 0.6199 - val_loss: 0.8878 - val_acc: 0.5904\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.8351 - acc: 0.6229 - val_loss: 0.8746 - val_acc: 0.5973\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.8291 - acc: 0.6241 - val_loss: 0.8728 - val_acc: 0.5968\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.8256 - acc: 0.6266 - val_loss: 0.8692 - val_acc: 0.5963\n",
      "Epoch 33/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8205 - acc: 0.6316 - val_loss: 0.8650 - val_acc: 0.5899\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8168 - acc: 0.6277 - val_loss: 0.8629 - val_acc: 0.5915\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8115 - acc: 0.6378 - val_loss: 0.8625 - val_acc: 0.5979\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8083 - acc: 0.6373 - val_loss: 0.8612 - val_acc: 0.5989\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8084 - acc: 0.6359 - val_loss: 0.8558 - val_acc: 0.5931\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8034 - acc: 0.6428 - val_loss: 0.8564 - val_acc: 0.5968\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7992 - acc: 0.6449 - val_loss: 0.8584 - val_acc: 0.6037\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7963 - acc: 0.6490 - val_loss: 0.8556 - val_acc: 0.6048\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.7946 - acc: 0.6467 - val_loss: 0.8526 - val_acc: 0.5957\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7916 - acc: 0.6476 - val_loss: 0.8608 - val_acc: 0.5957\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7872 - acc: 0.6490 - val_loss: 0.8507 - val_acc: 0.6091\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7858 - acc: 0.6501 - val_loss: 0.8453 - val_acc: 0.6000\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7815 - acc: 0.6526 - val_loss: 0.8455 - val_acc: 0.6000\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7791 - acc: 0.6540 - val_loss: 0.8516 - val_acc: 0.5936\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7750 - acc: 0.6565 - val_loss: 0.8429 - val_acc: 0.6048\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7739 - acc: 0.6602 - val_loss: 0.8437 - val_acc: 0.6021\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7698 - acc: 0.6593 - val_loss: 0.8440 - val_acc: 0.6075\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7669 - acc: 0.6604 - val_loss: 0.8445 - val_acc: 0.6101\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 388us/step - loss: 0.7656 - acc: 0.6595 - val_loss: 0.8465 - val_acc: 0.5995\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7612 - acc: 0.6716 - val_loss: 0.8603 - val_acc: 0.6096\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7583 - acc: 0.6668 - val_loss: 0.8393 - val_acc: 0.6160\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7580 - acc: 0.6659 - val_loss: 0.8381 - val_acc: 0.6155\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7544 - acc: 0.6700 - val_loss: 0.8443 - val_acc: 0.6064\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7519 - acc: 0.6673 - val_loss: 0.8359 - val_acc: 0.6144\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.7495 - acc: 0.6705 - val_loss: 0.8452 - val_acc: 0.6208\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7464 - acc: 0.6725 - val_loss: 0.8383 - val_acc: 0.6267\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.7431 - acc: 0.6737 - val_loss: 0.8429 - val_acc: 0.6080\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7428 - acc: 0.6725 - val_loss: 0.8333 - val_acc: 0.6160\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7416 - acc: 0.6767 - val_loss: 0.8669 - val_acc: 0.6192\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7394 - acc: 0.6796 - val_loss: 0.8367 - val_acc: 0.6091\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7364 - acc: 0.6833 - val_loss: 0.8476 - val_acc: 0.6117\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7337 - acc: 0.6780 - val_loss: 0.8435 - val_acc: 0.6245\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 512us/step - loss: 0.7315 - acc: 0.6821 - val_loss: 0.8332 - val_acc: 0.6181\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7271 - acc: 0.6789 - val_loss: 0.8364 - val_acc: 0.6293\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.7258 - acc: 0.6844 - val_loss: 0.8293 - val_acc: 0.6213\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.7233 - acc: 0.6888 - val_loss: 0.8282 - val_acc: 0.6235\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7201 - acc: 0.6837 - val_loss: 0.8315 - val_acc: 0.6261\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7188 - acc: 0.6885 - val_loss: 0.8381 - val_acc: 0.6203\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.7148 - acc: 0.6947 - val_loss: 0.8284 - val_acc: 0.6219\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7139 - acc: 0.6940 - val_loss: 0.8657 - val_acc: 0.6203\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 0.7135 - acc: 0.6899 - val_loss: 0.8625 - val_acc: 0.6208\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 0.7090 - acc: 0.6929 - val_loss: 0.8257 - val_acc: 0.6357\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7073 - acc: 0.6970 - val_loss: 0.8317 - val_acc: 0.6171\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7053 - acc: 0.6938 - val_loss: 0.8270 - val_acc: 0.6325\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.7003 - acc: 0.6938 - val_loss: 0.8446 - val_acc: 0.6107\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.6998 - acc: 0.6972 - val_loss: 0.8254 - val_acc: 0.6336\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.6981 - acc: 0.6986 - val_loss: 0.8459 - val_acc: 0.6229\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.6933 - acc: 0.7029 - val_loss: 0.8454 - val_acc: 0.6117\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.6911 - acc: 0.7043 - val_loss: 0.8275 - val_acc: 0.6235\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.6901 - acc: 0.7025 - val_loss: 0.8258 - val_acc: 0.6405\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.6868 - acc: 0.7091 - val_loss: 0.8279 - val_acc: 0.6229\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.6877 - acc: 0.7078 - val_loss: 0.8398 - val_acc: 0.6341\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.6810 - acc: 0.7132 - val_loss: 0.8529 - val_acc: 0.6011\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6780 - acc: 0.7103 - val_loss: 0.8344 - val_acc: 0.6229\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6802 - acc: 0.7039 - val_loss: 0.8270 - val_acc: 0.6320\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.6756 - acc: 0.7110 - val_loss: 0.8247 - val_acc: 0.6347\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.6723 - acc: 0.7151 - val_loss: 0.8206 - val_acc: 0.6272\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.6742 - acc: 0.7116 - val_loss: 0.8452 - val_acc: 0.6171\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.6672 - acc: 0.7192 - val_loss: 0.8256 - val_acc: 0.6315\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6663 - acc: 0.7190 - val_loss: 0.8264 - val_acc: 0.6331\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.6645 - acc: 0.7155 - val_loss: 0.8320 - val_acc: 0.6261\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6593 - acc: 0.7208 - val_loss: 0.8390 - val_acc: 0.6229\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6613 - acc: 0.7167 - val_loss: 0.8395 - val_acc: 0.6283\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.6538 - acc: 0.7263 - val_loss: 0.8300 - val_acc: 0.6224\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6511 - acc: 0.7315 - val_loss: 0.8292 - val_acc: 0.6341\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.6493 - acc: 0.7256 - val_loss: 0.8318 - val_acc: 0.6352\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6466 - acc: 0.7260 - val_loss: 0.8576 - val_acc: 0.6283\n",
      "0.597099386229\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 11s 2ms/step - loss: 1.0509 - acc: 0.4997 - val_loss: 1.0398 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 1.0350 - acc: 0.5006 - val_loss: 1.0357 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 1.0299 - acc: 0.5006 - val_loss: 1.0316 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 1.0246 - acc: 0.5006 - val_loss: 1.0271 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 1.0190 - acc: 0.5006 - val_loss: 1.0223 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 1.0125 - acc: 0.5006 - val_loss: 1.0168 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 1.0055 - acc: 0.5008 - val_loss: 1.0111 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.9976 - acc: 0.5017 - val_loss: 1.0045 - val_acc: 0.4997\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9890 - acc: 0.5042 - val_loss: 0.9972 - val_acc: 0.5035\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.9795 - acc: 0.5097 - val_loss: 0.9893 - val_acc: 0.5088\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.9695 - acc: 0.5175 - val_loss: 0.9819 - val_acc: 0.5205\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.9592 - acc: 0.5253 - val_loss: 0.9736 - val_acc: 0.5269\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9498 - acc: 0.5362 - val_loss: 0.9659 - val_acc: 0.5291\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.9408 - acc: 0.5463 - val_loss: 0.9610 - val_acc: 0.5403\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9323 - acc: 0.5507 - val_loss: 0.9533 - val_acc: 0.5483\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9236 - acc: 0.5628 - val_loss: 0.9548 - val_acc: 0.5493\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.9157 - acc: 0.5644 - val_loss: 0.9441 - val_acc: 0.5509\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9082 - acc: 0.5680 - val_loss: 0.9349 - val_acc: 0.5600\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.8994 - acc: 0.5772 - val_loss: 0.9325 - val_acc: 0.5589\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.8928 - acc: 0.5769 - val_loss: 0.9323 - val_acc: 0.5637\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.8864 - acc: 0.5806 - val_loss: 0.9182 - val_acc: 0.5765\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8788 - acc: 0.5891 - val_loss: 0.9253 - val_acc: 0.5637\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8738 - acc: 0.5950 - val_loss: 0.9088 - val_acc: 0.5872\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8669 - acc: 0.5904 - val_loss: 0.9075 - val_acc: 0.5813\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8613 - acc: 0.5984 - val_loss: 0.9068 - val_acc: 0.5707\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8571 - acc: 0.6005 - val_loss: 0.9066 - val_acc: 0.5749\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8529 - acc: 0.6071 - val_loss: 0.8920 - val_acc: 0.5893\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8467 - acc: 0.6080 - val_loss: 0.8881 - val_acc: 0.5861\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8429 - acc: 0.6167 - val_loss: 0.8872 - val_acc: 0.5904\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.8376 - acc: 0.6206 - val_loss: 0.8855 - val_acc: 0.5915\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8341 - acc: 0.6215 - val_loss: 0.8814 - val_acc: 0.5909\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8310 - acc: 0.6220 - val_loss: 0.8764 - val_acc: 0.5984\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.8246 - acc: 0.6291 - val_loss: 0.8744 - val_acc: 0.5963\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8223 - acc: 0.6277 - val_loss: 0.8702 - val_acc: 0.6059\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8199 - acc: 0.6318 - val_loss: 0.8699 - val_acc: 0.5957\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.8162 - acc: 0.6318 - val_loss: 0.8718 - val_acc: 0.6091\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8122 - acc: 0.6332 - val_loss: 0.8716 - val_acc: 0.6021\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8080 - acc: 0.6343 - val_loss: 0.8677 - val_acc: 0.5979\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8049 - acc: 0.6357 - val_loss: 0.8625 - val_acc: 0.6133\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8002 - acc: 0.6385 - val_loss: 0.8842 - val_acc: 0.5840\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7999 - acc: 0.6398 - val_loss: 0.8566 - val_acc: 0.6032\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.7947 - acc: 0.6462 - val_loss: 0.8561 - val_acc: 0.6021\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7944 - acc: 0.6478 - val_loss: 0.8544 - val_acc: 0.6101\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 392us/step - loss: 0.7897 - acc: 0.6472 - val_loss: 0.8588 - val_acc: 0.6096\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7873 - acc: 0.6474 - val_loss: 0.8450 - val_acc: 0.6235\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7833 - acc: 0.6462 - val_loss: 0.8491 - val_acc: 0.6133\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7827 - acc: 0.6529 - val_loss: 0.8486 - val_acc: 0.6155\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7818 - acc: 0.6581 - val_loss: 0.8468 - val_acc: 0.6133\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 520us/step - loss: 0.7753 - acc: 0.6590 - val_loss: 0.8407 - val_acc: 0.6176\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7766 - acc: 0.6513 - val_loss: 0.8395 - val_acc: 0.6176\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.7724 - acc: 0.6545 - val_loss: 0.8383 - val_acc: 0.6240\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7686 - acc: 0.6563 - val_loss: 0.8374 - val_acc: 0.6277\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7635 - acc: 0.6641 - val_loss: 0.8371 - val_acc: 0.6128\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7612 - acc: 0.6622 - val_loss: 0.8388 - val_acc: 0.6133\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7613 - acc: 0.6602 - val_loss: 0.8356 - val_acc: 0.6309\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7557 - acc: 0.6625 - val_loss: 0.8352 - val_acc: 0.6176\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7560 - acc: 0.6604 - val_loss: 0.8471 - val_acc: 0.6251\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.7533 - acc: 0.6684 - val_loss: 0.8387 - val_acc: 0.6176\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 380us/step - loss: 0.7513 - acc: 0.6668 - val_loss: 0.8564 - val_acc: 0.6112\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7487 - acc: 0.6714 - val_loss: 0.8380 - val_acc: 0.6341\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7478 - acc: 0.6666 - val_loss: 0.8329 - val_acc: 0.6277\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7421 - acc: 0.6735 - val_loss: 0.8341 - val_acc: 0.6379\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7401 - acc: 0.6725 - val_loss: 0.8232 - val_acc: 0.6267\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.7374 - acc: 0.6732 - val_loss: 0.8301 - val_acc: 0.6352\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7361 - acc: 0.6787 - val_loss: 0.8256 - val_acc: 0.6293\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7337 - acc: 0.6744 - val_loss: 0.8345 - val_acc: 0.6203\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7291 - acc: 0.6785 - val_loss: 0.8315 - val_acc: 0.6336\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7231 - acc: 0.6847 - val_loss: 0.8329 - val_acc: 0.6192\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7247 - acc: 0.6812 - val_loss: 0.8208 - val_acc: 0.6272\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7202 - acc: 0.6808 - val_loss: 0.8165 - val_acc: 0.6357\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7225 - acc: 0.6824 - val_loss: 0.8126 - val_acc: 0.6411\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7195 - acc: 0.6831 - val_loss: 0.8230 - val_acc: 0.6400\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.7131 - acc: 0.6844 - val_loss: 0.8368 - val_acc: 0.6395\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7128 - acc: 0.6853 - val_loss: 0.8162 - val_acc: 0.6347\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.7102 - acc: 0.6876 - val_loss: 0.8217 - val_acc: 0.6437\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7092 - acc: 0.6847 - val_loss: 0.8116 - val_acc: 0.6443\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7053 - acc: 0.6956 - val_loss: 0.8174 - val_acc: 0.6347\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7024 - acc: 0.6979 - val_loss: 0.8210 - val_acc: 0.6304\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.7010 - acc: 0.6959 - val_loss: 0.8111 - val_acc: 0.6384\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 551us/step - loss: 0.6989 - acc: 0.6975 - val_loss: 0.8075 - val_acc: 0.6432\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.6962 - acc: 0.7025 - val_loss: 0.8106 - val_acc: 0.6512\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6938 - acc: 0.6970 - val_loss: 0.8109 - val_acc: 0.6453\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6895 - acc: 0.7013 - val_loss: 0.8090 - val_acc: 0.6459\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.6858 - acc: 0.7041 - val_loss: 0.8151 - val_acc: 0.6475\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6868 - acc: 0.7041 - val_loss: 0.8199 - val_acc: 0.6341\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6830 - acc: 0.7027 - val_loss: 0.8335 - val_acc: 0.6213\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6823 - acc: 0.7062 - val_loss: 0.8291 - val_acc: 0.6389\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.6787 - acc: 0.7078 - val_loss: 0.8076 - val_acc: 0.6491\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6832 - acc: 0.7025 - val_loss: 0.8170 - val_acc: 0.6453\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6744 - acc: 0.7123 - val_loss: 0.8043 - val_acc: 0.6523\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.6736 - acc: 0.7098 - val_loss: 0.8289 - val_acc: 0.6352\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6704 - acc: 0.7103 - val_loss: 0.8127 - val_acc: 0.6459\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.6693 - acc: 0.7091 - val_loss: 0.8167 - val_acc: 0.6411\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6613 - acc: 0.7196 - val_loss: 0.8166 - val_acc: 0.6453\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 409us/step - loss: 0.6636 - acc: 0.7169 - val_loss: 0.8392 - val_acc: 0.6523\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6616 - acc: 0.7201 - val_loss: 0.8201 - val_acc: 0.6400\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6540 - acc: 0.7192 - val_loss: 0.8371 - val_acc: 0.6309\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.6551 - acc: 0.7210 - val_loss: 0.8103 - val_acc: 0.6555\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6531 - acc: 0.7139 - val_loss: 0.8172 - val_acc: 0.6528\n",
      "Epoch 100/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6506 - acc: 0.7176 - val_loss: 0.8480 - val_acc: 0.6325\n",
      "0.584248170308\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 11s 2ms/step - loss: 1.0520 - acc: 0.4978 - val_loss: 1.0390 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 1.0344 - acc: 0.5006 - val_loss: 1.0333 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 1.0286 - acc: 0.5006 - val_loss: 1.0281 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 1.0227 - acc: 0.5006 - val_loss: 1.0223 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 1.0161 - acc: 0.5006 - val_loss: 1.0165 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0093 - acc: 0.5015 - val_loss: 1.0101 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 1.0020 - acc: 0.5019 - val_loss: 1.0032 - val_acc: 0.5045\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 512us/step - loss: 0.9948 - acc: 0.5047 - val_loss: 0.9957 - val_acc: 0.5099\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.9869 - acc: 0.5115 - val_loss: 0.9885 - val_acc: 0.5093\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 0.9787 - acc: 0.5143 - val_loss: 0.9800 - val_acc: 0.5179\n",
      "Epoch 11/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.9700 - acc: 0.5260 - val_loss: 0.9716 - val_acc: 0.5253\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.9610 - acc: 0.5312 - val_loss: 0.9639 - val_acc: 0.5275\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.9517 - acc: 0.5369 - val_loss: 0.9556 - val_acc: 0.5381\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.9428 - acc: 0.5475 - val_loss: 0.9472 - val_acc: 0.5355\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.9340 - acc: 0.5543 - val_loss: 0.9399 - val_acc: 0.5467\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9255 - acc: 0.5648 - val_loss: 0.9342 - val_acc: 0.5451\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.9176 - acc: 0.5646 - val_loss: 0.9280 - val_acc: 0.5547\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.9101 - acc: 0.5733 - val_loss: 0.9189 - val_acc: 0.5568\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.9026 - acc: 0.5753 - val_loss: 0.9192 - val_acc: 0.5627\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8952 - acc: 0.5818 - val_loss: 0.9073 - val_acc: 0.5648\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8880 - acc: 0.5836 - val_loss: 0.9037 - val_acc: 0.5701\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8830 - acc: 0.5930 - val_loss: 0.8983 - val_acc: 0.5675\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8756 - acc: 0.5930 - val_loss: 0.8958 - val_acc: 0.5691\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8697 - acc: 0.5973 - val_loss: 0.8929 - val_acc: 0.5776\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8643 - acc: 0.6039 - val_loss: 0.8858 - val_acc: 0.5883\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8581 - acc: 0.6080 - val_loss: 0.8835 - val_acc: 0.5739\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8544 - acc: 0.6035 - val_loss: 0.8766 - val_acc: 0.5904\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 381us/step - loss: 0.8475 - acc: 0.6124 - val_loss: 0.8794 - val_acc: 0.5851\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8457 - acc: 0.6113 - val_loss: 0.8856 - val_acc: 0.5813\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8397 - acc: 0.6195 - val_loss: 0.8696 - val_acc: 0.5968\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.8355 - acc: 0.6145 - val_loss: 0.8694 - val_acc: 0.5909\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8310 - acc: 0.6222 - val_loss: 0.8687 - val_acc: 0.5984\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.8273 - acc: 0.6257 - val_loss: 0.8627 - val_acc: 0.6043\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8224 - acc: 0.6259 - val_loss: 0.8666 - val_acc: 0.5909\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8202 - acc: 0.6263 - val_loss: 0.8603 - val_acc: 0.5957\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8160 - acc: 0.6350 - val_loss: 0.8595 - val_acc: 0.6043\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.8123 - acc: 0.6343 - val_loss: 0.8566 - val_acc: 0.6043\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.8077 - acc: 0.6364 - val_loss: 0.8535 - val_acc: 0.6032\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.8047 - acc: 0.6348 - val_loss: 0.8503 - val_acc: 0.6123\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.8009 - acc: 0.6380 - val_loss: 0.8506 - val_acc: 0.6091\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7968 - acc: 0.6408 - val_loss: 0.8462 - val_acc: 0.6096\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7955 - acc: 0.6430 - val_loss: 0.8453 - val_acc: 0.6112\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.7919 - acc: 0.6488 - val_loss: 0.8454 - val_acc: 0.6123\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7864 - acc: 0.6433 - val_loss: 0.8429 - val_acc: 0.6133\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7860 - acc: 0.6469 - val_loss: 0.8504 - val_acc: 0.6048\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7825 - acc: 0.6446 - val_loss: 0.8505 - val_acc: 0.6064\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7766 - acc: 0.6529 - val_loss: 0.8477 - val_acc: 0.6048\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7743 - acc: 0.6542 - val_loss: 0.8451 - val_acc: 0.6149\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7733 - acc: 0.6563 - val_loss: 0.8385 - val_acc: 0.6128\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7702 - acc: 0.6590 - val_loss: 0.8545 - val_acc: 0.6096\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7675 - acc: 0.6629 - val_loss: 0.8425 - val_acc: 0.6155\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7638 - acc: 0.6627 - val_loss: 0.8411 - val_acc: 0.6075\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7616 - acc: 0.6632 - val_loss: 0.8333 - val_acc: 0.6176\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7576 - acc: 0.6677 - val_loss: 0.8350 - val_acc: 0.6187\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7539 - acc: 0.6705 - val_loss: 0.8345 - val_acc: 0.6181\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7515 - acc: 0.6689 - val_loss: 0.8349 - val_acc: 0.6181\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7487 - acc: 0.6705 - val_loss: 0.8459 - val_acc: 0.6112\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.7448 - acc: 0.6700 - val_loss: 0.8395 - val_acc: 0.6192\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.7429 - acc: 0.6767 - val_loss: 0.8357 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.7410 - acc: 0.6714 - val_loss: 0.8576 - val_acc: 0.6144\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7380 - acc: 0.6769 - val_loss: 0.8303 - val_acc: 0.6229\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7333 - acc: 0.6808 - val_loss: 0.8274 - val_acc: 0.6272\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7319 - acc: 0.6853 - val_loss: 0.8325 - val_acc: 0.6235\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7293 - acc: 0.6828 - val_loss: 0.8498 - val_acc: 0.6133\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 407us/step - loss: 0.7284 - acc: 0.6794 - val_loss: 0.8280 - val_acc: 0.6224\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7231 - acc: 0.6920 - val_loss: 0.8334 - val_acc: 0.6192\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7220 - acc: 0.6828 - val_loss: 0.8275 - val_acc: 0.6208\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7198 - acc: 0.6888 - val_loss: 0.8463 - val_acc: 0.6101\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7179 - acc: 0.6865 - val_loss: 0.8410 - val_acc: 0.6240\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.7122 - acc: 0.6922 - val_loss: 0.8296 - val_acc: 0.6283\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.7118 - acc: 0.6997 - val_loss: 0.8448 - val_acc: 0.6181\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 0.7072 - acc: 0.6901 - val_loss: 0.8274 - val_acc: 0.6267\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7070 - acc: 0.6952 - val_loss: 0.8780 - val_acc: 0.6085\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7017 - acc: 0.6924 - val_loss: 0.8401 - val_acc: 0.6277\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7002 - acc: 0.6961 - val_loss: 0.8245 - val_acc: 0.6293\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6966 - acc: 0.7013 - val_loss: 0.8308 - val_acc: 0.6240\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.6961 - acc: 0.6988 - val_loss: 0.8467 - val_acc: 0.6053\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6892 - acc: 0.7052 - val_loss: 0.8908 - val_acc: 0.6016\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6911 - acc: 0.7009 - val_loss: 0.8648 - val_acc: 0.6171\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.6875 - acc: 0.7046 - val_loss: 0.8318 - val_acc: 0.6299\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6837 - acc: 0.7068 - val_loss: 0.8313 - val_acc: 0.6325\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6867 - acc: 0.7059 - val_loss: 0.8296 - val_acc: 0.6315\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.6779 - acc: 0.7068 - val_loss: 0.8522 - val_acc: 0.6165\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6767 - acc: 0.7137 - val_loss: 0.8247 - val_acc: 0.6341\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 401us/step - loss: 0.6755 - acc: 0.7123 - val_loss: 0.8330 - val_acc: 0.6325\n",
      "0.589948434603\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 11s 3ms/step - loss: 1.0484 - acc: 0.4987 - val_loss: 1.0346 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 520us/step - loss: 1.0328 - acc: 0.5006 - val_loss: 1.0287 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 1.0259 - acc: 0.5006 - val_loss: 1.0224 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 1.0185 - acc: 0.5006 - val_loss: 1.0162 - val_acc: 0.5008\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 1.0109 - acc: 0.5006 - val_loss: 1.0092 - val_acc: 0.5008\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 1.0028 - acc: 0.5008 - val_loss: 1.0018 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.9936 - acc: 0.5017 - val_loss: 0.9935 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 526us/step - loss: 0.9845 - acc: 0.5079 - val_loss: 0.9854 - val_acc: 0.5088\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.9750 - acc: 0.5120 - val_loss: 0.9780 - val_acc: 0.5115\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9660 - acc: 0.5202 - val_loss: 0.9711 - val_acc: 0.5200\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 516us/step - loss: 0.9566 - acc: 0.5305 - val_loss: 0.9651 - val_acc: 0.5291\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 522us/step - loss: 0.9480 - acc: 0.5445 - val_loss: 0.9567 - val_acc: 0.5317\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.9399 - acc: 0.5481 - val_loss: 0.9556 - val_acc: 0.5451\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9326 - acc: 0.5584 - val_loss: 0.9441 - val_acc: 0.5483\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.9264 - acc: 0.5657 - val_loss: 0.9384 - val_acc: 0.5536\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.9173 - acc: 0.5772 - val_loss: 0.9315 - val_acc: 0.5488\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.9109 - acc: 0.5792 - val_loss: 0.9259 - val_acc: 0.5579\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9028 - acc: 0.5895 - val_loss: 0.9284 - val_acc: 0.5579\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8964 - acc: 0.5907 - val_loss: 0.9155 - val_acc: 0.5627\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8883 - acc: 0.5952 - val_loss: 0.9096 - val_acc: 0.5723\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.8809 - acc: 0.5998 - val_loss: 0.9047 - val_acc: 0.5760\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8769 - acc: 0.6044 - val_loss: 0.9042 - val_acc: 0.5707\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.8703 - acc: 0.6048 - val_loss: 0.9001 - val_acc: 0.5787\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8639 - acc: 0.6090 - val_loss: 0.8914 - val_acc: 0.5829\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.8584 - acc: 0.6140 - val_loss: 0.8938 - val_acc: 0.5659\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8543 - acc: 0.6117 - val_loss: 0.8959 - val_acc: 0.5680\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8506 - acc: 0.6174 - val_loss: 0.8794 - val_acc: 0.5915\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8456 - acc: 0.6179 - val_loss: 0.8757 - val_acc: 0.5904\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.8404 - acc: 0.6211 - val_loss: 0.8765 - val_acc: 0.5861\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.8357 - acc: 0.6263 - val_loss: 0.8798 - val_acc: 0.5877\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8302 - acc: 0.6252 - val_loss: 0.8713 - val_acc: 0.5931\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.8269 - acc: 0.6293 - val_loss: 0.8703 - val_acc: 0.5920\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8238 - acc: 0.6257 - val_loss: 0.8631 - val_acc: 0.5984\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 406us/step - loss: 0.8189 - acc: 0.6254 - val_loss: 0.8604 - val_acc: 0.6027\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8169 - acc: 0.6257 - val_loss: 0.8597 - val_acc: 0.5979\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.8133 - acc: 0.6366 - val_loss: 0.8564 - val_acc: 0.6091\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.8070 - acc: 0.6325 - val_loss: 0.8531 - val_acc: 0.6096\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8069 - acc: 0.6346 - val_loss: 0.8532 - val_acc: 0.6128\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.8017 - acc: 0.6389 - val_loss: 0.8563 - val_acc: 0.6085\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.7979 - acc: 0.6378 - val_loss: 0.8508 - val_acc: 0.6075\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7959 - acc: 0.6412 - val_loss: 0.8480 - val_acc: 0.6069\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.7915 - acc: 0.6437 - val_loss: 0.8509 - val_acc: 0.6048\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.7895 - acc: 0.6522 - val_loss: 0.8490 - val_acc: 0.6091\n",
      "Epoch 44/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7868 - acc: 0.6497 - val_loss: 0.8500 - val_acc: 0.6165\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7843 - acc: 0.6492 - val_loss: 0.8421 - val_acc: 0.6107\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7820 - acc: 0.6508 - val_loss: 0.8599 - val_acc: 0.6027\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7789 - acc: 0.6529 - val_loss: 0.8399 - val_acc: 0.6181\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7762 - acc: 0.6517 - val_loss: 0.8526 - val_acc: 0.6085\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7740 - acc: 0.6497 - val_loss: 0.8434 - val_acc: 0.6069\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7703 - acc: 0.6572 - val_loss: 0.8449 - val_acc: 0.6149\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7677 - acc: 0.6565 - val_loss: 0.8398 - val_acc: 0.6219\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7638 - acc: 0.6661 - val_loss: 0.8405 - val_acc: 0.6080\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7613 - acc: 0.6618 - val_loss: 0.8410 - val_acc: 0.6144\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7578 - acc: 0.6668 - val_loss: 0.8349 - val_acc: 0.6117\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.7563 - acc: 0.6666 - val_loss: 0.8392 - val_acc: 0.6160\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7547 - acc: 0.6643 - val_loss: 0.8285 - val_acc: 0.6192\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7526 - acc: 0.6664 - val_loss: 0.8325 - val_acc: 0.6219\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7495 - acc: 0.6682 - val_loss: 0.8322 - val_acc: 0.6149\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7477 - acc: 0.6664 - val_loss: 0.8312 - val_acc: 0.6235\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7442 - acc: 0.6707 - val_loss: 0.8334 - val_acc: 0.6187\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.7412 - acc: 0.6808 - val_loss: 0.8294 - val_acc: 0.6261\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7385 - acc: 0.6780 - val_loss: 0.8331 - val_acc: 0.6213\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7389 - acc: 0.6709 - val_loss: 0.8268 - val_acc: 0.6176\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7331 - acc: 0.6812 - val_loss: 0.8542 - val_acc: 0.6144\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7309 - acc: 0.6801 - val_loss: 0.8280 - val_acc: 0.6293\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.7298 - acc: 0.6803 - val_loss: 0.8303 - val_acc: 0.6283\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 410us/step - loss: 0.7272 - acc: 0.6835 - val_loss: 0.8270 - val_acc: 0.6288\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7266 - acc: 0.6780 - val_loss: 0.8323 - val_acc: 0.6261\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7217 - acc: 0.6824 - val_loss: 0.8595 - val_acc: 0.6043\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7189 - acc: 0.6885 - val_loss: 0.8396 - val_acc: 0.6171\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7171 - acc: 0.6897 - val_loss: 0.8320 - val_acc: 0.6240\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7150 - acc: 0.6906 - val_loss: 0.8311 - val_acc: 0.6261\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.7113 - acc: 0.6876 - val_loss: 0.8261 - val_acc: 0.6320\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.7077 - acc: 0.6842 - val_loss: 0.8220 - val_acc: 0.6336\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7079 - acc: 0.6931 - val_loss: 0.8276 - val_acc: 0.6341\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7036 - acc: 0.6922 - val_loss: 0.8242 - val_acc: 0.6304\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7011 - acc: 0.6993 - val_loss: 0.8340 - val_acc: 0.6272\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7006 - acc: 0.6993 - val_loss: 0.8226 - val_acc: 0.6325\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6957 - acc: 0.6981 - val_loss: 0.8241 - val_acc: 0.6309\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6937 - acc: 0.6959 - val_loss: 0.8259 - val_acc: 0.6293\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6940 - acc: 0.7029 - val_loss: 0.8517 - val_acc: 0.6224\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.6896 - acc: 0.7046 - val_loss: 0.8694 - val_acc: 0.6128\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6856 - acc: 0.7013 - val_loss: 0.8296 - val_acc: 0.6304\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.6837 - acc: 0.7048 - val_loss: 0.8232 - val_acc: 0.6347\n",
      "0.592891479796\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 11s 3ms/step - loss: 1.0531 - acc: 0.4981 - val_loss: 1.0384 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 1.0362 - acc: 0.5006 - val_loss: 1.0331 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 1.0311 - acc: 0.5006 - val_loss: 1.0284 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 1.0261 - acc: 0.5006 - val_loss: 1.0233 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 1.0208 - acc: 0.5006 - val_loss: 1.0179 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 1.0151 - acc: 0.5008 - val_loss: 1.0120 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 1.0090 - acc: 0.5022 - val_loss: 1.0057 - val_acc: 0.5035\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 1.0025 - acc: 0.5056 - val_loss: 0.9991 - val_acc: 0.5120\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.9953 - acc: 0.5093 - val_loss: 0.9918 - val_acc: 0.5163\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9876 - acc: 0.5168 - val_loss: 0.9840 - val_acc: 0.5211\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9796 - acc: 0.5200 - val_loss: 0.9760 - val_acc: 0.5211\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.9705 - acc: 0.5230 - val_loss: 0.9685 - val_acc: 0.5285\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.9617 - acc: 0.5294 - val_loss: 0.9600 - val_acc: 0.5349\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9528 - acc: 0.5358 - val_loss: 0.9505 - val_acc: 0.5371\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.9432 - acc: 0.5394 - val_loss: 0.9424 - val_acc: 0.5408\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.9341 - acc: 0.5493 - val_loss: 0.9329 - val_acc: 0.5525\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.9257 - acc: 0.5552 - val_loss: 0.9261 - val_acc: 0.5643\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.9165 - acc: 0.5646 - val_loss: 0.9177 - val_acc: 0.5621\n",
      "Epoch 19/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9076 - acc: 0.5712 - val_loss: 0.9112 - val_acc: 0.5733\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9022 - acc: 0.5735 - val_loss: 0.9045 - val_acc: 0.5675\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.8931 - acc: 0.5863 - val_loss: 0.8989 - val_acc: 0.5781\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.8870 - acc: 0.5831 - val_loss: 0.8915 - val_acc: 0.5776\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8811 - acc: 0.5902 - val_loss: 0.8866 - val_acc: 0.5845\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.8748 - acc: 0.5927 - val_loss: 0.8799 - val_acc: 0.5957\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.8671 - acc: 0.5959 - val_loss: 0.8763 - val_acc: 0.5952\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.8633 - acc: 0.6003 - val_loss: 0.8713 - val_acc: 0.6064\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8578 - acc: 0.5991 - val_loss: 0.8763 - val_acc: 0.5957\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8534 - acc: 0.6085 - val_loss: 0.8653 - val_acc: 0.6043\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.8485 - acc: 0.6113 - val_loss: 0.8590 - val_acc: 0.6091\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.8431 - acc: 0.6183 - val_loss: 0.8562 - val_acc: 0.6085\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8383 - acc: 0.6211 - val_loss: 0.8709 - val_acc: 0.5984\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8355 - acc: 0.6220 - val_loss: 0.8672 - val_acc: 0.5957\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.8295 - acc: 0.6279 - val_loss: 0.8603 - val_acc: 0.5995\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.8269 - acc: 0.6298 - val_loss: 0.8555 - val_acc: 0.6005\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8222 - acc: 0.6305 - val_loss: 0.8436 - val_acc: 0.6117\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8193 - acc: 0.6266 - val_loss: 0.8507 - val_acc: 0.6064\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8168 - acc: 0.6353 - val_loss: 0.8415 - val_acc: 0.6208\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8126 - acc: 0.6398 - val_loss: 0.8438 - val_acc: 0.6117\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.8073 - acc: 0.6437 - val_loss: 0.8725 - val_acc: 0.5941\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8065 - acc: 0.6419 - val_loss: 0.8404 - val_acc: 0.6224\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 0.8015 - acc: 0.6451 - val_loss: 0.8401 - val_acc: 0.6181\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7985 - acc: 0.6474 - val_loss: 0.8379 - val_acc: 0.6133\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.7940 - acc: 0.6492 - val_loss: 0.8339 - val_acc: 0.6272\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.7927 - acc: 0.6481 - val_loss: 0.8332 - val_acc: 0.6288\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7899 - acc: 0.6545 - val_loss: 0.8333 - val_acc: 0.6240\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7871 - acc: 0.6513 - val_loss: 0.8257 - val_acc: 0.6331\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.7848 - acc: 0.6556 - val_loss: 0.8332 - val_acc: 0.6149\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7814 - acc: 0.6574 - val_loss: 0.8351 - val_acc: 0.6203\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7766 - acc: 0.6597 - val_loss: 0.8307 - val_acc: 0.6267\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7748 - acc: 0.6602 - val_loss: 0.8223 - val_acc: 0.6304\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7735 - acc: 0.6606 - val_loss: 0.8341 - val_acc: 0.6272\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7699 - acc: 0.6668 - val_loss: 0.8229 - val_acc: 0.6325\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7657 - acc: 0.6682 - val_loss: 0.8312 - val_acc: 0.6245\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7647 - acc: 0.6668 - val_loss: 0.8329 - val_acc: 0.6304\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7611 - acc: 0.6693 - val_loss: 0.8241 - val_acc: 0.6267\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7608 - acc: 0.6641 - val_loss: 0.8184 - val_acc: 0.6331\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 405us/step - loss: 0.7579 - acc: 0.6702 - val_loss: 0.8193 - val_acc: 0.6373\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7540 - acc: 0.6746 - val_loss: 0.8135 - val_acc: 0.6341\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 505us/step - loss: 0.7491 - acc: 0.6780 - val_loss: 0.8198 - val_acc: 0.6325\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7497 - acc: 0.6732 - val_loss: 0.8121 - val_acc: 0.6363\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7451 - acc: 0.6732 - val_loss: 0.8099 - val_acc: 0.6384\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7443 - acc: 0.6762 - val_loss: 0.8123 - val_acc: 0.6373\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7435 - acc: 0.6812 - val_loss: 0.8153 - val_acc: 0.6320\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7397 - acc: 0.6796 - val_loss: 0.8094 - val_acc: 0.6325\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7326 - acc: 0.6853 - val_loss: 0.8075 - val_acc: 0.6352\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7323 - acc: 0.6849 - val_loss: 0.8121 - val_acc: 0.6475\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7318 - acc: 0.6906 - val_loss: 0.8133 - val_acc: 0.6427\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7286 - acc: 0.6867 - val_loss: 0.8159 - val_acc: 0.6448\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7261 - acc: 0.6888 - val_loss: 0.8141 - val_acc: 0.6251\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7266 - acc: 0.6831 - val_loss: 0.8282 - val_acc: 0.6373\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7228 - acc: 0.6803 - val_loss: 0.8054 - val_acc: 0.6384\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7199 - acc: 0.6867 - val_loss: 0.8988 - val_acc: 0.5733\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7173 - acc: 0.6899 - val_loss: 0.8322 - val_acc: 0.6235\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 522us/step - loss: 0.7149 - acc: 0.6949 - val_loss: 0.8027 - val_acc: 0.6352\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.7134 - acc: 0.6899 - val_loss: 0.8098 - val_acc: 0.6352\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7091 - acc: 0.6968 - val_loss: 0.8083 - val_acc: 0.6384\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7074 - acc: 0.6956 - val_loss: 0.8137 - val_acc: 0.6448\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.7053 - acc: 0.6956 - val_loss: 0.8156 - val_acc: 0.6405\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7046 - acc: 0.6949 - val_loss: 0.8228 - val_acc: 0.6347\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 389us/step - loss: 0.6983 - acc: 0.6988 - val_loss: 0.8392 - val_acc: 0.6309\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7007 - acc: 0.6997 - val_loss: 0.8024 - val_acc: 0.6411\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.6938 - acc: 0.7000 - val_loss: 0.8256 - val_acc: 0.6320\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.6907 - acc: 0.7055 - val_loss: 0.8086 - val_acc: 0.6421\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.6911 - acc: 0.7050 - val_loss: 0.8108 - val_acc: 0.6341\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6890 - acc: 0.7020 - val_loss: 0.8073 - val_acc: 0.6384\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.6857 - acc: 0.7066 - val_loss: 0.8061 - val_acc: 0.6416\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.6833 - acc: 0.7087 - val_loss: 0.8064 - val_acc: 0.6357\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6808 - acc: 0.7105 - val_loss: 0.8246 - val_acc: 0.6341\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.6786 - acc: 0.7048 - val_loss: 0.8005 - val_acc: 0.6395\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.6729 - acc: 0.7167 - val_loss: 0.8157 - val_acc: 0.6432\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6731 - acc: 0.7164 - val_loss: 0.8355 - val_acc: 0.6411\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.6732 - acc: 0.7114 - val_loss: 0.8281 - val_acc: 0.6341\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 437us/step - loss: 0.6679 - acc: 0.7171 - val_loss: 0.8097 - val_acc: 0.6384\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.6670 - acc: 0.7208 - val_loss: 0.8174 - val_acc: 0.6379\n",
      "Epoch 95/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6625 - acc: 0.7190 - val_loss: 0.8051 - val_acc: 0.6389\n",
      "Epoch 96/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.6645 - acc: 0.7158 - val_loss: 0.8044 - val_acc: 0.6384\n",
      "Epoch 97/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.6566 - acc: 0.7167 - val_loss: 0.8106 - val_acc: 0.6475\n",
      "Epoch 98/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.6567 - acc: 0.7231 - val_loss: 0.8035 - val_acc: 0.6379\n",
      "Epoch 99/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6534 - acc: 0.7254 - val_loss: 0.8056 - val_acc: 0.6453\n",
      "0.614239917107\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 12s 3ms/step - loss: 1.0516 - acc: 0.4999 - val_loss: 1.0386 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 1.0334 - acc: 0.5006 - val_loss: 1.0336 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 508us/step - loss: 1.0278 - acc: 0.5006 - val_loss: 1.0284 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 1.0219 - acc: 0.5006 - val_loss: 1.0233 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 1.0158 - acc: 0.5006 - val_loss: 1.0175 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 1.0089 - acc: 0.5013 - val_loss: 1.0115 - val_acc: 0.5013\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 1.0016 - acc: 0.5024 - val_loss: 1.0045 - val_acc: 0.5029\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.9933 - acc: 0.5054 - val_loss: 0.9973 - val_acc: 0.5056\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.9846 - acc: 0.5093 - val_loss: 0.9897 - val_acc: 0.5109\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.9754 - acc: 0.5200 - val_loss: 0.9811 - val_acc: 0.5147\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.9654 - acc: 0.5271 - val_loss: 0.9735 - val_acc: 0.5157\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9553 - acc: 0.5378 - val_loss: 0.9714 - val_acc: 0.5275\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.9466 - acc: 0.5408 - val_loss: 0.9570 - val_acc: 0.5397\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.9378 - acc: 0.5548 - val_loss: 0.9515 - val_acc: 0.5467\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.9298 - acc: 0.5612 - val_loss: 0.9460 - val_acc: 0.5403\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.9209 - acc: 0.5667 - val_loss: 0.9362 - val_acc: 0.5504\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9122 - acc: 0.5769 - val_loss: 0.9317 - val_acc: 0.5504\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.9056 - acc: 0.5772 - val_loss: 0.9241 - val_acc: 0.5563\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8973 - acc: 0.5847 - val_loss: 0.9189 - val_acc: 0.5632\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8912 - acc: 0.5886 - val_loss: 0.9148 - val_acc: 0.5643\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.8853 - acc: 0.5902 - val_loss: 0.9137 - val_acc: 0.5632\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8799 - acc: 0.5914 - val_loss: 0.9096 - val_acc: 0.5632\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8717 - acc: 0.5978 - val_loss: 0.9017 - val_acc: 0.5627\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8679 - acc: 0.6069 - val_loss: 0.8984 - val_acc: 0.5728\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8603 - acc: 0.6094 - val_loss: 0.8979 - val_acc: 0.5749\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8561 - acc: 0.6115 - val_loss: 0.8946 - val_acc: 0.5776\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.8489 - acc: 0.6165 - val_loss: 0.8831 - val_acc: 0.5808\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.8466 - acc: 0.6145 - val_loss: 0.8841 - val_acc: 0.5765\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.8397 - acc: 0.6220 - val_loss: 0.8731 - val_acc: 0.5915\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8349 - acc: 0.6243 - val_loss: 0.8795 - val_acc: 0.5781\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8313 - acc: 0.6275 - val_loss: 0.8753 - val_acc: 0.5867\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.8269 - acc: 0.6337 - val_loss: 0.8671 - val_acc: 0.5941\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.8221 - acc: 0.6291 - val_loss: 0.8656 - val_acc: 0.5877\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.8188 - acc: 0.6348 - val_loss: 0.8667 - val_acc: 0.5909\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8145 - acc: 0.6380 - val_loss: 0.8594 - val_acc: 0.5973\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.8083 - acc: 0.6389 - val_loss: 0.8603 - val_acc: 0.5973\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.8056 - acc: 0.6467 - val_loss: 0.8563 - val_acc: 0.6021\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8025 - acc: 0.6442 - val_loss: 0.8715 - val_acc: 0.5867\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 0.8004 - acc: 0.6481 - val_loss: 0.8510 - val_acc: 0.6101\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 511us/step - loss: 0.7957 - acc: 0.6449 - val_loss: 0.8472 - val_acc: 0.6123\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7927 - acc: 0.6504 - val_loss: 0.8437 - val_acc: 0.6149\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 505us/step - loss: 0.7895 - acc: 0.6494 - val_loss: 0.8525 - val_acc: 0.6080\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7836 - acc: 0.6604 - val_loss: 0.8405 - val_acc: 0.6128\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7800 - acc: 0.6590 - val_loss: 0.8404 - val_acc: 0.6133\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.7766 - acc: 0.6595 - val_loss: 0.8412 - val_acc: 0.6107\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.7746 - acc: 0.6588 - val_loss: 0.8382 - val_acc: 0.6149\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7713 - acc: 0.6670 - val_loss: 0.8552 - val_acc: 0.6107\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7710 - acc: 0.6618 - val_loss: 0.8309 - val_acc: 0.6240\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.7662 - acc: 0.6622 - val_loss: 0.8537 - val_acc: 0.6064\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7646 - acc: 0.6627 - val_loss: 0.8438 - val_acc: 0.6107\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7586 - acc: 0.6684 - val_loss: 0.8410 - val_acc: 0.6107\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7577 - acc: 0.6645 - val_loss: 0.8278 - val_acc: 0.6256\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7542 - acc: 0.6664 - val_loss: 0.8416 - val_acc: 0.6197\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 496us/step - loss: 0.7506 - acc: 0.6744 - val_loss: 0.8278 - val_acc: 0.6251\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7489 - acc: 0.6718 - val_loss: 0.8302 - val_acc: 0.6192\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.7445 - acc: 0.6771 - val_loss: 0.8398 - val_acc: 0.6203\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.7444 - acc: 0.6771 - val_loss: 0.8328 - val_acc: 0.6208\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 499us/step - loss: 0.7379 - acc: 0.6767 - val_loss: 0.8288 - val_acc: 0.6261\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7374 - acc: 0.6789 - val_loss: 0.8213 - val_acc: 0.6341\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7371 - acc: 0.6748 - val_loss: 0.8272 - val_acc: 0.6288\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 475us/step - loss: 0.7334 - acc: 0.6803 - val_loss: 0.8604 - val_acc: 0.5915\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7279 - acc: 0.6840 - val_loss: 0.8198 - val_acc: 0.6251\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 511us/step - loss: 0.7272 - acc: 0.6805 - val_loss: 0.8204 - val_acc: 0.6320\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.7242 - acc: 0.6783 - val_loss: 0.8241 - val_acc: 0.6368\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.7227 - acc: 0.6860 - val_loss: 0.8165 - val_acc: 0.6320\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7198 - acc: 0.6892 - val_loss: 0.8242 - val_acc: 0.6357\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7198 - acc: 0.6853 - val_loss: 0.8249 - val_acc: 0.6389\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7147 - acc: 0.6883 - val_loss: 0.8190 - val_acc: 0.6299\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.7091 - acc: 0.6920 - val_loss: 0.8158 - val_acc: 0.6357\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7096 - acc: 0.6929 - val_loss: 0.8291 - val_acc: 0.6192\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7046 - acc: 0.6929 - val_loss: 0.8190 - val_acc: 0.6245\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7043 - acc: 0.6924 - val_loss: 0.8403 - val_acc: 0.6187\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.6990 - acc: 0.6954 - val_loss: 0.8256 - val_acc: 0.6171\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6994 - acc: 0.6913 - val_loss: 0.8162 - val_acc: 0.6443\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.6954 - acc: 0.6945 - val_loss: 0.8224 - val_acc: 0.6341\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6926 - acc: 0.6979 - val_loss: 0.8239 - val_acc: 0.6219\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6899 - acc: 0.7025 - val_loss: 0.8477 - val_acc: 0.6112\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.6861 - acc: 0.7025 - val_loss: 0.8127 - val_acc: 0.6379\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6808 - acc: 0.7057 - val_loss: 0.8273 - val_acc: 0.6277\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.6792 - acc: 0.7119 - val_loss: 0.8386 - val_acc: 0.6181\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6786 - acc: 0.7098 - val_loss: 0.8238 - val_acc: 0.6245\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.6774 - acc: 0.7066 - val_loss: 0.8472 - val_acc: 0.6277\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.6741 - acc: 0.7078 - val_loss: 0.8213 - val_acc: 0.6347\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.6680 - acc: 0.7116 - val_loss: 0.8123 - val_acc: 0.6347\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.6683 - acc: 0.7071 - val_loss: 0.8480 - val_acc: 0.6176\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.6651 - acc: 0.7139 - val_loss: 0.8304 - val_acc: 0.6379\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.6607 - acc: 0.7199 - val_loss: 0.8160 - val_acc: 0.6384\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6598 - acc: 0.7185 - val_loss: 0.8237 - val_acc: 0.6357\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 0.6544 - acc: 0.7281 - val_loss: 0.8199 - val_acc: 0.6347\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6512 - acc: 0.7217 - val_loss: 0.8287 - val_acc: 0.6389\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.6493 - acc: 0.7254 - val_loss: 0.8485 - val_acc: 0.6256\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.6495 - acc: 0.7196 - val_loss: 0.8392 - val_acc: 0.6171\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.6418 - acc: 0.7304 - val_loss: 0.8573 - val_acc: 0.6229\n",
      "Epoch 94/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 0.6393 - acc: 0.7295 - val_loss: 0.8137 - val_acc: 0.6491\n",
      "0.616545889148\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 12s 3ms/step - loss: 1.0489 - acc: 0.5003 - val_loss: 1.0388 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 1.0338 - acc: 0.5006 - val_loss: 1.0340 - val_acc: 0.5003\n",
      "Epoch 3/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 449us/step - loss: 1.0280 - acc: 0.5006 - val_loss: 1.0292 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 1.0226 - acc: 0.5006 - val_loss: 1.0240 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 1.0161 - acc: 0.5008 - val_loss: 1.0192 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 514us/step - loss: 1.0097 - acc: 0.5010 - val_loss: 1.0123 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 1.0024 - acc: 0.5019 - val_loss: 1.0061 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9944 - acc: 0.5017 - val_loss: 0.9979 - val_acc: 0.5040\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.9856 - acc: 0.5049 - val_loss: 0.9899 - val_acc: 0.5093\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9764 - acc: 0.5115 - val_loss: 0.9813 - val_acc: 0.5163\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9659 - acc: 0.5184 - val_loss: 0.9726 - val_acc: 0.5237\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9555 - acc: 0.5298 - val_loss: 0.9632 - val_acc: 0.5307\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 489us/step - loss: 0.9447 - acc: 0.5436 - val_loss: 0.9550 - val_acc: 0.5323\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9343 - acc: 0.5550 - val_loss: 0.9488 - val_acc: 0.5435\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.9249 - acc: 0.5600 - val_loss: 0.9367 - val_acc: 0.5504\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9147 - acc: 0.5708 - val_loss: 0.9300 - val_acc: 0.5589\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.9071 - acc: 0.5726 - val_loss: 0.9227 - val_acc: 0.5579\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8979 - acc: 0.5843 - val_loss: 0.9187 - val_acc: 0.5696\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8916 - acc: 0.5829 - val_loss: 0.9111 - val_acc: 0.5611\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 518us/step - loss: 0.8834 - acc: 0.5914 - val_loss: 0.9046 - val_acc: 0.5733\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 524us/step - loss: 0.8765 - acc: 0.5966 - val_loss: 0.9042 - val_acc: 0.5669\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8707 - acc: 0.5982 - val_loss: 0.8980 - val_acc: 0.5755\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8645 - acc: 0.6028 - val_loss: 0.8937 - val_acc: 0.5755\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 518us/step - loss: 0.8589 - acc: 0.6113 - val_loss: 0.8886 - val_acc: 0.5824\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.8540 - acc: 0.6131 - val_loss: 0.8843 - val_acc: 0.5883\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 497us/step - loss: 0.8480 - acc: 0.6145 - val_loss: 0.8831 - val_acc: 0.5931\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8437 - acc: 0.6186 - val_loss: 0.8792 - val_acc: 0.5851\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.8374 - acc: 0.6206 - val_loss: 0.8758 - val_acc: 0.6000\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8342 - acc: 0.6211 - val_loss: 0.8828 - val_acc: 0.5909\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.8317 - acc: 0.6218 - val_loss: 0.8690 - val_acc: 0.6043\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 417us/step - loss: 0.8269 - acc: 0.6209 - val_loss: 0.8665 - val_acc: 0.6000\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8235 - acc: 0.6286 - val_loss: 0.8669 - val_acc: 0.6085\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8175 - acc: 0.6327 - val_loss: 0.8689 - val_acc: 0.5947\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.8177 - acc: 0.6316 - val_loss: 0.8634 - val_acc: 0.6053\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8122 - acc: 0.6348 - val_loss: 0.8608 - val_acc: 0.6075\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8093 - acc: 0.6385 - val_loss: 0.8568 - val_acc: 0.6128\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.8060 - acc: 0.6421 - val_loss: 0.8596 - val_acc: 0.6117\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.8024 - acc: 0.6385 - val_loss: 0.8483 - val_acc: 0.6203\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.7979 - acc: 0.6437 - val_loss: 0.8723 - val_acc: 0.6016\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.7950 - acc: 0.6430 - val_loss: 0.8473 - val_acc: 0.6160\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7933 - acc: 0.6467 - val_loss: 0.8437 - val_acc: 0.6251\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7896 - acc: 0.6456 - val_loss: 0.8424 - val_acc: 0.6192\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7841 - acc: 0.6472 - val_loss: 0.8601 - val_acc: 0.6133\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 473us/step - loss: 0.7798 - acc: 0.6510 - val_loss: 0.8391 - val_acc: 0.6293\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7793 - acc: 0.6531 - val_loss: 0.8394 - val_acc: 0.6315\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7770 - acc: 0.6522 - val_loss: 0.8448 - val_acc: 0.6213\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 400us/step - loss: 0.7746 - acc: 0.6565 - val_loss: 0.8404 - val_acc: 0.6272\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7696 - acc: 0.6558 - val_loss: 0.8379 - val_acc: 0.6384\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7650 - acc: 0.6604 - val_loss: 0.8362 - val_acc: 0.6352\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7631 - acc: 0.6638 - val_loss: 0.8536 - val_acc: 0.6208\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 0.7616 - acc: 0.6645 - val_loss: 0.8430 - val_acc: 0.6123\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7573 - acc: 0.6597 - val_loss: 0.8369 - val_acc: 0.6315\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7549 - acc: 0.6680 - val_loss: 0.8506 - val_acc: 0.6261\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 548us/step - loss: 0.7516 - acc: 0.6664 - val_loss: 0.8330 - val_acc: 0.6411\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7499 - acc: 0.6705 - val_loss: 0.8545 - val_acc: 0.6171\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7473 - acc: 0.6702 - val_loss: 0.8330 - val_acc: 0.6336\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7431 - acc: 0.6760 - val_loss: 0.8364 - val_acc: 0.6379\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7409 - acc: 0.6744 - val_loss: 0.8282 - val_acc: 0.6395\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7352 - acc: 0.6787 - val_loss: 0.8298 - val_acc: 0.6384\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7350 - acc: 0.6794 - val_loss: 0.8278 - val_acc: 0.6416\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7306 - acc: 0.6826 - val_loss: 0.8257 - val_acc: 0.6384\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7277 - acc: 0.6833 - val_loss: 0.8317 - val_acc: 0.6411\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.7263 - acc: 0.6824 - val_loss: 0.8358 - val_acc: 0.6363\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7242 - acc: 0.6847 - val_loss: 0.8445 - val_acc: 0.6245\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.7225 - acc: 0.6842 - val_loss: 0.8403 - val_acc: 0.6235\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7144 - acc: 0.6860 - val_loss: 0.8342 - val_acc: 0.6277\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7134 - acc: 0.6920 - val_loss: 0.8255 - val_acc: 0.6405\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7115 - acc: 0.6940 - val_loss: 0.8332 - val_acc: 0.6389\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7076 - acc: 0.6917 - val_loss: 0.8237 - val_acc: 0.6491\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7056 - acc: 0.6961 - val_loss: 0.9177 - val_acc: 0.5611\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7027 - acc: 0.6995 - val_loss: 0.8267 - val_acc: 0.6496\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.7024 - acc: 0.6959 - val_loss: 0.8245 - val_acc: 0.6347\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7000 - acc: 0.6931 - val_loss: 0.8482 - val_acc: 0.6341\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.6980 - acc: 0.7039 - val_loss: 0.8232 - val_acc: 0.6379\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.6916 - acc: 0.7027 - val_loss: 0.8205 - val_acc: 0.6443\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.6879 - acc: 0.7016 - val_loss: 0.8380 - val_acc: 0.6267\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6869 - acc: 0.6997 - val_loss: 0.8349 - val_acc: 0.6421\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.6830 - acc: 0.7066 - val_loss: 0.8238 - val_acc: 0.6347\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.6825 - acc: 0.7034 - val_loss: 0.8240 - val_acc: 0.6373\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6787 - acc: 0.7080 - val_loss: 0.8282 - val_acc: 0.6437\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.6779 - acc: 0.7068 - val_loss: 0.8250 - val_acc: 0.6496\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.6772 - acc: 0.7073 - val_loss: 0.8232 - val_acc: 0.6437\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.6676 - acc: 0.7128 - val_loss: 0.8424 - val_acc: 0.6341\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6671 - acc: 0.7162 - val_loss: 0.8634 - val_acc: 0.5952\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.6649 - acc: 0.7151 - val_loss: 0.8309 - val_acc: 0.6309\n",
      "0.590121986599\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 12s 3ms/step - loss: 1.0485 - acc: 0.4994 - val_loss: 1.0365 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 1.0327 - acc: 0.5006 - val_loss: 1.0303 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0267 - acc: 0.5006 - val_loss: 1.0243 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 1.0202 - acc: 0.5006 - val_loss: 1.0183 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 493us/step - loss: 1.0138 - acc: 0.5006 - val_loss: 1.0114 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 1.0063 - acc: 0.5006 - val_loss: 1.0045 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.9991 - acc: 0.5022 - val_loss: 0.9961 - val_acc: 0.5019\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.9907 - acc: 0.5038 - val_loss: 0.9879 - val_acc: 0.5024\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.9818 - acc: 0.5095 - val_loss: 0.9798 - val_acc: 0.5115\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.9731 - acc: 0.5154 - val_loss: 0.9704 - val_acc: 0.5232\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.9636 - acc: 0.5253 - val_loss: 0.9616 - val_acc: 0.5275\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 462us/step - loss: 0.9542 - acc: 0.5330 - val_loss: 0.9510 - val_acc: 0.5445\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9450 - acc: 0.5415 - val_loss: 0.9418 - val_acc: 0.5365\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.9351 - acc: 0.5479 - val_loss: 0.9345 - val_acc: 0.5504\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.9270 - acc: 0.5529 - val_loss: 0.9238 - val_acc: 0.5643\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.9180 - acc: 0.5662 - val_loss: 0.9231 - val_acc: 0.5648\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.9104 - acc: 0.5687 - val_loss: 0.9086 - val_acc: 0.5787\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 498us/step - loss: 0.9022 - acc: 0.5756 - val_loss: 0.9012 - val_acc: 0.5803\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8959 - acc: 0.5802 - val_loss: 0.8950 - val_acc: 0.5883\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.8886 - acc: 0.5870 - val_loss: 0.8897 - val_acc: 0.5920\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 467us/step - loss: 0.8814 - acc: 0.5884 - val_loss: 0.8828 - val_acc: 0.6016\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.8748 - acc: 0.5914 - val_loss: 0.8839 - val_acc: 0.6005\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 0.8702 - acc: 0.5950 - val_loss: 0.8751 - val_acc: 0.6160\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 485us/step - loss: 0.8654 - acc: 0.5941 - val_loss: 0.8713 - val_acc: 0.6160\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 510us/step - loss: 0.8589 - acc: 0.5994 - val_loss: 0.8692 - val_acc: 0.6053\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 423us/step - loss: 0.8543 - acc: 0.6062 - val_loss: 0.8653 - val_acc: 0.6075\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8492 - acc: 0.6115 - val_loss: 0.8586 - val_acc: 0.6107\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8457 - acc: 0.6069 - val_loss: 0.8623 - val_acc: 0.5973\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 397us/step - loss: 0.8412 - acc: 0.6069 - val_loss: 0.8761 - val_acc: 0.6128\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.8346 - acc: 0.6181 - val_loss: 0.8502 - val_acc: 0.6171\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.8308 - acc: 0.6163 - val_loss: 0.8766 - val_acc: 0.6112\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.8277 - acc: 0.6231 - val_loss: 0.8497 - val_acc: 0.6229\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8232 - acc: 0.6236 - val_loss: 0.8504 - val_acc: 0.6224\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.8200 - acc: 0.6300 - val_loss: 0.8611 - val_acc: 0.6139\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.8155 - acc: 0.6293 - val_loss: 0.8467 - val_acc: 0.6171\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.8122 - acc: 0.6289 - val_loss: 0.8400 - val_acc: 0.6283\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8089 - acc: 0.6369 - val_loss: 0.8445 - val_acc: 0.6112\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8037 - acc: 0.6387 - val_loss: 0.8437 - val_acc: 0.6261\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8030 - acc: 0.6391 - val_loss: 0.8346 - val_acc: 0.6293\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 440us/step - loss: 0.7982 - acc: 0.6449 - val_loss: 0.8354 - val_acc: 0.6341\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7961 - acc: 0.6421 - val_loss: 0.8393 - val_acc: 0.6336\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7924 - acc: 0.6435 - val_loss: 0.8321 - val_acc: 0.6331\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7900 - acc: 0.6490 - val_loss: 0.8308 - val_acc: 0.6288\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.7846 - acc: 0.6440 - val_loss: 0.8316 - val_acc: 0.6261\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7836 - acc: 0.6481 - val_loss: 0.8270 - val_acc: 0.6320\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 469us/step - loss: 0.7794 - acc: 0.6565 - val_loss: 0.8248 - val_acc: 0.6320\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7773 - acc: 0.6460 - val_loss: 0.8255 - val_acc: 0.6416\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7753 - acc: 0.6565 - val_loss: 0.8525 - val_acc: 0.6224\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 425us/step - loss: 0.7711 - acc: 0.6613 - val_loss: 0.8228 - val_acc: 0.6389\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7681 - acc: 0.6568 - val_loss: 0.8299 - val_acc: 0.6293\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 492us/step - loss: 0.7658 - acc: 0.6586 - val_loss: 0.8208 - val_acc: 0.6331\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 506us/step - loss: 0.7622 - acc: 0.6698 - val_loss: 0.8198 - val_acc: 0.6320\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 471us/step - loss: 0.7580 - acc: 0.6682 - val_loss: 0.8298 - val_acc: 0.6277\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 532us/step - loss: 0.7568 - acc: 0.6725 - val_loss: 0.8199 - val_acc: 0.6469\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7540 - acc: 0.6735 - val_loss: 0.8242 - val_acc: 0.6379\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7494 - acc: 0.6744 - val_loss: 0.8307 - val_acc: 0.6267\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 394us/step - loss: 0.7495 - acc: 0.6673 - val_loss: 0.8645 - val_acc: 0.6027\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7450 - acc: 0.6780 - val_loss: 0.8154 - val_acc: 0.6373\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7408 - acc: 0.6739 - val_loss: 0.8179 - val_acc: 0.6448\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.7389 - acc: 0.6794 - val_loss: 0.8343 - val_acc: 0.6277\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7367 - acc: 0.6860 - val_loss: 0.8356 - val_acc: 0.6352\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.7339 - acc: 0.6867 - val_loss: 0.8139 - val_acc: 0.6464\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7318 - acc: 0.6872 - val_loss: 0.8121 - val_acc: 0.6336\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.7315 - acc: 0.6835 - val_loss: 0.8134 - val_acc: 0.6443\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7281 - acc: 0.6913 - val_loss: 0.8094 - val_acc: 0.6453\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7237 - acc: 0.6865 - val_loss: 0.8087 - val_acc: 0.6427\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7232 - acc: 0.6890 - val_loss: 0.8276 - val_acc: 0.6320\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.7172 - acc: 0.6881 - val_loss: 0.8386 - val_acc: 0.6304\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7162 - acc: 0.6892 - val_loss: 0.8182 - val_acc: 0.6411\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 474us/step - loss: 0.7138 - acc: 0.6979 - val_loss: 0.8074 - val_acc: 0.6443\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7101 - acc: 0.6981 - val_loss: 0.8353 - val_acc: 0.6309\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.7091 - acc: 0.6995 - val_loss: 0.8178 - val_acc: 0.6395\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7044 - acc: 0.6979 - val_loss: 0.8448 - val_acc: 0.6192\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 414us/step - loss: 0.7022 - acc: 0.7025 - val_loss: 0.8232 - val_acc: 0.6400\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.6995 - acc: 0.7007 - val_loss: 0.8099 - val_acc: 0.6464\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 434us/step - loss: 0.6966 - acc: 0.7116 - val_loss: 0.8255 - val_acc: 0.6448\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6958 - acc: 0.7041 - val_loss: 0.8071 - val_acc: 0.6496\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.6919 - acc: 0.7039 - val_loss: 0.8044 - val_acc: 0.6491\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.6892 - acc: 0.7071 - val_loss: 0.8182 - val_acc: 0.6501\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.6875 - acc: 0.7091 - val_loss: 0.8487 - val_acc: 0.6160\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.6818 - acc: 0.7148 - val_loss: 0.8129 - val_acc: 0.6469\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.6870 - acc: 0.7039 - val_loss: 0.8110 - val_acc: 0.6448\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.6788 - acc: 0.7112 - val_loss: 0.8043 - val_acc: 0.6432\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.6769 - acc: 0.7110 - val_loss: 0.8210 - val_acc: 0.6389\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 521us/step - loss: 0.6728 - acc: 0.7116 - val_loss: 0.8196 - val_acc: 0.6437\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.6706 - acc: 0.7185 - val_loss: 0.8076 - val_acc: 0.6485\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 2s 517us/step - loss: 0.6687 - acc: 0.7176 - val_loss: 0.8074 - val_acc: 0.6448\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.6625 - acc: 0.7228 - val_loss: 0.8809 - val_acc: 0.6219\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.6587 - acc: 0.7206 - val_loss: 0.8202 - val_acc: 0.6469\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 2s 480us/step - loss: 0.6561 - acc: 0.7260 - val_loss: 0.8564 - val_acc: 0.6379\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 2s 527us/step - loss: 0.6538 - acc: 0.7254 - val_loss: 0.8067 - val_acc: 0.6485\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.6513 - acc: 0.7270 - val_loss: 0.8504 - val_acc: 0.6293\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.6514 - acc: 0.7281 - val_loss: 0.8464 - val_acc: 0.6405\n",
      "0.602015709013\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 12s 3ms/step - loss: 1.0521 - acc: 0.4965 - val_loss: 1.0360 - val_acc: 0.5003\n",
      "Epoch 2/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 462us/step - loss: 1.0356 - acc: 0.5006 - val_loss: 1.0310 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 1.0310 - acc: 0.5006 - val_loss: 1.0267 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 1.0263 - acc: 0.5006 - val_loss: 1.0220 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 1.0210 - acc: 0.5006 - val_loss: 1.0169 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 1.0154 - acc: 0.5008 - val_loss: 1.0116 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 1.0093 - acc: 0.5010 - val_loss: 1.0056 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 501us/step - loss: 1.0024 - acc: 0.5010 - val_loss: 0.9991 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.9949 - acc: 0.5026 - val_loss: 0.9917 - val_acc: 0.5029\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.9864 - acc: 0.5056 - val_loss: 0.9835 - val_acc: 0.5099\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.9774 - acc: 0.5138 - val_loss: 0.9753 - val_acc: 0.5184\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9675 - acc: 0.5260 - val_loss: 0.9660 - val_acc: 0.5232\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 526us/step - loss: 0.9573 - acc: 0.5335 - val_loss: 0.9571 - val_acc: 0.5285\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.9468 - acc: 0.5376 - val_loss: 0.9485 - val_acc: 0.5408\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.9366 - acc: 0.5481 - val_loss: 0.9401 - val_acc: 0.5435\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.9263 - acc: 0.5557 - val_loss: 0.9315 - val_acc: 0.5435\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.9175 - acc: 0.5639 - val_loss: 0.9226 - val_acc: 0.5515\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 424us/step - loss: 0.9073 - acc: 0.5708 - val_loss: 0.9162 - val_acc: 0.5531\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.8997 - acc: 0.5799 - val_loss: 0.9098 - val_acc: 0.5579\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8930 - acc: 0.5840 - val_loss: 0.9060 - val_acc: 0.5675\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8854 - acc: 0.5955 - val_loss: 0.8992 - val_acc: 0.5669\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8778 - acc: 0.5918 - val_loss: 0.8990 - val_acc: 0.5771\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8715 - acc: 0.5994 - val_loss: 0.9073 - val_acc: 0.5685\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.8672 - acc: 0.6071 - val_loss: 0.8899 - val_acc: 0.5845\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 431us/step - loss: 0.8604 - acc: 0.6037 - val_loss: 0.8825 - val_acc: 0.5877\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 435us/step - loss: 0.8545 - acc: 0.6087 - val_loss: 0.8808 - val_acc: 0.5771\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8478 - acc: 0.6154 - val_loss: 0.8767 - val_acc: 0.5797\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 430us/step - loss: 0.8439 - acc: 0.6183 - val_loss: 0.8709 - val_acc: 0.5952\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.8375 - acc: 0.6188 - val_loss: 0.8692 - val_acc: 0.5867\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8311 - acc: 0.6263 - val_loss: 0.8793 - val_acc: 0.5872\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 500us/step - loss: 0.8309 - acc: 0.6229 - val_loss: 0.8625 - val_acc: 0.5947\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 443us/step - loss: 0.8224 - acc: 0.6305 - val_loss: 0.8793 - val_acc: 0.5925\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8184 - acc: 0.6305 - val_loss: 0.8613 - val_acc: 0.5963\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.8132 - acc: 0.6362 - val_loss: 0.8586 - val_acc: 0.5968\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8107 - acc: 0.6348 - val_loss: 0.8483 - val_acc: 0.6133\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8061 - acc: 0.6330 - val_loss: 0.8518 - val_acc: 0.6043\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8021 - acc: 0.6378 - val_loss: 0.8701 - val_acc: 0.6043\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7956 - acc: 0.6424 - val_loss: 0.8491 - val_acc: 0.6069\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 482us/step - loss: 0.7923 - acc: 0.6449 - val_loss: 0.8471 - val_acc: 0.6219\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.7890 - acc: 0.6462 - val_loss: 0.8393 - val_acc: 0.6277\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 523us/step - loss: 0.7881 - acc: 0.6488 - val_loss: 0.8612 - val_acc: 0.6096\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.7823 - acc: 0.6513 - val_loss: 0.8374 - val_acc: 0.6277\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 2s 495us/step - loss: 0.7807 - acc: 0.6517 - val_loss: 0.8387 - val_acc: 0.6187\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 507us/step - loss: 0.7771 - acc: 0.6558 - val_loss: 0.8466 - val_acc: 0.6181\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 519us/step - loss: 0.7705 - acc: 0.6584 - val_loss: 0.8465 - val_acc: 0.6293\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7676 - acc: 0.6686 - val_loss: 0.8444 - val_acc: 0.6208\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7645 - acc: 0.6664 - val_loss: 0.8475 - val_acc: 0.6069\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 484us/step - loss: 0.7618 - acc: 0.6654 - val_loss: 0.8343 - val_acc: 0.6331\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.7579 - acc: 0.6691 - val_loss: 0.8484 - val_acc: 0.6197\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7572 - acc: 0.6668 - val_loss: 0.8311 - val_acc: 0.6341\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 422us/step - loss: 0.7534 - acc: 0.6721 - val_loss: 0.8280 - val_acc: 0.6288\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 455us/step - loss: 0.7512 - acc: 0.6716 - val_loss: 0.8331 - val_acc: 0.6341\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 453us/step - loss: 0.7459 - acc: 0.6735 - val_loss: 0.8299 - val_acc: 0.6267\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7429 - acc: 0.6757 - val_loss: 0.8310 - val_acc: 0.6299\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7379 - acc: 0.6776 - val_loss: 0.8270 - val_acc: 0.6304\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 468us/step - loss: 0.7393 - acc: 0.6789 - val_loss: 0.8454 - val_acc: 0.6181\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 415us/step - loss: 0.7346 - acc: 0.6812 - val_loss: 0.8484 - val_acc: 0.6229\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7320 - acc: 0.6856 - val_loss: 0.8322 - val_acc: 0.6309\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 445us/step - loss: 0.7274 - acc: 0.6879 - val_loss: 0.8252 - val_acc: 0.6373\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 470us/step - loss: 0.7250 - acc: 0.6922 - val_loss: 0.8445 - val_acc: 0.6235\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 426us/step - loss: 0.7250 - acc: 0.6847 - val_loss: 0.8354 - val_acc: 0.6320\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.7206 - acc: 0.6904 - val_loss: 0.8737 - val_acc: 0.6011\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7190 - acc: 0.6906 - val_loss: 0.8243 - val_acc: 0.6331\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 408us/step - loss: 0.7175 - acc: 0.6936 - val_loss: 0.8266 - val_acc: 0.6336\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 463us/step - loss: 0.7110 - acc: 0.6940 - val_loss: 0.8252 - val_acc: 0.6320\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.7067 - acc: 0.7029 - val_loss: 0.8588 - val_acc: 0.6171\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7075 - acc: 0.7013 - val_loss: 0.8195 - val_acc: 0.6448\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7057 - acc: 0.6981 - val_loss: 0.8361 - val_acc: 0.6293\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 429us/step - loss: 0.7003 - acc: 0.7023 - val_loss: 0.8249 - val_acc: 0.6405\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.6964 - acc: 0.7034 - val_loss: 0.8319 - val_acc: 0.6325\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.7001 - acc: 0.7007 - val_loss: 0.8320 - val_acc: 0.6341\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 488us/step - loss: 0.6977 - acc: 0.7002 - val_loss: 0.8243 - val_acc: 0.6373\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.6897 - acc: 0.7107 - val_loss: 0.8331 - val_acc: 0.6325\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.6898 - acc: 0.7098 - val_loss: 0.8497 - val_acc: 0.6283\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 513us/step - loss: 0.6888 - acc: 0.7036 - val_loss: 0.8950 - val_acc: 0.5968\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6887 - acc: 0.7018 - val_loss: 0.8221 - val_acc: 0.6373\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.6804 - acc: 0.7121 - val_loss: 0.8402 - val_acc: 0.6299\n",
      "0.576721945499\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 12s 3ms/step - loss: 1.0530 - acc: 0.4965 - val_loss: 1.0384 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 1.0360 - acc: 0.5006 - val_loss: 1.0334 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 1.0307 - acc: 0.5006 - val_loss: 1.0285 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 2s 477us/step - loss: 1.0254 - acc: 0.5006 - val_loss: 1.0237 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 1.0201 - acc: 0.5006 - val_loss: 1.0185 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 1.0143 - acc: 0.5006 - val_loss: 1.0131 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 1.0081 - acc: 0.5006 - val_loss: 1.0074 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 2s 478us/step - loss: 1.0016 - acc: 0.5017 - val_loss: 1.0007 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 2s 458us/step - loss: 0.9946 - acc: 0.5033 - val_loss: 0.9938 - val_acc: 0.5019\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 2s 465us/step - loss: 0.9870 - acc: 0.5051 - val_loss: 0.9866 - val_acc: 0.5061\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.9785 - acc: 0.5120 - val_loss: 0.9787 - val_acc: 0.5104\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.9702 - acc: 0.5202 - val_loss: 0.9707 - val_acc: 0.5152\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 2s 472us/step - loss: 0.9614 - acc: 0.5241 - val_loss: 0.9621 - val_acc: 0.5243\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 2s 490us/step - loss: 0.9522 - acc: 0.5324 - val_loss: 0.9546 - val_acc: 0.5440\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 2s 515us/step - loss: 0.9429 - acc: 0.5532 - val_loss: 0.9490 - val_acc: 0.5344\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.9347 - acc: 0.5559 - val_loss: 0.9388 - val_acc: 0.5557\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 2s 486us/step - loss: 0.9264 - acc: 0.5630 - val_loss: 0.9289 - val_acc: 0.5568\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 2s 503us/step - loss: 0.9183 - acc: 0.5740 - val_loss: 0.9249 - val_acc: 0.5600\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 2s 512us/step - loss: 0.9095 - acc: 0.5799 - val_loss: 0.9167 - val_acc: 0.5659\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 2s 520us/step - loss: 0.9022 - acc: 0.5845 - val_loss: 0.9079 - val_acc: 0.5755\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 2s 491us/step - loss: 0.8963 - acc: 0.5909 - val_loss: 0.9010 - val_acc: 0.5739\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8898 - acc: 0.5939 - val_loss: 0.8985 - val_acc: 0.5931\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.8821 - acc: 0.5959 - val_loss: 0.8924 - val_acc: 0.5931\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 2s 452us/step - loss: 0.8767 - acc: 0.6012 - val_loss: 0.9029 - val_acc: 0.5813\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.8707 - acc: 0.6019 - val_loss: 0.8840 - val_acc: 0.5760\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 2s 413us/step - loss: 0.8651 - acc: 0.5998 - val_loss: 0.8746 - val_acc: 0.5851\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8614 - acc: 0.6097 - val_loss: 0.8723 - val_acc: 0.5936\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8556 - acc: 0.6115 - val_loss: 0.8767 - val_acc: 0.5899\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 2s 433us/step - loss: 0.8508 - acc: 0.6151 - val_loss: 0.8758 - val_acc: 0.5973\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 2s 476us/step - loss: 0.8453 - acc: 0.6147 - val_loss: 0.8604 - val_acc: 0.6016\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.8434 - acc: 0.6199 - val_loss: 0.8633 - val_acc: 0.6085\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8382 - acc: 0.6202 - val_loss: 0.8651 - val_acc: 0.6037\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 2s 450us/step - loss: 0.8354 - acc: 0.6209 - val_loss: 0.8535 - val_acc: 0.6144\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 2s 466us/step - loss: 0.8318 - acc: 0.6227 - val_loss: 0.8510 - val_acc: 0.6091\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.8265 - acc: 0.6241 - val_loss: 0.8536 - val_acc: 0.6037\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.8232 - acc: 0.6279 - val_loss: 0.8513 - val_acc: 0.6128\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.8209 - acc: 0.6289 - val_loss: 0.8465 - val_acc: 0.6176\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.8168 - acc: 0.6282 - val_loss: 0.8529 - val_acc: 0.6059\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 2s 441us/step - loss: 0.8133 - acc: 0.6321 - val_loss: 0.8533 - val_acc: 0.5995\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 2s 451us/step - loss: 0.8120 - acc: 0.6318 - val_loss: 0.8393 - val_acc: 0.6203\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.8074 - acc: 0.6371 - val_loss: 0.8371 - val_acc: 0.6187\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 2s 421us/step - loss: 0.8041 - acc: 0.6396 - val_loss: 0.8384 - val_acc: 0.6208\n",
      "Epoch 43/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 2s 459us/step - loss: 0.8011 - acc: 0.6394 - val_loss: 0.8391 - val_acc: 0.6235\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7990 - acc: 0.6408 - val_loss: 0.8367 - val_acc: 0.6272\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7951 - acc: 0.6428 - val_loss: 0.8309 - val_acc: 0.6208\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 456us/step - loss: 0.7931 - acc: 0.6488 - val_loss: 0.8348 - val_acc: 0.6224\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 2s 454us/step - loss: 0.7888 - acc: 0.6449 - val_loss: 0.8323 - val_acc: 0.6213\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 2s 509us/step - loss: 0.7861 - acc: 0.6444 - val_loss: 0.8268 - val_acc: 0.6272\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 2s 479us/step - loss: 0.7843 - acc: 0.6490 - val_loss: 0.8245 - val_acc: 0.6320\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 2s 494us/step - loss: 0.7818 - acc: 0.6490 - val_loss: 0.8316 - val_acc: 0.6229\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 2s 502us/step - loss: 0.7782 - acc: 0.6545 - val_loss: 0.8285 - val_acc: 0.6267\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7737 - acc: 0.6556 - val_loss: 0.8243 - val_acc: 0.6352\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 2s 418us/step - loss: 0.7713 - acc: 0.6586 - val_loss: 0.8411 - val_acc: 0.6203\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 2s 412us/step - loss: 0.7703 - acc: 0.6545 - val_loss: 0.8261 - val_acc: 0.6288\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 2s 442us/step - loss: 0.7663 - acc: 0.6595 - val_loss: 0.8315 - val_acc: 0.6325\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 419us/step - loss: 0.7634 - acc: 0.6618 - val_loss: 0.8344 - val_acc: 0.6293\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 2s 504us/step - loss: 0.7595 - acc: 0.6620 - val_loss: 0.8215 - val_acc: 0.6395\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 2s 449us/step - loss: 0.7589 - acc: 0.6629 - val_loss: 0.8208 - val_acc: 0.6309\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 2s 416us/step - loss: 0.7567 - acc: 0.6654 - val_loss: 0.8150 - val_acc: 0.6400\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 2s 457us/step - loss: 0.7537 - acc: 0.6677 - val_loss: 0.8568 - val_acc: 0.5979\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 2s 420us/step - loss: 0.7492 - acc: 0.6622 - val_loss: 0.8172 - val_acc: 0.6389\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 2s 411us/step - loss: 0.7460 - acc: 0.6693 - val_loss: 0.8329 - val_acc: 0.6416\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 2s 446us/step - loss: 0.7445 - acc: 0.6737 - val_loss: 0.8156 - val_acc: 0.6384\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7420 - acc: 0.6700 - val_loss: 0.8217 - val_acc: 0.6400\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.7404 - acc: 0.6789 - val_loss: 0.8136 - val_acc: 0.6411\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 2s 402us/step - loss: 0.7362 - acc: 0.6735 - val_loss: 0.8178 - val_acc: 0.6405\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 2s 447us/step - loss: 0.7336 - acc: 0.6776 - val_loss: 0.8239 - val_acc: 0.6363\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.7317 - acc: 0.6741 - val_loss: 0.8216 - val_acc: 0.6363\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 2s 481us/step - loss: 0.7280 - acc: 0.6824 - val_loss: 0.8099 - val_acc: 0.6507\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 2s 428us/step - loss: 0.7258 - acc: 0.6831 - val_loss: 0.8172 - val_acc: 0.6464\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 2s 403us/step - loss: 0.7230 - acc: 0.6885 - val_loss: 0.8123 - val_acc: 0.6379\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 2s 461us/step - loss: 0.7195 - acc: 0.6865 - val_loss: 0.8311 - val_acc: 0.6299\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 2s 444us/step - loss: 0.7216 - acc: 0.6847 - val_loss: 0.8290 - val_acc: 0.6373\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 2s 448us/step - loss: 0.7145 - acc: 0.6849 - val_loss: 0.8334 - val_acc: 0.6256\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 2s 432us/step - loss: 0.7130 - acc: 0.6929 - val_loss: 0.8087 - val_acc: 0.6517\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 2s 427us/step - loss: 0.7102 - acc: 0.6917 - val_loss: 0.8253 - val_acc: 0.6336\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 2s 439us/step - loss: 0.7090 - acc: 0.6901 - val_loss: 0.8125 - val_acc: 0.6539\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 2s 464us/step - loss: 0.7029 - acc: 0.6965 - val_loss: 0.8375 - val_acc: 0.6405\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 2s 515us/step - loss: 0.7029 - acc: 0.6975 - val_loss: 0.8250 - val_acc: 0.6427\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 2s 436us/step - loss: 0.6986 - acc: 0.6997 - val_loss: 0.8092 - val_acc: 0.6533\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 2s 483us/step - loss: 0.6958 - acc: 0.6995 - val_loss: 0.8093 - val_acc: 0.6512\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 2s 487us/step - loss: 0.6941 - acc: 0.6984 - val_loss: 0.8094 - val_acc: 0.6565\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 2s 396us/step - loss: 0.6908 - acc: 0.6972 - val_loss: 0.8281 - val_acc: 0.6485\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 2s 460us/step - loss: 0.6849 - acc: 0.7055 - val_loss: 0.9001 - val_acc: 0.5947\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 2s 438us/step - loss: 0.6869 - acc: 0.7048 - val_loss: 0.8131 - val_acc: 0.6475\n",
      "0.597163520557\n",
      "[0.60377729550143344, 0.60886542860371728, 0.59163696212965877, 0.61579810826914938, 0.60390538054866671, 0.60552617180246038, 0.62221945621777863, 0.6011003377607459, 0.60653154774761797, 0.57401398145752658, 0.6096350496838302, 0.5979764260625845, 0.60785961094019003, 0.62232539969743661, 0.58447679631131788, 0.6074446581248395, 0.60469485083823127, 0.63045625123444593, 0.59438574000485211, 0.59631223763218022, 0.61840029546488717, 0.62170698924731183, 0.58202237277572222, 0.60508865404647949, 0.59759446381656156, 0.61151804200479531, 0.58865709425918278, 0.61151619963242076, 0.5913693196235128, 0.60276403214658048, 0.60861055470458081, 0.5742349322774255, 0.59769587656449297, 0.60062855082115796, 0.58824898521788826, 0.59947808646240031, 0.61018109007678623, 0.59783156915533864, 0.58507746013002204, 0.60950543512626387, 0.61160523509075271, 0.59998715225335519, 0.61090494535260886, 0.59855455854702289, 0.60608766163195915, 0.599066619722879, 0.58558837467645808, 0.61557827425283529, 0.60927722415742791, 0.59741828276402265, 0.59709938622913572, 0.58424817030756959, 0.58994843460259394, 0.59289147979633849, 0.61423991710673043, 0.61654588914819275, 0.59012198659926818, 0.60201570901266133, 0.57672194549862954, 0.59716352055668953]\n",
      "15\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 13s 3ms/step - loss: 1.0479 - acc: 0.5003 - val_loss: 1.0372 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 1.0347 - acc: 0.5006 - val_loss: 1.0327 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 1.0300 - acc: 0.5006 - val_loss: 1.0283 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 1.0257 - acc: 0.5006 - val_loss: 1.0234 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 1.0203 - acc: 0.5006 - val_loss: 1.0192 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 1.0156 - acc: 0.5006 - val_loss: 1.0127 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 1.0095 - acc: 0.5006 - val_loss: 1.0072 - val_acc: 0.5003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 1.0034 - acc: 0.5019 - val_loss: 1.0005 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.9971 - acc: 0.5040 - val_loss: 0.9932 - val_acc: 0.5099\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.9897 - acc: 0.5090 - val_loss: 0.9865 - val_acc: 0.5141\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 0.9819 - acc: 0.5180 - val_loss: 0.9783 - val_acc: 0.5216\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.9741 - acc: 0.5237 - val_loss: 0.9715 - val_acc: 0.5248\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 704us/step - loss: 0.9658 - acc: 0.5337 - val_loss: 0.9616 - val_acc: 0.5349\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.9578 - acc: 0.5360 - val_loss: 0.9532 - val_acc: 0.5483\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.9485 - acc: 0.5495 - val_loss: 0.9466 - val_acc: 0.5451\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.9397 - acc: 0.5532 - val_loss: 0.9336 - val_acc: 0.5557\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 729us/step - loss: 0.9309 - acc: 0.5593 - val_loss: 0.9236 - val_acc: 0.5664\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.9208 - acc: 0.5625 - val_loss: 0.9143 - val_acc: 0.5595\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 724us/step - loss: 0.9104 - acc: 0.5735 - val_loss: 0.9025 - val_acc: 0.5792\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.9004 - acc: 0.5797 - val_loss: 0.8953 - val_acc: 0.5707\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.8920 - acc: 0.5788 - val_loss: 0.8837 - val_acc: 0.5755\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.8858 - acc: 0.5831 - val_loss: 0.9068 - val_acc: 0.5733\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 718us/step - loss: 0.8800 - acc: 0.5904 - val_loss: 0.8802 - val_acc: 0.5963\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 744us/step - loss: 0.8709 - acc: 0.5920 - val_loss: 0.8762 - val_acc: 0.6117\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.8656 - acc: 0.5941 - val_loss: 0.8667 - val_acc: 0.6011\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.8589 - acc: 0.6030 - val_loss: 0.8620 - val_acc: 0.6171\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.8539 - acc: 0.6062 - val_loss: 0.8470 - val_acc: 0.6192\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8494 - acc: 0.6062 - val_loss: 0.8494 - val_acc: 0.6091\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.8439 - acc: 0.6129 - val_loss: 0.8480 - val_acc: 0.6203\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.8376 - acc: 0.6163 - val_loss: 0.8383 - val_acc: 0.6144\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 0.8324 - acc: 0.6172 - val_loss: 0.8305 - val_acc: 0.6288\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.8287 - acc: 0.6126 - val_loss: 0.8385 - val_acc: 0.6245\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.8247 - acc: 0.6211 - val_loss: 0.8377 - val_acc: 0.6171\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8192 - acc: 0.6250 - val_loss: 0.8238 - val_acc: 0.6240\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 617us/step - loss: 0.8150 - acc: 0.6245 - val_loss: 0.8304 - val_acc: 0.6235\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.8134 - acc: 0.6261 - val_loss: 0.8344 - val_acc: 0.6187\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.8069 - acc: 0.6284 - val_loss: 0.8212 - val_acc: 0.6299\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.8035 - acc: 0.6334 - val_loss: 0.8314 - val_acc: 0.6256\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8009 - acc: 0.6323 - val_loss: 0.8118 - val_acc: 0.6336\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7965 - acc: 0.6424 - val_loss: 0.8129 - val_acc: 0.6288\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 635us/step - loss: 0.7921 - acc: 0.6373 - val_loss: 0.8265 - val_acc: 0.6304\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 601us/step - loss: 0.7903 - acc: 0.6410 - val_loss: 0.8105 - val_acc: 0.6411\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7858 - acc: 0.6453 - val_loss: 0.8219 - val_acc: 0.6261\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 617us/step - loss: 0.7830 - acc: 0.6481 - val_loss: 0.8350 - val_acc: 0.6192\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7757 - acc: 0.6492 - val_loss: 0.8090 - val_acc: 0.6251\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 602us/step - loss: 0.7760 - acc: 0.6533 - val_loss: 0.8054 - val_acc: 0.6357\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 601us/step - loss: 0.7731 - acc: 0.6497 - val_loss: 0.8185 - val_acc: 0.6304\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7736 - acc: 0.6565 - val_loss: 0.8024 - val_acc: 0.6309\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.7644 - acc: 0.6579 - val_loss: 0.8021 - val_acc: 0.6507\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7653 - acc: 0.6586 - val_loss: 0.8012 - val_acc: 0.6544\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7573 - acc: 0.6570 - val_loss: 0.8105 - val_acc: 0.6331\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.7577 - acc: 0.6664 - val_loss: 0.8364 - val_acc: 0.6187\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.7559 - acc: 0.6648 - val_loss: 0.7965 - val_acc: 0.6437\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.7510 - acc: 0.6664 - val_loss: 0.8454 - val_acc: 0.6101\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 737us/step - loss: 0.7473 - acc: 0.6657 - val_loss: 0.8212 - val_acc: 0.6288\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7468 - acc: 0.6709 - val_loss: 0.7997 - val_acc: 0.6496\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7392 - acc: 0.6728 - val_loss: 0.8207 - val_acc: 0.6405\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.7433 - acc: 0.6707 - val_loss: 0.7984 - val_acc: 0.6485\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 614us/step - loss: 0.7385 - acc: 0.6767 - val_loss: 0.8126 - val_acc: 0.6347\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7348 - acc: 0.6776 - val_loss: 0.7972 - val_acc: 0.6427\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 606us/step - loss: 0.7299 - acc: 0.6769 - val_loss: 0.8102 - val_acc: 0.6411\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.7292 - acc: 0.6819 - val_loss: 0.7935 - val_acc: 0.6565\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 594us/step - loss: 0.7245 - acc: 0.6824 - val_loss: 0.7880 - val_acc: 0.6507\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7251 - acc: 0.6892 - val_loss: 0.7898 - val_acc: 0.6501\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 622us/step - loss: 0.7215 - acc: 0.6872 - val_loss: 0.8084 - val_acc: 0.6405\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7177 - acc: 0.6869 - val_loss: 0.8121 - val_acc: 0.6448\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7143 - acc: 0.6911 - val_loss: 0.8238 - val_acc: 0.6192\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.7107 - acc: 0.6844 - val_loss: 0.7942 - val_acc: 0.6517\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.7073 - acc: 0.6913 - val_loss: 0.8225 - val_acc: 0.6373\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 637us/step - loss: 0.7061 - acc: 0.6977 - val_loss: 0.7976 - val_acc: 0.6416\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7041 - acc: 0.6940 - val_loss: 0.7965 - val_acc: 0.6501\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.7014 - acc: 0.6922 - val_loss: 0.7889 - val_acc: 0.6523\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 700us/step - loss: 0.6969 - acc: 0.7055 - val_loss: 0.8180 - val_acc: 0.6331\n",
      "0.598519106314\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 13s 3ms/step - loss: 1.0475 - acc: 0.4994 - val_loss: 1.0391 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 1.0358 - acc: 0.5006 - val_loss: 1.0354 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 1.0316 - acc: 0.5006 - val_loss: 1.0318 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 1.0273 - acc: 0.5006 - val_loss: 1.0279 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 611us/step - loss: 1.0222 - acc: 0.5006 - val_loss: 1.0237 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 1.0174 - acc: 0.5006 - val_loss: 1.0189 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 1.0111 - acc: 0.5006 - val_loss: 1.0140 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 1.0054 - acc: 0.5017 - val_loss: 1.0080 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 623us/step - loss: 0.9983 - acc: 0.5042 - val_loss: 1.0013 - val_acc: 0.5104\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.9902 - acc: 0.5118 - val_loss: 0.9942 - val_acc: 0.5115\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.9808 - acc: 0.5200 - val_loss: 0.9857 - val_acc: 0.5120\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.9716 - acc: 0.5266 - val_loss: 0.9775 - val_acc: 0.5237\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 618us/step - loss: 0.9607 - acc: 0.5362 - val_loss: 0.9650 - val_acc: 0.5285\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.9488 - acc: 0.5472 - val_loss: 0.9532 - val_acc: 0.5376\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.9384 - acc: 0.5561 - val_loss: 0.9475 - val_acc: 0.5419\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.9266 - acc: 0.5669 - val_loss: 0.9328 - val_acc: 0.5467\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 743us/step - loss: 0.9164 - acc: 0.5756 - val_loss: 0.9294 - val_acc: 0.5429\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.9078 - acc: 0.5774 - val_loss: 0.9178 - val_acc: 0.5627\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.8988 - acc: 0.5811 - val_loss: 0.9104 - val_acc: 0.5680\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8906 - acc: 0.5872 - val_loss: 0.9076 - val_acc: 0.5621\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.8808 - acc: 0.5941 - val_loss: 0.8988 - val_acc: 0.5744\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.8741 - acc: 0.5952 - val_loss: 0.8926 - val_acc: 0.5877\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.8660 - acc: 0.5962 - val_loss: 0.8924 - val_acc: 0.5840\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.8594 - acc: 0.6064 - val_loss: 0.8876 - val_acc: 0.5749\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 0.8545 - acc: 0.6021 - val_loss: 0.8824 - val_acc: 0.5915\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.8491 - acc: 0.6122 - val_loss: 0.8795 - val_acc: 0.5968\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.8432 - acc: 0.6151 - val_loss: 0.8797 - val_acc: 0.5893\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8371 - acc: 0.6113 - val_loss: 0.8736 - val_acc: 0.5755\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.8318 - acc: 0.6225 - val_loss: 0.8710 - val_acc: 0.5845\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.8293 - acc: 0.6213 - val_loss: 0.8834 - val_acc: 0.5781\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.8240 - acc: 0.6245 - val_loss: 0.8662 - val_acc: 0.6059\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.8200 - acc: 0.6307 - val_loss: 0.8621 - val_acc: 0.5931\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8160 - acc: 0.6314 - val_loss: 0.8597 - val_acc: 0.6064\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.8105 - acc: 0.6314 - val_loss: 0.8583 - val_acc: 0.6005\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.8078 - acc: 0.6327 - val_loss: 0.8604 - val_acc: 0.5995\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.8031 - acc: 0.6371 - val_loss: 0.8557 - val_acc: 0.6064\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7977 - acc: 0.6391 - val_loss: 0.8614 - val_acc: 0.5973\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 720us/step - loss: 0.7931 - acc: 0.6430 - val_loss: 0.8530 - val_acc: 0.6128\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7926 - acc: 0.6430 - val_loss: 0.8639 - val_acc: 0.5883\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7888 - acc: 0.6456 - val_loss: 0.8588 - val_acc: 0.5984\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 700us/step - loss: 0.7881 - acc: 0.6424 - val_loss: 0.8522 - val_acc: 0.6101\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7818 - acc: 0.6497 - val_loss: 0.8570 - val_acc: 0.5952\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.7771 - acc: 0.6536 - val_loss: 0.8483 - val_acc: 0.6048\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7798 - acc: 0.6520 - val_loss: 0.8433 - val_acc: 0.6277\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7722 - acc: 0.6545 - val_loss: 0.8408 - val_acc: 0.6261\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7714 - acc: 0.6579 - val_loss: 0.8488 - val_acc: 0.6075\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 0.7652 - acc: 0.6611 - val_loss: 0.8425 - val_acc: 0.6165\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.7651 - acc: 0.6622 - val_loss: 0.8445 - val_acc: 0.6251\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.7622 - acc: 0.6604 - val_loss: 0.8352 - val_acc: 0.6187\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7606 - acc: 0.6627 - val_loss: 0.8419 - val_acc: 0.6251\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.7559 - acc: 0.6629 - val_loss: 0.8755 - val_acc: 0.6107\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.7542 - acc: 0.6634 - val_loss: 0.8357 - val_acc: 0.6208\n",
      "Epoch 53/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7521 - acc: 0.6709 - val_loss: 0.8369 - val_acc: 0.6165\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.7479 - acc: 0.6682 - val_loss: 0.8387 - val_acc: 0.6176\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.7484 - acc: 0.6664 - val_loss: 0.8350 - val_acc: 0.6235\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.7454 - acc: 0.6730 - val_loss: 0.8411 - val_acc: 0.6155\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.7389 - acc: 0.6778 - val_loss: 0.8393 - val_acc: 0.6197\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 0.7375 - acc: 0.6799 - val_loss: 0.8406 - val_acc: 0.6176\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 738us/step - loss: 0.7348 - acc: 0.6764 - val_loss: 0.8363 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.7334 - acc: 0.6723 - val_loss: 0.8346 - val_acc: 0.6304\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7316 - acc: 0.6751 - val_loss: 0.8390 - val_acc: 0.6144\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7286 - acc: 0.6794 - val_loss: 0.8422 - val_acc: 0.6288\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 614us/step - loss: 0.7303 - acc: 0.6796 - val_loss: 0.8475 - val_acc: 0.6309\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7223 - acc: 0.6819 - val_loss: 0.8336 - val_acc: 0.6245\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7230 - acc: 0.6849 - val_loss: 0.8317 - val_acc: 0.6256\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7176 - acc: 0.6904 - val_loss: 0.8278 - val_acc: 0.6368\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.7139 - acc: 0.6908 - val_loss: 0.8320 - val_acc: 0.6267\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 0.7127 - acc: 0.6844 - val_loss: 0.8309 - val_acc: 0.6261\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 0.7097 - acc: 0.6913 - val_loss: 0.8490 - val_acc: 0.6245\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.7094 - acc: 0.6975 - val_loss: 0.8412 - val_acc: 0.6315\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.7082 - acc: 0.6899 - val_loss: 0.8293 - val_acc: 0.6304\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.7033 - acc: 0.6956 - val_loss: 0.8318 - val_acc: 0.6256\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7033 - acc: 0.6995 - val_loss: 0.8273 - val_acc: 0.6299\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.6996 - acc: 0.7007 - val_loss: 0.8307 - val_acc: 0.6288\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 590us/step - loss: 0.6973 - acc: 0.6988 - val_loss: 0.8322 - val_acc: 0.6341\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.6941 - acc: 0.7020 - val_loss: 0.8496 - val_acc: 0.6283\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.6938 - acc: 0.6995 - val_loss: 0.8466 - val_acc: 0.6277\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 744us/step - loss: 0.6886 - acc: 0.7075 - val_loss: 0.8253 - val_acc: 0.6368\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 0.6874 - acc: 0.6984 - val_loss: 0.8322 - val_acc: 0.6400\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.6871 - acc: 0.7048 - val_loss: 0.8287 - val_acc: 0.6363\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.6831 - acc: 0.7068 - val_loss: 0.8283 - val_acc: 0.6277\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 631us/step - loss: 0.6783 - acc: 0.7142 - val_loss: 0.8373 - val_acc: 0.6245\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 620us/step - loss: 0.6772 - acc: 0.7126 - val_loss: 0.8258 - val_acc: 0.6373\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.6734 - acc: 0.7139 - val_loss: 0.8310 - val_acc: 0.6320\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.6696 - acc: 0.7196 - val_loss: 0.8368 - val_acc: 0.6432\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.6716 - acc: 0.7199 - val_loss: 0.8286 - val_acc: 0.6315\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.6718 - acc: 0.7123 - val_loss: 0.9452 - val_acc: 0.5845\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.6659 - acc: 0.7238 - val_loss: 0.8578 - val_acc: 0.6363\n",
      "0.609211380881\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 13s 3ms/step - loss: 1.0465 - acc: 0.4985 - val_loss: 1.0370 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 1.0347 - acc: 0.5006 - val_loss: 1.0332 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 1.0305 - acc: 0.5006 - val_loss: 1.0293 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 1.0262 - acc: 0.5006 - val_loss: 1.0250 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 1.0215 - acc: 0.5006 - val_loss: 1.0206 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 1.0167 - acc: 0.5006 - val_loss: 1.0165 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 748us/step - loss: 1.0113 - acc: 0.5008 - val_loss: 1.0111 - val_acc: 0.4997\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 1.0056 - acc: 0.5010 - val_loss: 1.0051 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.9991 - acc: 0.5022 - val_loss: 0.9992 - val_acc: 0.5056\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 758us/step - loss: 0.9919 - acc: 0.5065 - val_loss: 0.9914 - val_acc: 0.5093\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.9840 - acc: 0.5143 - val_loss: 0.9831 - val_acc: 0.5131\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 721us/step - loss: 0.9746 - acc: 0.5209 - val_loss: 0.9729 - val_acc: 0.5237\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 719us/step - loss: 0.9627 - acc: 0.5289 - val_loss: 0.9672 - val_acc: 0.5328\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.9500 - acc: 0.5367 - val_loss: 0.9468 - val_acc: 0.5317\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.9374 - acc: 0.5456 - val_loss: 0.9360 - val_acc: 0.5376\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.9264 - acc: 0.5575 - val_loss: 0.9246 - val_acc: 0.5701\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.9147 - acc: 0.5651 - val_loss: 0.9164 - val_acc: 0.5627\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.9060 - acc: 0.5737 - val_loss: 0.9100 - val_acc: 0.5835\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8960 - acc: 0.5884 - val_loss: 0.9304 - val_acc: 0.5573\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.8881 - acc: 0.5879 - val_loss: 0.9211 - val_acc: 0.5573\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.8811 - acc: 0.5909 - val_loss: 0.8919 - val_acc: 0.5899\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.8732 - acc: 0.5971 - val_loss: 0.8906 - val_acc: 0.5824\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 721us/step - loss: 0.8673 - acc: 0.5973 - val_loss: 0.8848 - val_acc: 0.5856\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 701us/step - loss: 0.8594 - acc: 0.5971 - val_loss: 0.8798 - val_acc: 0.5867\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 730us/step - loss: 0.8540 - acc: 0.6090 - val_loss: 0.8800 - val_acc: 0.5813\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 711us/step - loss: 0.8477 - acc: 0.6126 - val_loss: 0.8817 - val_acc: 0.5835\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.8420 - acc: 0.6129 - val_loss: 0.8639 - val_acc: 0.5989\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 0.8361 - acc: 0.6170 - val_loss: 0.8735 - val_acc: 0.5840\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.8316 - acc: 0.6213 - val_loss: 0.8609 - val_acc: 0.5957\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.8249 - acc: 0.6250 - val_loss: 0.8585 - val_acc: 0.5995\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.8226 - acc: 0.6241 - val_loss: 0.8645 - val_acc: 0.5989\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.8184 - acc: 0.6277 - val_loss: 0.8640 - val_acc: 0.5915\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.8124 - acc: 0.6279 - val_loss: 0.8826 - val_acc: 0.5808\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.8086 - acc: 0.6364 - val_loss: 0.8446 - val_acc: 0.6128\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 0.8015 - acc: 0.6385 - val_loss: 0.8422 - val_acc: 0.6192\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7991 - acc: 0.6334 - val_loss: 0.8544 - val_acc: 0.6032\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.7970 - acc: 0.6369 - val_loss: 0.8440 - val_acc: 0.6112\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7931 - acc: 0.6412 - val_loss: 0.8525 - val_acc: 0.6048\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7902 - acc: 0.6437 - val_loss: 0.8411 - val_acc: 0.6128\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7842 - acc: 0.6442 - val_loss: 0.8475 - val_acc: 0.6096\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.7813 - acc: 0.6501 - val_loss: 0.8305 - val_acc: 0.6245\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7745 - acc: 0.6510 - val_loss: 0.8379 - val_acc: 0.6149\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.7745 - acc: 0.6568 - val_loss: 0.8482 - val_acc: 0.6091\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.7699 - acc: 0.6595 - val_loss: 0.8480 - val_acc: 0.6149\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.7674 - acc: 0.6554 - val_loss: 0.8254 - val_acc: 0.6304\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 747us/step - loss: 0.7642 - acc: 0.6593 - val_loss: 0.8242 - val_acc: 0.6256\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 0.7637 - acc: 0.6602 - val_loss: 0.8248 - val_acc: 0.6288\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 709us/step - loss: 0.7566 - acc: 0.6545 - val_loss: 0.8551 - val_acc: 0.6032\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7568 - acc: 0.6618 - val_loss: 0.8394 - val_acc: 0.6213\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.7530 - acc: 0.6709 - val_loss: 0.8234 - val_acc: 0.6277\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7474 - acc: 0.6691 - val_loss: 0.8209 - val_acc: 0.6363\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7449 - acc: 0.6739 - val_loss: 0.8782 - val_acc: 0.6005\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7401 - acc: 0.6753 - val_loss: 0.8304 - val_acc: 0.6315\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7397 - acc: 0.6778 - val_loss: 0.8204 - val_acc: 0.6235\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.7359 - acc: 0.6778 - val_loss: 0.8372 - val_acc: 0.6325\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7353 - acc: 0.6789 - val_loss: 0.8187 - val_acc: 0.6389\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 616us/step - loss: 0.7320 - acc: 0.6771 - val_loss: 0.8167 - val_acc: 0.6325\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7304 - acc: 0.6783 - val_loss: 0.8148 - val_acc: 0.6293\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7270 - acc: 0.6803 - val_loss: 0.8261 - val_acc: 0.6315\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.7203 - acc: 0.6863 - val_loss: 0.8305 - val_acc: 0.6203\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.7206 - acc: 0.6851 - val_loss: 0.8178 - val_acc: 0.6400\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 623us/step - loss: 0.7167 - acc: 0.6847 - val_loss: 0.8139 - val_acc: 0.6357\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.7133 - acc: 0.6924 - val_loss: 0.8334 - val_acc: 0.6245\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7104 - acc: 0.6899 - val_loss: 0.8206 - val_acc: 0.6219\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 0.7075 - acc: 0.6936 - val_loss: 0.8282 - val_acc: 0.6187\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7081 - acc: 0.6847 - val_loss: 0.8165 - val_acc: 0.6395\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7005 - acc: 0.6945 - val_loss: 0.8156 - val_acc: 0.6256\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.6957 - acc: 0.7064 - val_loss: 0.8179 - val_acc: 0.6256\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 724us/step - loss: 0.6952 - acc: 0.6936 - val_loss: 0.8126 - val_acc: 0.6331\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.6893 - acc: 0.7048 - val_loss: 0.9330 - val_acc: 0.5595\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.6937 - acc: 0.6977 - val_loss: 0.8165 - val_acc: 0.6245\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.6902 - acc: 0.7018 - val_loss: 0.8315 - val_acc: 0.6400\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.6829 - acc: 0.7110 - val_loss: 0.8060 - val_acc: 0.6411\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.6780 - acc: 0.7096 - val_loss: 0.8424 - val_acc: 0.6224\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.6765 - acc: 0.7094 - val_loss: 0.8169 - val_acc: 0.6347\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.6756 - acc: 0.7096 - val_loss: 0.8272 - val_acc: 0.6272\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.6713 - acc: 0.7153 - val_loss: 0.8091 - val_acc: 0.6416\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.6677 - acc: 0.7194 - val_loss: 0.8318 - val_acc: 0.6224\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.6679 - acc: 0.7148 - val_loss: 0.9186 - val_acc: 0.5824\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 618us/step - loss: 0.6681 - acc: 0.7075 - val_loss: 0.8329 - val_acc: 0.6165\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.6640 - acc: 0.7148 - val_loss: 0.8217 - val_acc: 0.6368\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.6591 - acc: 0.7185 - val_loss: 0.8397 - val_acc: 0.6267\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.6536 - acc: 0.7219 - val_loss: 0.8095 - val_acc: 0.6437\n",
      "0.632518876033\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 14s 3ms/step - loss: 1.0465 - acc: 0.4987 - val_loss: 1.0380 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 1.0357 - acc: 0.5006 - val_loss: 1.0336 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 1.0317 - acc: 0.5006 - val_loss: 1.0298 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 1.0278 - acc: 0.5006 - val_loss: 1.0257 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 1.0237 - acc: 0.5006 - val_loss: 1.0210 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 1.0194 - acc: 0.5006 - val_loss: 1.0157 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 606us/step - loss: 1.0141 - acc: 0.5006 - val_loss: 1.0105 - val_acc: 0.4997\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 1.0088 - acc: 0.5003 - val_loss: 1.0043 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 630us/step - loss: 1.0028 - acc: 0.5006 - val_loss: 0.9977 - val_acc: 0.5040\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.9963 - acc: 0.5024 - val_loss: 0.9904 - val_acc: 0.5061\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.9893 - acc: 0.5047 - val_loss: 0.9828 - val_acc: 0.5136\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.9814 - acc: 0.5138 - val_loss: 0.9740 - val_acc: 0.5227\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.9728 - acc: 0.5241 - val_loss: 0.9651 - val_acc: 0.5275\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.9636 - acc: 0.5319 - val_loss: 0.9589 - val_acc: 0.5349\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.9525 - acc: 0.5413 - val_loss: 0.9473 - val_acc: 0.5483\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.9446 - acc: 0.5518 - val_loss: 0.9402 - val_acc: 0.5659\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.9318 - acc: 0.5630 - val_loss: 0.9410 - val_acc: 0.5552\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 709us/step - loss: 0.9227 - acc: 0.5692 - val_loss: 0.9155 - val_acc: 0.5611\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.9113 - acc: 0.5749 - val_loss: 0.9064 - val_acc: 0.5819\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.9001 - acc: 0.5850 - val_loss: 0.9002 - val_acc: 0.5803\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.8906 - acc: 0.5907 - val_loss: 0.8922 - val_acc: 0.5936\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.8849 - acc: 0.5932 - val_loss: 0.8776 - val_acc: 0.5925\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.8743 - acc: 0.5955 - val_loss: 0.8717 - val_acc: 0.5915\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.8685 - acc: 0.6016 - val_loss: 0.8702 - val_acc: 0.5941\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.8623 - acc: 0.6055 - val_loss: 0.8762 - val_acc: 0.5797\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.8567 - acc: 0.6067 - val_loss: 0.8555 - val_acc: 0.6032\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.8479 - acc: 0.6085 - val_loss: 0.8825 - val_acc: 0.5835\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.8460 - acc: 0.6231 - val_loss: 0.8658 - val_acc: 0.6027\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.8398 - acc: 0.6181 - val_loss: 0.8560 - val_acc: 0.6048\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8356 - acc: 0.6259 - val_loss: 0.8437 - val_acc: 0.6043\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.8296 - acc: 0.6289 - val_loss: 0.8653 - val_acc: 0.6021\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.8266 - acc: 0.6305 - val_loss: 0.8486 - val_acc: 0.6037\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 0.8246 - acc: 0.6289 - val_loss: 0.8478 - val_acc: 0.6187\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.8178 - acc: 0.6282 - val_loss: 0.8357 - val_acc: 0.6096\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 715us/step - loss: 0.8147 - acc: 0.6371 - val_loss: 0.8331 - val_acc: 0.6192\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.8114 - acc: 0.6440 - val_loss: 0.8396 - val_acc: 0.6107\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.8053 - acc: 0.6412 - val_loss: 0.8332 - val_acc: 0.6171\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8019 - acc: 0.6508 - val_loss: 0.8338 - val_acc: 0.6176\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.8016 - acc: 0.6460 - val_loss: 0.8294 - val_acc: 0.6117\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7979 - acc: 0.6492 - val_loss: 0.8241 - val_acc: 0.6235\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7931 - acc: 0.6542 - val_loss: 0.8312 - val_acc: 0.6149\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 741us/step - loss: 0.7912 - acc: 0.6552 - val_loss: 0.8213 - val_acc: 0.6240\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.7882 - acc: 0.6542 - val_loss: 0.8238 - val_acc: 0.6272\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.7846 - acc: 0.6572 - val_loss: 0.8266 - val_acc: 0.6315\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.7831 - acc: 0.6609 - val_loss: 0.8199 - val_acc: 0.6325\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7774 - acc: 0.6677 - val_loss: 0.8228 - val_acc: 0.6315\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.7760 - acc: 0.6618 - val_loss: 0.8188 - val_acc: 0.6299\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 0.7694 - acc: 0.6645 - val_loss: 0.8222 - val_acc: 0.6288\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7679 - acc: 0.6698 - val_loss: 0.8214 - val_acc: 0.6341\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7670 - acc: 0.6666 - val_loss: 0.8193 - val_acc: 0.6309\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7616 - acc: 0.6691 - val_loss: 0.8229 - val_acc: 0.6208\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.7611 - acc: 0.6741 - val_loss: 0.8178 - val_acc: 0.6277\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7567 - acc: 0.6725 - val_loss: 0.8210 - val_acc: 0.6256\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.7540 - acc: 0.6751 - val_loss: 0.8096 - val_acc: 0.6368\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 630us/step - loss: 0.7527 - acc: 0.6716 - val_loss: 0.8091 - val_acc: 0.6331\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 627us/step - loss: 0.7503 - acc: 0.6739 - val_loss: 0.8184 - val_acc: 0.6352\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.7463 - acc: 0.6787 - val_loss: 0.8463 - val_acc: 0.6096\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.7416 - acc: 0.6817 - val_loss: 0.8086 - val_acc: 0.6304\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7382 - acc: 0.6808 - val_loss: 0.8171 - val_acc: 0.6315\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.7361 - acc: 0.6844 - val_loss: 0.8139 - val_acc: 0.6288\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.7350 - acc: 0.6835 - val_loss: 0.8248 - val_acc: 0.6245\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 700us/step - loss: 0.7328 - acc: 0.6863 - val_loss: 0.8160 - val_acc: 0.6363\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7307 - acc: 0.6897 - val_loss: 0.8071 - val_acc: 0.6357\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7261 - acc: 0.6911 - val_loss: 0.8191 - val_acc: 0.6133\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.7227 - acc: 0.6933 - val_loss: 0.8027 - val_acc: 0.6389\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7213 - acc: 0.6940 - val_loss: 0.8165 - val_acc: 0.6389\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7177 - acc: 0.6917 - val_loss: 0.8611 - val_acc: 0.6032\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7148 - acc: 0.6954 - val_loss: 0.8007 - val_acc: 0.6331\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7146 - acc: 0.6961 - val_loss: 0.8219 - val_acc: 0.6373\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 572us/step - loss: 0.7096 - acc: 0.6979 - val_loss: 0.8005 - val_acc: 0.6416\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.7089 - acc: 0.6949 - val_loss: 0.8070 - val_acc: 0.6464\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7052 - acc: 0.7029 - val_loss: 0.8149 - val_acc: 0.6389\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7006 - acc: 0.6984 - val_loss: 0.8530 - val_acc: 0.6203\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 618us/step - loss: 0.7013 - acc: 0.7064 - val_loss: 0.8066 - val_acc: 0.6379\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.6965 - acc: 0.7029 - val_loss: 0.8224 - val_acc: 0.6331\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.6952 - acc: 0.6995 - val_loss: 0.8063 - val_acc: 0.6357\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.6941 - acc: 0.7043 - val_loss: 0.8129 - val_acc: 0.6389\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.6904 - acc: 0.7107 - val_loss: 0.8401 - val_acc: 0.6299\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.6862 - acc: 0.7087 - val_loss: 0.8018 - val_acc: 0.6427\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 738us/step - loss: 0.6880 - acc: 0.7064 - val_loss: 0.7984 - val_acc: 0.6491\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.6822 - acc: 0.7105 - val_loss: 0.8086 - val_acc: 0.6475\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.6782 - acc: 0.7114 - val_loss: 0.8061 - val_acc: 0.6395\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.6754 - acc: 0.7112 - val_loss: 0.8411 - val_acc: 0.6357\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.6742 - acc: 0.7155 - val_loss: 0.8003 - val_acc: 0.6453\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 604us/step - loss: 0.6704 - acc: 0.7180 - val_loss: 0.8027 - val_acc: 0.6523\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.6674 - acc: 0.7212 - val_loss: 0.8103 - val_acc: 0.6320\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 613us/step - loss: 0.6718 - acc: 0.7171 - val_loss: 0.8021 - val_acc: 0.6464\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.6623 - acc: 0.7194 - val_loss: 0.8256 - val_acc: 0.6379\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.6634 - acc: 0.7247 - val_loss: 0.8008 - val_acc: 0.6448\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.6596 - acc: 0.7194 - val_loss: 0.8228 - val_acc: 0.6368\n",
      "0.624876754635\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 14s 3ms/step - loss: 1.0481 - acc: 0.4985 - val_loss: 1.0386 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 1.0356 - acc: 0.5006 - val_loss: 1.0352 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 736us/step - loss: 1.0323 - acc: 0.5006 - val_loss: 1.0316 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 1.0286 - acc: 0.5006 - val_loss: 1.0279 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 745us/step - loss: 1.0250 - acc: 0.5006 - val_loss: 1.0241 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 701us/step - loss: 1.0211 - acc: 0.5006 - val_loss: 1.0201 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 718us/step - loss: 1.0170 - acc: 0.5010 - val_loss: 1.0158 - val_acc: 0.4997\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 1.0124 - acc: 0.5017 - val_loss: 1.0113 - val_acc: 0.4992\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 1.0077 - acc: 0.5045 - val_loss: 1.0067 - val_acc: 0.5035\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 1.0026 - acc: 0.5086 - val_loss: 1.0025 - val_acc: 0.5125\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.9976 - acc: 0.5125 - val_loss: 0.9961 - val_acc: 0.5147\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.9913 - acc: 0.5147 - val_loss: 0.9909 - val_acc: 0.5275\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.9848 - acc: 0.5193 - val_loss: 0.9841 - val_acc: 0.5243\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.9784 - acc: 0.5230 - val_loss: 0.9770 - val_acc: 0.5269\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.9708 - acc: 0.5282 - val_loss: 0.9696 - val_acc: 0.5317\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.9619 - acc: 0.5305 - val_loss: 0.9628 - val_acc: 0.5467\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.9545 - acc: 0.5417 - val_loss: 0.9518 - val_acc: 0.5483\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 0.9446 - acc: 0.5472 - val_loss: 0.9420 - val_acc: 0.5445\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.9353 - acc: 0.5589 - val_loss: 0.9323 - val_acc: 0.5536\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.9254 - acc: 0.5566 - val_loss: 0.9232 - val_acc: 0.5659\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.9158 - acc: 0.5630 - val_loss: 0.9131 - val_acc: 0.5707\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.9062 - acc: 0.5687 - val_loss: 0.9185 - val_acc: 0.5573\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.8996 - acc: 0.5710 - val_loss: 0.8998 - val_acc: 0.5696\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.8909 - acc: 0.5838 - val_loss: 0.8955 - val_acc: 0.5749\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.8833 - acc: 0.5866 - val_loss: 0.8973 - val_acc: 0.5851\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 787us/step - loss: 0.8763 - acc: 0.5895 - val_loss: 0.8807 - val_acc: 0.5909\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8693 - acc: 0.5975 - val_loss: 0.8772 - val_acc: 0.5931\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 701us/step - loss: 0.8641 - acc: 0.5980 - val_loss: 0.8708 - val_acc: 0.6027\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8578 - acc: 0.5950 - val_loss: 0.8690 - val_acc: 0.5931\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.8554 - acc: 0.6010 - val_loss: 0.8664 - val_acc: 0.6043\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.8449 - acc: 0.6092 - val_loss: 0.8613 - val_acc: 0.6032\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 619us/step - loss: 0.8434 - acc: 0.6099 - val_loss: 0.8599 - val_acc: 0.6011\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.8360 - acc: 0.6197 - val_loss: 0.8589 - val_acc: 0.5952\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.8317 - acc: 0.6158 - val_loss: 0.8745 - val_acc: 0.5952\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.8292 - acc: 0.6163 - val_loss: 0.8469 - val_acc: 0.6096\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.8239 - acc: 0.6238 - val_loss: 0.8463 - val_acc: 0.6053\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.8221 - acc: 0.6236 - val_loss: 0.8683 - val_acc: 0.5915\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.8155 - acc: 0.6284 - val_loss: 0.8383 - val_acc: 0.6160\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.8154 - acc: 0.6275 - val_loss: 0.8386 - val_acc: 0.6107\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.8096 - acc: 0.6330 - val_loss: 0.8396 - val_acc: 0.6069\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 618us/step - loss: 0.8053 - acc: 0.6334 - val_loss: 0.8356 - val_acc: 0.6123\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.8062 - acc: 0.6362 - val_loss: 0.8302 - val_acc: 0.6171\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.7993 - acc: 0.6359 - val_loss: 0.8230 - val_acc: 0.6283\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.7936 - acc: 0.6398 - val_loss: 0.8341 - val_acc: 0.6085\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.7914 - acc: 0.6435 - val_loss: 0.8285 - val_acc: 0.6192\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 0.7924 - acc: 0.6412 - val_loss: 0.8222 - val_acc: 0.6208\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7856 - acc: 0.6462 - val_loss: 0.8218 - val_acc: 0.6272\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.7852 - acc: 0.6488 - val_loss: 0.8183 - val_acc: 0.6267\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.7815 - acc: 0.6481 - val_loss: 0.8467 - val_acc: 0.6021\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 602us/step - loss: 0.7744 - acc: 0.6531 - val_loss: 0.8175 - val_acc: 0.6267\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7747 - acc: 0.6483 - val_loss: 0.8089 - val_acc: 0.6341\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 630us/step - loss: 0.7696 - acc: 0.6556 - val_loss: 0.8581 - val_acc: 0.6085\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7695 - acc: 0.6554 - val_loss: 0.8116 - val_acc: 0.6341\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 615us/step - loss: 0.7635 - acc: 0.6554 - val_loss: 0.8083 - val_acc: 0.6368\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7629 - acc: 0.6648 - val_loss: 0.8161 - val_acc: 0.6245\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 2s 559us/step - loss: 0.7603 - acc: 0.6632 - val_loss: 0.8022 - val_acc: 0.6400\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 606us/step - loss: 0.7548 - acc: 0.6664 - val_loss: 0.8406 - val_acc: 0.6112\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7538 - acc: 0.6691 - val_loss: 0.8034 - val_acc: 0.6293\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7498 - acc: 0.6696 - val_loss: 0.8062 - val_acc: 0.6363\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.7497 - acc: 0.6721 - val_loss: 0.8001 - val_acc: 0.6357\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.7430 - acc: 0.6735 - val_loss: 0.8026 - val_acc: 0.6379\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.7463 - acc: 0.6746 - val_loss: 0.8307 - val_acc: 0.6224\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7405 - acc: 0.6764 - val_loss: 0.7997 - val_acc: 0.6400\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7389 - acc: 0.6718 - val_loss: 0.8135 - val_acc: 0.6336\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7319 - acc: 0.6794 - val_loss: 0.7986 - val_acc: 0.6373\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.7338 - acc: 0.6805 - val_loss: 0.8006 - val_acc: 0.6400\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7293 - acc: 0.6895 - val_loss: 0.7969 - val_acc: 0.6453\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 724us/step - loss: 0.7284 - acc: 0.6833 - val_loss: 0.7940 - val_acc: 0.6427\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.7254 - acc: 0.6945 - val_loss: 0.7926 - val_acc: 0.6421\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.7237 - acc: 0.6931 - val_loss: 0.7862 - val_acc: 0.6475\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7235 - acc: 0.6876 - val_loss: 0.7922 - val_acc: 0.6437\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.7140 - acc: 0.6956 - val_loss: 0.7951 - val_acc: 0.6464\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7149 - acc: 0.6888 - val_loss: 0.7929 - val_acc: 0.6411\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7115 - acc: 0.6954 - val_loss: 0.7887 - val_acc: 0.6485\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 611us/step - loss: 0.7083 - acc: 0.6997 - val_loss: 0.7944 - val_acc: 0.6448\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7083 - acc: 0.6965 - val_loss: 0.7921 - val_acc: 0.6507\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7030 - acc: 0.7027 - val_loss: 0.7804 - val_acc: 0.6592\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.7006 - acc: 0.7041 - val_loss: 0.8004 - val_acc: 0.6453\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.6984 - acc: 0.7020 - val_loss: 0.7919 - val_acc: 0.6528\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.6969 - acc: 0.7029 - val_loss: 0.8032 - val_acc: 0.6411\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.6897 - acc: 0.7103 - val_loss: 0.8249 - val_acc: 0.6341\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.6875 - acc: 0.7039 - val_loss: 0.7983 - val_acc: 0.6341\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.6874 - acc: 0.7048 - val_loss: 0.8012 - val_acc: 0.6464\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.6848 - acc: 0.7091 - val_loss: 0.8084 - val_acc: 0.6501\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.6825 - acc: 0.7128 - val_loss: 0.7982 - val_acc: 0.6533\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.6769 - acc: 0.7142 - val_loss: 0.7997 - val_acc: 0.6539\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 751us/step - loss: 0.6773 - acc: 0.7091 - val_loss: 0.7903 - val_acc: 0.6571\n",
      "0.626065061074\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 14s 3ms/step - loss: 1.0465 - acc: 0.5006 - val_loss: 1.0374 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 1.0335 - acc: 0.5006 - val_loss: 1.0329 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 1.0289 - acc: 0.5006 - val_loss: 1.0285 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 722us/step - loss: 1.0241 - acc: 0.5006 - val_loss: 1.0237 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 1.0187 - acc: 0.5006 - val_loss: 1.0181 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 1.0126 - acc: 0.5006 - val_loss: 1.0120 - val_acc: 0.5013\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 1.0049 - acc: 0.5010 - val_loss: 1.0047 - val_acc: 0.5013\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.9961 - acc: 0.5042 - val_loss: 0.9947 - val_acc: 0.5088\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 0.9861 - acc: 0.5127 - val_loss: 0.9838 - val_acc: 0.5104\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.9760 - acc: 0.5173 - val_loss: 0.9786 - val_acc: 0.5221\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 597us/step - loss: 0.9649 - acc: 0.5248 - val_loss: 0.9650 - val_acc: 0.5317\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.9541 - acc: 0.5310 - val_loss: 0.9505 - val_acc: 0.5264\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.9436 - acc: 0.5369 - val_loss: 0.9601 - val_acc: 0.5435\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 715us/step - loss: 0.9360 - acc: 0.5520 - val_loss: 0.9342 - val_acc: 0.5376\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 753us/step - loss: 0.9238 - acc: 0.5568 - val_loss: 0.9229 - val_acc: 0.5509\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.9123 - acc: 0.5719 - val_loss: 0.9175 - val_acc: 0.5483\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.9062 - acc: 0.5753 - val_loss: 0.9138 - val_acc: 0.5701\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.8978 - acc: 0.5781 - val_loss: 0.8960 - val_acc: 0.5851\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.8889 - acc: 0.5904 - val_loss: 0.8918 - val_acc: 0.5760\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.8811 - acc: 0.5907 - val_loss: 0.8849 - val_acc: 0.5856\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8738 - acc: 0.5994 - val_loss: 0.8780 - val_acc: 0.5947\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8681 - acc: 0.5959 - val_loss: 0.8731 - val_acc: 0.5952\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.8593 - acc: 0.6053 - val_loss: 0.8768 - val_acc: 0.5835\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.8564 - acc: 0.6099 - val_loss: 0.8657 - val_acc: 0.5925\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.8510 - acc: 0.6076 - val_loss: 0.8722 - val_acc: 0.5968\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.8434 - acc: 0.6181 - val_loss: 0.8620 - val_acc: 0.6021\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.8403 - acc: 0.6097 - val_loss: 0.8770 - val_acc: 0.5957\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.8343 - acc: 0.6243 - val_loss: 0.8573 - val_acc: 0.5957\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.8291 - acc: 0.6186 - val_loss: 0.8563 - val_acc: 0.5936\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 631us/step - loss: 0.8258 - acc: 0.6218 - val_loss: 0.8564 - val_acc: 0.6000\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8202 - acc: 0.6302 - val_loss: 0.8614 - val_acc: 0.5931\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.8163 - acc: 0.6254 - val_loss: 0.8632 - val_acc: 0.5872\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.8136 - acc: 0.6311 - val_loss: 0.8477 - val_acc: 0.6053\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.8103 - acc: 0.6330 - val_loss: 0.8511 - val_acc: 0.5984\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 720us/step - loss: 0.8062 - acc: 0.6314 - val_loss: 0.8360 - val_acc: 0.6133\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.8005 - acc: 0.6375 - val_loss: 0.8417 - val_acc: 0.6043\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.7989 - acc: 0.6375 - val_loss: 0.8405 - val_acc: 0.6000\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7969 - acc: 0.6375 - val_loss: 0.8326 - val_acc: 0.6144\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7918 - acc: 0.6391 - val_loss: 0.8327 - val_acc: 0.6219\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 0.7905 - acc: 0.6460 - val_loss: 0.8299 - val_acc: 0.6224\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7852 - acc: 0.6490 - val_loss: 0.8345 - val_acc: 0.6235\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7809 - acc: 0.6476 - val_loss: 0.8267 - val_acc: 0.6229\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.7770 - acc: 0.6412 - val_loss: 0.8259 - val_acc: 0.6197\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 619us/step - loss: 0.7777 - acc: 0.6558 - val_loss: 0.8402 - val_acc: 0.6064\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.7714 - acc: 0.6506 - val_loss: 0.8353 - val_acc: 0.6080\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.7687 - acc: 0.6542 - val_loss: 0.8322 - val_acc: 0.6096\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.7660 - acc: 0.6586 - val_loss: 0.8308 - val_acc: 0.6251\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 597us/step - loss: 0.7618 - acc: 0.6590 - val_loss: 0.8289 - val_acc: 0.6171\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7600 - acc: 0.6661 - val_loss: 0.8318 - val_acc: 0.6165\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7598 - acc: 0.6609 - val_loss: 0.8287 - val_acc: 0.6149\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 637us/step - loss: 0.7554 - acc: 0.6675 - val_loss: 0.8402 - val_acc: 0.6160\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7563 - acc: 0.6666 - val_loss: 0.8389 - val_acc: 0.6224\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7490 - acc: 0.6712 - val_loss: 0.8229 - val_acc: 0.6224\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 718us/step - loss: 0.7468 - acc: 0.6696 - val_loss: 0.8218 - val_acc: 0.6171\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 726us/step - loss: 0.7433 - acc: 0.6702 - val_loss: 0.8229 - val_acc: 0.6240\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.7436 - acc: 0.6748 - val_loss: 0.8189 - val_acc: 0.6352\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.7405 - acc: 0.6728 - val_loss: 0.8254 - val_acc: 0.6235\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7389 - acc: 0.6751 - val_loss: 0.8551 - val_acc: 0.6101\n",
      "Epoch 59/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7363 - acc: 0.6783 - val_loss: 0.8208 - val_acc: 0.6336\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.7322 - acc: 0.6780 - val_loss: 0.8235 - val_acc: 0.6293\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7293 - acc: 0.6821 - val_loss: 0.8233 - val_acc: 0.6219\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.7285 - acc: 0.6874 - val_loss: 0.8129 - val_acc: 0.6373\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7214 - acc: 0.6835 - val_loss: 0.8214 - val_acc: 0.6235\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7221 - acc: 0.6819 - val_loss: 0.8278 - val_acc: 0.6405\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.7193 - acc: 0.6888 - val_loss: 0.8158 - val_acc: 0.6405\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.7178 - acc: 0.6911 - val_loss: 0.8156 - val_acc: 0.6235\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.7157 - acc: 0.6899 - val_loss: 0.8152 - val_acc: 0.6288\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7118 - acc: 0.6865 - val_loss: 0.8229 - val_acc: 0.6208\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.7118 - acc: 0.6913 - val_loss: 0.8219 - val_acc: 0.6251\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.7091 - acc: 0.6929 - val_loss: 0.8214 - val_acc: 0.6379\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7040 - acc: 0.6979 - val_loss: 0.8403 - val_acc: 0.6229\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.7041 - acc: 0.6956 - val_loss: 0.8111 - val_acc: 0.6336\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 637us/step - loss: 0.7003 - acc: 0.6968 - val_loss: 0.8196 - val_acc: 0.6363\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.6976 - acc: 0.6959 - val_loss: 0.8325 - val_acc: 0.6405\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 720us/step - loss: 0.6968 - acc: 0.6959 - val_loss: 0.8257 - val_acc: 0.6277\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 726us/step - loss: 0.6991 - acc: 0.7052 - val_loss: 0.8265 - val_acc: 0.6395\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.7003 - acc: 0.6981 - val_loss: 0.8362 - val_acc: 0.6112\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 740us/step - loss: 0.6938 - acc: 0.7052 - val_loss: 0.8225 - val_acc: 0.6288\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.6927 - acc: 0.7004 - val_loss: 0.8157 - val_acc: 0.6235\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.6913 - acc: 0.7064 - val_loss: 0.8344 - val_acc: 0.6245\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.6843 - acc: 0.7080 - val_loss: 0.8136 - val_acc: 0.6384\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.6812 - acc: 0.7071 - val_loss: 0.8092 - val_acc: 0.6448\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.6762 - acc: 0.7123 - val_loss: 0.8099 - val_acc: 0.6400\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.6790 - acc: 0.7103 - val_loss: 0.8344 - val_acc: 0.6021\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.6772 - acc: 0.7055 - val_loss: 0.8190 - val_acc: 0.6501\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.6708 - acc: 0.7110 - val_loss: 0.8458 - val_acc: 0.6203\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 740us/step - loss: 0.6657 - acc: 0.7167 - val_loss: 0.8096 - val_acc: 0.6357\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.6616 - acc: 0.7174 - val_loss: 0.8507 - val_acc: 0.6229\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.6664 - acc: 0.7171 - val_loss: 0.8498 - val_acc: 0.6187\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.6642 - acc: 0.7171 - val_loss: 0.8120 - val_acc: 0.6459\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.6560 - acc: 0.7174 - val_loss: 0.8613 - val_acc: 0.6101\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.6532 - acc: 0.7238 - val_loss: 0.8755 - val_acc: 0.5840\n",
      "0.617056923205\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 14s 3ms/step - loss: 1.0480 - acc: 0.4981 - val_loss: 1.0384 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 1.0365 - acc: 0.5006 - val_loss: 1.0348 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 727us/step - loss: 1.0327 - acc: 0.5006 - val_loss: 1.0313 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 1.0289 - acc: 0.5006 - val_loss: 1.0278 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 1.0247 - acc: 0.5006 - val_loss: 1.0245 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 1.0204 - acc: 0.5006 - val_loss: 1.0198 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 729us/step - loss: 1.0153 - acc: 0.5006 - val_loss: 1.0150 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 720us/step - loss: 1.0098 - acc: 0.5008 - val_loss: 1.0093 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 1.0028 - acc: 0.5010 - val_loss: 1.0021 - val_acc: 0.5024\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.9942 - acc: 0.5040 - val_loss: 0.9936 - val_acc: 0.5056\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 0.9844 - acc: 0.5090 - val_loss: 0.9852 - val_acc: 0.5088\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.9742 - acc: 0.5141 - val_loss: 0.9771 - val_acc: 0.5205\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.9631 - acc: 0.5186 - val_loss: 0.9656 - val_acc: 0.5221\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.9525 - acc: 0.5296 - val_loss: 0.9550 - val_acc: 0.5259\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 0.9423 - acc: 0.5429 - val_loss: 0.9481 - val_acc: 0.5456\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.9331 - acc: 0.5497 - val_loss: 0.9372 - val_acc: 0.5472\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 731us/step - loss: 0.9218 - acc: 0.5653 - val_loss: 0.9354 - val_acc: 0.5488\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.9133 - acc: 0.5648 - val_loss: 0.9367 - val_acc: 0.5552\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.9025 - acc: 0.5797 - val_loss: 0.9173 - val_acc: 0.5696\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.8976 - acc: 0.5808 - val_loss: 0.9069 - val_acc: 0.5616\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.8873 - acc: 0.5840 - val_loss: 0.8996 - val_acc: 0.5803\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.8864 - acc: 0.5840 - val_loss: 0.8990 - val_acc: 0.5845\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.8814 - acc: 0.5863 - val_loss: 0.9104 - val_acc: 0.5664\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8669 - acc: 0.5968 - val_loss: 0.8804 - val_acc: 0.5963\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.8605 - acc: 0.6069 - val_loss: 0.8790 - val_acc: 0.5776\n",
      "Epoch 26/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 715us/step - loss: 0.8544 - acc: 0.6078 - val_loss: 0.8754 - val_acc: 0.5893\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.8473 - acc: 0.6126 - val_loss: 0.8750 - val_acc: 0.6112\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 701us/step - loss: 0.8459 - acc: 0.6154 - val_loss: 0.8691 - val_acc: 0.5872\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.8389 - acc: 0.6094 - val_loss: 0.8637 - val_acc: 0.5941\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.8345 - acc: 0.6209 - val_loss: 0.8750 - val_acc: 0.5995\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.8287 - acc: 0.6154 - val_loss: 0.8517 - val_acc: 0.6187\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.8256 - acc: 0.6270 - val_loss: 0.8778 - val_acc: 0.5941\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 0.8233 - acc: 0.6206 - val_loss: 0.8517 - val_acc: 0.6251\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8175 - acc: 0.6323 - val_loss: 0.8411 - val_acc: 0.6235\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 732us/step - loss: 0.8114 - acc: 0.6334 - val_loss: 0.8442 - val_acc: 0.6203\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.8074 - acc: 0.6314 - val_loss: 0.8518 - val_acc: 0.6128\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 726us/step - loss: 0.8052 - acc: 0.6305 - val_loss: 0.8354 - val_acc: 0.6229\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 758us/step - loss: 0.7998 - acc: 0.6401 - val_loss: 0.8325 - val_acc: 0.6315\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.7981 - acc: 0.6378 - val_loss: 0.8351 - val_acc: 0.6288\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 701us/step - loss: 0.7924 - acc: 0.6430 - val_loss: 0.8619 - val_acc: 0.6123\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.7898 - acc: 0.6401 - val_loss: 0.8321 - val_acc: 0.6267\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.7850 - acc: 0.6529 - val_loss: 0.8267 - val_acc: 0.6288\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7890 - acc: 0.6410 - val_loss: 0.8352 - val_acc: 0.6245\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7798 - acc: 0.6501 - val_loss: 0.8368 - val_acc: 0.6192\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7763 - acc: 0.6522 - val_loss: 0.8324 - val_acc: 0.6208\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7762 - acc: 0.6522 - val_loss: 0.8153 - val_acc: 0.6411\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7689 - acc: 0.6602 - val_loss: 0.8118 - val_acc: 0.6416\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 637us/step - loss: 0.7707 - acc: 0.6545 - val_loss: 0.8121 - val_acc: 0.6389\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7640 - acc: 0.6563 - val_loss: 0.8305 - val_acc: 0.6240\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.7632 - acc: 0.6620 - val_loss: 0.8116 - val_acc: 0.6357\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.7597 - acc: 0.6643 - val_loss: 0.8125 - val_acc: 0.6416\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7548 - acc: 0.6636 - val_loss: 0.8115 - val_acc: 0.6416\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.7548 - acc: 0.6645 - val_loss: 0.8235 - val_acc: 0.6320\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.7510 - acc: 0.6670 - val_loss: 0.8012 - val_acc: 0.6437\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 0.7479 - acc: 0.6652 - val_loss: 0.8044 - val_acc: 0.6411\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.7451 - acc: 0.6709 - val_loss: 0.8043 - val_acc: 0.6432\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 701us/step - loss: 0.7410 - acc: 0.6769 - val_loss: 0.8054 - val_acc: 0.6501\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.7374 - acc: 0.6730 - val_loss: 0.8032 - val_acc: 0.6485\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7361 - acc: 0.6789 - val_loss: 0.7983 - val_acc: 0.6448\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.7340 - acc: 0.6787 - val_loss: 0.8395 - val_acc: 0.6240\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.7337 - acc: 0.6789 - val_loss: 0.7964 - val_acc: 0.6512\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7298 - acc: 0.6728 - val_loss: 0.8011 - val_acc: 0.6427\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7224 - acc: 0.6819 - val_loss: 0.8185 - val_acc: 0.6389\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.7225 - acc: 0.6874 - val_loss: 0.8039 - val_acc: 0.6368\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7225 - acc: 0.6851 - val_loss: 0.7956 - val_acc: 0.6443\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.7172 - acc: 0.6856 - val_loss: 0.8448 - val_acc: 0.6085\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.7168 - acc: 0.6885 - val_loss: 0.7885 - val_acc: 0.6592\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7093 - acc: 0.6876 - val_loss: 0.8029 - val_acc: 0.6549\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.7115 - acc: 0.6883 - val_loss: 0.7906 - val_acc: 0.6571\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7089 - acc: 0.6954 - val_loss: 0.7993 - val_acc: 0.6416\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7050 - acc: 0.6972 - val_loss: 0.7920 - val_acc: 0.6523\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 627us/step - loss: 0.7038 - acc: 0.6911 - val_loss: 0.7977 - val_acc: 0.6475\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.6973 - acc: 0.6995 - val_loss: 0.7841 - val_acc: 0.6560\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 0.6931 - acc: 0.6984 - val_loss: 0.8515 - val_acc: 0.6336\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 736us/step - loss: 0.6952 - acc: 0.7000 - val_loss: 0.7890 - val_acc: 0.6501\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.6939 - acc: 0.6988 - val_loss: 0.7963 - val_acc: 0.6571\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.6876 - acc: 0.7029 - val_loss: 0.7924 - val_acc: 0.6427\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.6838 - acc: 0.7087 - val_loss: 0.7911 - val_acc: 0.6592\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.6829 - acc: 0.7013 - val_loss: 0.8184 - val_acc: 0.6539\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.6841 - acc: 0.7027 - val_loss: 0.7887 - val_acc: 0.6555\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.6794 - acc: 0.7052 - val_loss: 0.7943 - val_acc: 0.6576\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.6774 - acc: 0.7039 - val_loss: 0.7915 - val_acc: 0.6576\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.6713 - acc: 0.7100 - val_loss: 0.7825 - val_acc: 0.6645\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.6704 - acc: 0.7114 - val_loss: 0.7877 - val_acc: 0.6560\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 631us/step - loss: 0.6667 - acc: 0.7151 - val_loss: 0.7890 - val_acc: 0.6549\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.6659 - acc: 0.7103 - val_loss: 0.7974 - val_acc: 0.6469\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.6581 - acc: 0.7164 - val_loss: 0.8044 - val_acc: 0.6379\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.6621 - acc: 0.7130 - val_loss: 0.8324 - val_acc: 0.6219\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.6561 - acc: 0.7137 - val_loss: 0.7951 - val_acc: 0.6507\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.6570 - acc: 0.7187 - val_loss: 0.7916 - val_acc: 0.6555\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.6517 - acc: 0.7210 - val_loss: 0.8165 - val_acc: 0.6496\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.6482 - acc: 0.7233 - val_loss: 0.8041 - val_acc: 0.6603\n",
      "Epoch 93/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 0.6449 - acc: 0.7160 - val_loss: 0.7843 - val_acc: 0.6629\n",
      "0.603870631603\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 15s 3ms/step - loss: 1.0474 - acc: 0.4997 - val_loss: 1.0363 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 617us/step - loss: 1.0344 - acc: 0.5006 - val_loss: 1.0305 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 1.0281 - acc: 0.5006 - val_loss: 1.0244 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 1.0219 - acc: 0.5006 - val_loss: 1.0177 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 1.0154 - acc: 0.5006 - val_loss: 1.0128 - val_acc: 0.4997\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 1.0081 - acc: 0.5013 - val_loss: 1.0045 - val_acc: 0.5008\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 1.0004 - acc: 0.5031 - val_loss: 0.9949 - val_acc: 0.5024\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.9915 - acc: 0.5051 - val_loss: 0.9895 - val_acc: 0.5035\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.9820 - acc: 0.5095 - val_loss: 0.9801 - val_acc: 0.5184\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.9729 - acc: 0.5168 - val_loss: 0.9643 - val_acc: 0.5179\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.9639 - acc: 0.5234 - val_loss: 0.9573 - val_acc: 0.5280\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.9562 - acc: 0.5383 - val_loss: 0.9449 - val_acc: 0.5301\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.9457 - acc: 0.5385 - val_loss: 0.9429 - val_acc: 0.5376\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.9379 - acc: 0.5481 - val_loss: 0.9407 - val_acc: 0.5525\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.9323 - acc: 0.5573 - val_loss: 0.9197 - val_acc: 0.5589\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 734us/step - loss: 0.9224 - acc: 0.5655 - val_loss: 0.9193 - val_acc: 0.5664\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.9187 - acc: 0.5669 - val_loss: 0.9223 - val_acc: 0.5563\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 727us/step - loss: 0.9078 - acc: 0.5726 - val_loss: 0.9052 - val_acc: 0.5744\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 711us/step - loss: 0.8988 - acc: 0.5820 - val_loss: 0.9046 - val_acc: 0.5771\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 752us/step - loss: 0.8912 - acc: 0.5795 - val_loss: 0.8892 - val_acc: 0.5840\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.8853 - acc: 0.5868 - val_loss: 0.8969 - val_acc: 0.5792\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 706us/step - loss: 0.8744 - acc: 0.5932 - val_loss: 0.8791 - val_acc: 0.5877\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.8700 - acc: 0.5946 - val_loss: 0.8748 - val_acc: 0.5888\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.8657 - acc: 0.5998 - val_loss: 0.8769 - val_acc: 0.5888\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.8572 - acc: 0.6021 - val_loss: 0.8651 - val_acc: 0.5941\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.8518 - acc: 0.6046 - val_loss: 0.8676 - val_acc: 0.5824\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.8486 - acc: 0.6099 - val_loss: 0.8568 - val_acc: 0.6016\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 635us/step - loss: 0.8426 - acc: 0.6126 - val_loss: 0.8549 - val_acc: 0.5957\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.8374 - acc: 0.6213 - val_loss: 0.8495 - val_acc: 0.6069\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 630us/step - loss: 0.8325 - acc: 0.6227 - val_loss: 0.8619 - val_acc: 0.5867\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.8301 - acc: 0.6145 - val_loss: 0.8594 - val_acc: 0.5931\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.8245 - acc: 0.6279 - val_loss: 0.8515 - val_acc: 0.6112\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.8194 - acc: 0.6325 - val_loss: 0.8831 - val_acc: 0.5920\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.8172 - acc: 0.6314 - val_loss: 0.8454 - val_acc: 0.5957\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.8161 - acc: 0.6277 - val_loss: 0.8352 - val_acc: 0.6112\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8095 - acc: 0.6321 - val_loss: 0.8388 - val_acc: 0.6053\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.8063 - acc: 0.6369 - val_loss: 0.8567 - val_acc: 0.5936\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.8057 - acc: 0.6350 - val_loss: 0.8276 - val_acc: 0.6208\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.8004 - acc: 0.6348 - val_loss: 0.8321 - val_acc: 0.6107\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 704us/step - loss: 0.7943 - acc: 0.6442 - val_loss: 0.8471 - val_acc: 0.6016\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.7910 - acc: 0.6504 - val_loss: 0.8390 - val_acc: 0.6069\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.7896 - acc: 0.6522 - val_loss: 0.8362 - val_acc: 0.6085\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 699us/step - loss: 0.7857 - acc: 0.6517 - val_loss: 0.8719 - val_acc: 0.5973\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.7841 - acc: 0.6494 - val_loss: 0.8559 - val_acc: 0.5968\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.7820 - acc: 0.6540 - val_loss: 0.8308 - val_acc: 0.6155\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.7797 - acc: 0.6524 - val_loss: 0.8318 - val_acc: 0.6021\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 784us/step - loss: 0.7751 - acc: 0.6561 - val_loss: 0.8263 - val_acc: 0.6203\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.7724 - acc: 0.6581 - val_loss: 0.8220 - val_acc: 0.6224\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.7715 - acc: 0.6547 - val_loss: 0.8113 - val_acc: 0.6272\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 730us/step - loss: 0.7675 - acc: 0.6613 - val_loss: 0.8083 - val_acc: 0.6277\n",
      "Epoch 51/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 721us/step - loss: 0.7624 - acc: 0.6625 - val_loss: 0.8099 - val_acc: 0.6272\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 725us/step - loss: 0.7605 - acc: 0.6629 - val_loss: 0.8318 - val_acc: 0.6272\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 730us/step - loss: 0.7596 - acc: 0.6625 - val_loss: 0.8069 - val_acc: 0.6379\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 741us/step - loss: 0.7555 - acc: 0.6684 - val_loss: 0.8073 - val_acc: 0.6293\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.7526 - acc: 0.6757 - val_loss: 0.8307 - val_acc: 0.6288\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.7542 - acc: 0.6689 - val_loss: 0.8265 - val_acc: 0.6277\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.7509 - acc: 0.6677 - val_loss: 0.8088 - val_acc: 0.6379\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 758us/step - loss: 0.7483 - acc: 0.6753 - val_loss: 0.8005 - val_acc: 0.6453\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.7426 - acc: 0.6732 - val_loss: 0.8032 - val_acc: 0.6299\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 725us/step - loss: 0.7444 - acc: 0.6771 - val_loss: 0.8120 - val_acc: 0.6288\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.7408 - acc: 0.6728 - val_loss: 0.8120 - val_acc: 0.6421\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 700us/step - loss: 0.7364 - acc: 0.6778 - val_loss: 0.8060 - val_acc: 0.6389\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.7359 - acc: 0.6778 - val_loss: 0.8049 - val_acc: 0.6368\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 711us/step - loss: 0.7347 - acc: 0.6776 - val_loss: 0.8105 - val_acc: 0.6219\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7315 - acc: 0.6780 - val_loss: 0.8021 - val_acc: 0.6400\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.7273 - acc: 0.6831 - val_loss: 0.7975 - val_acc: 0.6309\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7250 - acc: 0.6853 - val_loss: 0.8004 - val_acc: 0.6368\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7230 - acc: 0.6860 - val_loss: 0.8074 - val_acc: 0.6427\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 602us/step - loss: 0.7200 - acc: 0.6840 - val_loss: 0.8981 - val_acc: 0.5861\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 617us/step - loss: 0.7188 - acc: 0.6901 - val_loss: 0.7999 - val_acc: 0.6432\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7167 - acc: 0.6915 - val_loss: 0.8003 - val_acc: 0.6395\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 0.7149 - acc: 0.6933 - val_loss: 0.7978 - val_acc: 0.6411\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.7143 - acc: 0.6917 - val_loss: 0.8278 - val_acc: 0.6235\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7065 - acc: 0.6977 - val_loss: 0.8066 - val_acc: 0.6352\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 609us/step - loss: 0.7061 - acc: 0.6876 - val_loss: 0.7946 - val_acc: 0.6459\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.7034 - acc: 0.6949 - val_loss: 0.8107 - val_acc: 0.6427\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.6986 - acc: 0.7046 - val_loss: 0.8221 - val_acc: 0.6299\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.6993 - acc: 0.6988 - val_loss: 0.8123 - val_acc: 0.6309\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.6981 - acc: 0.6981 - val_loss: 0.9049 - val_acc: 0.6016\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.6941 - acc: 0.7013 - val_loss: 0.8371 - val_acc: 0.6331\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.6927 - acc: 0.7002 - val_loss: 0.8061 - val_acc: 0.6389\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.6898 - acc: 0.7075 - val_loss: 0.8036 - val_acc: 0.6432\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.6846 - acc: 0.7050 - val_loss: 0.8573 - val_acc: 0.6139\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.6874 - acc: 0.7007 - val_loss: 0.8042 - val_acc: 0.6443\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.6832 - acc: 0.7039 - val_loss: 0.8046 - val_acc: 0.6475\n",
      "0.623026915949\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 15s 3ms/step - loss: 1.0494 - acc: 0.4999 - val_loss: 1.0370 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 1.0349 - acc: 0.5006 - val_loss: 1.0326 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 1.0307 - acc: 0.5006 - val_loss: 1.0281 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 709us/step - loss: 1.0263 - acc: 0.5006 - val_loss: 1.0236 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 733us/step - loss: 1.0212 - acc: 0.5006 - val_loss: 1.0186 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 1.0158 - acc: 0.5006 - val_loss: 1.0126 - val_acc: 0.4997\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 1.0092 - acc: 0.5008 - val_loss: 1.0069 - val_acc: 0.4997\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 709us/step - loss: 1.0021 - acc: 0.5010 - val_loss: 0.9989 - val_acc: 0.4997\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.9942 - acc: 0.5024 - val_loss: 0.9929 - val_acc: 0.5003\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.9856 - acc: 0.5063 - val_loss: 0.9815 - val_acc: 0.5099\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.9756 - acc: 0.5166 - val_loss: 0.9716 - val_acc: 0.5141\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.9651 - acc: 0.5266 - val_loss: 0.9633 - val_acc: 0.5211\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.9541 - acc: 0.5362 - val_loss: 0.9558 - val_acc: 0.5291\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.9441 - acc: 0.5461 - val_loss: 0.9430 - val_acc: 0.5317\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.9324 - acc: 0.5571 - val_loss: 0.9397 - val_acc: 0.5429\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 614us/step - loss: 0.9215 - acc: 0.5648 - val_loss: 0.9292 - val_acc: 0.5440\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.9100 - acc: 0.5747 - val_loss: 0.9248 - val_acc: 0.5765\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.9009 - acc: 0.5820 - val_loss: 0.9069 - val_acc: 0.5749\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 740us/step - loss: 0.8959 - acc: 0.5824 - val_loss: 0.8998 - val_acc: 0.5792\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.8865 - acc: 0.5886 - val_loss: 0.8965 - val_acc: 0.5835\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.8752 - acc: 0.5902 - val_loss: 0.9297 - val_acc: 0.5557\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.8668 - acc: 0.5982 - val_loss: 0.8766 - val_acc: 0.5920\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 734us/step - loss: 0.8625 - acc: 0.5989 - val_loss: 0.8720 - val_acc: 0.5920\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.8559 - acc: 0.6106 - val_loss: 0.8705 - val_acc: 0.5957\n",
      "Epoch 25/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8480 - acc: 0.6074 - val_loss: 0.8680 - val_acc: 0.5877\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 704us/step - loss: 0.8430 - acc: 0.6129 - val_loss: 0.8852 - val_acc: 0.5765\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.8377 - acc: 0.6142 - val_loss: 0.8616 - val_acc: 0.6064\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.8334 - acc: 0.6167 - val_loss: 0.8600 - val_acc: 0.5899\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.8287 - acc: 0.6199 - val_loss: 0.8563 - val_acc: 0.5909\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.8244 - acc: 0.6220 - val_loss: 0.8469 - val_acc: 0.6091\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.8204 - acc: 0.6183 - val_loss: 0.8564 - val_acc: 0.5856\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8158 - acc: 0.6270 - val_loss: 0.8413 - val_acc: 0.6107\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.8132 - acc: 0.6286 - val_loss: 0.8520 - val_acc: 0.6101\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.8099 - acc: 0.6305 - val_loss: 0.8374 - val_acc: 0.6091\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8044 - acc: 0.6371 - val_loss: 0.8468 - val_acc: 0.6000\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.8044 - acc: 0.6401 - val_loss: 0.8395 - val_acc: 0.6000\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.8005 - acc: 0.6403 - val_loss: 0.8293 - val_acc: 0.6187\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7941 - acc: 0.6426 - val_loss: 0.8375 - val_acc: 0.6064\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.7962 - acc: 0.6380 - val_loss: 0.8467 - val_acc: 0.6213\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 635us/step - loss: 0.7899 - acc: 0.6499 - val_loss: 0.8272 - val_acc: 0.6107\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7863 - acc: 0.6538 - val_loss: 0.8470 - val_acc: 0.5915\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.7863 - acc: 0.6501 - val_loss: 0.8498 - val_acc: 0.6011\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.7825 - acc: 0.6526 - val_loss: 0.8273 - val_acc: 0.6128\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 743us/step - loss: 0.7803 - acc: 0.6508 - val_loss: 0.8203 - val_acc: 0.6240\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.7771 - acc: 0.6554 - val_loss: 0.8409 - val_acc: 0.6053\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.7732 - acc: 0.6570 - val_loss: 0.8178 - val_acc: 0.6213\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7704 - acc: 0.6590 - val_loss: 0.8232 - val_acc: 0.6192\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7690 - acc: 0.6606 - val_loss: 0.8254 - val_acc: 0.6112\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7647 - acc: 0.6588 - val_loss: 0.8193 - val_acc: 0.6283\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7639 - acc: 0.6613 - val_loss: 0.8160 - val_acc: 0.6176\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 604us/step - loss: 0.7603 - acc: 0.6650 - val_loss: 0.8115 - val_acc: 0.6283\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.7559 - acc: 0.6680 - val_loss: 0.8204 - val_acc: 0.6197\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.7566 - acc: 0.6691 - val_loss: 0.8286 - val_acc: 0.6219\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7516 - acc: 0.6650 - val_loss: 0.8079 - val_acc: 0.6373\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.7526 - acc: 0.6737 - val_loss: 0.8268 - val_acc: 0.6219\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7481 - acc: 0.6751 - val_loss: 0.8274 - val_acc: 0.6181\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.7457 - acc: 0.6723 - val_loss: 0.8241 - val_acc: 0.6165\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.7425 - acc: 0.6732 - val_loss: 0.8047 - val_acc: 0.6389\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.7374 - acc: 0.6776 - val_loss: 0.8317 - val_acc: 0.6123\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7368 - acc: 0.6698 - val_loss: 0.8105 - val_acc: 0.6309\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7336 - acc: 0.6863 - val_loss: 0.8097 - val_acc: 0.6320\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.7315 - acc: 0.6851 - val_loss: 0.7998 - val_acc: 0.6299\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7303 - acc: 0.6895 - val_loss: 0.8100 - val_acc: 0.6309\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.7271 - acc: 0.6831 - val_loss: 0.7953 - val_acc: 0.6395\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.7240 - acc: 0.6863 - val_loss: 0.8593 - val_acc: 0.6053\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.7198 - acc: 0.6943 - val_loss: 0.8254 - val_acc: 0.6272\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7198 - acc: 0.6885 - val_loss: 0.8056 - val_acc: 0.6315\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.7166 - acc: 0.6915 - val_loss: 0.8049 - val_acc: 0.6304\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.7167 - acc: 0.6915 - val_loss: 0.8116 - val_acc: 0.6352\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7110 - acc: 0.6956 - val_loss: 0.8212 - val_acc: 0.6229\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 627us/step - loss: 0.7080 - acc: 0.7000 - val_loss: 0.8311 - val_acc: 0.6096\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.7095 - acc: 0.7016 - val_loss: 0.8035 - val_acc: 0.6315\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7036 - acc: 0.6984 - val_loss: 0.7966 - val_acc: 0.6395\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.7025 - acc: 0.7041 - val_loss: 0.7983 - val_acc: 0.6325\n",
      "0.611297043286\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 14s 3ms/step - loss: 1.0494 - acc: 0.4994 - val_loss: 1.0362 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 748us/step - loss: 1.0346 - acc: 0.5006 - val_loss: 1.0308 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 729us/step - loss: 1.0290 - acc: 0.5006 - val_loss: 1.0252 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 1.0229 - acc: 0.5006 - val_loss: 1.0188 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 718us/step - loss: 1.0163 - acc: 0.5006 - val_loss: 1.0127 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 1.0091 - acc: 0.5006 - val_loss: 1.0040 - val_acc: 0.5013\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 1.0009 - acc: 0.5015 - val_loss: 0.9959 - val_acc: 0.5056\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.9922 - acc: 0.5063 - val_loss: 0.9906 - val_acc: 0.5104\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.9830 - acc: 0.5150 - val_loss: 0.9850 - val_acc: 0.5211\n",
      "Epoch 10/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.9756 - acc: 0.5228 - val_loss: 0.9828 - val_acc: 0.5253\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.9698 - acc: 0.5292 - val_loss: 0.9660 - val_acc: 0.5419\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 721us/step - loss: 0.9592 - acc: 0.5349 - val_loss: 0.9559 - val_acc: 0.5483\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.9523 - acc: 0.5454 - val_loss: 0.9498 - val_acc: 0.5563\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.9446 - acc: 0.5509 - val_loss: 0.9699 - val_acc: 0.5493\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.9393 - acc: 0.5561 - val_loss: 0.9357 - val_acc: 0.5621\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.9288 - acc: 0.5630 - val_loss: 0.9312 - val_acc: 0.5701\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 631us/step - loss: 0.9224 - acc: 0.5589 - val_loss: 0.9229 - val_acc: 0.5733\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.9123 - acc: 0.5680 - val_loss: 0.9389 - val_acc: 0.5515\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 611us/step - loss: 0.9098 - acc: 0.5728 - val_loss: 0.9363 - val_acc: 0.5664\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 655us/step - loss: 0.8995 - acc: 0.5813 - val_loss: 0.9059 - val_acc: 0.5744\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 606us/step - loss: 0.8894 - acc: 0.5856 - val_loss: 0.9121 - val_acc: 0.5680\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.8836 - acc: 0.5934 - val_loss: 0.9185 - val_acc: 0.5648\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.8752 - acc: 0.5996 - val_loss: 0.8851 - val_acc: 0.5840\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.8673 - acc: 0.6005 - val_loss: 0.8833 - val_acc: 0.5829\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.8617 - acc: 0.5991 - val_loss: 0.8770 - val_acc: 0.5904\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 747us/step - loss: 0.8541 - acc: 0.6071 - val_loss: 0.8738 - val_acc: 0.5920\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 742us/step - loss: 0.8474 - acc: 0.6167 - val_loss: 0.8591 - val_acc: 0.6069\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 775us/step - loss: 0.8455 - acc: 0.6174 - val_loss: 0.8548 - val_acc: 0.6059\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.8370 - acc: 0.6197 - val_loss: 0.8595 - val_acc: 0.6016\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 728us/step - loss: 0.8309 - acc: 0.6250 - val_loss: 0.8632 - val_acc: 0.5957\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 713us/step - loss: 0.8258 - acc: 0.6339 - val_loss: 0.8496 - val_acc: 0.6043\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8225 - acc: 0.6325 - val_loss: 0.8565 - val_acc: 0.5957\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 701us/step - loss: 0.8163 - acc: 0.6318 - val_loss: 0.8443 - val_acc: 0.6075\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 725us/step - loss: 0.8125 - acc: 0.6371 - val_loss: 0.8371 - val_acc: 0.6219\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 719us/step - loss: 0.8132 - acc: 0.6369 - val_loss: 0.8389 - val_acc: 0.6192\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 715us/step - loss: 0.8043 - acc: 0.6490 - val_loss: 0.8542 - val_acc: 0.6037\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.7997 - acc: 0.6526 - val_loss: 0.8339 - val_acc: 0.6171\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.7947 - acc: 0.6538 - val_loss: 0.8365 - val_acc: 0.6123\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 627us/step - loss: 0.7943 - acc: 0.6492 - val_loss: 0.8676 - val_acc: 0.5883\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7906 - acc: 0.6554 - val_loss: 0.8477 - val_acc: 0.6059\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.7876 - acc: 0.6517 - val_loss: 0.8334 - val_acc: 0.6155\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.7808 - acc: 0.6636 - val_loss: 0.8274 - val_acc: 0.6224\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.7797 - acc: 0.6629 - val_loss: 0.8306 - val_acc: 0.6240\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7754 - acc: 0.6650 - val_loss: 0.8257 - val_acc: 0.6192\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.7712 - acc: 0.6634 - val_loss: 0.8228 - val_acc: 0.6208\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 740us/step - loss: 0.7694 - acc: 0.6680 - val_loss: 0.8222 - val_acc: 0.6277\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7636 - acc: 0.6696 - val_loss: 0.8810 - val_acc: 0.5829\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.7658 - acc: 0.6645 - val_loss: 0.8311 - val_acc: 0.6235\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.7611 - acc: 0.6718 - val_loss: 0.8281 - val_acc: 0.6133\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7576 - acc: 0.6677 - val_loss: 0.8233 - val_acc: 0.6288\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7511 - acc: 0.6739 - val_loss: 0.8562 - val_acc: 0.5899\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7470 - acc: 0.6767 - val_loss: 0.8408 - val_acc: 0.6187\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7475 - acc: 0.6778 - val_loss: 0.8260 - val_acc: 0.6251\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7445 - acc: 0.6821 - val_loss: 0.8272 - val_acc: 0.6235\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7435 - acc: 0.6842 - val_loss: 0.8277 - val_acc: 0.6272\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7395 - acc: 0.6808 - val_loss: 0.8189 - val_acc: 0.6277\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.7358 - acc: 0.6808 - val_loss: 0.8267 - val_acc: 0.6213\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.7358 - acc: 0.6863 - val_loss: 0.8169 - val_acc: 0.6325\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.7324 - acc: 0.6833 - val_loss: 0.8627 - val_acc: 0.6192\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.7263 - acc: 0.6885 - val_loss: 0.8134 - val_acc: 0.6363\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.7281 - acc: 0.6899 - val_loss: 0.8246 - val_acc: 0.6331\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.7217 - acc: 0.6927 - val_loss: 0.8584 - val_acc: 0.5963\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 713us/step - loss: 0.7212 - acc: 0.6956 - val_loss: 0.8120 - val_acc: 0.6331\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.7190 - acc: 0.6954 - val_loss: 0.8203 - val_acc: 0.6245\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.7169 - acc: 0.6995 - val_loss: 0.8078 - val_acc: 0.6336\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7131 - acc: 0.6977 - val_loss: 0.8201 - val_acc: 0.6325\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.7123 - acc: 0.6993 - val_loss: 0.8111 - val_acc: 0.6363\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 635us/step - loss: 0.7093 - acc: 0.6997 - val_loss: 0.8136 - val_acc: 0.6272\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.7041 - acc: 0.6995 - val_loss: 0.8247 - val_acc: 0.6219\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7017 - acc: 0.7041 - val_loss: 0.8410 - val_acc: 0.6139\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.7005 - acc: 0.7013 - val_loss: 0.8072 - val_acc: 0.6400\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.6993 - acc: 0.7052 - val_loss: 0.8103 - val_acc: 0.6357\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.6970 - acc: 0.7059 - val_loss: 0.8074 - val_acc: 0.6331\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 589us/step - loss: 0.6946 - acc: 0.7084 - val_loss: 0.8135 - val_acc: 0.6443\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.6943 - acc: 0.7066 - val_loss: 0.8524 - val_acc: 0.6133\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.6873 - acc: 0.7153 - val_loss: 0.8468 - val_acc: 0.6272\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.6877 - acc: 0.7139 - val_loss: 0.8218 - val_acc: 0.6405\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 601us/step - loss: 0.6855 - acc: 0.7121 - val_loss: 0.8096 - val_acc: 0.6357\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.6789 - acc: 0.7119 - val_loss: 0.8153 - val_acc: 0.6347\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.6807 - acc: 0.7080 - val_loss: 0.8053 - val_acc: 0.6443\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 0.6749 - acc: 0.7144 - val_loss: 0.8495 - val_acc: 0.6320\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.6745 - acc: 0.7146 - val_loss: 0.8087 - val_acc: 0.6379\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.6714 - acc: 0.7233 - val_loss: 0.8993 - val_acc: 0.5867\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.6663 - acc: 0.7208 - val_loss: 0.8103 - val_acc: 0.6443\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 0.6636 - acc: 0.7208 - val_loss: 0.8170 - val_acc: 0.6352\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.6620 - acc: 0.7206 - val_loss: 0.8115 - val_acc: 0.6373\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.6609 - acc: 0.7242 - val_loss: 0.8091 - val_acc: 0.6416\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.6612 - acc: 0.7226 - val_loss: 0.8107 - val_acc: 0.6421\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.6572 - acc: 0.7279 - val_loss: 0.8246 - val_acc: 0.6427\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 3s 637us/step - loss: 0.6523 - acc: 0.7219 - val_loss: 0.8118 - val_acc: 0.6384\n",
      "0.611920505684\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 15s 4ms/step - loss: 1.0490 - acc: 0.4978 - val_loss: 1.0377 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 1.0345 - acc: 0.5006 - val_loss: 1.0340 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 1.0300 - acc: 0.5006 - val_loss: 1.0300 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 1.0252 - acc: 0.5006 - val_loss: 1.0258 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 701us/step - loss: 1.0201 - acc: 0.5006 - val_loss: 1.0216 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 746us/step - loss: 1.0146 - acc: 0.5006 - val_loss: 1.0162 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 1.0086 - acc: 0.5008 - val_loss: 1.0108 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 1.0018 - acc: 0.5022 - val_loss: 1.0053 - val_acc: 0.5008\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.9950 - acc: 0.5070 - val_loss: 0.9984 - val_acc: 0.5099\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.9871 - acc: 0.5134 - val_loss: 0.9913 - val_acc: 0.5141\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.9789 - acc: 0.5186 - val_loss: 0.9837 - val_acc: 0.5200\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 616us/step - loss: 0.9693 - acc: 0.5310 - val_loss: 0.9751 - val_acc: 0.5211\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 634us/step - loss: 0.9594 - acc: 0.5388 - val_loss: 0.9669 - val_acc: 0.5248\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.9471 - acc: 0.5493 - val_loss: 0.9524 - val_acc: 0.5419\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.9333 - acc: 0.5552 - val_loss: 0.9517 - val_acc: 0.5515\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.9231 - acc: 0.5671 - val_loss: 0.9426 - val_acc: 0.5627\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.9121 - acc: 0.5719 - val_loss: 0.9225 - val_acc: 0.5616\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 0.9010 - acc: 0.5806 - val_loss: 0.9237 - val_acc: 0.5728\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8923 - acc: 0.5872 - val_loss: 0.9046 - val_acc: 0.5829\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.8832 - acc: 0.5934 - val_loss: 0.9031 - val_acc: 0.5691\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.8781 - acc: 0.5957 - val_loss: 0.8934 - val_acc: 0.5771\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.8695 - acc: 0.6000 - val_loss: 0.9045 - val_acc: 0.5595\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.8622 - acc: 0.6026 - val_loss: 0.8844 - val_acc: 0.5867\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.8546 - acc: 0.6115 - val_loss: 0.8895 - val_acc: 0.5760\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.8483 - acc: 0.6080 - val_loss: 0.8795 - val_acc: 0.5899\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 737us/step - loss: 0.8422 - acc: 0.6103 - val_loss: 0.9028 - val_acc: 0.5877\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.8384 - acc: 0.6170 - val_loss: 0.8720 - val_acc: 0.6027\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.8299 - acc: 0.6218 - val_loss: 0.8814 - val_acc: 0.5808\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 729us/step - loss: 0.8270 - acc: 0.6227 - val_loss: 0.8786 - val_acc: 0.5979\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.8216 - acc: 0.6323 - val_loss: 0.8812 - val_acc: 0.6059\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.8155 - acc: 0.6314 - val_loss: 0.8561 - val_acc: 0.6123\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 627us/step - loss: 0.8081 - acc: 0.6341 - val_loss: 0.8684 - val_acc: 0.6101\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8069 - acc: 0.6341 - val_loss: 0.8767 - val_acc: 0.6021\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8030 - acc: 0.6421 - val_loss: 0.8604 - val_acc: 0.6069\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.7994 - acc: 0.6357 - val_loss: 0.8531 - val_acc: 0.6027\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.7977 - acc: 0.6408 - val_loss: 0.8454 - val_acc: 0.6123\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.7931 - acc: 0.6419 - val_loss: 0.8486 - val_acc: 0.6085\n",
      "Epoch 38/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.7906 - acc: 0.6458 - val_loss: 0.8429 - val_acc: 0.6213\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 616us/step - loss: 0.7847 - acc: 0.6460 - val_loss: 0.8537 - val_acc: 0.6123\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 618us/step - loss: 0.7792 - acc: 0.6497 - val_loss: 0.8405 - val_acc: 0.6171\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.7776 - acc: 0.6494 - val_loss: 0.8461 - val_acc: 0.6160\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.7758 - acc: 0.6490 - val_loss: 0.8411 - val_acc: 0.6149\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7724 - acc: 0.6561 - val_loss: 0.8577 - val_acc: 0.6123\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.7675 - acc: 0.6579 - val_loss: 0.8406 - val_acc: 0.6208\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.7670 - acc: 0.6508 - val_loss: 0.8356 - val_acc: 0.6325\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 2s 560us/step - loss: 0.7666 - acc: 0.6547 - val_loss: 0.8671 - val_acc: 0.6133\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7597 - acc: 0.6654 - val_loss: 0.8363 - val_acc: 0.6235\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.7571 - acc: 0.6622 - val_loss: 0.8327 - val_acc: 0.6336\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 739us/step - loss: 0.7548 - acc: 0.6632 - val_loss: 0.8298 - val_acc: 0.6299\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.7504 - acc: 0.6611 - val_loss: 0.8320 - val_acc: 0.6283\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 0.7504 - acc: 0.6627 - val_loss: 0.8353 - val_acc: 0.6283\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.7458 - acc: 0.6712 - val_loss: 0.8274 - val_acc: 0.6352\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7451 - acc: 0.6661 - val_loss: 0.8293 - val_acc: 0.6240\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.7407 - acc: 0.6684 - val_loss: 0.8330 - val_acc: 0.6411\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.7402 - acc: 0.6712 - val_loss: 0.8638 - val_acc: 0.6144\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 611us/step - loss: 0.7361 - acc: 0.6732 - val_loss: 0.8345 - val_acc: 0.6277\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7308 - acc: 0.6735 - val_loss: 0.8171 - val_acc: 0.6357\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.7296 - acc: 0.6748 - val_loss: 0.8411 - val_acc: 0.6389\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7301 - acc: 0.6762 - val_loss: 0.8158 - val_acc: 0.6389\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7237 - acc: 0.6785 - val_loss: 0.8207 - val_acc: 0.6453\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7225 - acc: 0.6844 - val_loss: 0.8158 - val_acc: 0.6448\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 613us/step - loss: 0.7212 - acc: 0.6783 - val_loss: 0.8919 - val_acc: 0.6048\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.7124 - acc: 0.6883 - val_loss: 0.8383 - val_acc: 0.6331\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 624us/step - loss: 0.7146 - acc: 0.6831 - val_loss: 0.8190 - val_acc: 0.6347\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.7141 - acc: 0.6904 - val_loss: 0.8135 - val_acc: 0.6464\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7090 - acc: 0.6904 - val_loss: 0.9348 - val_acc: 0.5765\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.7078 - acc: 0.6913 - val_loss: 0.8143 - val_acc: 0.6336\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.7053 - acc: 0.6920 - val_loss: 0.8144 - val_acc: 0.6453\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 732us/step - loss: 0.7020 - acc: 0.6911 - val_loss: 0.8131 - val_acc: 0.6453\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.7008 - acc: 0.6917 - val_loss: 0.8281 - val_acc: 0.6347\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.6989 - acc: 0.6874 - val_loss: 0.8263 - val_acc: 0.6437\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 616us/step - loss: 0.6972 - acc: 0.6977 - val_loss: 0.8186 - val_acc: 0.6437\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.6923 - acc: 0.7007 - val_loss: 0.8144 - val_acc: 0.6347\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 633us/step - loss: 0.6894 - acc: 0.7032 - val_loss: 0.8327 - val_acc: 0.6432\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.6866 - acc: 0.7027 - val_loss: 0.8123 - val_acc: 0.6368\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.6830 - acc: 0.7020 - val_loss: 0.8625 - val_acc: 0.6187\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 686us/step - loss: 0.6804 - acc: 0.7023 - val_loss: 0.8040 - val_acc: 0.6501\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 622us/step - loss: 0.6764 - acc: 0.7087 - val_loss: 0.8072 - val_acc: 0.6347\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.6756 - acc: 0.7007 - val_loss: 0.8255 - val_acc: 0.6421\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.6724 - acc: 0.7057 - val_loss: 0.8287 - val_acc: 0.6443\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.6721 - acc: 0.7112 - val_loss: 0.8113 - val_acc: 0.6347\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.6689 - acc: 0.7064 - val_loss: 0.8028 - val_acc: 0.6475\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 610us/step - loss: 0.6663 - acc: 0.7114 - val_loss: 0.8105 - val_acc: 0.6411\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 721us/step - loss: 0.6626 - acc: 0.7121 - val_loss: 0.8314 - val_acc: 0.6453\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 604us/step - loss: 0.6606 - acc: 0.7178 - val_loss: 0.8470 - val_acc: 0.6347\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.6596 - acc: 0.7199 - val_loss: 0.8126 - val_acc: 0.6277\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.6598 - acc: 0.7126 - val_loss: 0.8084 - val_acc: 0.6453\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.6523 - acc: 0.7153 - val_loss: 0.8364 - val_acc: 0.6464\n",
      "Epoch 89/300\n",
      "4373/4373 [==============================] - 3s 640us/step - loss: 0.6534 - acc: 0.7164 - val_loss: 0.8078 - val_acc: 0.6421\n",
      "Epoch 90/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.6528 - acc: 0.7247 - val_loss: 0.8112 - val_acc: 0.6347\n",
      "Epoch 91/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.6458 - acc: 0.7267 - val_loss: 0.8535 - val_acc: 0.6352\n",
      "Epoch 92/300\n",
      "4373/4373 [==============================] - 3s 744us/step - loss: 0.6422 - acc: 0.7224 - val_loss: 0.8155 - val_acc: 0.6352\n",
      "0.639857611736\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 16s 4ms/step - loss: 1.0493 - acc: 0.4969 - val_loss: 1.0376 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 1.0352 - acc: 0.5006 - val_loss: 1.0339 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 1.0307 - acc: 0.5006 - val_loss: 1.0302 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 1.0256 - acc: 0.5006 - val_loss: 1.0264 - val_acc: 0.5003\n",
      "Epoch 5/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 681us/step - loss: 1.0203 - acc: 0.5006 - val_loss: 1.0205 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 781us/step - loss: 1.0129 - acc: 0.5006 - val_loss: 1.0140 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 1.0056 - acc: 0.5006 - val_loss: 1.0070 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 736us/step - loss: 0.9975 - acc: 0.5013 - val_loss: 0.9989 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 735us/step - loss: 0.9871 - acc: 0.5033 - val_loss: 0.9893 - val_acc: 0.5056\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 729us/step - loss: 0.9763 - acc: 0.5079 - val_loss: 0.9787 - val_acc: 0.5083\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.9665 - acc: 0.5175 - val_loss: 0.9710 - val_acc: 0.5200\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.9554 - acc: 0.5333 - val_loss: 0.9651 - val_acc: 0.5125\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 612us/step - loss: 0.9451 - acc: 0.5422 - val_loss: 0.9606 - val_acc: 0.5253\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.9346 - acc: 0.5511 - val_loss: 0.9421 - val_acc: 0.5467\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.9261 - acc: 0.5616 - val_loss: 0.9409 - val_acc: 0.5504\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.9153 - acc: 0.5758 - val_loss: 0.9443 - val_acc: 0.5296\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.9094 - acc: 0.5747 - val_loss: 0.9243 - val_acc: 0.5611\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.8950 - acc: 0.5877 - val_loss: 0.9148 - val_acc: 0.5621\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.8859 - acc: 0.5991 - val_loss: 0.9301 - val_acc: 0.5584\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.8788 - acc: 0.5948 - val_loss: 0.9115 - val_acc: 0.5675\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.8690 - acc: 0.5991 - val_loss: 0.9178 - val_acc: 0.5643\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.8624 - acc: 0.6069 - val_loss: 0.9147 - val_acc: 0.5541\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 654us/step - loss: 0.8530 - acc: 0.6147 - val_loss: 0.8892 - val_acc: 0.5813\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.8482 - acc: 0.6140 - val_loss: 0.8926 - val_acc: 0.5723\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.8438 - acc: 0.6211 - val_loss: 0.9002 - val_acc: 0.5728\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.8364 - acc: 0.6179 - val_loss: 0.9028 - val_acc: 0.5717\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.8315 - acc: 0.6177 - val_loss: 0.9212 - val_acc: 0.5557\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 743us/step - loss: 0.8288 - acc: 0.6243 - val_loss: 0.8836 - val_acc: 0.5840\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 718us/step - loss: 0.8202 - acc: 0.6300 - val_loss: 0.8761 - val_acc: 0.5936\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.8147 - acc: 0.6337 - val_loss: 0.8750 - val_acc: 0.5861\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.8103 - acc: 0.6311 - val_loss: 0.8736 - val_acc: 0.5915\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.8046 - acc: 0.6433 - val_loss: 0.8703 - val_acc: 0.5925\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.8044 - acc: 0.6401 - val_loss: 0.8803 - val_acc: 0.5877\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.7964 - acc: 0.6433 - val_loss: 0.8609 - val_acc: 0.5909\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.7928 - acc: 0.6478 - val_loss: 0.8666 - val_acc: 0.5947\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7889 - acc: 0.6428 - val_loss: 0.8648 - val_acc: 0.5984\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 0.7878 - acc: 0.6465 - val_loss: 0.8891 - val_acc: 0.5931\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7868 - acc: 0.6478 - val_loss: 0.8643 - val_acc: 0.6000\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.7795 - acc: 0.6515 - val_loss: 0.8859 - val_acc: 0.5904\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7768 - acc: 0.6510 - val_loss: 0.8713 - val_acc: 0.5963\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7738 - acc: 0.6542 - val_loss: 0.8605 - val_acc: 0.5936\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7701 - acc: 0.6510 - val_loss: 0.9114 - val_acc: 0.5787\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.7683 - acc: 0.6563 - val_loss: 0.8607 - val_acc: 0.6016\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.7647 - acc: 0.6616 - val_loss: 0.8528 - val_acc: 0.6117\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.7604 - acc: 0.6609 - val_loss: 0.8859 - val_acc: 0.5973\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7579 - acc: 0.6668 - val_loss: 0.8774 - val_acc: 0.6021\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7570 - acc: 0.6620 - val_loss: 0.8639 - val_acc: 0.6064\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 0.7544 - acc: 0.6707 - val_loss: 0.8551 - val_acc: 0.6139\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 704us/step - loss: 0.7476 - acc: 0.6716 - val_loss: 0.8900 - val_acc: 0.5925\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 631us/step - loss: 0.7512 - acc: 0.6636 - val_loss: 0.8540 - val_acc: 0.6176\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.7474 - acc: 0.6682 - val_loss: 0.8683 - val_acc: 0.6000\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.7402 - acc: 0.6702 - val_loss: 0.8725 - val_acc: 0.6032\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 724us/step - loss: 0.7381 - acc: 0.6739 - val_loss: 0.8494 - val_acc: 0.6155\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 718us/step - loss: 0.7330 - acc: 0.6755 - val_loss: 0.8639 - val_acc: 0.6085\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.7310 - acc: 0.6780 - val_loss: 0.8489 - val_acc: 0.6208\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.7287 - acc: 0.6831 - val_loss: 0.8423 - val_acc: 0.6187\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.7309 - acc: 0.6776 - val_loss: 0.8476 - val_acc: 0.6181\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 726us/step - loss: 0.7258 - acc: 0.6805 - val_loss: 0.8573 - val_acc: 0.6101\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7252 - acc: 0.6776 - val_loss: 0.8880 - val_acc: 0.5888\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.7206 - acc: 0.6817 - val_loss: 0.8506 - val_acc: 0.6187\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.7157 - acc: 0.6863 - val_loss: 0.8472 - val_acc: 0.6187\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7171 - acc: 0.6831 - val_loss: 0.8722 - val_acc: 0.6048\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7141 - acc: 0.6908 - val_loss: 0.8600 - val_acc: 0.6176\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.7119 - acc: 0.6906 - val_loss: 0.8457 - val_acc: 0.6208\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 0.7087 - acc: 0.6917 - val_loss: 0.8429 - val_acc: 0.6251\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7031 - acc: 0.6993 - val_loss: 0.8459 - val_acc: 0.6133\n",
      "0.579034693738\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 15s 3ms/step - loss: 1.0496 - acc: 0.4983 - val_loss: 1.0357 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 751us/step - loss: 1.0366 - acc: 0.5006 - val_loss: 1.0311 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 1.0320 - acc: 0.5006 - val_loss: 1.0268 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 736us/step - loss: 1.0273 - acc: 0.5006 - val_loss: 1.0218 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 1.0222 - acc: 0.5006 - val_loss: 1.0167 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 1.0175 - acc: 0.5006 - val_loss: 1.0115 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 1.0120 - acc: 0.5006 - val_loss: 1.0055 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 1.0064 - acc: 0.5019 - val_loss: 0.9996 - val_acc: 0.5024\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 1.0004 - acc: 0.5045 - val_loss: 0.9932 - val_acc: 0.5061\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 0.9934 - acc: 0.5067 - val_loss: 0.9866 - val_acc: 0.5125\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 728us/step - loss: 0.9861 - acc: 0.5145 - val_loss: 0.9782 - val_acc: 0.5179\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 751us/step - loss: 0.9787 - acc: 0.5200 - val_loss: 0.9691 - val_acc: 0.5243\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 756us/step - loss: 0.9699 - acc: 0.5287 - val_loss: 0.9641 - val_acc: 0.5205\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 765us/step - loss: 0.9606 - acc: 0.5349 - val_loss: 0.9526 - val_acc: 0.5509\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.9504 - acc: 0.5442 - val_loss: 0.9396 - val_acc: 0.5563\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.9392 - acc: 0.5584 - val_loss: 0.9266 - val_acc: 0.5563\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 698us/step - loss: 0.9302 - acc: 0.5655 - val_loss: 0.9188 - val_acc: 0.5877\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.9205 - acc: 0.5644 - val_loss: 0.9132 - val_acc: 0.5723\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.9109 - acc: 0.5731 - val_loss: 0.9009 - val_acc: 0.5760\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 0.9019 - acc: 0.5703 - val_loss: 0.8926 - val_acc: 0.5787\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.8938 - acc: 0.5813 - val_loss: 0.8896 - val_acc: 0.5776\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 707us/step - loss: 0.8868 - acc: 0.5859 - val_loss: 0.8737 - val_acc: 0.5861\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 680us/step - loss: 0.8802 - acc: 0.5850 - val_loss: 0.8665 - val_acc: 0.5947\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 0.8724 - acc: 0.5962 - val_loss: 0.8892 - val_acc: 0.5723\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.8675 - acc: 0.5991 - val_loss: 0.8899 - val_acc: 0.5712\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 716us/step - loss: 0.8607 - acc: 0.6003 - val_loss: 0.8541 - val_acc: 0.5947\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.8552 - acc: 0.6064 - val_loss: 0.8487 - val_acc: 0.5925\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.8464 - acc: 0.6044 - val_loss: 0.8496 - val_acc: 0.6037\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8435 - acc: 0.6165 - val_loss: 0.8444 - val_acc: 0.6027\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 704us/step - loss: 0.8391 - acc: 0.6076 - val_loss: 0.8422 - val_acc: 0.6043\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.8343 - acc: 0.6151 - val_loss: 0.8421 - val_acc: 0.6053\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 0.8292 - acc: 0.6202 - val_loss: 0.8345 - val_acc: 0.6117\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 733us/step - loss: 0.8257 - acc: 0.6273 - val_loss: 0.8753 - val_acc: 0.5835\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.8229 - acc: 0.6227 - val_loss: 0.8591 - val_acc: 0.6011\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.8205 - acc: 0.6266 - val_loss: 0.8613 - val_acc: 0.6021\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.8140 - acc: 0.6309 - val_loss: 0.8195 - val_acc: 0.6320\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.8116 - acc: 0.6332 - val_loss: 0.8317 - val_acc: 0.6149\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.8079 - acc: 0.6341 - val_loss: 0.8282 - val_acc: 0.6144\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.8047 - acc: 0.6378 - val_loss: 0.8243 - val_acc: 0.6267\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.8023 - acc: 0.6389 - val_loss: 0.8217 - val_acc: 0.6139\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 674us/step - loss: 0.8007 - acc: 0.6382 - val_loss: 0.8084 - val_acc: 0.6267\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.7940 - acc: 0.6433 - val_loss: 0.8096 - val_acc: 0.6240\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.7885 - acc: 0.6456 - val_loss: 0.8080 - val_acc: 0.6341\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 704us/step - loss: 0.7874 - acc: 0.6465 - val_loss: 0.8098 - val_acc: 0.6309\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 0.7870 - acc: 0.6485 - val_loss: 0.8065 - val_acc: 0.6293\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7811 - acc: 0.6510 - val_loss: 0.8202 - val_acc: 0.6219\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7782 - acc: 0.6545 - val_loss: 0.8035 - val_acc: 0.6304\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.7758 - acc: 0.6579 - val_loss: 0.7969 - val_acc: 0.6389\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.7718 - acc: 0.6590 - val_loss: 0.7962 - val_acc: 0.6432\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7699 - acc: 0.6604 - val_loss: 0.8157 - val_acc: 0.6336\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7671 - acc: 0.6625 - val_loss: 0.8199 - val_acc: 0.6187\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7642 - acc: 0.6602 - val_loss: 0.7926 - val_acc: 0.6389\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 727us/step - loss: 0.7588 - acc: 0.6654 - val_loss: 0.7997 - val_acc: 0.6485\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7579 - acc: 0.6625 - val_loss: 0.8099 - val_acc: 0.6336\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 705us/step - loss: 0.7494 - acc: 0.6705 - val_loss: 0.8415 - val_acc: 0.6139\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7536 - acc: 0.6686 - val_loss: 0.8243 - val_acc: 0.6251\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7492 - acc: 0.6652 - val_loss: 0.8006 - val_acc: 0.6405\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 607us/step - loss: 0.7503 - acc: 0.6666 - val_loss: 0.7939 - val_acc: 0.6480\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 0.7426 - acc: 0.6739 - val_loss: 0.7869 - val_acc: 0.6453\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 609us/step - loss: 0.7378 - acc: 0.6810 - val_loss: 0.7941 - val_acc: 0.6437\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7361 - acc: 0.6815 - val_loss: 0.7953 - val_acc: 0.6400\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.7382 - acc: 0.6785 - val_loss: 0.7991 - val_acc: 0.6368\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.7336 - acc: 0.6803 - val_loss: 0.8023 - val_acc: 0.6283\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.7315 - acc: 0.6801 - val_loss: 0.7881 - val_acc: 0.6411\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.7303 - acc: 0.6821 - val_loss: 0.7855 - val_acc: 0.6517\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 0.7248 - acc: 0.6831 - val_loss: 0.7963 - val_acc: 0.6480\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.7241 - acc: 0.6847 - val_loss: 0.7963 - val_acc: 0.6373\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 630us/step - loss: 0.7228 - acc: 0.6842 - val_loss: 0.8015 - val_acc: 0.6459\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.7197 - acc: 0.6869 - val_loss: 0.7977 - val_acc: 0.6373\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7156 - acc: 0.6899 - val_loss: 0.7974 - val_acc: 0.6357\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.7145 - acc: 0.6911 - val_loss: 0.8208 - val_acc: 0.6267\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 703us/step - loss: 0.7120 - acc: 0.6920 - val_loss: 0.7815 - val_acc: 0.6560\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 676us/step - loss: 0.7094 - acc: 0.6913 - val_loss: 0.7767 - val_acc: 0.6512\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7073 - acc: 0.6920 - val_loss: 0.7877 - val_acc: 0.6512\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.7041 - acc: 0.6904 - val_loss: 0.8258 - val_acc: 0.6240\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.7067 - acc: 0.6961 - val_loss: 0.7801 - val_acc: 0.6485\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 0.7013 - acc: 0.6945 - val_loss: 0.8176 - val_acc: 0.6229\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.6992 - acc: 0.6993 - val_loss: 0.7756 - val_acc: 0.6581\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.6956 - acc: 0.6961 - val_loss: 0.7862 - val_acc: 0.6491\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.6944 - acc: 0.7000 - val_loss: 0.7778 - val_acc: 0.6576\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 583us/step - loss: 0.6905 - acc: 0.7004 - val_loss: 0.7934 - val_acc: 0.6389\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.6869 - acc: 0.7009 - val_loss: 0.7772 - val_acc: 0.6549\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.6853 - acc: 0.7059 - val_loss: 0.7804 - val_acc: 0.6571\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 617us/step - loss: 0.6866 - acc: 0.6984 - val_loss: 0.8513 - val_acc: 0.6139\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 675us/step - loss: 0.6808 - acc: 0.7036 - val_loss: 0.7801 - val_acc: 0.6560\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 625us/step - loss: 0.6807 - acc: 0.7103 - val_loss: 0.8167 - val_acc: 0.6325\n",
      "Epoch 87/300\n",
      "4373/4373 [==============================] - 3s 618us/step - loss: 0.6752 - acc: 0.7091 - val_loss: 0.7818 - val_acc: 0.6544\n",
      "Epoch 88/300\n",
      "4373/4373 [==============================] - 3s 671us/step - loss: 0.6730 - acc: 0.7153 - val_loss: 0.7886 - val_acc: 0.6523\n",
      "0.603007860958\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n",
      "4373/4373 [==============================] - 16s 4ms/step - loss: 1.0473 - acc: 0.4997 - val_loss: 1.0365 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 1.0348 - acc: 0.5006 - val_loss: 1.0328 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 1.0308 - acc: 0.5006 - val_loss: 1.0287 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 1.0265 - acc: 0.5006 - val_loss: 1.0246 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 672us/step - loss: 1.0218 - acc: 0.5006 - val_loss: 1.0203 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 1.0163 - acc: 0.5003 - val_loss: 1.0163 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 679us/step - loss: 1.0105 - acc: 0.5008 - val_loss: 1.0096 - val_acc: 0.5008\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 723us/step - loss: 1.0031 - acc: 0.5019 - val_loss: 1.0022 - val_acc: 0.5019\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.9950 - acc: 0.5040 - val_loss: 0.9943 - val_acc: 0.5056\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.9861 - acc: 0.5086 - val_loss: 0.9855 - val_acc: 0.5088\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.9762 - acc: 0.5134 - val_loss: 0.9764 - val_acc: 0.5248\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.9658 - acc: 0.5232 - val_loss: 0.9661 - val_acc: 0.5237\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.9547 - acc: 0.5333 - val_loss: 0.9559 - val_acc: 0.5387\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 710us/step - loss: 0.9449 - acc: 0.5429 - val_loss: 0.9502 - val_acc: 0.5488\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.9354 - acc: 0.5493 - val_loss: 0.9343 - val_acc: 0.5563\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.9259 - acc: 0.5584 - val_loss: 0.9271 - val_acc: 0.5547\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 0.9173 - acc: 0.5612 - val_loss: 0.9194 - val_acc: 0.5760\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 720us/step - loss: 0.9093 - acc: 0.5694 - val_loss: 0.9199 - val_acc: 0.5557\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 700us/step - loss: 0.9013 - acc: 0.5786 - val_loss: 0.9041 - val_acc: 0.5749\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 713us/step - loss: 0.8934 - acc: 0.5763 - val_loss: 0.8995 - val_acc: 0.5696\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.8866 - acc: 0.5836 - val_loss: 0.8968 - val_acc: 0.5605\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.8801 - acc: 0.5850 - val_loss: 0.8896 - val_acc: 0.5856\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 0.8739 - acc: 0.5918 - val_loss: 0.8784 - val_acc: 0.5899\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.8668 - acc: 0.5964 - val_loss: 0.8828 - val_acc: 0.5845\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 658us/step - loss: 0.8600 - acc: 0.5991 - val_loss: 0.8823 - val_acc: 0.5872\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.8556 - acc: 0.6037 - val_loss: 0.8682 - val_acc: 0.5931\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.8503 - acc: 0.6094 - val_loss: 0.8605 - val_acc: 0.5952\n",
      "Epoch 28/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.8420 - acc: 0.6149 - val_loss: 0.8975 - val_acc: 0.5867\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 683us/step - loss: 0.8384 - acc: 0.6151 - val_loss: 0.8736 - val_acc: 0.5909\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.8334 - acc: 0.6163 - val_loss: 0.8732 - val_acc: 0.5941\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.8301 - acc: 0.6188 - val_loss: 0.8470 - val_acc: 0.6101\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.8243 - acc: 0.6241 - val_loss: 0.8438 - val_acc: 0.6123\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.8195 - acc: 0.6284 - val_loss: 0.8614 - val_acc: 0.5963\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.8150 - acc: 0.6305 - val_loss: 0.8578 - val_acc: 0.6005\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 626us/step - loss: 0.8140 - acc: 0.6314 - val_loss: 0.9166 - val_acc: 0.5653\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.8073 - acc: 0.6307 - val_loss: 0.8355 - val_acc: 0.6171\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.8051 - acc: 0.6408 - val_loss: 0.8461 - val_acc: 0.6027\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 747us/step - loss: 0.7985 - acc: 0.6375 - val_loss: 0.8337 - val_acc: 0.6240\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 727us/step - loss: 0.7969 - acc: 0.6408 - val_loss: 0.8342 - val_acc: 0.6176\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 709us/step - loss: 0.7964 - acc: 0.6391 - val_loss: 0.8541 - val_acc: 0.6133\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 689us/step - loss: 0.7899 - acc: 0.6437 - val_loss: 0.8340 - val_acc: 0.6197\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.7885 - acc: 0.6417 - val_loss: 0.8323 - val_acc: 0.6304\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7838 - acc: 0.6494 - val_loss: 0.8423 - val_acc: 0.6187\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7819 - acc: 0.6453 - val_loss: 0.8305 - val_acc: 0.6299\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7810 - acc: 0.6510 - val_loss: 0.8319 - val_acc: 0.6240\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 0.7732 - acc: 0.6531 - val_loss: 0.8569 - val_acc: 0.6043\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 641us/step - loss: 0.7736 - acc: 0.6558 - val_loss: 0.8257 - val_acc: 0.6325\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7692 - acc: 0.6558 - val_loss: 0.8160 - val_acc: 0.6384\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 645us/step - loss: 0.7651 - acc: 0.6568 - val_loss: 0.8223 - val_acc: 0.6336\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7640 - acc: 0.6604 - val_loss: 0.8378 - val_acc: 0.6192\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.7605 - acc: 0.6600 - val_loss: 0.8200 - val_acc: 0.6368\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7586 - acc: 0.6629 - val_loss: 0.8244 - val_acc: 0.6384\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7548 - acc: 0.6606 - val_loss: 0.8347 - val_acc: 0.6203\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7528 - acc: 0.6648 - val_loss: 0.8228 - val_acc: 0.6309\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 647us/step - loss: 0.7485 - acc: 0.6668 - val_loss: 0.8144 - val_acc: 0.6352\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.7441 - acc: 0.6762 - val_loss: 0.8270 - val_acc: 0.6357\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7449 - acc: 0.6760 - val_loss: 0.8064 - val_acc: 0.6421\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 696us/step - loss: 0.7373 - acc: 0.6712 - val_loss: 0.8098 - val_acc: 0.6405\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.7395 - acc: 0.6787 - val_loss: 0.8142 - val_acc: 0.6373\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.7388 - acc: 0.6702 - val_loss: 0.8692 - val_acc: 0.6091\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7314 - acc: 0.6767 - val_loss: 0.8252 - val_acc: 0.6315\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 638us/step - loss: 0.7276 - acc: 0.6796 - val_loss: 0.8187 - val_acc: 0.6261\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.7289 - acc: 0.6785 - val_loss: 0.8133 - val_acc: 0.6320\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 659us/step - loss: 0.7251 - acc: 0.6810 - val_loss: 0.8409 - val_acc: 0.6293\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 653us/step - loss: 0.7231 - acc: 0.6808 - val_loss: 0.8135 - val_acc: 0.6336\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 668us/step - loss: 0.7208 - acc: 0.6769 - val_loss: 0.8027 - val_acc: 0.6448\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 615us/step - loss: 0.7160 - acc: 0.6799 - val_loss: 0.8274 - val_acc: 0.6379\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 627us/step - loss: 0.7131 - acc: 0.6874 - val_loss: 0.8275 - val_acc: 0.6437\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 584us/step - loss: 0.7130 - acc: 0.6897 - val_loss: 0.8048 - val_acc: 0.6480\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 687us/step - loss: 0.7067 - acc: 0.6901 - val_loss: 0.7985 - val_acc: 0.6480\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7095 - acc: 0.6913 - val_loss: 0.7979 - val_acc: 0.6475\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 636us/step - loss: 0.7017 - acc: 0.6915 - val_loss: 0.8172 - val_acc: 0.6357\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.6999 - acc: 0.6890 - val_loss: 0.8140 - val_acc: 0.6389\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 656us/step - loss: 0.7028 - acc: 0.6883 - val_loss: 0.8004 - val_acc: 0.6485\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 717us/step - loss: 0.6967 - acc: 0.6952 - val_loss: 0.8813 - val_acc: 0.6165\n",
      "Epoch 76/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.6920 - acc: 0.6965 - val_loss: 0.7972 - val_acc: 0.6469\n",
      "Epoch 77/300\n",
      "4373/4373 [==============================] - 3s 667us/step - loss: 0.6908 - acc: 0.6977 - val_loss: 0.7984 - val_acc: 0.6491\n",
      "Epoch 78/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.6857 - acc: 0.7011 - val_loss: 0.8435 - val_acc: 0.6176\n",
      "Epoch 79/300\n",
      "4373/4373 [==============================] - 3s 669us/step - loss: 0.6846 - acc: 0.6984 - val_loss: 0.8064 - val_acc: 0.6389\n",
      "Epoch 80/300\n",
      "4373/4373 [==============================] - 3s 684us/step - loss: 0.6792 - acc: 0.7039 - val_loss: 0.8214 - val_acc: 0.6331\n",
      "Epoch 81/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.6801 - acc: 0.7071 - val_loss: 0.8399 - val_acc: 0.6368\n",
      "Epoch 82/300\n",
      "4373/4373 [==============================] - 3s 708us/step - loss: 0.6778 - acc: 0.7039 - val_loss: 0.8021 - val_acc: 0.6501\n",
      "Epoch 83/300\n",
      "4373/4373 [==============================] - 3s 690us/step - loss: 0.6760 - acc: 0.7036 - val_loss: 0.8102 - val_acc: 0.6443\n",
      "Epoch 84/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.6719 - acc: 0.7078 - val_loss: 0.8241 - val_acc: 0.6459\n",
      "Epoch 85/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.6686 - acc: 0.7066 - val_loss: 0.8424 - val_acc: 0.6299\n",
      "Epoch 86/300\n",
      "4373/4373 [==============================] - 3s 688us/step - loss: 0.6646 - acc: 0.7158 - val_loss: 0.8107 - val_acc: 0.6549\n",
      "0.635480404094\n",
      "Train on 4373 samples, validate on 1875 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373/4373 [==============================] - 15s 4ms/step - loss: 1.0483 - acc: 0.4992 - val_loss: 1.0414 - val_acc: 0.5003\n",
      "Epoch 2/300\n",
      "4373/4373 [==============================] - 3s 678us/step - loss: 1.0367 - acc: 0.5006 - val_loss: 1.0391 - val_acc: 0.5003\n",
      "Epoch 3/300\n",
      "4373/4373 [==============================] - 3s 691us/step - loss: 1.0339 - acc: 0.5006 - val_loss: 1.0363 - val_acc: 0.5003\n",
      "Epoch 4/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 1.0311 - acc: 0.5006 - val_loss: 1.0336 - val_acc: 0.5003\n",
      "Epoch 5/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 1.0281 - acc: 0.5006 - val_loss: 1.0307 - val_acc: 0.5003\n",
      "Epoch 6/300\n",
      "4373/4373 [==============================] - 3s 755us/step - loss: 1.0246 - acc: 0.5006 - val_loss: 1.0275 - val_acc: 0.5003\n",
      "Epoch 7/300\n",
      "4373/4373 [==============================] - 3s 739us/step - loss: 1.0211 - acc: 0.5006 - val_loss: 1.0241 - val_acc: 0.5003\n",
      "Epoch 8/300\n",
      "4373/4373 [==============================] - 3s 681us/step - loss: 1.0172 - acc: 0.5003 - val_loss: 1.0204 - val_acc: 0.5003\n",
      "Epoch 9/300\n",
      "4373/4373 [==============================] - 3s 733us/step - loss: 1.0123 - acc: 0.5003 - val_loss: 1.0167 - val_acc: 0.5003\n",
      "Epoch 10/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 1.0073 - acc: 0.5013 - val_loss: 1.0110 - val_acc: 0.5035\n",
      "Epoch 11/300\n",
      "4373/4373 [==============================] - 3s 695us/step - loss: 1.0019 - acc: 0.5029 - val_loss: 1.0056 - val_acc: 0.5035\n",
      "Epoch 12/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.9960 - acc: 0.5054 - val_loss: 0.9994 - val_acc: 0.5088\n",
      "Epoch 13/300\n",
      "4373/4373 [==============================] - 3s 685us/step - loss: 0.9891 - acc: 0.5120 - val_loss: 0.9931 - val_acc: 0.5109\n",
      "Epoch 14/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.9811 - acc: 0.5180 - val_loss: 0.9844 - val_acc: 0.5237\n",
      "Epoch 15/300\n",
      "4373/4373 [==============================] - 3s 648us/step - loss: 0.9721 - acc: 0.5230 - val_loss: 0.9756 - val_acc: 0.5307\n",
      "Epoch 16/300\n",
      "4373/4373 [==============================] - 3s 694us/step - loss: 0.9630 - acc: 0.5326 - val_loss: 0.9661 - val_acc: 0.5381\n",
      "Epoch 17/300\n",
      "4373/4373 [==============================] - 3s 677us/step - loss: 0.9538 - acc: 0.5424 - val_loss: 0.9570 - val_acc: 0.5403\n",
      "Epoch 18/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.9438 - acc: 0.5477 - val_loss: 0.9483 - val_acc: 0.5563\n",
      "Epoch 19/300\n",
      "4373/4373 [==============================] - 3s 603us/step - loss: 0.9345 - acc: 0.5573 - val_loss: 0.9374 - val_acc: 0.5669\n",
      "Epoch 20/300\n",
      "4373/4373 [==============================] - 3s 632us/step - loss: 0.9240 - acc: 0.5639 - val_loss: 0.9291 - val_acc: 0.5723\n",
      "Epoch 21/300\n",
      "4373/4373 [==============================] - 3s 692us/step - loss: 0.9159 - acc: 0.5710 - val_loss: 0.9221 - val_acc: 0.5739\n",
      "Epoch 22/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.9067 - acc: 0.5756 - val_loss: 0.9137 - val_acc: 0.5808\n",
      "Epoch 23/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.8991 - acc: 0.5763 - val_loss: 0.9078 - val_acc: 0.5835\n",
      "Epoch 24/300\n",
      "4373/4373 [==============================] - 3s 721us/step - loss: 0.8903 - acc: 0.5845 - val_loss: 0.9008 - val_acc: 0.5808\n",
      "Epoch 25/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8826 - acc: 0.5868 - val_loss: 0.8929 - val_acc: 0.5872\n",
      "Epoch 26/300\n",
      "4373/4373 [==============================] - 3s 697us/step - loss: 0.8753 - acc: 0.5950 - val_loss: 0.8964 - val_acc: 0.5723\n",
      "Epoch 27/300\n",
      "4373/4373 [==============================] - 3s 709us/step - loss: 0.8678 - acc: 0.5952 - val_loss: 0.8847 - val_acc: 0.5920\n",
      "Epoch 28/300\n",
      "4373/4373 [==============================] - 3s 714us/step - loss: 0.8615 - acc: 0.6019 - val_loss: 0.9040 - val_acc: 0.5781\n",
      "Epoch 29/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.8568 - acc: 0.6044 - val_loss: 0.8750 - val_acc: 0.5941\n",
      "Epoch 30/300\n",
      "4373/4373 [==============================] - 3s 644us/step - loss: 0.8498 - acc: 0.6074 - val_loss: 0.8899 - val_acc: 0.5941\n",
      "Epoch 31/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.8460 - acc: 0.6032 - val_loss: 0.8651 - val_acc: 0.6037\n",
      "Epoch 32/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.8405 - acc: 0.6110 - val_loss: 0.8889 - val_acc: 0.5915\n",
      "Epoch 33/300\n",
      "4373/4373 [==============================] - 3s 599us/step - loss: 0.8339 - acc: 0.6069 - val_loss: 0.8718 - val_acc: 0.6000\n",
      "Epoch 34/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.8317 - acc: 0.6225 - val_loss: 0.8509 - val_acc: 0.6117\n",
      "Epoch 35/300\n",
      "4373/4373 [==============================] - 3s 606us/step - loss: 0.8248 - acc: 0.6179 - val_loss: 0.8542 - val_acc: 0.6016\n",
      "Epoch 36/300\n",
      "4373/4373 [==============================] - 3s 673us/step - loss: 0.8209 - acc: 0.6135 - val_loss: 0.8450 - val_acc: 0.6139\n",
      "Epoch 37/300\n",
      "4373/4373 [==============================] - 3s 657us/step - loss: 0.8171 - acc: 0.6236 - val_loss: 0.8518 - val_acc: 0.6229\n",
      "Epoch 38/300\n",
      "4373/4373 [==============================] - 3s 652us/step - loss: 0.8112 - acc: 0.6218 - val_loss: 0.8494 - val_acc: 0.6096\n",
      "Epoch 39/300\n",
      "4373/4373 [==============================] - 3s 643us/step - loss: 0.8093 - acc: 0.6231 - val_loss: 0.8479 - val_acc: 0.6171\n",
      "Epoch 40/300\n",
      "4373/4373 [==============================] - 3s 615us/step - loss: 0.8055 - acc: 0.6284 - val_loss: 0.8407 - val_acc: 0.6165\n",
      "Epoch 41/300\n",
      "4373/4373 [==============================] - 3s 650us/step - loss: 0.8023 - acc: 0.6330 - val_loss: 0.8668 - val_acc: 0.6101\n",
      "Epoch 42/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7970 - acc: 0.6362 - val_loss: 0.8371 - val_acc: 0.6181\n",
      "Epoch 43/300\n",
      "4373/4373 [==============================] - 3s 666us/step - loss: 0.7964 - acc: 0.6387 - val_loss: 0.8387 - val_acc: 0.6219\n",
      "Epoch 44/300\n",
      "4373/4373 [==============================] - 3s 621us/step - loss: 0.7892 - acc: 0.6430 - val_loss: 0.8263 - val_acc: 0.6309\n",
      "Epoch 45/300\n",
      "4373/4373 [==============================] - 3s 693us/step - loss: 0.7880 - acc: 0.6387 - val_loss: 0.8305 - val_acc: 0.6315\n",
      "Epoch 46/300\n",
      "4373/4373 [==============================] - 3s 702us/step - loss: 0.7841 - acc: 0.6469 - val_loss: 0.8307 - val_acc: 0.6336\n",
      "Epoch 47/300\n",
      "4373/4373 [==============================] - 3s 726us/step - loss: 0.7838 - acc: 0.6430 - val_loss: 0.8228 - val_acc: 0.6384\n",
      "Epoch 48/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7784 - acc: 0.6474 - val_loss: 0.8353 - val_acc: 0.6304\n",
      "Epoch 49/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7727 - acc: 0.6570 - val_loss: 0.8676 - val_acc: 0.6043\n",
      "Epoch 50/300\n",
      "4373/4373 [==============================] - 3s 631us/step - loss: 0.7725 - acc: 0.6524 - val_loss: 0.8194 - val_acc: 0.6363\n",
      "Epoch 51/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7665 - acc: 0.6577 - val_loss: 0.8291 - val_acc: 0.6251\n",
      "Epoch 52/300\n",
      "4373/4373 [==============================] - 3s 637us/step - loss: 0.7651 - acc: 0.6586 - val_loss: 0.8300 - val_acc: 0.6192\n",
      "Epoch 53/300\n",
      "4373/4373 [==============================] - 3s 639us/step - loss: 0.7624 - acc: 0.6565 - val_loss: 0.8260 - val_acc: 0.6320\n",
      "Epoch 54/300\n",
      "4373/4373 [==============================] - 3s 646us/step - loss: 0.7571 - acc: 0.6609 - val_loss: 0.8213 - val_acc: 0.6459\n",
      "Epoch 55/300\n",
      "4373/4373 [==============================] - 3s 661us/step - loss: 0.7535 - acc: 0.6712 - val_loss: 0.8191 - val_acc: 0.6336\n",
      "Epoch 56/300\n",
      "4373/4373 [==============================] - 3s 628us/step - loss: 0.7523 - acc: 0.6684 - val_loss: 0.8147 - val_acc: 0.6309\n",
      "Epoch 57/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7501 - acc: 0.6634 - val_loss: 0.8173 - val_acc: 0.6293\n",
      "Epoch 58/300\n",
      "4373/4373 [==============================] - 3s 612us/step - loss: 0.7474 - acc: 0.6654 - val_loss: 0.8135 - val_acc: 0.6325\n",
      "Epoch 59/300\n",
      "4373/4373 [==============================] - 3s 651us/step - loss: 0.7436 - acc: 0.6718 - val_loss: 0.8256 - val_acc: 0.6304\n",
      "Epoch 60/300\n",
      "4373/4373 [==============================] - 3s 664us/step - loss: 0.7393 - acc: 0.6753 - val_loss: 0.8107 - val_acc: 0.6389\n",
      "Epoch 61/300\n",
      "4373/4373 [==============================] - 3s 649us/step - loss: 0.7365 - acc: 0.6773 - val_loss: 0.8120 - val_acc: 0.6384\n",
      "Epoch 62/300\n",
      "4373/4373 [==============================] - 3s 662us/step - loss: 0.7291 - acc: 0.6769 - val_loss: 0.8106 - val_acc: 0.6368\n",
      "Epoch 63/300\n",
      "4373/4373 [==============================] - 3s 629us/step - loss: 0.7286 - acc: 0.6815 - val_loss: 0.8245 - val_acc: 0.6315\n",
      "Epoch 64/300\n",
      "4373/4373 [==============================] - 3s 642us/step - loss: 0.7263 - acc: 0.6805 - val_loss: 0.8120 - val_acc: 0.6352\n",
      "Epoch 65/300\n",
      "4373/4373 [==============================] - 3s 660us/step - loss: 0.7250 - acc: 0.6883 - val_loss: 0.8144 - val_acc: 0.6373\n",
      "Epoch 66/300\n",
      "4373/4373 [==============================] - 3s 663us/step - loss: 0.7175 - acc: 0.6867 - val_loss: 0.8160 - val_acc: 0.6384\n",
      "Epoch 67/300\n",
      "4373/4373 [==============================] - 3s 712us/step - loss: 0.7190 - acc: 0.6851 - val_loss: 0.8158 - val_acc: 0.6357\n",
      "Epoch 68/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7170 - acc: 0.6826 - val_loss: 0.8119 - val_acc: 0.6395\n",
      "Epoch 69/300\n",
      "4373/4373 [==============================] - 3s 670us/step - loss: 0.7129 - acc: 0.6915 - val_loss: 0.8071 - val_acc: 0.6421\n",
      "Epoch 70/300\n",
      "4373/4373 [==============================] - 3s 682us/step - loss: 0.7099 - acc: 0.6915 - val_loss: 0.8207 - val_acc: 0.6363\n",
      "Epoch 71/300\n",
      "4373/4373 [==============================] - 3s 720us/step - loss: 0.7089 - acc: 0.6885 - val_loss: 0.8280 - val_acc: 0.6315\n",
      "Epoch 72/300\n",
      "4373/4373 [==============================] - 3s 757us/step - loss: 0.7055 - acc: 0.6933 - val_loss: 0.8064 - val_acc: 0.6427\n",
      "Epoch 73/300\n",
      "4373/4373 [==============================] - 3s 752us/step - loss: 0.7015 - acc: 0.6972 - val_loss: 0.8315 - val_acc: 0.6299\n",
      "Epoch 74/300\n",
      "4373/4373 [==============================] - 3s 665us/step - loss: 0.7013 - acc: 0.6924 - val_loss: 0.8069 - val_acc: 0.6395\n",
      "Epoch 75/300\n",
      "4373/4373 [==============================] - 3s 757us/step - loss: 0.6953 - acc: 0.6915 - val_loss: 0.8080 - val_acc: 0.6411\n",
      "Epoch 76/300\n",
      "4352/4373 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.6974"
     ]
    }
   ],
   "source": [
    "result_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results', 'TDLstm'))\n",
    "tdlstm_result_folder = os.path.join(result_folder, 'tdlstm')\n",
    "os.makedirs(tdlstm_result_folder, exist_ok=True)\n",
    "repeated_params = {'reproducible' : False, 'validation_size' : 0.3, \n",
    "                   'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                   'org_initialisers' : True}\n",
    "score_kwargs = {'average' : 'macro'}\n",
    "pad_sizes = [5, 10, half_average_dataset(dong_train), 15, -1]\n",
    "for pad_size in pad_sizes:\n",
    "    print(pad_size)\n",
    "    tdlstm_repeated_results = os.path.join(tdlstm_result_folder, 'TDLSTM {} Pad Size {} Repeated Results.json'\\\n",
    "                                                                 .format(sswe, pad_size))\n",
    "    tdlstm = TDLSTM(ark_twokenize, sswe, lower=True, pad_size=pad_size)\n",
    "    tdlstm_rep_results = tdlstm.repeated_results(dong_train, dong_test, 60, f1_score,\n",
    "                                                 'Dong Twitter', results_file=tdlstm_repeated_results,\n",
    "                                                 re_write=False, score_kwargs=score_kwargs, **repeated_params)\n",
    "    print(tdlstm_rep_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0.575071605057\n",
      "0.578956048353\n",
      "0.577522258288\n",
      "0.580774728634\n",
      "0.576629561436\n",
      "0.564848415811\n",
      "0.567182584733\n",
      "0.598506388583\n",
      "0.586753105895\n",
      "0.586477856865\n",
      "0.594236995271\n",
      "0.57227319135\n",
      "0.584232993092\n",
      "0.585387153372\n",
      "0.578009966541\n",
      "0.579147181367\n",
      "0.581287938362\n",
      "0.567508497655\n",
      "0.572615330415\n",
      "0.569645770413\n",
      "0.588021653271\n",
      "0.582009507875\n",
      "0.570751368044\n",
      "0.576820683194\n"
     ]
    }
   ],
   "source": [
    "result_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results', 'TDLstm'))\n",
    "tclstm_result_folder = os.path.join(result_folder, 'tclstm')\n",
    "os.makedirs(tclstm_result_folder, exist_ok=True)\n",
    "repeated_params = {'reproducible' : False, 'validation_size' : 0.3, \n",
    "                   'patience' : 10, 'epochs' : 300, 'verbose' : 0, \n",
    "                   'org_initialisers' : True}\n",
    "score_kwargs = {'average' : 'macro'}\n",
    "pad_sizes = [5, 10, half_average_dataset(dong_train), 15, -1]\n",
    "for pad_size in pad_sizes:\n",
    "    print(pad_size)\n",
    "    tclstm_repeated_results = os.path.join(tclstm_result_folder, 'TCLSTM {} Pad Size {} Repeated Results.json'\\\n",
    "                                                                 .format(sswe, pad_size))\n",
    "    tclstm = TCLSTM(ark_twokenize, sswe, lower=True, pad_size=pad_size)\n",
    "    tclstm_rep_results = tclstm.repeated_results(dong_train, dong_test, 60, f1_score,\n",
    "                                                 'Dong Twitter', results_file=tclstm_repeated_results,\n",
    "                                                 re_write=False, score_kwargs=score_kwargs, **repeated_params)\n",
    "    print(tclstm_rep_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General results folder for the method\n",
    "result_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results', 'TDLstm'))\n",
    "tdlstm_pad_sizes_results = os.path.join(result_folder, 'TDLSTM Pad Sizes.json')\n",
    "\n",
    "tdlstm_pad_size_results = {}\n",
    "for pad_size in pad_sizes:\n",
    "    model = TDLSTM(ark_twokenize, sswe, lower=True, pad_size=pad_size)\n",
    "    fit_params = {'reproducible' : True, 'validation_size' : 0.3, \n",
    "                  'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                  'org_initialisers' : True}\n",
    "    pad_size_name = str(pad_size)\n",
    "    scores, preds = model.cross_val(dong_train.data_dict(), dong_train.sentiment_data(), \n",
    "                                    accuracy_score, 'Dong Twitter', pad_size_name, \n",
    "                                    kfold_reproducible=True, results_file=tdlstm_pad_sizes_results, \n",
    "                                    re_write=False, **fit_params)\n",
    "    tdlstm_pad_size_results[pad_size_name] = np.array(scores).mean()\n",
    "tdlstm_pad_size_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdlstm_best_pad_size = int(sorted(tdlstm_pad_size_results.items(), key=lambda x: x[1])[-1][0])\n",
    "tdlstm_best_pad_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_params = {'reproducible' : False, 'validation_size' : 0.3, \n",
    "                   'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                   'org_initialisers' : True}\n",
    "\n",
    "tdlstm_repeated_results = os.path.join(result_folder, 'TDLSTM Repeated Results.json')\n",
    "tdlstm = TDLSTM(ark_twokenize, sswe, lower=True, pad_size=tdlstm_best_pad_size)\n",
    "tdlstm_rep_results = tdlstm.repeated_results(dong_train, dong_test, 60, accuracy_score,\n",
    "                                             'Dong Twitter',\n",
    "                                             results_file=tdlstm_repeated_results,\n",
    "                                             re_write=True, **repeated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclstm_pad_sizes_results = os.path.join(result_folder, 'TCLSTM Pad Sizes.json')\n",
    "pad_sizes = [5, 10, half_average_dataset(dong_train), 15, -1]\n",
    "tclstm_pad_size_results = {}\n",
    "for pad_size in pad_sizes:\n",
    "    model = TCLSTM(ark_twokenize, sswe, lower=True, pad_size=pad_size)\n",
    "    fit_params = {'reproducible' : True, 'validation_size' : 0.3, \n",
    "                  'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                  'org_initialisers' : True}\n",
    "    pad_size_name = str(pad_size)\n",
    "    scores, preds = model.cross_val(dong_train.data_dict(), dong_train.sentiment_data(), \n",
    "                                    accuracy_score, 'Dong Twitter', pad_size_name, \n",
    "                                    kfold_reproducible=True, results_file=tclstm_pad_sizes_results, \n",
    "                                    re_write=True, **fit_params)\n",
    "    tclstm_pad_size_results[pad_size_name] = np.array(scores).mean()\n",
    "tclstm_pad_size_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclstm_best_pad_size = int(sorted(tclstm_pad_size_results.items(), key=lambda x: x[1])[-1][0])\n",
    "tclstm_best_pad_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclstm_repeated_results = os.path.join(result_folder, 'TCLSTM Repeated Results.json')\n",
    "tclstm = TCLSTM(ark_twokenize, glove_200, lower=True, pad_size=tclstm_best_pad_size)\n",
    "tclstm_rep_results = tclstm.repeated_results(dong_train, dong_test, 60, accuracy_score,\n",
    "                                             'Dong Twitter',\n",
    "                                             results_file=tclstm_repeated_results,\n",
    "                                             re_write=True, **repeated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_repeated_results = os.path.join(result_folder, 'LSTM Repeated Results.json')\n",
    "lstm = LSTM(ark_twokenize, glove_200, lower=True, pad_size=-1)\n",
    "lstm_rep_results = lstm.repeated_results(dong_train, dong_test, 60, accuracy_score,\n",
    "                                             'Dong Twitter',\n",
    "                                             results_file=lstm_repeated_results,\n",
    "                                             re_write=True, **repeated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "c={'ark_twokenize': [0.61630695443645089,\n",
    "  0.63439999999999996,\n",
    "  0.6381104883907126,\n",
    "  0.62930344275420336,\n",
    "  0.61889511609287429],\n",
    " 'stanford': [0.60671462829736211,\n",
    "  0.62639999999999996,\n",
    "  0.62690152121697362,\n",
    "  0.63891112890312252,\n",
    "  0.63570856685348276],\n",
    " 'whitespace': [0.60671462829736211,\n",
    "  0.62,\n",
    "  0.61809447558046438,\n",
    "  0.62449959967974378,\n",
    "  0.61889511609287429]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ark_twokenize 62.74032003348482\n",
      "stanford 62.692716905418834\n",
      "whitespace 61.76407639300889\n"
     ]
    }
   ],
   "source": [
    "for name, values in c.items():\n",
    "    sum_values = sum(values)\n",
    "    avg_values = 100 * (sum_values / len(values))\n",
    "    print('{} {}'.format(name, avg_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'reproducible': True, 'validation_size': 0.3, 'patience': 10, 'epochs': 300, 'verbose': 1, 'org_initialisers': True}\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 5s 2ms/step - loss: 1.0802 - acc: 0.5004 - val_loss: 1.0657 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0577 - acc: 0.5004 - val_loss: 1.0509 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0474 - acc: 0.5004 - val_loss: 1.0444 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0430 - acc: 0.5004 - val_loss: 1.0414 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0410 - acc: 0.5004 - val_loss: 1.0401 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0400 - acc: 0.5004 - val_loss: 1.0396 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0397 - acc: 0.5004 - val_loss: 1.0393 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0394 - acc: 0.5004 - val_loss: 1.0391 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0393 - acc: 0.5004 - val_loss: 1.0389 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0391 - acc: 0.5004 - val_loss: 1.0388 - val_acc: 0.5007\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0389 - acc: 0.5004 - val_loss: 1.0386 - val_acc: 0.5007\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0387 - acc: 0.5004 - val_loss: 1.0383 - val_acc: 0.5007\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0384 - acc: 0.5004 - val_loss: 1.0379 - val_acc: 0.5007\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0380 - acc: 0.5004 - val_loss: 1.0375 - val_acc: 0.5007\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0375 - acc: 0.5004 - val_loss: 1.0369 - val_acc: 0.5007\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0368 - acc: 0.5004 - val_loss: 1.0361 - val_acc: 0.5007\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0360 - acc: 0.5004 - val_loss: 1.0351 - val_acc: 0.5007\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0349 - acc: 0.5004 - val_loss: 1.0339 - val_acc: 0.5007\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0336 - acc: 0.5004 - val_loss: 1.0324 - val_acc: 0.5007\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0320 - acc: 0.5004 - val_loss: 1.0305 - val_acc: 0.5007\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0300 - acc: 0.5004 - val_loss: 1.0283 - val_acc: 0.5007\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0276 - acc: 0.5004 - val_loss: 1.0257 - val_acc: 0.5007\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0249 - acc: 0.5004 - val_loss: 1.0226 - val_acc: 0.5007\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0217 - acc: 0.5004 - val_loss: 1.0191 - val_acc: 0.5007\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0180 - acc: 0.5004 - val_loss: 1.0151 - val_acc: 0.5007\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0140 - acc: 0.5004 - val_loss: 1.0109 - val_acc: 0.5007\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0095 - acc: 0.5004 - val_loss: 1.0060 - val_acc: 0.5007\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0047 - acc: 0.5004 - val_loss: 1.0009 - val_acc: 0.5013\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9995 - acc: 0.5019 - val_loss: 0.9952 - val_acc: 0.5013\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9938 - acc: 0.5039 - val_loss: 0.9888 - val_acc: 0.4993\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9872 - acc: 0.5061 - val_loss: 0.9837 - val_acc: 0.5073\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9791 - acc: 0.5104 - val_loss: 0.9735 - val_acc: 0.5087\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9729 - acc: 0.5124 - val_loss: 0.9663 - val_acc: 0.5153\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9666 - acc: 0.5199 - val_loss: 0.9877 - val_acc: 0.5027\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9631 - acc: 0.5222 - val_loss: 0.9521 - val_acc: 0.5227\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9591 - acc: 0.5330 - val_loss: 0.9569 - val_acc: 0.5167\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9546 - acc: 0.5299 - val_loss: 0.9621 - val_acc: 0.5280\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9525 - acc: 0.5373 - val_loss: 0.9427 - val_acc: 0.5313\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9513 - acc: 0.5373 - val_loss: 0.9364 - val_acc: 0.5347\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9413 - acc: 0.5356 - val_loss: 0.9582 - val_acc: 0.5340\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9375 - acc: 0.5502 - val_loss: 0.9284 - val_acc: 0.5360\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9425 - acc: 0.5473 - val_loss: 0.9793 - val_acc: 0.5093\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9396 - acc: 0.5370 - val_loss: 0.9675 - val_acc: 0.5153\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9339 - acc: 0.5425 - val_loss: 0.9211 - val_acc: 0.5487\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9318 - acc: 0.5476 - val_loss: 0.9326 - val_acc: 0.5333\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9305 - acc: 0.5473 - val_loss: 0.9196 - val_acc: 0.5453\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9231 - acc: 0.5545 - val_loss: 0.9145 - val_acc: 0.5493\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9243 - acc: 0.5516 - val_loss: 0.9133 - val_acc: 0.5533\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 6s 2ms/step - loss: 0.9178 - acc: 0.5616 - val_loss: 0.9305 - val_acc: 0.5447\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9176 - acc: 0.5536 - val_loss: 0.9070 - val_acc: 0.5620\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9171 - acc: 0.5599 - val_loss: 1.0056 - val_acc: 0.5080\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9166 - acc: 0.5582 - val_loss: 0.9167 - val_acc: 0.5500\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9081 - acc: 0.5719 - val_loss: 0.9040 - val_acc: 0.5587\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9060 - acc: 0.5685 - val_loss: 1.0358 - val_acc: 0.4933\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9031 - acc: 0.5814 - val_loss: 0.9086 - val_acc: 0.5647\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9004 - acc: 0.5791 - val_loss: 0.9212 - val_acc: 0.5533\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.9023 - acc: 0.5814 - val_loss: 0.9063 - val_acc: 0.5640\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8971 - acc: 0.5774 - val_loss: 0.9009 - val_acc: 0.5700\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8979 - acc: 0.5822 - val_loss: 0.9190 - val_acc: 0.5640\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8914 - acc: 0.5842 - val_loss: 0.8943 - val_acc: 0.5793\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8910 - acc: 0.5782 - val_loss: 0.8915 - val_acc: 0.5740\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8868 - acc: 0.5885 - val_loss: 0.8984 - val_acc: 0.5660\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8861 - acc: 0.5888 - val_loss: 0.9103 - val_acc: 0.5653\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8834 - acc: 0.5822 - val_loss: 0.8877 - val_acc: 0.5853\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8809 - acc: 0.5962 - val_loss: 0.9030 - val_acc: 0.5713\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8799 - acc: 0.5916 - val_loss: 0.8942 - val_acc: 0.5780\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8769 - acc: 0.5908 - val_loss: 0.8851 - val_acc: 0.5847\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8778 - acc: 0.5928 - val_loss: 0.9393 - val_acc: 0.5680\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8751 - acc: 0.5985 - val_loss: 0.9585 - val_acc: 0.5567\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8699 - acc: 0.5985 - val_loss: 0.8785 - val_acc: 0.5847\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8697 - acc: 0.5939 - val_loss: 0.9221 - val_acc: 0.5393\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8681 - acc: 0.6014 - val_loss: 0.8763 - val_acc: 0.5853\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8691 - acc: 0.5977 - val_loss: 0.8981 - val_acc: 0.5753\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8694 - acc: 0.5951 - val_loss: 0.8784 - val_acc: 0.5840\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8603 - acc: 0.6102 - val_loss: 0.9121 - val_acc: 0.5740\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8602 - acc: 0.6011 - val_loss: 0.8759 - val_acc: 0.5933\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8597 - acc: 0.5982 - val_loss: 0.8989 - val_acc: 0.5740\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8633 - acc: 0.6028 - val_loss: 0.8975 - val_acc: 0.5713\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8562 - acc: 0.6019 - val_loss: 0.8728 - val_acc: 0.5880\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8542 - acc: 0.6111 - val_loss: 0.8999 - val_acc: 0.5773\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8487 - acc: 0.6140 - val_loss: 0.8696 - val_acc: 0.5907\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8459 - acc: 0.6079 - val_loss: 0.8994 - val_acc: 0.5627\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8470 - acc: 0.6125 - val_loss: 0.8745 - val_acc: 0.5933\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8479 - acc: 0.6057 - val_loss: 0.8792 - val_acc: 0.5860\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8401 - acc: 0.6131 - val_loss: 0.8745 - val_acc: 0.5907\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8453 - acc: 0.6059 - val_loss: 0.8811 - val_acc: 0.5913\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8410 - acc: 0.6134 - val_loss: 0.8826 - val_acc: 0.5820\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 0.8365 - acc: 0.6220 - val_loss: 0.8724 - val_acc: 0.6007\n"
     ]
    }
   ],
   "source": [
    "word_embeddings = [sswe, glove_50, glove_100, glove_200]\n",
    "embed_results = {}\n",
    "for word_embedding in word_embeddings:\n",
    "    model = LSTM(ark_twokenize, word_embedding, lower=True, pad_size=-1)\n",
    "    fit_params = {'reproducible' : True, 'validation_size' : 0.3, \n",
    "                  'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                  'org_initialisers' : True}\n",
    "    scores, preds = model.cross_val(dong_train.data_dict(), dong_train.sentiment_data(), \n",
    "                                    accuracy_score, kfold_reproducible=True, \n",
    "                                    multiprocess=False, **fit_params)\n",
    "    embed_results[word_embedding.name] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sswe 58.3543338920537\n",
      "glove twitter 50d 60.35606321412045\n",
      "glove twitter 100d 61.620217387659125\n",
      "glove twitter 200d 62.74032003348482\n"
     ]
    }
   ],
   "source": [
    "for name, values in embed_results.items():\n",
    "    sum_values = sum(values)\n",
    "    avg_values = 100 * (sum_values / len(values))\n",
    "    print('{} {}'.format(name, avg_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'glove twitter 100d': [0.60991207034372497,\n",
       "  0.59760000000000002,\n",
       "  0.63330664531625303,\n",
       "  0.62209767814251404,\n",
       "  0.61809447558046438],\n",
       " 'glove twitter 200d': [0.61630695443645089,\n",
       "  0.63439999999999996,\n",
       "  0.6381104883907126,\n",
       "  0.62930344275420336,\n",
       "  0.61889511609287429],\n",
       " 'glove twitter 50d': [0.592326139088729,\n",
       "  0.57920000000000005,\n",
       "  0.62049639711769411,\n",
       "  0.6261008807045636,\n",
       "  0.59967974379503608],\n",
       " 'sswe': [0.59472422062350117,\n",
       "  0.58240000000000003,\n",
       "  0.58526821457165734,\n",
       "  0.60608486789431548,\n",
       "  0.54923939151321055]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0464 - acc: 0.4987 - val_loss: 1.0380 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0379 - acc: 0.5004 - val_loss: 1.0359 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.0353 - acc: 0.5004 - val_loss: 1.0337 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0325 - acc: 0.5004 - val_loss: 1.0314 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0296 - acc: 0.5004 - val_loss: 1.0289 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0269 - acc: 0.5004 - val_loss: 1.0267 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0238 - acc: 0.5004 - val_loss: 1.0241 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0210 - acc: 0.5004 - val_loss: 1.0214 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.0176 - acc: 0.5004 - val_loss: 1.0188 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.0136 - acc: 0.5004 - val_loss: 1.0171 - val_acc: 0.5007\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.0106 - acc: 0.5004 - val_loss: 1.0135 - val_acc: 0.5013\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.0064 - acc: 0.5019 - val_loss: 1.0091 - val_acc: 0.5020\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 1.0022 - acc: 0.5044 - val_loss: 1.0050 - val_acc: 0.5067\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.9975 - acc: 0.5081 - val_loss: 1.0013 - val_acc: 0.5067\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.9917 - acc: 0.5119 - val_loss: 0.9952 - val_acc: 0.5073\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.9856 - acc: 0.5182 - val_loss: 0.9903 - val_acc: 0.5173\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9803 - acc: 0.5202 - val_loss: 0.9859 - val_acc: 0.5133\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.9734 - acc: 0.5265 - val_loss: 0.9940 - val_acc: 0.5400\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9693 - acc: 0.5356 - val_loss: 0.9746 - val_acc: 0.5513\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9618 - acc: 0.5365 - val_loss: 0.9773 - val_acc: 0.5293\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9532 - acc: 0.5462 - val_loss: 0.9647 - val_acc: 0.5267\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9474 - acc: 0.5576 - val_loss: 0.9623 - val_acc: 0.5513\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.9411 - acc: 0.5616 - val_loss: 0.9669 - val_acc: 0.5227\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9301 - acc: 0.5699 - val_loss: 0.9590 - val_acc: 0.5420\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9255 - acc: 0.5748 - val_loss: 0.9522 - val_acc: 0.5580\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9179 - acc: 0.5748 - val_loss: 0.9451 - val_acc: 0.5533\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9119 - acc: 0.5794 - val_loss: 0.9365 - val_acc: 0.5607\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9048 - acc: 0.5862 - val_loss: 0.9350 - val_acc: 0.5493\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9013 - acc: 0.5882 - val_loss: 0.9192 - val_acc: 0.5687\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8933 - acc: 0.5922 - val_loss: 0.9194 - val_acc: 0.5660\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8898 - acc: 0.5957 - val_loss: 0.9019 - val_acc: 0.5740\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8831 - acc: 0.5994 - val_loss: 0.9495 - val_acc: 0.5587\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8758 - acc: 0.6065 - val_loss: 0.9321 - val_acc: 0.5687\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8721 - acc: 0.6065 - val_loss: 0.8955 - val_acc: 0.5853\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8697 - acc: 0.6057 - val_loss: 0.9118 - val_acc: 0.5660\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8690 - acc: 0.6008 - val_loss: 0.8906 - val_acc: 0.5753\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8625 - acc: 0.6102 - val_loss: 0.8999 - val_acc: 0.5813\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8594 - acc: 0.6168 - val_loss: 0.8979 - val_acc: 0.5680\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8537 - acc: 0.6117 - val_loss: 0.9178 - val_acc: 0.5673\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8521 - acc: 0.6140 - val_loss: 0.8963 - val_acc: 0.5727\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8498 - acc: 0.6174 - val_loss: 0.8848 - val_acc: 0.5840\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8480 - acc: 0.6160 - val_loss: 0.8809 - val_acc: 0.5967\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8414 - acc: 0.6185 - val_loss: 0.8674 - val_acc: 0.5960\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8391 - acc: 0.6177 - val_loss: 0.8679 - val_acc: 0.5933\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8373 - acc: 0.6205 - val_loss: 0.8686 - val_acc: 0.5933\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8349 - acc: 0.6263 - val_loss: 0.8694 - val_acc: 0.5967\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8323 - acc: 0.6237 - val_loss: 0.8687 - val_acc: 0.5867\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8291 - acc: 0.6311 - val_loss: 0.8905 - val_acc: 0.5587\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8276 - acc: 0.6340 - val_loss: 0.8657 - val_acc: 0.5940\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8280 - acc: 0.6285 - val_loss: 0.8672 - val_acc: 0.5960\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8187 - acc: 0.6311 - val_loss: 0.8696 - val_acc: 0.5993\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8184 - acc: 0.6334 - val_loss: 0.8631 - val_acc: 0.6033\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8199 - acc: 0.6325 - val_loss: 0.8553 - val_acc: 0.5933\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8112 - acc: 0.6317 - val_loss: 0.8568 - val_acc: 0.5960\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8066 - acc: 0.6426 - val_loss: 0.9082 - val_acc: 0.5713\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.8064 - acc: 0.6391 - val_loss: 0.8660 - val_acc: 0.6000\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8077 - acc: 0.6440 - val_loss: 0.8453 - val_acc: 0.6067\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8029 - acc: 0.6343 - val_loss: 0.8738 - val_acc: 0.5967\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8009 - acc: 0.6534 - val_loss: 0.8570 - val_acc: 0.6073\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7969 - acc: 0.6448 - val_loss: 0.8701 - val_acc: 0.5880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7921 - acc: 0.6480 - val_loss: 0.8523 - val_acc: 0.6067\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7929 - acc: 0.6480 - val_loss: 0.8414 - val_acc: 0.6133\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7903 - acc: 0.6500 - val_loss: 0.8787 - val_acc: 0.5960\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7864 - acc: 0.6546 - val_loss: 0.8513 - val_acc: 0.6027\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7840 - acc: 0.6534 - val_loss: 0.8597 - val_acc: 0.6013\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7842 - acc: 0.6531 - val_loss: 0.8351 - val_acc: 0.6033\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7788 - acc: 0.6623 - val_loss: 0.8453 - val_acc: 0.6093\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7779 - acc: 0.6594 - val_loss: 0.8380 - val_acc: 0.6067\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7753 - acc: 0.6646 - val_loss: 0.8331 - val_acc: 0.6153\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7708 - acc: 0.6591 - val_loss: 0.8353 - val_acc: 0.6173\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7710 - acc: 0.6649 - val_loss: 0.8435 - val_acc: 0.6080\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7666 - acc: 0.6654 - val_loss: 0.8889 - val_acc: 0.5807\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7642 - acc: 0.6646 - val_loss: 0.8480 - val_acc: 0.6087\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7648 - acc: 0.6606 - val_loss: 0.8369 - val_acc: 0.6147\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7586 - acc: 0.6709 - val_loss: 0.8564 - val_acc: 0.6093\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7553 - acc: 0.6757 - val_loss: 0.8745 - val_acc: 0.5867\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7520 - acc: 0.6800 - val_loss: 0.8380 - val_acc: 0.6087\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7547 - acc: 0.6689 - val_loss: 0.8359 - val_acc: 0.6073\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7489 - acc: 0.6754 - val_loss: 0.8326 - val_acc: 0.6180\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7455 - acc: 0.6789 - val_loss: 0.8400 - val_acc: 0.6080\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7420 - acc: 0.6823 - val_loss: 0.8468 - val_acc: 0.6140\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7433 - acc: 0.6849 - val_loss: 0.8356 - val_acc: 0.6087\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7408 - acc: 0.6806 - val_loss: 0.9278 - val_acc: 0.5780\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7388 - acc: 0.6806 - val_loss: 0.8635 - val_acc: 0.6187\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7350 - acc: 0.6860 - val_loss: 0.8440 - val_acc: 0.6093\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 7s 2ms/step - loss: 0.7314 - acc: 0.6872 - val_loss: 0.8512 - val_acc: 0.5933\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7309 - acc: 0.6892 - val_loss: 0.8957 - val_acc: 0.5740\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7295 - acc: 0.6849 - val_loss: 0.8505 - val_acc: 0.5980\n",
      "Epoch 89/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7293 - acc: 0.6892 - val_loss: 0.8333 - val_acc: 0.6313\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0479 - acc: 0.4983 - val_loss: 1.0378 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0367 - acc: 0.5003 - val_loss: 1.0346 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0333 - acc: 0.5003 - val_loss: 1.0314 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0291 - acc: 0.5003 - val_loss: 1.0288 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0263 - acc: 0.5003 - val_loss: 1.0254 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0222 - acc: 0.5003 - val_loss: 1.0216 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0177 - acc: 0.5003 - val_loss: 1.0174 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0136 - acc: 0.5003 - val_loss: 1.0136 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0084 - acc: 0.5017 - val_loss: 1.0099 - val_acc: 0.5020\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 1.0035 - acc: 0.5057 - val_loss: 1.0060 - val_acc: 0.5060\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9988 - acc: 0.5071 - val_loss: 0.9995 - val_acc: 0.5087\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9930 - acc: 0.5089 - val_loss: 0.9979 - val_acc: 0.5140\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9872 - acc: 0.5129 - val_loss: 0.9908 - val_acc: 0.5147\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9806 - acc: 0.5169 - val_loss: 0.9814 - val_acc: 0.5187\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9746 - acc: 0.5232 - val_loss: 0.9753 - val_acc: 0.5327\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9688 - acc: 0.5280 - val_loss: 0.9716 - val_acc: 0.5353\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9645 - acc: 0.5363 - val_loss: 0.9690 - val_acc: 0.5307\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9569 - acc: 0.5392 - val_loss: 0.9651 - val_acc: 0.5720\n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9526 - acc: 0.5495 - val_loss: 0.9524 - val_acc: 0.5327\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9437 - acc: 0.5506 - val_loss: 0.9430 - val_acc: 0.5540\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9358 - acc: 0.5520 - val_loss: 0.9390 - val_acc: 0.5633\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9300 - acc: 0.5552 - val_loss: 0.9313 - val_acc: 0.5653\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9221 - acc: 0.5689 - val_loss: 0.9265 - val_acc: 0.5733\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9150 - acc: 0.5686 - val_loss: 0.9502 - val_acc: 0.5547\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9078 - acc: 0.5772 - val_loss: 0.9187 - val_acc: 0.5753\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.9011 - acc: 0.5746 - val_loss: 0.9154 - val_acc: 0.5753\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8972 - acc: 0.5855 - val_loss: 0.9058 - val_acc: 0.5840\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8921 - acc: 0.5858 - val_loss: 0.9269 - val_acc: 0.5653\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8863 - acc: 0.5949 - val_loss: 0.8982 - val_acc: 0.5807\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8823 - acc: 0.5978 - val_loss: 0.8956 - val_acc: 0.5833\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8776 - acc: 0.6023 - val_loss: 0.9259 - val_acc: 0.5767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8768 - acc: 0.5998 - val_loss: 0.9163 - val_acc: 0.5747\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8740 - acc: 0.5955 - val_loss: 0.8881 - val_acc: 0.5827\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8680 - acc: 0.6012 - val_loss: 0.9085 - val_acc: 0.5680\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8639 - acc: 0.6052 - val_loss: 0.9098 - val_acc: 0.5653\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8614 - acc: 0.6043 - val_loss: 0.8823 - val_acc: 0.5840\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8578 - acc: 0.6052 - val_loss: 0.8771 - val_acc: 0.5900\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8561 - acc: 0.6098 - val_loss: 0.8826 - val_acc: 0.5927\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8517 - acc: 0.6141 - val_loss: 0.8740 - val_acc: 0.5920\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8490 - acc: 0.6101 - val_loss: 0.8943 - val_acc: 0.5807\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8460 - acc: 0.6226 - val_loss: 0.8842 - val_acc: 0.5827\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8447 - acc: 0.6129 - val_loss: 0.8712 - val_acc: 0.5853\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8417 - acc: 0.6149 - val_loss: 0.8821 - val_acc: 0.5840\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8364 - acc: 0.6249 - val_loss: 0.8830 - val_acc: 0.5773\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8348 - acc: 0.6221 - val_loss: 0.9147 - val_acc: 0.5713\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8338 - acc: 0.6249 - val_loss: 0.8655 - val_acc: 0.5933\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8304 - acc: 0.6246 - val_loss: 0.8641 - val_acc: 0.6020\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8275 - acc: 0.6229 - val_loss: 0.9056 - val_acc: 0.5780\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8270 - acc: 0.6318 - val_loss: 0.8900 - val_acc: 0.5827\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8232 - acc: 0.6295 - val_loss: 0.9032 - val_acc: 0.5553\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8221 - acc: 0.6232 - val_loss: 0.8737 - val_acc: 0.5800\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8184 - acc: 0.6286 - val_loss: 0.8570 - val_acc: 0.6013\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8140 - acc: 0.6326 - val_loss: 0.8660 - val_acc: 0.5980\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8163 - acc: 0.6298 - val_loss: 0.8639 - val_acc: 0.5987\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8123 - acc: 0.6284 - val_loss: 0.8788 - val_acc: 0.5927\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8095 - acc: 0.6378 - val_loss: 0.8710 - val_acc: 0.5873\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8078 - acc: 0.6392 - val_loss: 0.9092 - val_acc: 0.5687\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8055 - acc: 0.6358 - val_loss: 0.8841 - val_acc: 0.5847\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8030 - acc: 0.6409 - val_loss: 0.9040 - val_acc: 0.5907\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.8029 - acc: 0.6321 - val_loss: 0.8581 - val_acc: 0.5953\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7996 - acc: 0.6432 - val_loss: 0.8617 - val_acc: 0.6060\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7991 - acc: 0.6412 - val_loss: 0.8569 - val_acc: 0.6020\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7978 - acc: 0.6429 - val_loss: 0.8704 - val_acc: 0.5860\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7950 - acc: 0.6409 - val_loss: 0.8552 - val_acc: 0.6013\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7905 - acc: 0.6458 - val_loss: 0.8506 - val_acc: 0.6107\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7873 - acc: 0.6487 - val_loss: 0.8545 - val_acc: 0.5913\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7856 - acc: 0.6464 - val_loss: 0.8445 - val_acc: 0.6100\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7847 - acc: 0.6509 - val_loss: 0.8672 - val_acc: 0.5980\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7811 - acc: 0.6555 - val_loss: 0.8449 - val_acc: 0.6133\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7811 - acc: 0.6501 - val_loss: 0.8519 - val_acc: 0.6073\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7800 - acc: 0.6492 - val_loss: 0.8462 - val_acc: 0.5993\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7757 - acc: 0.6461 - val_loss: 0.8498 - val_acc: 0.6187\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7761 - acc: 0.6518 - val_loss: 0.8487 - val_acc: 0.6073\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7734 - acc: 0.6501 - val_loss: 0.8487 - val_acc: 0.6013\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7706 - acc: 0.6475 - val_loss: 0.8554 - val_acc: 0.6027\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7662 - acc: 0.6532 - val_loss: 0.8409 - val_acc: 0.6147\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7663 - acc: 0.6552 - val_loss: 0.8414 - val_acc: 0.6200\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7649 - acc: 0.6589 - val_loss: 0.8816 - val_acc: 0.5693\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7615 - acc: 0.6589 - val_loss: 0.8525 - val_acc: 0.5933\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7599 - acc: 0.6630 - val_loss: 0.8666 - val_acc: 0.5973\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7575 - acc: 0.6675 - val_loss: 0.8503 - val_acc: 0.6100\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7623 - acc: 0.6598 - val_loss: 0.8691 - val_acc: 0.5873\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7551 - acc: 0.6658 - val_loss: 0.8562 - val_acc: 0.5953\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7529 - acc: 0.6664 - val_loss: 0.8475 - val_acc: 0.6140\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7493 - acc: 0.6698 - val_loss: 0.8436 - val_acc: 0.5980\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 7s 2ms/step - loss: 0.7464 - acc: 0.6775 - val_loss: 0.8543 - val_acc: 0.6180\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0476 - acc: 0.4990 - val_loss: 1.0372 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0368 - acc: 0.5004 - val_loss: 1.0351 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0335 - acc: 0.5004 - val_loss: 1.0324 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0303 - acc: 0.5004 - val_loss: 1.0285 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0264 - acc: 0.5004 - val_loss: 1.0268 - val_acc: 0.5007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0228 - acc: 0.5004 - val_loss: 1.0242 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0188 - acc: 0.5004 - val_loss: 1.0186 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0142 - acc: 0.5010 - val_loss: 1.0137 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0095 - acc: 0.5021 - val_loss: 1.0093 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0041 - acc: 0.5041 - val_loss: 1.0096 - val_acc: 0.5087\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0001 - acc: 0.5081 - val_loss: 1.0006 - val_acc: 0.5080\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9949 - acc: 0.5116 - val_loss: 0.9957 - val_acc: 0.5093\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9890 - acc: 0.5124 - val_loss: 0.9887 - val_acc: 0.5133\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9825 - acc: 0.5201 - val_loss: 0.9829 - val_acc: 0.5160\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9793 - acc: 0.5233 - val_loss: 0.9773 - val_acc: 0.5293\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9718 - acc: 0.5350 - val_loss: 0.9871 - val_acc: 0.5553\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9641 - acc: 0.5362 - val_loss: 0.9816 - val_acc: 0.5300\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9614 - acc: 0.5436 - val_loss: 0.9639 - val_acc: 0.5400\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9575 - acc: 0.5419 - val_loss: 0.9592 - val_acc: 0.5600\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9462 - acc: 0.5576 - val_loss: 0.9568 - val_acc: 0.5520\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9414 - acc: 0.5553 - val_loss: 1.0080 - val_acc: 0.4620\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9348 - acc: 0.5650 - val_loss: 0.9375 - val_acc: 0.5553\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9283 - acc: 0.5710 - val_loss: 0.9447 - val_acc: 0.5667\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9243 - acc: 0.5744 - val_loss: 0.9386 - val_acc: 0.5600\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9168 - acc: 0.5770 - val_loss: 0.9262 - val_acc: 0.5773\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9080 - acc: 0.5796 - val_loss: 0.9307 - val_acc: 0.5680\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9033 - acc: 0.5827 - val_loss: 0.9124 - val_acc: 0.5773\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8973 - acc: 0.5859 - val_loss: 0.9120 - val_acc: 0.5813\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8911 - acc: 0.5922 - val_loss: 0.9077 - val_acc: 0.5787\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8897 - acc: 0.5939 - val_loss: 0.9042 - val_acc: 0.5813\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8803 - acc: 0.5990 - val_loss: 0.8960 - val_acc: 0.5813\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8779 - acc: 0.6002 - val_loss: 0.9120 - val_acc: 0.5793\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8756 - acc: 0.5962 - val_loss: 0.8926 - val_acc: 0.5867\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8705 - acc: 0.5993 - val_loss: 0.8907 - val_acc: 0.5947\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8665 - acc: 0.6033 - val_loss: 0.8858 - val_acc: 0.5847\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8628 - acc: 0.6127 - val_loss: 0.8900 - val_acc: 0.5960\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8589 - acc: 0.6116 - val_loss: 0.9007 - val_acc: 0.5820\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8558 - acc: 0.6096 - val_loss: 0.8889 - val_acc: 0.5887\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8540 - acc: 0.6139 - val_loss: 0.9036 - val_acc: 0.5880\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8524 - acc: 0.6096 - val_loss: 0.8747 - val_acc: 0.5927\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8466 - acc: 0.6147 - val_loss: 0.8706 - val_acc: 0.6027\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8445 - acc: 0.6170 - val_loss: 0.9061 - val_acc: 0.5733\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8410 - acc: 0.6187 - val_loss: 0.8702 - val_acc: 0.6013\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8386 - acc: 0.6187 - val_loss: 0.8712 - val_acc: 0.6020\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8348 - acc: 0.6233 - val_loss: 0.8966 - val_acc: 0.5700\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8325 - acc: 0.6199 - val_loss: 0.8795 - val_acc: 0.5920\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8305 - acc: 0.6227 - val_loss: 0.8632 - val_acc: 0.6040\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8266 - acc: 0.6282 - val_loss: 0.8618 - val_acc: 0.6000\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8236 - acc: 0.6285 - val_loss: 0.8715 - val_acc: 0.6000\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8196 - acc: 0.6328 - val_loss: 0.8604 - val_acc: 0.6033\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8177 - acc: 0.6345 - val_loss: 0.8574 - val_acc: 0.6027\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8152 - acc: 0.6339 - val_loss: 0.8600 - val_acc: 0.6120\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8129 - acc: 0.6299 - val_loss: 0.8557 - val_acc: 0.6120\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8121 - acc: 0.6376 - val_loss: 0.8528 - val_acc: 0.6053\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8044 - acc: 0.6408 - val_loss: 0.8698 - val_acc: 0.5840\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8095 - acc: 0.6379 - val_loss: 0.8681 - val_acc: 0.6000\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8046 - acc: 0.6368 - val_loss: 0.8755 - val_acc: 0.6080\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8001 - acc: 0.6393 - val_loss: 0.8961 - val_acc: 0.5713\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8004 - acc: 0.6465 - val_loss: 0.8825 - val_acc: 0.5813\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7976 - acc: 0.6430 - val_loss: 0.8479 - val_acc: 0.6100\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7949 - acc: 0.6442 - val_loss: 0.8494 - val_acc: 0.6120\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7914 - acc: 0.6505 - val_loss: 0.8574 - val_acc: 0.6027\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7910 - acc: 0.6502 - val_loss: 0.8532 - val_acc: 0.6133\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7878 - acc: 0.6482 - val_loss: 0.8465 - val_acc: 0.6127\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7852 - acc: 0.6550 - val_loss: 0.8451 - val_acc: 0.6127\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7830 - acc: 0.6533 - val_loss: 0.8412 - val_acc: 0.6147\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7830 - acc: 0.6519 - val_loss: 0.8542 - val_acc: 0.6240\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7793 - acc: 0.6519 - val_loss: 0.8477 - val_acc: 0.6207\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7785 - acc: 0.6553 - val_loss: 0.8463 - val_acc: 0.6127\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7758 - acc: 0.6596 - val_loss: 0.8396 - val_acc: 0.6193\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7715 - acc: 0.6588 - val_loss: 0.8709 - val_acc: 0.6007\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7697 - acc: 0.6633 - val_loss: 0.8533 - val_acc: 0.6127\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7706 - acc: 0.6650 - val_loss: 0.8668 - val_acc: 0.6187\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7643 - acc: 0.6650 - val_loss: 0.8478 - val_acc: 0.6080\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7647 - acc: 0.6662 - val_loss: 0.8524 - val_acc: 0.6027\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7650 - acc: 0.6690 - val_loss: 0.8420 - val_acc: 0.6160\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7600 - acc: 0.6622 - val_loss: 0.8342 - val_acc: 0.6267\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7593 - acc: 0.6730 - val_loss: 0.8336 - val_acc: 0.6247\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7543 - acc: 0.6693 - val_loss: 0.8540 - val_acc: 0.6213\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7557 - acc: 0.6688 - val_loss: 0.8567 - val_acc: 0.6160\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7555 - acc: 0.6662 - val_loss: 0.8319 - val_acc: 0.6233\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7511 - acc: 0.6733 - val_loss: 0.8598 - val_acc: 0.6060\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7522 - acc: 0.6762 - val_loss: 0.9240 - val_acc: 0.5493\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7493 - acc: 0.6739 - val_loss: 0.8754 - val_acc: 0.6167\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7447 - acc: 0.6736 - val_loss: 0.8312 - val_acc: 0.6307\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7444 - acc: 0.6751 - val_loss: 0.8499 - val_acc: 0.6100\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7412 - acc: 0.6785 - val_loss: 0.8379 - val_acc: 0.6120\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7405 - acc: 0.6839 - val_loss: 0.8722 - val_acc: 0.6147\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7383 - acc: 0.6833 - val_loss: 0.8397 - val_acc: 0.6233\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7369 - acc: 0.6748 - val_loss: 0.8312 - val_acc: 0.6260\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7358 - acc: 0.6848 - val_loss: 0.8493 - val_acc: 0.6287\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7299 - acc: 0.6853 - val_loss: 0.8422 - val_acc: 0.6167\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7277 - acc: 0.6836 - val_loss: 0.8573 - val_acc: 0.6213\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7311 - acc: 0.6822 - val_loss: 0.8329 - val_acc: 0.6233\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7242 - acc: 0.6902 - val_loss: 0.8382 - val_acc: 0.6273\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7194 - acc: 0.6913 - val_loss: 1.0263 - val_acc: 0.5060\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7260 - acc: 0.6865 - val_loss: 0.8447 - val_acc: 0.6127\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7157 - acc: 0.6928 - val_loss: 0.8379 - val_acc: 0.6253\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7183 - acc: 0.6876 - val_loss: 0.8303 - val_acc: 0.6273\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7170 - acc: 0.6913 - val_loss: 0.8350 - val_acc: 0.6227\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7139 - acc: 0.6948 - val_loss: 0.8584 - val_acc: 0.6140\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7098 - acc: 0.7002 - val_loss: 0.8644 - val_acc: 0.6133\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7138 - acc: 0.6939 - val_loss: 0.8457 - val_acc: 0.6233\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7118 - acc: 0.6919 - val_loss: 0.8356 - val_acc: 0.6267\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7047 - acc: 0.6979 - val_loss: 0.8498 - val_acc: 0.6220\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7038 - acc: 0.7008 - val_loss: 0.8326 - val_acc: 0.6253\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7030 - acc: 0.6968 - val_loss: 0.8883 - val_acc: 0.5813\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7009 - acc: 0.7042 - val_loss: 0.8269 - val_acc: 0.6247\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6972 - acc: 0.7002 - val_loss: 0.8733 - val_acc: 0.6107\n",
      "Epoch 110/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6961 - acc: 0.7053 - val_loss: 0.8502 - val_acc: 0.6000\n",
      "Epoch 111/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6964 - acc: 0.6999 - val_loss: 0.8455 - val_acc: 0.6187\n",
      "Epoch 112/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6902 - acc: 0.7076 - val_loss: 0.8540 - val_acc: 0.6167\n",
      "Epoch 113/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6842 - acc: 0.7113 - val_loss: 0.8344 - val_acc: 0.6253\n",
      "Epoch 114/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6850 - acc: 0.7122 - val_loss: 0.8440 - val_acc: 0.6267\n",
      "Epoch 115/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6877 - acc: 0.7062 - val_loss: 0.8843 - val_acc: 0.5873\n",
      "Epoch 116/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6832 - acc: 0.7148 - val_loss: 0.8362 - val_acc: 0.6253\n",
      "Epoch 117/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6831 - acc: 0.7105 - val_loss: 0.8982 - val_acc: 0.5747\n",
      "Epoch 118/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.6810 - acc: 0.7165 - val_loss: 0.8752 - val_acc: 0.6120\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0476 - acc: 0.4996 - val_loss: 1.0372 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0370 - acc: 0.5004 - val_loss: 1.0349 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0340 - acc: 0.5004 - val_loss: 1.0320 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0311 - acc: 0.5004 - val_loss: 1.0281 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0273 - acc: 0.5004 - val_loss: 1.0264 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0240 - acc: 0.5004 - val_loss: 1.0235 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0202 - acc: 0.5004 - val_loss: 1.0179 - val_acc: 0.5007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0158 - acc: 0.5004 - val_loss: 1.0125 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0113 - acc: 0.5016 - val_loss: 1.0081 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0061 - acc: 0.5024 - val_loss: 1.0070 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 1.0022 - acc: 0.5050 - val_loss: 0.9988 - val_acc: 0.5053\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9974 - acc: 0.5090 - val_loss: 0.9947 - val_acc: 0.5073\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9917 - acc: 0.5116 - val_loss: 0.9892 - val_acc: 0.5120\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9846 - acc: 0.5176 - val_loss: 0.9810 - val_acc: 0.5127\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9816 - acc: 0.5241 - val_loss: 0.9750 - val_acc: 0.5320\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9744 - acc: 0.5324 - val_loss: 0.9768 - val_acc: 0.5493\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9680 - acc: 0.5347 - val_loss: 0.9789 - val_acc: 0.5353\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9632 - acc: 0.5390 - val_loss: 0.9626 - val_acc: 0.5520\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9580 - acc: 0.5447 - val_loss: 0.9492 - val_acc: 0.5620\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9499 - acc: 0.5547 - val_loss: 0.9468 - val_acc: 0.5467\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9448 - acc: 0.5596 - val_loss: 0.9970 - val_acc: 0.4913\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9353 - acc: 0.5653 - val_loss: 0.9285 - val_acc: 0.5613\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9298 - acc: 0.5676 - val_loss: 0.9297 - val_acc: 0.5753\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9209 - acc: 0.5744 - val_loss: 0.9267 - val_acc: 0.5700\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9152 - acc: 0.5739 - val_loss: 0.9329 - val_acc: 0.5773\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9087 - acc: 0.5822 - val_loss: 0.9107 - val_acc: 0.5820\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9033 - acc: 0.5742 - val_loss: 0.9020 - val_acc: 0.5813\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8973 - acc: 0.5839 - val_loss: 0.9024 - val_acc: 0.5813\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8933 - acc: 0.5916 - val_loss: 0.8956 - val_acc: 0.5847\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8903 - acc: 0.5879 - val_loss: 0.8979 - val_acc: 0.5927\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8817 - acc: 0.5925 - val_loss: 0.8879 - val_acc: 0.5927\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8794 - acc: 0.5953 - val_loss: 0.9182 - val_acc: 0.5767\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8765 - acc: 0.5885 - val_loss: 0.8822 - val_acc: 0.5880\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8724 - acc: 0.5936 - val_loss: 0.8832 - val_acc: 0.5887\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8676 - acc: 0.5945 - val_loss: 0.8779 - val_acc: 0.5947\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8648 - acc: 0.6042 - val_loss: 0.8903 - val_acc: 0.5953\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8618 - acc: 0.6013 - val_loss: 0.8912 - val_acc: 0.5940\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8577 - acc: 0.6030 - val_loss: 0.8869 - val_acc: 0.6000\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8564 - acc: 0.6045 - val_loss: 0.9134 - val_acc: 0.5740\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8547 - acc: 0.6116 - val_loss: 0.8694 - val_acc: 0.5953\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8492 - acc: 0.6116 - val_loss: 0.8667 - val_acc: 0.6053\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8478 - acc: 0.6125 - val_loss: 0.8901 - val_acc: 0.5887\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8445 - acc: 0.6147 - val_loss: 0.8647 - val_acc: 0.5993\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8418 - acc: 0.6176 - val_loss: 0.8718 - val_acc: 0.6007\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8370 - acc: 0.6202 - val_loss: 0.8939 - val_acc: 0.5687\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8361 - acc: 0.6150 - val_loss: 0.8669 - val_acc: 0.6027\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8343 - acc: 0.6227 - val_loss: 0.8561 - val_acc: 0.6100\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8309 - acc: 0.6262 - val_loss: 0.8678 - val_acc: 0.6027\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8278 - acc: 0.6282 - val_loss: 0.8689 - val_acc: 0.6047\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8244 - acc: 0.6310 - val_loss: 0.8586 - val_acc: 0.6027\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8215 - acc: 0.6276 - val_loss: 0.8560 - val_acc: 0.6033\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8198 - acc: 0.6328 - val_loss: 0.8645 - val_acc: 0.6093\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8178 - acc: 0.6290 - val_loss: 0.8500 - val_acc: 0.6113\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8168 - acc: 0.6319 - val_loss: 0.8511 - val_acc: 0.6100\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8101 - acc: 0.6350 - val_loss: 0.8728 - val_acc: 0.5853\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8140 - acc: 0.6319 - val_loss: 0.8654 - val_acc: 0.6093\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8091 - acc: 0.6339 - val_loss: 0.8749 - val_acc: 0.6067\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8063 - acc: 0.6408 - val_loss: 0.8618 - val_acc: 0.6000\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8052 - acc: 0.6456 - val_loss: 0.8642 - val_acc: 0.5973\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8020 - acc: 0.6393 - val_loss: 0.8445 - val_acc: 0.6147\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8010 - acc: 0.6390 - val_loss: 0.8452 - val_acc: 0.6153\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7989 - acc: 0.6453 - val_loss: 0.8519 - val_acc: 0.6080\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7970 - acc: 0.6442 - val_loss: 0.8453 - val_acc: 0.6080\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7930 - acc: 0.6428 - val_loss: 0.8405 - val_acc: 0.6213\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7919 - acc: 0.6430 - val_loss: 0.8462 - val_acc: 0.6120\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7911 - acc: 0.6439 - val_loss: 0.8409 - val_acc: 0.6180\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7893 - acc: 0.6445 - val_loss: 0.8456 - val_acc: 0.6107\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7882 - acc: 0.6485 - val_loss: 0.8456 - val_acc: 0.6080\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7862 - acc: 0.6510 - val_loss: 0.8635 - val_acc: 0.6120\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7818 - acc: 0.6510 - val_loss: 0.8389 - val_acc: 0.6233\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7797 - acc: 0.6510 - val_loss: 0.8429 - val_acc: 0.6107\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7779 - acc: 0.6559 - val_loss: 0.8465 - val_acc: 0.6120\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7788 - acc: 0.6468 - val_loss: 0.8689 - val_acc: 0.6000\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7729 - acc: 0.6579 - val_loss: 0.8477 - val_acc: 0.6187\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7733 - acc: 0.6576 - val_loss: 0.8604 - val_acc: 0.5973\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7739 - acc: 0.6576 - val_loss: 0.8377 - val_acc: 0.6093\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7694 - acc: 0.6553 - val_loss: 0.8296 - val_acc: 0.6213\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7693 - acc: 0.6605 - val_loss: 0.8272 - val_acc: 0.6220\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7648 - acc: 0.6613 - val_loss: 0.8443 - val_acc: 0.6193\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7631 - acc: 0.6625 - val_loss: 0.8268 - val_acc: 0.6280\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7636 - acc: 0.6610 - val_loss: 0.8284 - val_acc: 0.6200\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7606 - acc: 0.6619 - val_loss: 0.8693 - val_acc: 0.5973\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7613 - acc: 0.6659 - val_loss: 0.8599 - val_acc: 0.6013\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7582 - acc: 0.6679 - val_loss: 0.8906 - val_acc: 0.6200\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7554 - acc: 0.6673 - val_loss: 0.8229 - val_acc: 0.6300\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7540 - acc: 0.6690 - val_loss: 0.8435 - val_acc: 0.6207\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7524 - acc: 0.6688 - val_loss: 0.8270 - val_acc: 0.6260\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7482 - acc: 0.6716 - val_loss: 0.8572 - val_acc: 0.6200\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7478 - acc: 0.6713 - val_loss: 0.8303 - val_acc: 0.6280\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7473 - acc: 0.6719 - val_loss: 0.8306 - val_acc: 0.6227\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7473 - acc: 0.6705 - val_loss: 0.8262 - val_acc: 0.6247\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7416 - acc: 0.6799 - val_loss: 0.8198 - val_acc: 0.6280\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7391 - acc: 0.6779 - val_loss: 0.8628 - val_acc: 0.6147\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7418 - acc: 0.6719 - val_loss: 0.8237 - val_acc: 0.6267\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7391 - acc: 0.6742 - val_loss: 0.8313 - val_acc: 0.6280\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7326 - acc: 0.6791 - val_loss: 0.8624 - val_acc: 0.5947\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7377 - acc: 0.6771 - val_loss: 0.8231 - val_acc: 0.6267\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7309 - acc: 0.6865 - val_loss: 0.8270 - val_acc: 0.6327\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7312 - acc: 0.6828 - val_loss: 0.8168 - val_acc: 0.6367\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7270 - acc: 0.6851 - val_loss: 0.8486 - val_acc: 0.6260\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7296 - acc: 0.6851 - val_loss: 0.8257 - val_acc: 0.6280\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7229 - acc: 0.6865 - val_loss: 0.9050 - val_acc: 0.5987\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7280 - acc: 0.6845 - val_loss: 0.8257 - val_acc: 0.6307\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7253 - acc: 0.6871 - val_loss: 0.8292 - val_acc: 0.6293\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7194 - acc: 0.6862 - val_loss: 0.8460 - val_acc: 0.6220\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7187 - acc: 0.6879 - val_loss: 0.8169 - val_acc: 0.6300\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7182 - acc: 0.6939 - val_loss: 0.8492 - val_acc: 0.6080\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7157 - acc: 0.6985 - val_loss: 0.8198 - val_acc: 0.6260\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7147 - acc: 0.6825 - val_loss: 0.8982 - val_acc: 0.5967\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0476 - acc: 0.4990 - val_loss: 1.0375 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0372 - acc: 0.5004 - val_loss: 1.0350 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0342 - acc: 0.5004 - val_loss: 1.0321 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0314 - acc: 0.5004 - val_loss: 1.0282 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0278 - acc: 0.5004 - val_loss: 1.0266 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0247 - acc: 0.5004 - val_loss: 1.0238 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0212 - acc: 0.5004 - val_loss: 1.0183 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0169 - acc: 0.5004 - val_loss: 1.0127 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0125 - acc: 0.5004 - val_loss: 1.0083 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0077 - acc: 0.5007 - val_loss: 1.0075 - val_acc: 0.5040\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0039 - acc: 0.5030 - val_loss: 0.9991 - val_acc: 0.5033\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9991 - acc: 0.5067 - val_loss: 0.9953 - val_acc: 0.5040\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9942 - acc: 0.5096 - val_loss: 0.9890 - val_acc: 0.5080\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9877 - acc: 0.5161 - val_loss: 0.9806 - val_acc: 0.5100\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9845 - acc: 0.5193 - val_loss: 0.9775 - val_acc: 0.5367\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9772 - acc: 0.5276 - val_loss: 0.9782 - val_acc: 0.5453\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9712 - acc: 0.5299 - val_loss: 0.9787 - val_acc: 0.5387\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9677 - acc: 0.5347 - val_loss: 0.9603 - val_acc: 0.5327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9605 - acc: 0.5430 - val_loss: 0.9480 - val_acc: 0.5553\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9520 - acc: 0.5496 - val_loss: 0.9664 - val_acc: 0.5660\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.9496 - acc: 0.5547 - val_loss: 0.9659 - val_acc: 0.5487\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9389 - acc: 0.5616 - val_loss: 0.9386 - val_acc: 0.5433\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9366 - acc: 0.5639 - val_loss: 0.9504 - val_acc: 0.5527\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9287 - acc: 0.5756 - val_loss: 0.9302 - val_acc: 0.5547\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9215 - acc: 0.5742 - val_loss: 0.9168 - val_acc: 0.5927\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9143 - acc: 0.5816 - val_loss: 0.9122 - val_acc: 0.5933\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9081 - acc: 0.5785 - val_loss: 0.9039 - val_acc: 0.5873\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9019 - acc: 0.5810 - val_loss: 0.9006 - val_acc: 0.5940\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8972 - acc: 0.5873 - val_loss: 0.8950 - val_acc: 0.5893\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8940 - acc: 0.5887 - val_loss: 0.8947 - val_acc: 0.6013\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8857 - acc: 0.5882 - val_loss: 0.8881 - val_acc: 0.5887\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8823 - acc: 0.5942 - val_loss: 0.9021 - val_acc: 0.5880\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8803 - acc: 0.5899 - val_loss: 0.8772 - val_acc: 0.5947\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8752 - acc: 0.5930 - val_loss: 0.8804 - val_acc: 0.6007\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8695 - acc: 0.5947 - val_loss: 0.8817 - val_acc: 0.5940\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8662 - acc: 0.5987 - val_loss: 0.8817 - val_acc: 0.6047\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8633 - acc: 0.6070 - val_loss: 0.8843 - val_acc: 0.6020\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8598 - acc: 0.6002 - val_loss: 0.8841 - val_acc: 0.6047\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8578 - acc: 0.6087 - val_loss: 0.8987 - val_acc: 0.5827\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8555 - acc: 0.6042 - val_loss: 0.8685 - val_acc: 0.5960\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8509 - acc: 0.6056 - val_loss: 0.8602 - val_acc: 0.6173\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8491 - acc: 0.6102 - val_loss: 0.8837 - val_acc: 0.5973\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8455 - acc: 0.6093 - val_loss: 0.8670 - val_acc: 0.6013\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8429 - acc: 0.6125 - val_loss: 0.8601 - val_acc: 0.6080\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8386 - acc: 0.6096 - val_loss: 0.8970 - val_acc: 0.5840\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8384 - acc: 0.6133 - val_loss: 0.8668 - val_acc: 0.5973\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8363 - acc: 0.6153 - val_loss: 0.8508 - val_acc: 0.6220\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8314 - acc: 0.6159 - val_loss: 0.8754 - val_acc: 0.6027\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8317 - acc: 0.6199 - val_loss: 0.8649 - val_acc: 0.6173\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8269 - acc: 0.6216 - val_loss: 0.8624 - val_acc: 0.6173\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8235 - acc: 0.6236 - val_loss: 0.8530 - val_acc: 0.6180\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8220 - acc: 0.6230 - val_loss: 0.8503 - val_acc: 0.6107\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.8207 - acc: 0.6296 - val_loss: 0.8521 - val_acc: 0.6100\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8196 - acc: 0.6296 - val_loss: 0.8499 - val_acc: 0.6033\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8130 - acc: 0.6299 - val_loss: 0.8601 - val_acc: 0.6020\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8158 - acc: 0.6256 - val_loss: 0.8605 - val_acc: 0.6053\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8126 - acc: 0.6276 - val_loss: 0.8491 - val_acc: 0.6220\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8085 - acc: 0.6342 - val_loss: 0.8485 - val_acc: 0.6133\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8080 - acc: 0.6399 - val_loss: 0.8460 - val_acc: 0.6147\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8049 - acc: 0.6330 - val_loss: 0.8430 - val_acc: 0.6227\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8032 - acc: 0.6376 - val_loss: 0.8403 - val_acc: 0.6267\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8017 - acc: 0.6396 - val_loss: 0.8487 - val_acc: 0.6133\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7990 - acc: 0.6459 - val_loss: 0.8400 - val_acc: 0.6260\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7959 - acc: 0.6442 - val_loss: 0.8434 - val_acc: 0.6253\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7931 - acc: 0.6473 - val_loss: 0.8418 - val_acc: 0.6180\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7934 - acc: 0.6396 - val_loss: 0.8334 - val_acc: 0.6320\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7909 - acc: 0.6433 - val_loss: 0.8434 - val_acc: 0.6227\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7910 - acc: 0.6485 - val_loss: 0.8530 - val_acc: 0.6227\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7882 - acc: 0.6470 - val_loss: 0.8516 - val_acc: 0.6200\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7857 - acc: 0.6488 - val_loss: 0.8409 - val_acc: 0.6320\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7830 - acc: 0.6453 - val_loss: 0.8326 - val_acc: 0.6260\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7795 - acc: 0.6519 - val_loss: 0.8410 - val_acc: 0.6233\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7825 - acc: 0.6493 - val_loss: 0.8909 - val_acc: 0.6040\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7778 - acc: 0.6545 - val_loss: 0.8421 - val_acc: 0.6233\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7747 - acc: 0.6493 - val_loss: 0.8541 - val_acc: 0.6113\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7741 - acc: 0.6485 - val_loss: 0.8360 - val_acc: 0.6267\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7730 - acc: 0.6539 - val_loss: 0.8328 - val_acc: 0.6340\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7686 - acc: 0.6588 - val_loss: 0.8275 - val_acc: 0.6367\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7693 - acc: 0.6570 - val_loss: 0.8484 - val_acc: 0.6267\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7689 - acc: 0.6525 - val_loss: 0.8307 - val_acc: 0.6413\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7671 - acc: 0.6588 - val_loss: 0.8265 - val_acc: 0.6313\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7642 - acc: 0.6522 - val_loss: 0.8368 - val_acc: 0.6313\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7638 - acc: 0.6610 - val_loss: 0.8928 - val_acc: 0.5940\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7595 - acc: 0.6616 - val_loss: 0.8513 - val_acc: 0.6233\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7615 - acc: 0.6668 - val_loss: 0.8292 - val_acc: 0.6300\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7561 - acc: 0.6630 - val_loss: 0.8626 - val_acc: 0.6013\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7569 - acc: 0.6605 - val_loss: 0.8402 - val_acc: 0.6267\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7553 - acc: 0.6639 - val_loss: 0.8665 - val_acc: 0.6227\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7505 - acc: 0.6673 - val_loss: 0.8355 - val_acc: 0.6307\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 7s 2ms/step - loss: 0.7524 - acc: 0.6668 - val_loss: 0.8351 - val_acc: 0.6340\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7494 - acc: 0.6673 - val_loss: 0.8270 - val_acc: 0.6460\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0468 - acc: 0.4990 - val_loss: 1.0377 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0380 - acc: 0.5004 - val_loss: 1.0354 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0352 - acc: 0.5004 - val_loss: 1.0332 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0324 - acc: 0.5004 - val_loss: 1.0307 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0294 - acc: 0.5004 - val_loss: 1.0282 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0266 - acc: 0.5004 - val_loss: 1.0258 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0236 - acc: 0.5004 - val_loss: 1.0233 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0209 - acc: 0.5004 - val_loss: 1.0206 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0175 - acc: 0.5004 - val_loss: 1.0180 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0135 - acc: 0.5004 - val_loss: 1.0158 - val_acc: 0.5007\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0103 - acc: 0.5004 - val_loss: 1.0123 - val_acc: 0.5027\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0059 - acc: 0.5024 - val_loss: 1.0084 - val_acc: 0.5033\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0014 - acc: 0.5036 - val_loss: 1.0042 - val_acc: 0.5073\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9962 - acc: 0.5079 - val_loss: 0.9987 - val_acc: 0.5067\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9906 - acc: 0.5122 - val_loss: 0.9915 - val_acc: 0.5100\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9840 - acc: 0.5176 - val_loss: 0.9863 - val_acc: 0.5120\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9784 - acc: 0.5219 - val_loss: 0.9904 - val_acc: 0.5180\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9712 - acc: 0.5256 - val_loss: 0.9848 - val_acc: 0.5467\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9643 - acc: 0.5345 - val_loss: 0.9636 - val_acc: 0.5353\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9575 - acc: 0.5376 - val_loss: 0.9793 - val_acc: 0.5287\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9504 - acc: 0.5468 - val_loss: 0.9486 - val_acc: 0.5333\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9395 - acc: 0.5545 - val_loss: 0.9446 - val_acc: 0.5420\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9331 - acc: 0.5639 - val_loss: 0.9338 - val_acc: 0.5407\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9214 - acc: 0.5722 - val_loss: 0.9254 - val_acc: 0.5553\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9130 - acc: 0.5713 - val_loss: 1.0126 - val_acc: 0.4660\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.9147 - acc: 0.5708 - val_loss: 0.9145 - val_acc: 0.5653\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8992 - acc: 0.5831 - val_loss: 0.9401 - val_acc: 0.5533\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8932 - acc: 0.5931 - val_loss: 0.9296 - val_acc: 0.5527\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8855 - acc: 0.5882 - val_loss: 0.8963 - val_acc: 0.5707\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8802 - acc: 0.6025 - val_loss: 0.8919 - val_acc: 0.5760: 3s - loss: 0 - \n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8731 - acc: 0.6057 - val_loss: 0.8875 - val_acc: 0.5793\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8709 - acc: 0.5994 - val_loss: 0.8908 - val_acc: 0.5747\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8653 - acc: 0.6037 - val_loss: 0.8949 - val_acc: 0.5773\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8591 - acc: 0.6074 - val_loss: 0.8846 - val_acc: 0.5793\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8557 - acc: 0.6134 - val_loss: 0.8677 - val_acc: 0.5953\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8519 - acc: 0.6137 - val_loss: 0.8724 - val_acc: 0.5860\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8467 - acc: 0.6174 - val_loss: 0.8756 - val_acc: 0.5900\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8450 - acc: 0.6157 - val_loss: 0.8678 - val_acc: 0.5933\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8374 - acc: 0.6211 - val_loss: 0.8984 - val_acc: 0.5713\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8338 - acc: 0.6188 - val_loss: 0.8684 - val_acc: 0.5913\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8280 - acc: 0.6231 - val_loss: 0.8581 - val_acc: 0.5993\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8260 - acc: 0.6242 - val_loss: 0.8659 - val_acc: 0.5887\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8202 - acc: 0.6240 - val_loss: 0.8643 - val_acc: 0.5947\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8184 - acc: 0.6308 - val_loss: 0.8506 - val_acc: 0.5980\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8161 - acc: 0.6283 - val_loss: 0.8472 - val_acc: 0.5933\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8151 - acc: 0.6311 - val_loss: 0.8384 - val_acc: 0.6093\n",
      "Epoch 47/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8102 - acc: 0.6368 - val_loss: 0.8437 - val_acc: 0.6067\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8057 - acc: 0.6397 - val_loss: 0.8921 - val_acc: 0.5727\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8035 - acc: 0.6411 - val_loss: 0.8366 - val_acc: 0.6053\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.8001 - acc: 0.6443 - val_loss: 0.8860 - val_acc: 0.5807\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7991 - acc: 0.6374 - val_loss: 0.8716 - val_acc: 0.5993\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7943 - acc: 0.6471 - val_loss: 0.8392 - val_acc: 0.6100\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7932 - acc: 0.6434 - val_loss: 0.8275 - val_acc: 0.6167\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7883 - acc: 0.6494 - val_loss: 0.8560 - val_acc: 0.6087\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7848 - acc: 0.6468 - val_loss: 0.8722 - val_acc: 0.5813\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7852 - acc: 0.6511 - val_loss: 0.8573 - val_acc: 0.6107\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7810 - acc: 0.6488 - val_loss: 0.8213 - val_acc: 0.6200\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7785 - acc: 0.6531 - val_loss: 0.8557 - val_acc: 0.6047\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7782 - acc: 0.6548 - val_loss: 0.8336 - val_acc: 0.6227\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7734 - acc: 0.6506 - val_loss: 0.8342 - val_acc: 0.6227\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7691 - acc: 0.6611 - val_loss: 0.8232 - val_acc: 0.6267\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7691 - acc: 0.6609 - val_loss: 0.8207 - val_acc: 0.6340\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7652 - acc: 0.6560 - val_loss: 0.9085 - val_acc: 0.5960 0s - loss: 0.7661 \n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7631 - acc: 0.6574 - val_loss: 0.8240 - val_acc: 0.6133\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7612 - acc: 0.6620 - val_loss: 0.9216 - val_acc: 0.5680\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7621 - acc: 0.6591 - val_loss: 0.8288 - val_acc: 0.6213\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7565 - acc: 0.6649 - val_loss: 0.8255 - val_acc: 0.6073\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7552 - acc: 0.6663 - val_loss: 0.8107 - val_acc: 0.6253\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7527 - acc: 0.6689 - val_loss: 0.8131 - val_acc: 0.6213\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7495 - acc: 0.6786 - val_loss: 0.8122 - val_acc: 0.6213\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7493 - acc: 0.6694 - val_loss: 0.8207 - val_acc: 0.6320\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7461 - acc: 0.6709 - val_loss: 0.8760 - val_acc: 0.5887\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7452 - acc: 0.6729 - val_loss: 0.8154 - val_acc: 0.6167\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7417 - acc: 0.6757 - val_loss: 0.8122 - val_acc: 0.6253\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7365 - acc: 0.6769 - val_loss: 0.8440 - val_acc: 0.6107\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7379 - acc: 0.6794 - val_loss: 0.8438 - val_acc: 0.6007\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7311 - acc: 0.6809 - val_loss: 0.8227 - val_acc: 0.6227\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7328 - acc: 0.6786 - val_loss: 0.8056 - val_acc: 0.6360\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7270 - acc: 0.6803 - val_loss: 0.8071 - val_acc: 0.6347\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7252 - acc: 0.6823 - val_loss: 0.8346 - val_acc: 0.6187\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7257 - acc: 0.6789 - val_loss: 0.8351 - val_acc: 0.6180: 1s - los\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7226 - acc: 0.6829 - val_loss: 0.8097 - val_acc: 0.6367\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7184 - acc: 0.6869 - val_loss: 0.8788 - val_acc: 0.59802s - lo - ETA: 1s - loss: 0. - ETA: 0s - loss: 0.7176 - acc: 0.6 - ETA: 0s - loss: 0.7177 - acc: 0.686\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7175 - acc: 0.6872 - val_loss: 0.8429 - val_acc: 0.6247\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7184 - acc: 0.6863 - val_loss: 0.8342 - val_acc: 0.6267\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7151 - acc: 0.6917 - val_loss: 0.8259 - val_acc: 0.6153\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7132 - acc: 0.6906 - val_loss: 0.8875 - val_acc: 0.5753\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 0.7122 - acc: 0.6906 - val_loss: 0.8154 - val_acc: 0.6307\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 9s 3ms/step - loss: 1.0480 - acc: 0.4983 - val_loss: 1.0377 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0367 - acc: 0.5003 - val_loss: 1.0345 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0332 - acc: 0.5003 - val_loss: 1.0312 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0290 - acc: 0.5003 - val_loss: 1.0285 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0260 - acc: 0.5003 - val_loss: 1.0250 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0219 - acc: 0.5003 - val_loss: 1.0214 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0175 - acc: 0.5003 - val_loss: 1.0171 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0132 - acc: 0.5006 - val_loss: 1.0130 - val_acc: 0.5027\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0080 - acc: 0.5017 - val_loss: 1.0098 - val_acc: 0.5047\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0031 - acc: 0.5046 - val_loss: 1.0054 - val_acc: 0.5060A:\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9983 - acc: 0.5071 - val_loss: 0.9980 - val_acc: 0.5080\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9927 - acc: 0.5094 - val_loss: 0.9939 - val_acc: 0.5133\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9865 - acc: 0.5146 - val_loss: 0.9898 - val_acc: 0.5140\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9805 - acc: 0.5172 - val_loss: 0.9793 - val_acc: 0.5180\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9736 - acc: 0.5223 - val_loss: 0.9737 - val_acc: 0.5253\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9681 - acc: 0.5286 - val_loss: 0.9858 - val_acc: 0.5340\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9704 - acc: 0.5300 - val_loss: 0.9705 - val_acc: 0.5293: 2s - loss: 0.9700 - acc: 0.53 - ETA: 1s - loss: 0.9667 - acc: - ETA: 1s - los\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9586 - acc: 0.5363 - val_loss: 0.9570 - val_acc: 0.57530.9566 \n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9502 - acc: 0.5460 - val_loss: 0.9480 - val_acc: 0.5307\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9432 - acc: 0.5500 - val_loss: 0.9418 - val_acc: 0.5440 ETA: 4s - loss: 0.9347 - acc: - ETA: 3s - loss: 0.9430 - acc: 0.5 - ETA: 3s - loss: 0.9466 - acc: 0.5 - ETA: 3 - ETA: 1s - loss: 0\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9328 - acc: 0.5506 - val_loss: 0.9275 - val_acc: 0.5740\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9248 - acc: 0.5606 - val_loss: 0.9290 - val_acc: 0.5627\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9123 - acc: 0.5715 - val_loss: 0.9144 - val_acc: 0.5827 - acc: 0.5 - ETA: 4s - loss: 0.9120 - acc: 0.5 - ETA: 4s  - ETA: 2s - loss: 0.9148 - ac - ETA\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9057 - acc: 0.5700 - val_loss: 0.9493 - val_acc: 0.5560\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8989 - acc: 0.5815 - val_loss: 0.9161 - val_acc: 0.5653s: 0.\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8922 - acc: 0.5786 - val_loss: 0.9017 - val_acc: 0.58330.8 - ETA: 1s - \n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8860 - acc: 0.5849 - val_loss: 0.8919 - val_acc: 0.5767\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8829 - acc: 0.5855 - val_loss: 0.9062 - val_acc: 0.5713\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8752 - acc: 0.5849 - val_loss: 0.8868 - val_acc: 0.5800\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8703 - acc: 0.5958 - val_loss: 0.8812 - val_acc: 0.5913TA: 6s - loss: 0.\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8661 - acc: 0.5935 - val_loss: 0.9504 - val_acc: 0.5673\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8679 - acc: 0.5952 - val_loss: 0.8896 - val_acc: 0.5847 \n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8612 - acc: 0.5955 - val_loss: 0.8727 - val_acc: 0.5967\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8539 - acc: 0.6049 - val_loss: 0.9250 - val_acc: 0.5520\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8520 - acc: 0.6018 - val_loss: 0.9031 - val_acc: 0.5600\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8485 - acc: 0.6049 - val_loss: 0.8718 - val_acc: 0.5887oss: 0.8487 - acc: 0.606 - \n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8437 - acc: 0.6089 - val_loss: 0.8627 - val_acc: 0.6000\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8411 - acc: 0.6146 - val_loss: 0.8692 - val_acc: 0.5860\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8374 - acc: 0.6166 - val_loss: 0.8643 - val_acc: 0.5967\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8318 - acc: 0.6118 - val_loss: 0.8805 - val_acc: 0.5727\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8298 - acc: 0.6272 - val_loss: 0.8620 - val_acc: 0.5947\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8285 - acc: 0.6161 - val_loss: 0.8568 - val_acc: 0.6020\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8259 - acc: 0.6118 - val_loss: 0.8596 - val_acc: 0.5880\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8188 - acc: 0.6284 - val_loss: 0.8617 - val_acc: 0.5813\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8177 - acc: 0.6241 - val_loss: 0.8650 - val_acc: 0.5893\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8167 - acc: 0.6246 - val_loss: 0.8499 - val_acc: 0.6033\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8119 - acc: 0.6226 - val_loss: 0.8473 - val_acc: 0.6060 - lo - ETA: 1s - los - ETA: 0s - loss: 0.8122 - acc: 0.623\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8104 - acc: 0.6261 - val_loss: 0.8635 - val_acc: 0.5887\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8080 - acc: 0.6275 - val_loss: 0.8920 - val_acc: 0.5660\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8038 - acc: 0.6326 - val_loss: 0.8655 - val_acc: 0.5847\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8024 - acc: 0.6315 - val_loss: 0.8582 - val_acc: 0.5960\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7986 - acc: 0.6341 - val_loss: 0.8511 - val_acc: 0.6053\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7957 - acc: 0.6372 - val_loss: 0.8563 - val_acc: 0.6033\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7966 - acc: 0.6404 - val_loss: 0.8518 - val_acc: 0.5927\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7908 - acc: 0.6378 - val_loss: 0.8747 - val_acc: 0.5980\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7885 - acc: 0.6378 - val_loss: 0.8415 - val_acc: 0.5960\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7875 - acc: 0.6461 - val_loss: 0.8746 - val_acc: 0.5807\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7826 - acc: 0.6452 - val_loss: 0.8700 - val_acc: 0.5853\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7823 - acc: 0.6438 - val_loss: 0.8392 - val_acc: 0.6060\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7792 - acc: 0.6427 - val_loss: 0.8425 - val_acc: 0.5987\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7780 - acc: 0.6475 - val_loss: 0.8432 - val_acc: 0.6060\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7781 - acc: 0.6509 - val_loss: 0.8314 - val_acc: 0.612047 - acc:\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7726 - acc: 0.6564 - val_loss: 0.8507 - val_acc: 0.5960\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7733 - acc: 0.6444 - val_loss: 0.8559 - val_acc: 0.5967\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7702 - acc: 0.6532 - val_loss: 0.8347 - val_acc: 0.6120\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7629 - acc: 0.6601 - val_loss: 0.8337 - val_acc: 0.6000\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7637 - acc: 0.6515 - val_loss: 0.8381 - val_acc: 0.6127\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7621 - acc: 0.6558 - val_loss: 0.8393 - val_acc: 0.6033TA: 0s - loss: 0.7610 \n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7597 - acc: 0.6592 - val_loss: 0.8276 - val_acc: 0.6013\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7570 - acc: 0.6630 - val_loss: 0.8509 - val_acc: 0.6087\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7577 - acc: 0.6587 - val_loss: 0.8347 - val_acc: 0.6120\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7503 - acc: 0.6687 - val_loss: 0.8343 - val_acc: 0.6020A: 1s - lo\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7499 - acc: 0.6652 - val_loss: 0.8298 - val_acc: 0.6100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7487 - acc: 0.6635 - val_loss: 0.8365 - val_acc: 0.6007\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7476 - acc: 0.6552 - val_loss: 0.8449 - val_acc: 0.6020\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7439 - acc: 0.6650 - val_loss: 0.8242 - val_acc: 0.6060\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7418 - acc: 0.6687 - val_loss: 0.8275 - val_acc: 0.6047 loss - ETA: 3s - los - ETA: 2s - loss: 0.7340 - acc:  - ETA: 1s - loss: 0.73 - ETA: 0s - loss: 0.7410 - \n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7426 - acc: 0.6712 - val_loss: 0.8500 - val_acc: 0.5980\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7394 - acc: 0.6698 - val_loss: 0.8396 - val_acc: 0.6047\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7339 - acc: 0.6732 - val_loss: 0.8506 - val_acc: 0.6060\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7353 - acc: 0.6755 - val_loss: 0.8504 - val_acc: 0.59532s - loss: 0.7278 - acc: 0\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7356 - acc: 0.6721 - val_loss: 0.8353 - val_acc: 0.6087\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7273 - acc: 0.6727 - val_loss: 0.8317 - val_acc: 0.6093 - ETA: 1s - l\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7242 - acc: 0.6741 - val_loss: 0.8255 - val_acc: 0.6153: 0s - loss: 0.7275 - \n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7266 - acc: 0.6801 - val_loss: 0.8221 - val_acc: 0.6127\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7200 - acc: 0.6852 - val_loss: 0.8325 - val_acc: 0.6120\n",
      "Epoch 87/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7239 - acc: 0.6832 - val_loss: 0.8293 - val_acc: 0.6080\n",
      "Epoch 88/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7221 - acc: 0.6812 - val_loss: 0.8199 - val_acc: 0.6187\n",
      "Epoch 89/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7167 - acc: 0.6830 - val_loss: 0.8222 - val_acc: 0.6127\n",
      "Epoch 90/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7115 - acc: 0.6887 - val_loss: 0.8323 - val_acc: 0.6093\n",
      "Epoch 91/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7106 - acc: 0.6898 - val_loss: 0.8248 - val_acc: 0.6127\n",
      "Epoch 92/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7131 - acc: 0.6864 - val_loss: 0.8590 - val_acc: 0.5953\n",
      "Epoch 93/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7087 - acc: 0.6938 - val_loss: 0.8894 - val_acc: 0.5800\n",
      "Epoch 94/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7077 - acc: 0.6890 - val_loss: 0.8258 - val_acc: 0.6233\n",
      "Epoch 95/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7038 - acc: 0.6967 - val_loss: 0.8174 - val_acc: 0.6187\n",
      "Epoch 96/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7003 - acc: 0.6961 - val_loss: 0.8604 - val_acc: 0.5967 6s - loss: 0.6 - ETA: 2s - loss: 0.6818 - - ETA: 1s - loss: 0 - ETA: 0s - loss: 0.7012 - acc\n",
      "Epoch 97/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7028 - acc: 0.6921 - val_loss: 0.9052 - val_acc: 0.5627\n",
      "Epoch 98/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6969 - acc: 0.6955 - val_loss: 0.8246 - val_acc: 0.6167\n",
      "Epoch 99/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6996 - acc: 0.6975 - val_loss: 0.8324 - val_acc: 0.6200\n",
      "Epoch 100/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6934 - acc: 0.7033 - val_loss: 0.8284 - val_acc: 0.6220\n",
      "Epoch 101/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6944 - acc: 0.6935 - val_loss: 0.8252 - val_acc: 0.6193\n",
      "Epoch 102/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6915 - acc: 0.6970 - val_loss: 0.8147 - val_acc: 0.6247\n",
      "Epoch 103/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6868 - acc: 0.7067 - val_loss: 0.8806 - val_acc: 0.6007A: 3s - loss: 0.6871 - acc: 0 - ETA: 3s - loss: 0.67 - ETA: 2s - lo - ETA: 0s - loss: 0.6822 - acc\n",
      "Epoch 104/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6868 - acc: 0.7013 - val_loss: 0.8318 - val_acc: 0.6260 l\n",
      "Epoch 105/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6897 - acc: 0.6995 - val_loss: 0.8296 - val_acc: 0.6180\n",
      "Epoch 106/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6803 - acc: 0.7055 - val_loss: 0.8151 - val_acc: 0.6227\n",
      "Epoch 107/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6801 - acc: 0.7010 - val_loss: 0.8611 - val_acc: 0.6113\n",
      "Epoch 108/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6754 - acc: 0.7093 - val_loss: 0.8966 - val_acc: 0.5720\n",
      "Epoch 109/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6754 - acc: 0.7047 - val_loss: 0.9405 - val_acc: 0.5587\n",
      "Epoch 110/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6745 - acc: 0.7127 - val_loss: 0.8425 - val_acc: 0.6120\n",
      "Epoch 111/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6695 - acc: 0.7144 - val_loss: 0.8419 - val_acc: 0.6233\n",
      "Epoch 112/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.6678 - acc: 0.7070 - val_loss: 0.8282 - val_acc: 0.6280\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 1.0478 - acc: 0.4990 - val_loss: 1.0373 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0369 - acc: 0.5004 - val_loss: 1.0352 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0336 - acc: 0.5004 - val_loss: 1.0325 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0305 - acc: 0.5004 - val_loss: 1.0287 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0266 - acc: 0.5004 - val_loss: 1.0271 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0232 - acc: 0.5004 - val_loss: 1.0246 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0195 - acc: 0.5004 - val_loss: 1.0189 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0149 - acc: 0.5007 - val_loss: 1.0142 - val_acc: 0.5007- ac - ETA: \n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0103 - acc: 0.5021 - val_loss: 1.0101 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0052 - acc: 0.5044 - val_loss: 1.0101 - val_acc: 0.5073\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0015 - acc: 0.5081 - val_loss: 1.0022 - val_acc: 0.5067\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9963 - acc: 0.5104 - val_loss: 0.9970 - val_acc: 0.5073\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9910 - acc: 0.5121 - val_loss: 0.9896 - val_acc: 0.5093s\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9856 - acc: 0.5170 - val_loss: 0.9873 - val_acc: 0.5127\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9808 - acc: 0.5204 - val_loss: 0.9818 - val_acc: 0.5273\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9731 - acc: 0.5279 - val_loss: 0.9906 - val_acc: 0.5440s: 0.9710 - acc\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9661 - acc: 0.5322 - val_loss: 0.9681 - val_acc: 0.5200 6s - loss: 0.97 - ETA: 2s - loss: - ETA: 1s - loss: 0.9640 - acc: - ETA: 0s - loss: 0.9650 - ac\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9622 - acc: 0.5367 - val_loss: 0.9615 - val_acc: 0.5360\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9598 - acc: 0.5393 - val_loss: 0.9679 - val_acc: 0.5573c: 0.532  - ETA: 0s - loss: 0.9639\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9494 - acc: 0.5550 - val_loss: 0.9435 - val_acc: 0.5447- acc: - ETA: 1s - loss: 0.946 - ETA: 0s - loss: 0.9488 \n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9422 - acc: 0.5547 - val_loss: 0.9601 - val_acc: 0.5387\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9309 - acc: 0.5647 - val_loss: 0.9604 - val_acc: 0.5420\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9260 - acc: 0.5673 - val_loss: 0.9491 - val_acc: 0.5593\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9151 - acc: 0.5762 - val_loss: 0.9339 - val_acc: 0.5620ETA: 0s - loss: 0.9142 \n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9097 - acc: 0.5779 - val_loss: 0.9158 - val_acc: 0.5713\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8987 - acc: 0.5893 - val_loss: 0.9154 - val_acc: 0.5713 - ETA: 0s - loss: 0.8969 - acc: 0.5\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8935 - acc: 0.5876 - val_loss: 0.8989 - val_acc: 0.5827\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8877 - acc: 0.5910 - val_loss: 0.8971 - val_acc: 0.5767\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8807 - acc: 0.5905 - val_loss: 0.8975 - val_acc: 0.5847\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8783 - acc: 0.5947 - val_loss: 0.8994 - val_acc: 0.5827: 2s - loss: 0.8662 - acc: 0.6\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8691 - acc: 0.6002 - val_loss: 0.8823 - val_acc: 0.5887\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8660 - acc: 0.5999 - val_loss: 0.8948 - val_acc: 0.5780\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8622 - acc: 0.6036 - val_loss: 0.8790 - val_acc: 0.5953\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8569 - acc: 0.6102 - val_loss: 0.8761 - val_acc: 0.5940\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8519 - acc: 0.6110 - val_loss: 0.8740 - val_acc: 0.5873\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8469 - acc: 0.6113 - val_loss: 0.8743 - val_acc: 0.59070 - ETA: 1s - loss: 0.84\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8428 - acc: 0.6176 - val_loss: 0.8849 - val_acc: 0.5927\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8404 - acc: 0.6147 - val_loss: 0.8722 - val_acc: 0.5907\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8374 - acc: 0.6205 - val_loss: 0.8867 - val_acc: 0.5827\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8360 - acc: 0.6233 - val_loss: 0.8606 - val_acc: 0.6027oss: 0.8358 - acc: 0.623\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8287 - acc: 0.6176 - val_loss: 0.8560 - val_acc: 0.6047\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8261 - acc: 0.6256 - val_loss: 0.8887 - val_acc: 0.5833\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8225 - acc: 0.6302 - val_loss: 0.8567 - val_acc: 0.6013\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8202 - acc: 0.6265 - val_loss: 0.8689 - val_acc: 0.6027: 5s - loss: 0.8568 - - ETA: 4s - loss: 0.839 - ETA: 3s - loss: 0.8281 - ETA: 0s - loss: 0.8190 - acc: \n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8166 - acc: 0.6305 - val_loss: 0.9013 - val_acc: 0.5480\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8139 - acc: 0.6288 - val_loss: 0.8601 - val_acc: 0.5900\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8106 - acc: 0.6345 - val_loss: 0.8471 - val_acc: 0.6060\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8054 - acc: 0.6362 - val_loss: 0.8503 - val_acc: 0.61200.80\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8032 - acc: 0.6385 - val_loss: 0.8688 - val_acc: 0.6060\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7992 - acc: 0.6430 - val_loss: 0.8435 - val_acc: 0.6087\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7975 - acc: 0.6419 - val_loss: 0.8420 - val_acc: 0.6113\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7948 - acc: 0.6399 - val_loss: 0.8531 - val_acc: 0.6060\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7917 - acc: 0.6453 - val_loss: 0.8380 - val_acc: 0.6200\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7887 - acc: 0.6425 - val_loss: 0.8399 - val_acc: 0.6093\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7840 - acc: 0.6482 - val_loss: 0.8431 - val_acc: 0.6073\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7851 - acc: 0.6465 - val_loss: 0.8565 - val_acc: 0.5907\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7832 - acc: 0.6470 - val_loss: 0.8622 - val_acc: 0.6020\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7796 - acc: 0.6476 - val_loss: 0.8743 - val_acc: 0.5833\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7786 - acc: 0.6502 - val_loss: 0.8422 - val_acc: 0.6067ETA: 1s - l\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7746 - acc: 0.6522 - val_loss: 0.8309 - val_acc: 0.6193\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7720 - acc: 0.6488 - val_loss: 0.8353 - val_acc: 0.6167 loss: 0.7703 - a\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7687 - acc: 0.6565 - val_loss: 0.8413 - val_acc: 0.6080.7698 - acc: \n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7689 - acc: 0.6553 - val_loss: 0.8309 - val_acc: 0.6180\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7637 - acc: 0.6576 - val_loss: 0.8312 - val_acc: 0.6220\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7630 - acc: 0.6619 - val_loss: 0.8301 - val_acc: 0.6133\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7597 - acc: 0.6642 - val_loss: 0.8275 - val_acc: 0.6213\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7587 - acc: 0.6696 - val_loss: 0.8390 - val_acc: 0.6120A: 0s - loss: 0.7515\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7574 - acc: 0.6648 - val_loss: 0.8470 - val_acc: 0.6067\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7535 - acc: 0.6653 - val_loss: 0.8346 - val_acc: 0.6193 - loss: 0.7573 - \n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7538 - acc: 0.6625 - val_loss: 0.8256 - val_acc: 0.6253\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7498 - acc: 0.6619 - val_loss: 0.8376 - val_acc: 0.6187\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7456 - acc: 0.6733 - val_loss: 0.8519 - val_acc: 0.6140\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7484 - acc: 0.6639 - val_loss: 0.8368 - val_acc: 0.6173\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7419 - acc: 0.6745 - val_loss: 0.8283 - val_acc: 0.6180\n",
      "Epoch 75/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7418 - acc: 0.6722 - val_loss: 0.8386 - val_acc: 0.6073\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7412 - acc: 0.6765 - val_loss: 0.8265 - val_acc: 0.6300 loss: 0.73 - \n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7370 - acc: 0.6728 - val_loss: 0.8190 - val_acc: 0.6247\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7372 - acc: 0.6753 - val_loss: 0.8179 - val_acc: 0.6260\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7320 - acc: 0.6788 - val_loss: 0.8456 - val_acc: 0.6060\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7333 - acc: 0.6773 - val_loss: 0.8328 - val_acc: 0.6227\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7331 - acc: 0.6730 - val_loss: 0.8266 - val_acc: 0.6200\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7297 - acc: 0.6873 - val_loss: 0.8700 - val_acc: 0.5893\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7313 - acc: 0.6751 - val_loss: 0.8357 - val_acc: 0.6080\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7260 - acc: 0.6779 - val_loss: 0.8839 - val_acc: 0.6147\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7216 - acc: 0.6845 - val_loss: 0.8168 - val_acc: 0.6327\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7222 - acc: 0.6856 - val_loss: 0.8306 - val_acc: 0.6147A: 2s - loss: 0.7095 - - ETA: 1s - loss: 0.7189 - acc - ETA: 1s - loss\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7220 - acc: 0.6893 - val_loss: 0.8215 - val_acc: 0.6293\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7177 - acc: 0.6885 - val_loss: 0.8669 - val_acc: 0.6173\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7181 - acc: 0.6851 - val_loss: 0.8209 - val_acc: 0.6247\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7161 - acc: 0.6876 - val_loss: 0.8175 - val_acc: 0.6287\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7123 - acc: 0.6945 - val_loss: 0.8309 - val_acc: 0.6147\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7074 - acc: 0.6965 - val_loss: 0.8226 - val_acc: 0.6300\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7084 - acc: 0.6979 - val_loss: 0.8430 - val_acc: 0.6213\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7100 - acc: 0.6993 - val_loss: 0.8160 - val_acc: 0.6293 loss: 0.7291 - acc - \n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7053 - acc: 0.6973 - val_loss: 0.8293 - val_acc: 0.6333\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6979 - acc: 0.6993 - val_loss: 1.0156 - val_acc: 0.5127\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7057 - acc: 0.6942 - val_loss: 0.8291 - val_acc: 0.6287\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6953 - acc: 0.6988 - val_loss: 0.8189 - val_acc: 0.6287\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6949 - acc: 0.7002 - val_loss: 0.8125 - val_acc: 0.6367\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6971 - acc: 0.6999 - val_loss: 0.8143 - val_acc: 0.6387\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6942 - acc: 0.6953 - val_loss: 0.8484 - val_acc: 0.6067\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6876 - acc: 0.7033 - val_loss: 0.8638 - val_acc: 0.6107\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6891 - acc: 0.7028 - val_loss: 0.8287 - val_acc: 0.6207\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6890 - acc: 0.7036 - val_loss: 0.8283 - val_acc: 0.6327\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6835 - acc: 0.7076 - val_loss: 0.8331 - val_acc: 0.6167\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6836 - acc: 0.7079 - val_loss: 0.8344 - val_acc: 0.6207\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6825 - acc: 0.7042 - val_loss: 0.8453 - val_acc: 0.6160\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6810 - acc: 0.7171 - val_loss: 0.8238 - val_acc: 0.6320\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6786 - acc: 0.7148 - val_loss: 0.8716 - val_acc: 0.6167\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 1.0477 - acc: 0.4996 - val_loss: 1.0372 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0370 - acc: 0.5004 - val_loss: 1.0346 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0339 - acc: 0.5004 - val_loss: 1.0317 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0310 - acc: 0.5004 - val_loss: 1.0277 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0273 - acc: 0.5004 - val_loss: 1.0259 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0241 - acc: 0.5004 - val_loss: 1.0228 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0204 - acc: 0.5004 - val_loss: 1.0172 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0160 - acc: 0.5004 - val_loss: 1.0118 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0115 - acc: 0.5010 - val_loss: 1.0074 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0066 - acc: 0.5027 - val_loss: 1.0051 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0027 - acc: 0.5061 - val_loss: 0.9989 - val_acc: 0.5053\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9976 - acc: 0.5087 - val_loss: 0.9939 - val_acc: 0.5073\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9924 - acc: 0.5116 - val_loss: 0.9849 - val_acc: 0.5127\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9864 - acc: 0.5147 - val_loss: 0.9828 - val_acc: 0.5127\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9823 - acc: 0.5193 - val_loss: 0.9834 - val_acc: 0.5367\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9759 - acc: 0.5287 - val_loss: 0.9670 - val_acc: 0.5387\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9689 - acc: 0.5313 - val_loss: 0.9576 - val_acc: 0.5273\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9630 - acc: 0.5382 - val_loss: 0.9489 - val_acc: 0.5353\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9581 - acc: 0.5430 - val_loss: 0.9434 - val_acc: 0.5473\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9481 - acc: 0.5519 - val_loss: 0.9363 - val_acc: 0.5500\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9423 - acc: 0.5524 - val_loss: 0.9987 - val_acc: 0.4947\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9324 - acc: 0.5550 - val_loss: 0.9355 - val_acc: 0.5553\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9235 - acc: 0.5616 - val_loss: 0.9421 - val_acc: 0.5593\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9137 - acc: 0.5682 - val_loss: 0.9184 - val_acc: 0.5607\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9070 - acc: 0.5724 - val_loss: 0.9023 - val_acc: 0.5893\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8981 - acc: 0.5776 - val_loss: 0.8931 - val_acc: 0.5900\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8931 - acc: 0.5765 - val_loss: 0.8889 - val_acc: 0.5927\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8864 - acc: 0.5839 - val_loss: 0.8868 - val_acc: 0.5827\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8824 - acc: 0.5859 - val_loss: 0.8836 - val_acc: 0.5840\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8778 - acc: 0.5879 - val_loss: 0.8787 - val_acc: 0.5860\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8703 - acc: 0.5965 - val_loss: 0.8711 - val_acc: 0.6013\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8675 - acc: 0.5987 - val_loss: 0.8991 - val_acc: 0.5800\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8629 - acc: 0.5965 - val_loss: 0.8690 - val_acc: 0.5967\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8589 - acc: 0.5985 - val_loss: 0.8634 - val_acc: 0.5987\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8534 - acc: 0.5990 - val_loss: 0.8608 - val_acc: 0.6067\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8494 - acc: 0.6093 - val_loss: 0.8702 - val_acc: 0.5980\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8456 - acc: 0.6125 - val_loss: 0.8777 - val_acc: 0.5940\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8438 - acc: 0.6090 - val_loss: 0.8643 - val_acc: 0.5940\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8402 - acc: 0.6136 - val_loss: 0.9208 - val_acc: 0.5627\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8402 - acc: 0.6122 - val_loss: 0.8531 - val_acc: 0.6120\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8322 - acc: 0.6213 - val_loss: 0.8490 - val_acc: 0.6127\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8307 - acc: 0.6170 - val_loss: 0.8660 - val_acc: 0.5940\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8276 - acc: 0.6247 - val_loss: 0.8481 - val_acc: 0.6067\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8240 - acc: 0.6216 - val_loss: 0.8655 - val_acc: 0.6033\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8209 - acc: 0.6202 - val_loss: 0.8699 - val_acc: 0.5787\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8190 - acc: 0.6225 - val_loss: 0.8493 - val_acc: 0.6033\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8167 - acc: 0.6308 - val_loss: 0.8367 - val_acc: 0.6147\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8121 - acc: 0.6339 - val_loss: 0.8530 - val_acc: 0.6113\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8095 - acc: 0.6290 - val_loss: 0.8635 - val_acc: 0.6100\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8082 - acc: 0.6353 - val_loss: 0.8404 - val_acc: 0.6093\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8049 - acc: 0.6359 - val_loss: 0.8375 - val_acc: 0.6113\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8000 - acc: 0.6370 - val_loss: 0.8513 - val_acc: 0.6027\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8002 - acc: 0.6350 - val_loss: 0.8343 - val_acc: 0.6140\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7963 - acc: 0.6325 - val_loss: 0.8318 - val_acc: 0.6200\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7913 - acc: 0.6385 - val_loss: 0.8554 - val_acc: 0.5980\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7937 - acc: 0.6356 - val_loss: 0.8593 - val_acc: 0.5993\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7905 - acc: 0.6396 - val_loss: 0.8549 - val_acc: 0.5900\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7883 - acc: 0.6399 - val_loss: 0.8528 - val_acc: 0.6040\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7878 - acc: 0.6410 - val_loss: 0.8490 - val_acc: 0.6027\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7820 - acc: 0.6482 - val_loss: 0.8302 - val_acc: 0.6127\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7802 - acc: 0.6439 - val_loss: 0.8329 - val_acc: 0.6113\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7781 - acc: 0.6439 - val_loss: 0.8338 - val_acc: 0.6147\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7768 - acc: 0.6459 - val_loss: 0.8255 - val_acc: 0.6167\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7738 - acc: 0.6499 - val_loss: 0.8213 - val_acc: 0.6260\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7700 - acc: 0.6505 - val_loss: 0.8282 - val_acc: 0.6207\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7701 - acc: 0.6456 - val_loss: 0.8201 - val_acc: 0.6240\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7684 - acc: 0.6510 - val_loss: 0.8296 - val_acc: 0.6133\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7673 - acc: 0.6530 - val_loss: 0.8575 - val_acc: 0.5900\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7640 - acc: 0.6553 - val_loss: 0.8453 - val_acc: 0.6093\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7626 - acc: 0.6510 - val_loss: 0.8169 - val_acc: 0.6233\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7592 - acc: 0.6582 - val_loss: 0.8259 - val_acc: 0.6153\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7540 - acc: 0.6625 - val_loss: 0.8574 - val_acc: 0.6087\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7576 - acc: 0.6562 - val_loss: 0.8250 - val_acc: 0.6120\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7509 - acc: 0.6628 - val_loss: 0.8271 - val_acc: 0.6253\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7521 - acc: 0.6602 - val_loss: 0.8834 - val_acc: 0.5913\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7495 - acc: 0.6625 - val_loss: 0.8150 - val_acc: 0.6240\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7456 - acc: 0.6628 - val_loss: 0.8124 - val_acc: 0.6193\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7464 - acc: 0.6679 - val_loss: 0.8100 - val_acc: 0.6213\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7420 - acc: 0.6622 - val_loss: 0.8194 - val_acc: 0.6207\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7401 - acc: 0.6648 - val_loss: 0.8116 - val_acc: 0.6273\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7430 - acc: 0.6679 - val_loss: 0.8166 - val_acc: 0.6247\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7381 - acc: 0.6693 - val_loss: 0.8453 - val_acc: 0.6073\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7383 - acc: 0.6710 - val_loss: 0.8151 - val_acc: 0.6260\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7342 - acc: 0.6753 - val_loss: 0.8780 - val_acc: 0.5973\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7313 - acc: 0.6791 - val_loss: 0.8063 - val_acc: 0.6200\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7290 - acc: 0.6756 - val_loss: 0.8232 - val_acc: 0.6273\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7292 - acc: 0.6756 - val_loss: 0.8085 - val_acc: 0.6300\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7253 - acc: 0.6768 - val_loss: 0.8983 - val_acc: 0.6093\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7270 - acc: 0.6771 - val_loss: 0.8180 - val_acc: 0.6200\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7211 - acc: 0.6730 - val_loss: 0.8167 - val_acc: 0.6267\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7246 - acc: 0.6751 - val_loss: 0.8159 - val_acc: 0.6287\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7166 - acc: 0.6859 - val_loss: 0.8041 - val_acc: 0.6320\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7130 - acc: 0.6825 - val_loss: 0.8380 - val_acc: 0.6167\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7188 - acc: 0.6816 - val_loss: 0.8030 - val_acc: 0.6293\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7121 - acc: 0.6816 - val_loss: 0.8153 - val_acc: 0.6240\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7040 - acc: 0.6919 - val_loss: 0.8393 - val_acc: 0.6007\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7126 - acc: 0.6848 - val_loss: 0.8124 - val_acc: 0.6300\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7048 - acc: 0.6876 - val_loss: 0.8043 - val_acc: 0.6253\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6999 - acc: 0.6919 - val_loss: 0.8001 - val_acc: 0.6320\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7010 - acc: 0.6925 - val_loss: 0.8073 - val_acc: 0.6240\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7041 - acc: 0.6871 - val_loss: 0.8160 - val_acc: 0.6273\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6964 - acc: 0.6956 - val_loss: 0.8428 - val_acc: 0.6227\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6980 - acc: 0.6931 - val_loss: 0.8164 - val_acc: 0.6360\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6971 - acc: 0.6919 - val_loss: 0.8063 - val_acc: 0.6273\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6899 - acc: 0.6956 - val_loss: 0.8345 - val_acc: 0.6267\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6895 - acc: 0.6959 - val_loss: 0.8055 - val_acc: 0.6220\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6895 - acc: 0.6985 - val_loss: 0.8467 - val_acc: 0.6047\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6876 - acc: 0.7073 - val_loss: 0.8098 - val_acc: 0.6127\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6869 - acc: 0.6982 - val_loss: 0.8494 - val_acc: 0.6227\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 1.0477 - acc: 0.4990 - val_loss: 1.0374 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0372 - acc: 0.5004 - val_loss: 1.0348 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0344 - acc: 0.5004 - val_loss: 1.0319 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0317 - acc: 0.5004 - val_loss: 1.0280 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0282 - acc: 0.5004 - val_loss: 1.0263 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0253 - acc: 0.5004 - val_loss: 1.0234 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0220 - acc: 0.5004 - val_loss: 1.0182 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0178 - acc: 0.5004 - val_loss: 1.0125 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0136 - acc: 0.5004 - val_loss: 1.0081 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0089 - acc: 0.5013 - val_loss: 1.0051 - val_acc: 0.5033\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0051 - acc: 0.5033 - val_loss: 0.9995 - val_acc: 0.5047\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0003 - acc: 0.5050 - val_loss: 0.9955 - val_acc: 0.5040\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9957 - acc: 0.5081 - val_loss: 0.9864 - val_acc: 0.5100\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9911 - acc: 0.5130 - val_loss: 0.9828 - val_acc: 0.5100\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9859 - acc: 0.5161 - val_loss: 0.9842 - val_acc: 0.5327\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9779 - acc: 0.5236 - val_loss: 0.9803 - val_acc: 0.5393\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9705 - acc: 0.5287 - val_loss: 0.9602 - val_acc: 0.5287\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9679 - acc: 0.5367 - val_loss: 0.9541 - val_acc: 0.5340\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9633 - acc: 0.5370 - val_loss: 0.9442 - val_acc: 0.5313\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9522 - acc: 0.5493 - val_loss: 0.9511 - val_acc: 0.5627\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9462 - acc: 0.5484 - val_loss: 0.9837 - val_acc: 0.5473\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9329 - acc: 0.5567 - val_loss: 0.9379 - val_acc: 0.5447\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9282 - acc: 0.5610 - val_loss: 0.9359 - val_acc: 0.5587\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9162 - acc: 0.5670 - val_loss: 0.9197 - val_acc: 0.5580\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9096 - acc: 0.5713 - val_loss: 0.9033 - val_acc: 0.5940\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9012 - acc: 0.5719 - val_loss: 0.8991 - val_acc: 0.5853\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8957 - acc: 0.5825 - val_loss: 0.8992 - val_acc: 0.5860\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8890 - acc: 0.5810 - val_loss: 0.8845 - val_acc: 0.5993\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8831 - acc: 0.5833 - val_loss: 0.8831 - val_acc: 0.5880\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8795 - acc: 0.5870 - val_loss: 0.8794 - val_acc: 0.5967\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8715 - acc: 0.5885 - val_loss: 0.8712 - val_acc: 0.5960\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8670 - acc: 0.5999 - val_loss: 0.8765 - val_acc: 0.6020\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8635 - acc: 0.5962 - val_loss: 0.8650 - val_acc: 0.6047\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8586 - acc: 0.5970 - val_loss: 0.8713 - val_acc: 0.6033\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8532 - acc: 0.5962 - val_loss: 0.8641 - val_acc: 0.6013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8491 - acc: 0.6133 - val_loss: 0.8675 - val_acc: 0.6000\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8464 - acc: 0.6150 - val_loss: 0.8830 - val_acc: 0.5980\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8430 - acc: 0.6087 - val_loss: 0.8735 - val_acc: 0.6020\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8386 - acc: 0.6139 - val_loss: 0.8854 - val_acc: 0.5887\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8357 - acc: 0.6130 - val_loss: 0.8585 - val_acc: 0.6053\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8319 - acc: 0.6153 - val_loss: 0.8474 - val_acc: 0.6060\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8315 - acc: 0.6147 - val_loss: 0.8868 - val_acc: 0.5920\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8286 - acc: 0.6170 - val_loss: 0.8522 - val_acc: 0.6013\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8243 - acc: 0.6270 - val_loss: 0.8465 - val_acc: 0.6160\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8192 - acc: 0.6230 - val_loss: 0.9037 - val_acc: 0.5620\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8174 - acc: 0.6285 - val_loss: 0.8508 - val_acc: 0.5993\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8166 - acc: 0.6259 - val_loss: 0.8389 - val_acc: 0.6273\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8103 - acc: 0.6333 - val_loss: 0.8471 - val_acc: 0.6033\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8100 - acc: 0.6279 - val_loss: 0.8499 - val_acc: 0.6160\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8057 - acc: 0.6325 - val_loss: 0.8422 - val_acc: 0.6180\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8008 - acc: 0.6342 - val_loss: 0.8378 - val_acc: 0.6167\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7966 - acc: 0.6328 - val_loss: 0.8347 - val_acc: 0.6200\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7966 - acc: 0.6370 - val_loss: 0.8395 - val_acc: 0.6127\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7944 - acc: 0.6356 - val_loss: 0.8362 - val_acc: 0.6173\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7873 - acc: 0.6490 - val_loss: 0.8444 - val_acc: 0.6253\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7901 - acc: 0.6376 - val_loss: 0.8481 - val_acc: 0.6067\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7864 - acc: 0.6430 - val_loss: 0.8388 - val_acc: 0.6140\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7834 - acc: 0.6448 - val_loss: 0.8429 - val_acc: 0.6267\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7821 - acc: 0.6473 - val_loss: 0.8394 - val_acc: 0.6220\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7784 - acc: 0.6502 - val_loss: 0.8245 - val_acc: 0.6233\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7757 - acc: 0.6465 - val_loss: 0.8242 - val_acc: 0.6140\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7750 - acc: 0.6499 - val_loss: 0.8315 - val_acc: 0.6300\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7701 - acc: 0.6548 - val_loss: 0.8276 - val_acc: 0.6247\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7729 - acc: 0.6596 - val_loss: 0.8292 - val_acc: 0.6300\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7647 - acc: 0.6576 - val_loss: 0.8275 - val_acc: 0.6253\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7635 - acc: 0.6533 - val_loss: 0.8377 - val_acc: 0.6213\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7598 - acc: 0.6539 - val_loss: 0.8276 - val_acc: 0.6293\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7621 - acc: 0.6585 - val_loss: 0.8562 - val_acc: 0.5933\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7570 - acc: 0.6633 - val_loss: 0.8541 - val_acc: 0.6087\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7600 - acc: 0.6562 - val_loss: 0.8238 - val_acc: 0.6287\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7530 - acc: 0.6648 - val_loss: 0.8140 - val_acc: 0.6313\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7480 - acc: 0.6653 - val_loss: 0.8301 - val_acc: 0.6193\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7516 - acc: 0.6622 - val_loss: 0.8470 - val_acc: 0.6140\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7464 - acc: 0.6679 - val_loss: 0.8224 - val_acc: 0.6207\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7442 - acc: 0.6625 - val_loss: 0.8220 - val_acc: 0.6253\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7411 - acc: 0.6682 - val_loss: 0.8157 - val_acc: 0.6360\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7394 - acc: 0.6702 - val_loss: 0.8169 - val_acc: 0.6267\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7388 - acc: 0.6751 - val_loss: 0.8087 - val_acc: 0.6380\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7369 - acc: 0.6773 - val_loss: 0.8100 - val_acc: 0.6373\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7366 - acc: 0.6733 - val_loss: 0.8114 - val_acc: 0.6373\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7353 - acc: 0.6736 - val_loss: 0.8084 - val_acc: 0.6353\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7330 - acc: 0.6802 - val_loss: 0.8374 - val_acc: 0.6027\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7309 - acc: 0.6759 - val_loss: 0.8176 - val_acc: 0.6347\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7253 - acc: 0.6851 - val_loss: 0.8558 - val_acc: 0.6233\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7247 - acc: 0.6851 - val_loss: 0.8072 - val_acc: 0.6300\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7225 - acc: 0.6919 - val_loss: 0.8540 - val_acc: 0.6133\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7210 - acc: 0.6856 - val_loss: 0.8120 - val_acc: 0.6367\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7184 - acc: 0.6888 - val_loss: 0.8827 - val_acc: 0.6273\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7204 - acc: 0.6828 - val_loss: 0.8279 - val_acc: 0.6187\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7153 - acc: 0.6896 - val_loss: 0.8337 - val_acc: 0.6280\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7160 - acc: 0.6882 - val_loss: 0.8297 - val_acc: 0.6280\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7139 - acc: 0.6962 - val_loss: 0.8174 - val_acc: 0.6373\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7092 - acc: 0.6885 - val_loss: 0.8257 - val_acc: 0.6280\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7085 - acc: 0.6902 - val_loss: 0.8052 - val_acc: 0.6400\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7052 - acc: 0.6939 - val_loss: 0.8229 - val_acc: 0.6340\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7024 - acc: 0.7011 - val_loss: 0.8086 - val_acc: 0.6387\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7039 - acc: 0.6928 - val_loss: 0.8107 - val_acc: 0.6360\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6957 - acc: 0.6971 - val_loss: 0.8096 - val_acc: 0.6327\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6951 - acc: 0.7025 - val_loss: 0.8220 - val_acc: 0.6333\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6985 - acc: 0.6959 - val_loss: 0.8109 - val_acc: 0.6333\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6938 - acc: 0.6999 - val_loss: 0.8393 - val_acc: 0.6180\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6919 - acc: 0.6996 - val_loss: 0.8551 - val_acc: 0.6133\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6932 - acc: 0.6916 - val_loss: 0.8536 - val_acc: 0.6253\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6910 - acc: 0.7045 - val_loss: 0.8056 - val_acc: 0.6340\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 11s 3ms/step - loss: 1.0467 - acc: 0.4984 - val_loss: 1.0378 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0380 - acc: 0.5004 - val_loss: 1.0356 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0352 - acc: 0.5004 - val_loss: 1.0334 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0324 - acc: 0.5004 - val_loss: 1.0309 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0294 - acc: 0.5004 - val_loss: 1.0285 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0266 - acc: 0.5004 - val_loss: 1.0262 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0236 - acc: 0.5004 - val_loss: 1.0237 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0209 - acc: 0.5004 - val_loss: 1.0211 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0175 - acc: 0.5004 - val_loss: 1.0186 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0138 - acc: 0.5004 - val_loss: 1.0165 - val_acc: 0.5007\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 1.0108 - acc: 0.5004 - val_loss: 1.0132 - val_acc: 0.5020\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 1.0067 - acc: 0.5016 - val_loss: 1.0091 - val_acc: 0.5033\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 1.0027 - acc: 0.5050 - val_loss: 1.0054 - val_acc: 0.5053\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9987 - acc: 0.5076 - val_loss: 1.0005 - val_acc: 0.5053\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9935 - acc: 0.5116 - val_loss: 0.9953 - val_acc: 0.5087\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9870 - acc: 0.5156 - val_loss: 0.9908 - val_acc: 0.5127\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9819 - acc: 0.5202 - val_loss: 0.9843 - val_acc: 0.5140\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9749 - acc: 0.5247 - val_loss: 0.9867 - val_acc: 0.5427\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9688 - acc: 0.5347 - val_loss: 0.9737 - val_acc: 0.5440\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9636 - acc: 0.5327 - val_loss: 0.9630 - val_acc: 0.5273\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9550 - acc: 0.5433 - val_loss: 0.9549 - val_acc: 0.5380\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9485 - acc: 0.5462 - val_loss: 0.9558 - val_acc: 0.5400\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9404 - acc: 0.5530 - val_loss: 0.9750 - val_acc: 0.5360\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9336 - acc: 0.5631 - val_loss: 0.9348 - val_acc: 0.5600\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9315 - acc: 0.5665 - val_loss: 0.9727 - val_acc: 0.5500\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9254 - acc: 0.5699 - val_loss: 0.9385 - val_acc: 0.5527\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9135 - acc: 0.5728 - val_loss: 0.9157 - val_acc: 0.5587\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9035 - acc: 0.5891 - val_loss: 0.9099 - val_acc: 0.5593\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.9001 - acc: 0.5768 - val_loss: 0.9269 - val_acc: 0.5747\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8904 - acc: 0.5914 - val_loss: 0.8945 - val_acc: 0.5727\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8841 - acc: 0.6011 - val_loss: 0.9179 - val_acc: 0.5740\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8784 - acc: 0.6011 - val_loss: 0.9395 - val_acc: 0.5567\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8699 - acc: 0.6048 - val_loss: 0.9233 - val_acc: 0.5613\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8691 - acc: 0.6002 - val_loss: 0.8838 - val_acc: 0.5820\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8678 - acc: 0.6077 - val_loss: 0.8839 - val_acc: 0.5973\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8590 - acc: 0.6057 - val_loss: 0.8844 - val_acc: 0.5893\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8549 - acc: 0.6108 - val_loss: 0.8810 - val_acc: 0.5867\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8491 - acc: 0.6140 - val_loss: 0.8700 - val_acc: 0.5867\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8472 - acc: 0.6122 - val_loss: 0.8792 - val_acc: 0.5920\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8441 - acc: 0.6100 - val_loss: 0.8850 - val_acc: 0.5767\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8382 - acc: 0.6197 - val_loss: 0.8579 - val_acc: 0.5993\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8337 - acc: 0.6277 - val_loss: 0.8879 - val_acc: 0.5800\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8294 - acc: 0.6194 - val_loss: 0.8583 - val_acc: 0.5973\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8261 - acc: 0.6191 - val_loss: 0.8490 - val_acc: 0.5947\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8261 - acc: 0.6237 - val_loss: 0.8574 - val_acc: 0.5860\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8219 - acc: 0.6225 - val_loss: 0.8511 - val_acc: 0.5900\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8151 - acc: 0.6317 - val_loss: 0.8495 - val_acc: 0.5853\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8135 - acc: 0.6331 - val_loss: 0.8853 - val_acc: 0.5720\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8113 - acc: 0.6340 - val_loss: 0.8382 - val_acc: 0.6053\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8063 - acc: 0.6360 - val_loss: 0.8554 - val_acc: 0.6040\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8053 - acc: 0.6414 - val_loss: 0.8554 - val_acc: 0.6067\n",
      "Epoch 52/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7998 - acc: 0.6354 - val_loss: 0.8375 - val_acc: 0.6040\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7987 - acc: 0.6354 - val_loss: 0.8324 - val_acc: 0.5987\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7939 - acc: 0.6437 - val_loss: 0.8388 - val_acc: 0.6067\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7909 - acc: 0.6448 - val_loss: 0.8712 - val_acc: 0.5873\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7891 - acc: 0.6440 - val_loss: 0.8431 - val_acc: 0.6060\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7872 - acc: 0.6454 - val_loss: 0.8267 - val_acc: 0.6047\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7838 - acc: 0.6397 - val_loss: 0.8437 - val_acc: 0.6073\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7819 - acc: 0.6471 - val_loss: 0.8540 - val_acc: 0.6107\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7777 - acc: 0.6503 - val_loss: 0.8404 - val_acc: 0.6033\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7748 - acc: 0.6551 - val_loss: 0.8193 - val_acc: 0.6167\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7745 - acc: 0.6520 - val_loss: 0.8185 - val_acc: 0.6133\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7737 - acc: 0.6474 - val_loss: 0.8893 - val_acc: 0.5967\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7710 - acc: 0.6557 - val_loss: 0.8243 - val_acc: 0.6100\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7691 - acc: 0.6557 - val_loss: 0.8528 - val_acc: 0.6107\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7650 - acc: 0.6600 - val_loss: 0.8371 - val_acc: 0.6120\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7608 - acc: 0.6600 - val_loss: 0.8222 - val_acc: 0.6087\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7609 - acc: 0.6586 - val_loss: 0.8130 - val_acc: 0.6193\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7588 - acc: 0.6600 - val_loss: 0.8131 - val_acc: 0.6220\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7544 - acc: 0.6680 - val_loss: 0.8424 - val_acc: 0.5980\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7578 - acc: 0.6591 - val_loss: 0.8457 - val_acc: 0.6067\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7521 - acc: 0.6683 - val_loss: 0.8434 - val_acc: 0.6147\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7519 - acc: 0.6657 - val_loss: 0.8240 - val_acc: 0.6107\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7475 - acc: 0.6663 - val_loss: 0.8151 - val_acc: 0.6180\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7419 - acc: 0.6729 - val_loss: 0.8426 - val_acc: 0.6060\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7415 - acc: 0.6749 - val_loss: 0.8355 - val_acc: 0.6227\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7356 - acc: 0.6789 - val_loss: 0.8294 - val_acc: 0.6280\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7375 - acc: 0.6714 - val_loss: 0.8083 - val_acc: 0.6253\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7316 - acc: 0.6752 - val_loss: 0.8115 - val_acc: 0.6273\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7294 - acc: 0.6803 - val_loss: 0.8342 - val_acc: 0.6287\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7305 - acc: 0.6829 - val_loss: 0.8428 - val_acc: 0.6153\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7285 - acc: 0.6814 - val_loss: 0.8115 - val_acc: 0.6333\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7248 - acc: 0.6843 - val_loss: 0.8713 - val_acc: 0.5980\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7218 - acc: 0.6814 - val_loss: 0.8464 - val_acc: 0.6187\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7248 - acc: 0.6794 - val_loss: 0.8685 - val_acc: 0.6107\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7213 - acc: 0.6843 - val_loss: 0.8297 - val_acc: 0.6227\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7199 - acc: 0.6877 - val_loss: 0.8954 - val_acc: 0.5693\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.7176 - acc: 0.6829 - val_loss: 0.8220 - val_acc: 0.6273\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 11s 3ms/step - loss: 1.0478 - acc: 0.4983 - val_loss: 1.0377 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0364 - acc: 0.5003 - val_loss: 1.0345 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0329 - acc: 0.5003 - val_loss: 1.0313 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 1.0287 - acc: 0.5003 - val_loss: 1.0286 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0257 - acc: 0.5003 - val_loss: 1.0252 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0215 - acc: 0.5003 - val_loss: 1.0215 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0170 - acc: 0.5003 - val_loss: 1.0175 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0129 - acc: 0.5009 - val_loss: 1.0135 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0077 - acc: 0.5020 - val_loss: 1.0103 - val_acc: 0.5047\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0029 - acc: 0.5054 - val_loss: 1.0059 - val_acc: 0.5060\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9980 - acc: 0.5074 - val_loss: 0.9986 - val_acc: 0.5073\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9925 - acc: 0.5100 - val_loss: 1.0029 - val_acc: 0.5147\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9867 - acc: 0.5169 - val_loss: 0.9927 - val_acc: 0.5167\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9806 - acc: 0.5163 - val_loss: 0.9786 - val_acc: 0.5167\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9728 - acc: 0.5229 - val_loss: 0.9774 - val_acc: 0.5227\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9694 - acc: 0.5283 - val_loss: 0.9647 - val_acc: 0.5267\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9627 - acc: 0.5389 - val_loss: 0.9562 - val_acc: 0.5313\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9573 - acc: 0.5369 - val_loss: 0.9549 - val_acc: 0.5793\n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9513 - acc: 0.5503 - val_loss: 0.9449 - val_acc: 0.5487\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9415 - acc: 0.5466 - val_loss: 0.9370 - val_acc: 0.5500\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9342 - acc: 0.5495 - val_loss: 0.9287 - val_acc: 0.5740\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9273 - acc: 0.5563 - val_loss: 0.9245 - val_acc: 0.5660\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9175 - acc: 0.5718 - val_loss: 0.9254 - val_acc: 0.5747\n",
      "Epoch 24/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9110 - acc: 0.5698 - val_loss: 0.9310 - val_acc: 0.5673\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9032 - acc: 0.5780 - val_loss: 0.9310 - val_acc: 0.5573\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8987 - acc: 0.5726 - val_loss: 0.9029 - val_acc: 0.5900\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8925 - acc: 0.5812 - val_loss: 0.8915 - val_acc: 0.5893\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8879 - acc: 0.5832 - val_loss: 0.9168 - val_acc: 0.5587\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8815 - acc: 0.5778 - val_loss: 0.8867 - val_acc: 0.5867\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8765 - acc: 0.5883 - val_loss: 0.8819 - val_acc: 0.5940\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8721 - acc: 0.5955 - val_loss: 0.8969 - val_acc: 0.5840\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8714 - acc: 0.5935 - val_loss: 0.8962 - val_acc: 0.5853\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8670 - acc: 0.5929 - val_loss: 0.8727 - val_acc: 0.6027\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8606 - acc: 0.5989 - val_loss: 0.9147 - val_acc: 0.5567\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8570 - acc: 0.6015 - val_loss: 0.8989 - val_acc: 0.5600\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8542 - acc: 0.5998 - val_loss: 0.8782 - val_acc: 0.5973\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8483 - acc: 0.6081 - val_loss: 0.8626 - val_acc: 0.6040\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8451 - acc: 0.6118 - val_loss: 0.8644 - val_acc: 0.5900\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8424 - acc: 0.6118 - val_loss: 0.8620 - val_acc: 0.6007\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8370 - acc: 0.6132 - val_loss: 0.8847 - val_acc: 0.5660\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8339 - acc: 0.6144 - val_loss: 0.8596 - val_acc: 0.6007\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8316 - acc: 0.6115 - val_loss: 0.8558 - val_acc: 0.6120\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8297 - acc: 0.6121 - val_loss: 0.8526 - val_acc: 0.5953\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8229 - acc: 0.6189 - val_loss: 0.8705 - val_acc: 0.5900\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8211 - acc: 0.6252 - val_loss: 0.8578 - val_acc: 0.6000\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8194 - acc: 0.6252 - val_loss: 0.8470 - val_acc: 0.6133\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8145 - acc: 0.6186 - val_loss: 0.8449 - val_acc: 0.6147\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8110 - acc: 0.6252 - val_loss: 0.8582 - val_acc: 0.5920\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8096 - acc: 0.6318 - val_loss: 0.8826 - val_acc: 0.5787\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8067 - acc: 0.6326 - val_loss: 0.8637 - val_acc: 0.5873\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8044 - acc: 0.6264 - val_loss: 0.8617 - val_acc: 0.5953\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7982 - acc: 0.6312 - val_loss: 0.8423 - val_acc: 0.6127\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7956 - acc: 0.6375 - val_loss: 0.8470 - val_acc: 0.5913\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7963 - acc: 0.6384 - val_loss: 0.8478 - val_acc: 0.5993\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7918 - acc: 0.6415 - val_loss: 0.9006 - val_acc: 0.5853\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7897 - acc: 0.6381 - val_loss: 0.8428 - val_acc: 0.6093\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7875 - acc: 0.6412 - val_loss: 0.8714 - val_acc: 0.5787\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7837 - acc: 0.6387 - val_loss: 0.8573 - val_acc: 0.5933\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7816 - acc: 0.6409 - val_loss: 0.8621 - val_acc: 0.5953\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7790 - acc: 0.6424 - val_loss: 0.8375 - val_acc: 0.6060\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7786 - acc: 0.6529 - val_loss: 0.8494 - val_acc: 0.6100\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7787 - acc: 0.6461 - val_loss: 0.8247 - val_acc: 0.6180\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7712 - acc: 0.6552 - val_loss: 0.8460 - val_acc: 0.5967\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7730 - acc: 0.6532 - val_loss: 0.8483 - val_acc: 0.6040\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7703 - acc: 0.6495 - val_loss: 0.8253 - val_acc: 0.6200\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7609 - acc: 0.6607 - val_loss: 0.8399 - val_acc: 0.6047\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7633 - acc: 0.6498 - val_loss: 0.8591 - val_acc: 0.6047\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7625 - acc: 0.6552 - val_loss: 0.8370 - val_acc: 0.6120\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7576 - acc: 0.6635 - val_loss: 0.8326 - val_acc: 0.6113\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7569 - acc: 0.6564 - val_loss: 0.8345 - val_acc: 0.6233\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7549 - acc: 0.6609 - val_loss: 0.8291 - val_acc: 0.6087\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7494 - acc: 0.6670 - val_loss: 0.8215 - val_acc: 0.6120\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7476 - acc: 0.6624 - val_loss: 0.8334 - val_acc: 0.6207\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7492 - acc: 0.6664 - val_loss: 0.8203 - val_acc: 0.6173\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7437 - acc: 0.6664 - val_loss: 0.8347 - val_acc: 0.6140\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7411 - acc: 0.6712 - val_loss: 0.8181 - val_acc: 0.6140\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7431 - acc: 0.6632 - val_loss: 0.8255 - val_acc: 0.6093\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7400 - acc: 0.6744 - val_loss: 0.8632 - val_acc: 0.5860\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7413 - acc: 0.6707 - val_loss: 0.8414 - val_acc: 0.6160\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7345 - acc: 0.6821 - val_loss: 0.8343 - val_acc: 0.6080\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7346 - acc: 0.6741 - val_loss: 0.8431 - val_acc: 0.6140\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7339 - acc: 0.6704 - val_loss: 0.8336 - val_acc: 0.6047\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7291 - acc: 0.6787 - val_loss: 0.8259 - val_acc: 0.6140\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7250 - acc: 0.6798 - val_loss: 0.8251 - val_acc: 0.6267\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7257 - acc: 0.6792 - val_loss: 0.8191 - val_acc: 0.6220\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7196 - acc: 0.6850 - val_loss: 0.8245 - val_acc: 0.6227\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 11s 3ms/step - loss: 1.0478 - acc: 0.4987 - val_loss: 1.0373 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0369 - acc: 0.5004 - val_loss: 1.0352 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0336 - acc: 0.5004 - val_loss: 1.0326 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0304 - acc: 0.5004 - val_loss: 1.0288 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0265 - acc: 0.5004 - val_loss: 1.0273 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0231 - acc: 0.5004 - val_loss: 1.0249 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0195 - acc: 0.5004 - val_loss: 1.0193 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0149 - acc: 0.5007 - val_loss: 1.0147 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0104 - acc: 0.5021 - val_loss: 1.0106 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0055 - acc: 0.5039 - val_loss: 1.0113 - val_acc: 0.5073\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0021 - acc: 0.5076 - val_loss: 1.0028 - val_acc: 0.5073\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9970 - acc: 0.5107 - val_loss: 0.9974 - val_acc: 0.5080\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9921 - acc: 0.5121 - val_loss: 0.9916 - val_acc: 0.5100\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9862 - acc: 0.5173 - val_loss: 0.9869 - val_acc: 0.5127\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9820 - acc: 0.5199 - val_loss: 0.9832 - val_acc: 0.5300\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9749 - acc: 0.5273 - val_loss: 0.9897 - val_acc: 0.5420\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9711 - acc: 0.5287 - val_loss: 0.9713 - val_acc: 0.5220\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9654 - acc: 0.5353 - val_loss: 0.9653 - val_acc: 0.5260\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9587 - acc: 0.5422 - val_loss: 0.9716 - val_acc: 0.5613\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9522 - acc: 0.5570 - val_loss: 0.9578 - val_acc: 0.5387\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9474 - acc: 0.5502 - val_loss: 0.9797 - val_acc: 0.5267\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9411 - acc: 0.5584 - val_loss: 0.9353 - val_acc: 0.5480\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.9328 - acc: 0.5679 - val_loss: 0.9450 - val_acc: 0.5693\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9272 - acc: 0.5759 - val_loss: 0.9431 - val_acc: 0.5547\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9209 - acc: 0.5747 - val_loss: 0.9206 - val_acc: 0.5787\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9121 - acc: 0.5790 - val_loss: 0.9259 - val_acc: 0.5740\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9052 - acc: 0.5827 - val_loss: 0.9044 - val_acc: 0.5807\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8987 - acc: 0.5807 - val_loss: 0.9038 - val_acc: 0.5833\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8927 - acc: 0.5945 - val_loss: 0.8976 - val_acc: 0.5833\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8885 - acc: 0.5907 - val_loss: 0.8940 - val_acc: 0.5867\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8797 - acc: 0.5965 - val_loss: 0.8843 - val_acc: 0.5900\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8759 - acc: 0.5930 - val_loss: 0.9078 - val_acc: 0.5667\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8734 - acc: 0.5965 - val_loss: 0.8776 - val_acc: 0.5920\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8675 - acc: 0.6016 - val_loss: 0.8758 - val_acc: 0.5860\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8622 - acc: 0.6013 - val_loss: 0.8693 - val_acc: 0.5913\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8571 - acc: 0.6007 - val_loss: 0.8912 - val_acc: 0.5853\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8529 - acc: 0.6125 - val_loss: 0.8954 - val_acc: 0.5893\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8486 - acc: 0.6059 - val_loss: 0.8679 - val_acc: 0.5980\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8459 - acc: 0.6176 - val_loss: 0.8882 - val_acc: 0.5793\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8440 - acc: 0.6159 - val_loss: 0.8594 - val_acc: 0.5953\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8360 - acc: 0.6202 - val_loss: 0.8548 - val_acc: 0.6013\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8341 - acc: 0.6150 - val_loss: 0.8808 - val_acc: 0.5840\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8301 - acc: 0.6165 - val_loss: 0.8542 - val_acc: 0.6013\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8277 - acc: 0.6173 - val_loss: 0.8551 - val_acc: 0.6080\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8238 - acc: 0.6245 - val_loss: 0.8990 - val_acc: 0.5540\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8203 - acc: 0.6239 - val_loss: 0.8539 - val_acc: 0.5940\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8176 - acc: 0.6282 - val_loss: 0.8451 - val_acc: 0.6133\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.8122 - acc: 0.6273 - val_loss: 0.8552 - val_acc: 0.6113\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8101 - acc: 0.6348 - val_loss: 0.8656 - val_acc: 0.6060\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8064 - acc: 0.6330 - val_loss: 0.8367 - val_acc: 0.6173\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8032 - acc: 0.6353 - val_loss: 0.8418 - val_acc: 0.6160\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7995 - acc: 0.6410 - val_loss: 0.8448 - val_acc: 0.6167\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7978 - acc: 0.6402 - val_loss: 0.8375 - val_acc: 0.6167\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7945 - acc: 0.6402 - val_loss: 0.8304 - val_acc: 0.6213\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7900 - acc: 0.6456 - val_loss: 0.8461 - val_acc: 0.6140\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7914 - acc: 0.6476 - val_loss: 0.8470 - val_acc: 0.5940\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7900 - acc: 0.6462 - val_loss: 0.8764 - val_acc: 0.5980\n",
      "Epoch 58/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7848 - acc: 0.6459 - val_loss: 0.8759 - val_acc: 0.5760\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7844 - acc: 0.6490 - val_loss: 0.8411 - val_acc: 0.6107\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7813 - acc: 0.6505 - val_loss: 0.8294 - val_acc: 0.6307\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7771 - acc: 0.6470 - val_loss: 0.8297 - val_acc: 0.6307\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7747 - acc: 0.6533 - val_loss: 0.8318 - val_acc: 0.6233\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7744 - acc: 0.6576 - val_loss: 0.8287 - val_acc: 0.6240\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7694 - acc: 0.6545 - val_loss: 0.8244 - val_acc: 0.6273\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7702 - acc: 0.6596 - val_loss: 0.8281 - val_acc: 0.6207\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7669 - acc: 0.6593 - val_loss: 0.8225 - val_acc: 0.6267\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7644 - acc: 0.6645 - val_loss: 0.8341 - val_acc: 0.6227\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7636 - acc: 0.6648 - val_loss: 0.8503 - val_acc: 0.6087\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7608 - acc: 0.6628 - val_loss: 0.8261 - val_acc: 0.6300\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7602 - acc: 0.6588 - val_loss: 0.8212 - val_acc: 0.6320\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7566 - acc: 0.6630 - val_loss: 0.8541 - val_acc: 0.6160\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7532 - acc: 0.6705 - val_loss: 0.8541 - val_acc: 0.6187\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7563 - acc: 0.6665 - val_loss: 0.8348 - val_acc: 0.6233\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7495 - acc: 0.6710 - val_loss: 0.8218 - val_acc: 0.6220\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7485 - acc: 0.6696 - val_loss: 0.8393 - val_acc: 0.6207\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7499 - acc: 0.6719 - val_loss: 0.8221 - val_acc: 0.6320\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7462 - acc: 0.6705 - val_loss: 0.8130 - val_acc: 0.6373\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7447 - acc: 0.6728 - val_loss: 0.8124 - val_acc: 0.6400\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7414 - acc: 0.6762 - val_loss: 0.8562 - val_acc: 0.6080\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7417 - acc: 0.6796 - val_loss: 0.8303 - val_acc: 0.6267\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7403 - acc: 0.6776 - val_loss: 0.8132 - val_acc: 0.6393\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7376 - acc: 0.6796 - val_loss: 0.8468 - val_acc: 0.6093\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7397 - acc: 0.6768 - val_loss: 0.8317 - val_acc: 0.6180\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7320 - acc: 0.6782 - val_loss: 0.8664 - val_acc: 0.6180\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7295 - acc: 0.6859 - val_loss: 0.8131 - val_acc: 0.6320\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7329 - acc: 0.6799 - val_loss: 0.8328 - val_acc: 0.6213\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7305 - acc: 0.6873 - val_loss: 0.8102 - val_acc: 0.6360\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7292 - acc: 0.6876 - val_loss: 0.8656 - val_acc: 0.6160\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7264 - acc: 0.6828 - val_loss: 0.8118 - val_acc: 0.6380\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7232 - acc: 0.6902 - val_loss: 0.8143 - val_acc: 0.6300\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7218 - acc: 0.6853 - val_loss: 0.8556 - val_acc: 0.6007\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7184 - acc: 0.6873 - val_loss: 0.8158 - val_acc: 0.6307\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7167 - acc: 0.6965 - val_loss: 0.8251 - val_acc: 0.6340\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7196 - acc: 0.6882 - val_loss: 0.8083 - val_acc: 0.6353\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7147 - acc: 0.6925 - val_loss: 0.8212 - val_acc: 0.6353\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7077 - acc: 0.6965 - val_loss: 0.8817 - val_acc: 0.5820\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7136 - acc: 0.6973 - val_loss: 0.8168 - val_acc: 0.6347\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7060 - acc: 0.6942 - val_loss: 0.8103 - val_acc: 0.6380\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7071 - acc: 0.6916 - val_loss: 0.8068 - val_acc: 0.6373\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7071 - acc: 0.6962 - val_loss: 0.8090 - val_acc: 0.6353\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.7036 - acc: 0.6968 - val_loss: 0.8461 - val_acc: 0.6100\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6998 - acc: 0.6953 - val_loss: 0.8515 - val_acc: 0.6093\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7011 - acc: 0.7022 - val_loss: 0.8160 - val_acc: 0.6293\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7028 - acc: 0.6979 - val_loss: 0.8221 - val_acc: 0.6287\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.6946 - acc: 0.7076 - val_loss: 0.8159 - val_acc: 0.6333\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6971 - acc: 0.7062 - val_loss: 0.8116 - val_acc: 0.6267\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6921 - acc: 0.7051 - val_loss: 0.8474 - val_acc: 0.6207\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6919 - acc: 0.7048 - val_loss: 0.8058 - val_acc: 0.6307\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6891 - acc: 0.7025 - val_loss: 0.8454 - val_acc: 0.6207\n",
      "Epoch 110/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6861 - acc: 0.7039 - val_loss: 0.8234 - val_acc: 0.6287\n",
      "Epoch 111/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6853 - acc: 0.7076 - val_loss: 0.8293 - val_acc: 0.6393\n",
      "Epoch 112/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6803 - acc: 0.7096 - val_loss: 0.8789 - val_acc: 0.6000\n",
      "Epoch 113/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6762 - acc: 0.7179 - val_loss: 0.8060 - val_acc: 0.6353\n",
      "Epoch 114/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6751 - acc: 0.7153 - val_loss: 0.8583 - val_acc: 0.6173\n",
      "Epoch 115/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6778 - acc: 0.7099 - val_loss: 0.8219 - val_acc: 0.6373\n",
      "Epoch 116/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6730 - acc: 0.7156 - val_loss: 0.8199 - val_acc: 0.6313\n",
      "Epoch 117/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 0.6713 - acc: 0.7145 - val_loss: 0.8260 - val_acc: 0.6320\n",
      "Epoch 118/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6690 - acc: 0.7219 - val_loss: 0.8653 - val_acc: 0.6107\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 12s 3ms/step - loss: 1.0477 - acc: 0.4993 - val_loss: 1.0372 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0370 - acc: 0.5004 - val_loss: 1.0347 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0339 - acc: 0.5004 - val_loss: 1.0318 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0309 - acc: 0.5004 - val_loss: 1.0278 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0272 - acc: 0.5004 - val_loss: 1.0261 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0240 - acc: 0.5004 - val_loss: 1.0232 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0205 - acc: 0.5004 - val_loss: 1.0175 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0160 - acc: 0.5007 - val_loss: 1.0124 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0115 - acc: 0.5010 - val_loss: 1.0081 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0068 - acc: 0.5033 - val_loss: 1.0072 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0030 - acc: 0.5061 - val_loss: 0.9999 - val_acc: 0.5053\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9981 - acc: 0.5096 - val_loss: 0.9943 - val_acc: 0.5087\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9930 - acc: 0.5121 - val_loss: 0.9868 - val_acc: 0.5120\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9863 - acc: 0.5164 - val_loss: 0.9795 - val_acc: 0.5140\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9835 - acc: 0.5210 - val_loss: 0.9814 - val_acc: 0.5320\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9766 - acc: 0.5287 - val_loss: 0.9786 - val_acc: 0.5433\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9742 - acc: 0.5279 - val_loss: 0.9613 - val_acc: 0.5280\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9653 - acc: 0.5356 - val_loss: 0.9563 - val_acc: 0.5327\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9595 - acc: 0.5436 - val_loss: 0.9580 - val_acc: 0.5700\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9528 - acc: 0.5496 - val_loss: 0.9383 - val_acc: 0.5507\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9480 - acc: 0.5504 - val_loss: 0.9387 - val_acc: 0.5673\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9399 - acc: 0.5556 - val_loss: 0.9396 - val_acc: 0.5547\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9320 - acc: 0.5599 - val_loss: 0.9201 - val_acc: 0.5840\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9284 - acc: 0.5642 - val_loss: 0.9255 - val_acc: 0.5687\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9184 - acc: 0.5627 - val_loss: 0.9133 - val_acc: 0.5733\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9099 - acc: 0.5704 - val_loss: 0.9008 - val_acc: 0.5833\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9030 - acc: 0.5722 - val_loss: 0.8949 - val_acc: 0.5933\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8959 - acc: 0.5796 - val_loss: 0.8910 - val_acc: 0.5847\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8917 - acc: 0.5813 - val_loss: 0.8867 - val_acc: 0.5800\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8864 - acc: 0.5859 - val_loss: 0.8815 - val_acc: 0.5873\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8789 - acc: 0.5896 - val_loss: 0.8733 - val_acc: 0.5967\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8752 - acc: 0.5927 - val_loss: 0.9004 - val_acc: 0.5767\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8724 - acc: 0.5916 - val_loss: 0.8677 - val_acc: 0.6013\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8675 - acc: 0.5865 - val_loss: 0.8655 - val_acc: 0.5967\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8617 - acc: 0.5882 - val_loss: 0.8589 - val_acc: 0.6013\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8581 - acc: 0.5993 - val_loss: 0.8890 - val_acc: 0.5920\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8545 - acc: 0.6096 - val_loss: 0.8806 - val_acc: 0.6007\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8511 - acc: 0.5979 - val_loss: 0.8630 - val_acc: 0.6007\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8478 - acc: 0.6047 - val_loss: 0.9108 - val_acc: 0.5680\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8468 - acc: 0.6065 - val_loss: 0.8516 - val_acc: 0.6027\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8401 - acc: 0.6122 - val_loss: 0.8494 - val_acc: 0.6133\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8397 - acc: 0.6159 - val_loss: 0.8574 - val_acc: 0.5940\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8353 - acc: 0.6130 - val_loss: 0.8461 - val_acc: 0.6073\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8313 - acc: 0.6156 - val_loss: 0.8495 - val_acc: 0.6087\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8284 - acc: 0.6170 - val_loss: 0.8837 - val_acc: 0.5747\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8262 - acc: 0.6107 - val_loss: 0.8445 - val_acc: 0.6007\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8232 - acc: 0.6227 - val_loss: 0.8356 - val_acc: 0.6233\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8192 - acc: 0.6216 - val_loss: 0.8451 - val_acc: 0.6220\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8171 - acc: 0.6205 - val_loss: 0.8633 - val_acc: 0.6200\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8142 - acc: 0.6279 - val_loss: 0.8299 - val_acc: 0.6180\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8113 - acc: 0.6288 - val_loss: 0.8433 - val_acc: 0.6113\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8070 - acc: 0.6339 - val_loss: 0.8599 - val_acc: 0.6007\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8069 - acc: 0.6328 - val_loss: 0.8253 - val_acc: 0.6313\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8021 - acc: 0.6336 - val_loss: 0.8238 - val_acc: 0.6247\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7976 - acc: 0.6365 - val_loss: 0.8468 - val_acc: 0.6060\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8021 - acc: 0.6322 - val_loss: 0.8406 - val_acc: 0.6053\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7969 - acc: 0.6365 - val_loss: 0.8539 - val_acc: 0.6093\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7936 - acc: 0.6388 - val_loss: 0.8578 - val_acc: 0.6027\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7914 - acc: 0.6450 - val_loss: 0.8376 - val_acc: 0.6127\n",
      "Epoch 60/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7881 - acc: 0.6430 - val_loss: 0.8325 - val_acc: 0.6160\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7866 - acc: 0.6422 - val_loss: 0.8302 - val_acc: 0.6220\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7843 - acc: 0.6442 - val_loss: 0.8264 - val_acc: 0.6253\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7809 - acc: 0.6505 - val_loss: 0.8232 - val_acc: 0.6240\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7781 - acc: 0.6513 - val_loss: 0.8157 - val_acc: 0.6367\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7770 - acc: 0.6510 - val_loss: 0.8207 - val_acc: 0.6253\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7755 - acc: 0.6459 - val_loss: 0.8130 - val_acc: 0.6300\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7728 - acc: 0.6479 - val_loss: 0.8220 - val_acc: 0.6200\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7733 - acc: 0.6536 - val_loss: 0.8482 - val_acc: 0.6073\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7698 - acc: 0.6539 - val_loss: 0.8478 - val_acc: 0.6173\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7684 - acc: 0.6505 - val_loss: 0.8130 - val_acc: 0.6313\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7644 - acc: 0.6525 - val_loss: 0.8276 - val_acc: 0.6193\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7611 - acc: 0.6596 - val_loss: 0.8617 - val_acc: 0.6180\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7650 - acc: 0.6530 - val_loss: 0.8173 - val_acc: 0.6360\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7560 - acc: 0.6622 - val_loss: 0.8140 - val_acc: 0.6347\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7566 - acc: 0.6636 - val_loss: 0.8485 - val_acc: 0.6100\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7566 - acc: 0.6679 - val_loss: 0.8078 - val_acc: 0.6367\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7506 - acc: 0.6613 - val_loss: 0.8051 - val_acc: 0.6333\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7509 - acc: 0.6679 - val_loss: 0.8024 - val_acc: 0.6427\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7507 - acc: 0.6665 - val_loss: 0.8121 - val_acc: 0.6327\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7466 - acc: 0.6716 - val_loss: 0.8020 - val_acc: 0.6433\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7468 - acc: 0.6679 - val_loss: 0.8016 - val_acc: 0.6427\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7437 - acc: 0.6679 - val_loss: 0.8478 - val_acc: 0.5980\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7444 - acc: 0.6690 - val_loss: 0.8185 - val_acc: 0.6220\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7410 - acc: 0.6730 - val_loss: 0.8733 - val_acc: 0.6160\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7382 - acc: 0.6753 - val_loss: 0.7999 - val_acc: 0.6367\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7366 - acc: 0.6710 - val_loss: 0.8176 - val_acc: 0.6313\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7368 - acc: 0.6742 - val_loss: 0.8064 - val_acc: 0.6367\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7330 - acc: 0.6756 - val_loss: 0.8549 - val_acc: 0.6280\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7318 - acc: 0.6756 - val_loss: 0.8062 - val_acc: 0.6287\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7280 - acc: 0.6782 - val_loss: 0.8146 - val_acc: 0.6320\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7310 - acc: 0.6742 - val_loss: 0.8274 - val_acc: 0.6180\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7260 - acc: 0.6796 - val_loss: 0.7999 - val_acc: 0.6387\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7201 - acc: 0.6816 - val_loss: 0.8191 - val_acc: 0.6313\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7236 - acc: 0.6805 - val_loss: 0.7987 - val_acc: 0.6420\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7191 - acc: 0.6793 - val_loss: 0.8081 - val_acc: 0.6333\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7142 - acc: 0.6882 - val_loss: 0.8780 - val_acc: 0.5887\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7194 - acc: 0.6851 - val_loss: 0.8011 - val_acc: 0.6300\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7126 - acc: 0.6868 - val_loss: 0.7933 - val_acc: 0.6460\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7093 - acc: 0.6891 - val_loss: 0.7948 - val_acc: 0.6493\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7107 - acc: 0.6939 - val_loss: 0.8046 - val_acc: 0.6287\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7093 - acc: 0.6962 - val_loss: 0.8124 - val_acc: 0.6240\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7040 - acc: 0.6991 - val_loss: 0.8233 - val_acc: 0.6187\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7073 - acc: 0.6916 - val_loss: 0.8090 - val_acc: 0.6373\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7083 - acc: 0.6922 - val_loss: 0.7972 - val_acc: 0.6320\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7023 - acc: 0.6973 - val_loss: 0.8098 - val_acc: 0.6307\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7027 - acc: 0.6951 - val_loss: 0.7990 - val_acc: 0.6353\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6986 - acc: 0.6973 - val_loss: 0.8285 - val_acc: 0.6227\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.6993 - acc: 0.6985 - val_loss: 0.7938 - val_acc: 0.6427\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 12s 4ms/step - loss: 1.0478 - acc: 0.4990 - val_loss: 1.0374 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0373 - acc: 0.5004 - val_loss: 1.0349 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0345 - acc: 0.5004 - val_loss: 1.0320 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0318 - acc: 0.5004 - val_loss: 1.0281 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0283 - acc: 0.5004 - val_loss: 1.0265 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0254 - acc: 0.5004 - val_loss: 1.0237 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0223 - acc: 0.5004 - val_loss: 1.0179 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0181 - acc: 0.5004 - val_loss: 1.0131 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0139 - acc: 0.5007 - val_loss: 1.0088 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0095 - acc: 0.5013 - val_loss: 1.0072 - val_acc: 0.5033\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0058 - acc: 0.5039 - val_loss: 1.0002 - val_acc: 0.5040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0013 - acc: 0.5061 - val_loss: 0.9973 - val_acc: 0.5053\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9968 - acc: 0.5087 - val_loss: 0.9938 - val_acc: 0.5080\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9910 - acc: 0.5139 - val_loss: 0.9822 - val_acc: 0.5100\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9875 - acc: 0.5170 - val_loss: 0.9761 - val_acc: 0.5160\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9794 - acc: 0.5239 - val_loss: 0.9798 - val_acc: 0.5353\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9727 - acc: 0.5279 - val_loss: 0.9743 - val_acc: 0.5333\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9699 - acc: 0.5362 - val_loss: 0.9539 - val_acc: 0.5313\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9644 - acc: 0.5324 - val_loss: 0.9476 - val_acc: 0.5413\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9548 - acc: 0.5467 - val_loss: 0.9473 - val_acc: 0.5600\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9539 - acc: 0.5439 - val_loss: 0.9820 - val_acc: 0.5440\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.9417 - acc: 0.5567 - val_loss: 0.9466 - val_acc: 0.5420\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9361 - acc: 0.5667 - val_loss: 0.9411 - val_acc: 0.5580\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9294 - acc: 0.5699 - val_loss: 0.9296 - val_acc: 0.5553\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9188 - acc: 0.5693 - val_loss: 0.9110 - val_acc: 0.5880\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9105 - acc: 0.5693 - val_loss: 0.9041 - val_acc: 0.5873\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.9045 - acc: 0.5787 - val_loss: 0.9007 - val_acc: 0.5920\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8980 - acc: 0.5796 - val_loss: 0.8920 - val_acc: 0.5953\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8927 - acc: 0.5822 - val_loss: 0.8893 - val_acc: 0.5840\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8875 - acc: 0.5836 - val_loss: 0.8838 - val_acc: 0.5960\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8800 - acc: 0.5882 - val_loss: 0.8782 - val_acc: 0.5887\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8759 - acc: 0.5976 - val_loss: 0.8808 - val_acc: 0.5940\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8728 - acc: 0.5945 - val_loss: 0.8718 - val_acc: 0.6053\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8680 - acc: 0.5959 - val_loss: 0.8703 - val_acc: 0.6033\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8618 - acc: 0.5942 - val_loss: 0.8650 - val_acc: 0.5953\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8575 - acc: 0.6025 - val_loss: 0.8683 - val_acc: 0.6033\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8534 - acc: 0.6127 - val_loss: 0.8880 - val_acc: 0.6000\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8500 - acc: 0.6027 - val_loss: 0.8663 - val_acc: 0.6047\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8477 - acc: 0.6076 - val_loss: 0.9015 - val_acc: 0.5760\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8445 - acc: 0.6050 - val_loss: 0.8615 - val_acc: 0.5987\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8414 - acc: 0.6079 - val_loss: 0.8470 - val_acc: 0.6133\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8386 - acc: 0.6167 - val_loss: 0.8639 - val_acc: 0.6047\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8340 - acc: 0.6153 - val_loss: 0.8552 - val_acc: 0.6033\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8315 - acc: 0.6239 - val_loss: 0.8476 - val_acc: 0.6127\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8270 - acc: 0.6142 - val_loss: 0.9032 - val_acc: 0.5693\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8256 - acc: 0.6250 - val_loss: 0.8508 - val_acc: 0.6027\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8235 - acc: 0.6273 - val_loss: 0.8355 - val_acc: 0.6240\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8177 - acc: 0.6313 - val_loss: 0.8542 - val_acc: 0.6180\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8173 - acc: 0.6265 - val_loss: 0.8542 - val_acc: 0.6120\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8121 - acc: 0.6310 - val_loss: 0.8360 - val_acc: 0.6240\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.8098 - acc: 0.6353 - val_loss: 0.8311 - val_acc: 0.6240\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8033 - acc: 0.6370 - val_loss: 0.8373 - val_acc: 0.6240\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8043 - acc: 0.6328 - val_loss: 0.8369 - val_acc: 0.6153\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.8010 - acc: 0.6368 - val_loss: 0.8321 - val_acc: 0.6200\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7966 - acc: 0.6390 - val_loss: 0.8376 - val_acc: 0.6233\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7980 - acc: 0.6345 - val_loss: 0.8399 - val_acc: 0.6107\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7933 - acc: 0.6442 - val_loss: 0.8434 - val_acc: 0.6140\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7918 - acc: 0.6410 - val_loss: 0.8484 - val_acc: 0.6100\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7891 - acc: 0.6496 - val_loss: 0.8300 - val_acc: 0.6293\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7860 - acc: 0.6442 - val_loss: 0.8225 - val_acc: 0.6293\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7831 - acc: 0.6479 - val_loss: 0.8286 - val_acc: 0.6273\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7827 - acc: 0.6453 - val_loss: 0.8335 - val_acc: 0.6287\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7788 - acc: 0.6499 - val_loss: 0.8260 - val_acc: 0.6253\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7768 - acc: 0.6550 - val_loss: 0.8274 - val_acc: 0.6280\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7731 - acc: 0.6559 - val_loss: 0.8165 - val_acc: 0.6267\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7737 - acc: 0.6490 - val_loss: 0.8142 - val_acc: 0.6380\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7691 - acc: 0.6542 - val_loss: 0.8220 - val_acc: 0.6260\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7695 - acc: 0.6562 - val_loss: 0.8686 - val_acc: 0.5933\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7668 - acc: 0.6562 - val_loss: 0.8412 - val_acc: 0.6180\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7661 - acc: 0.6556 - val_loss: 0.8088 - val_acc: 0.6367\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7619 - acc: 0.6610 - val_loss: 0.8181 - val_acc: 0.6367\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7579 - acc: 0.6648 - val_loss: 0.8218 - val_acc: 0.6233\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7629 - acc: 0.6590 - val_loss: 0.8602 - val_acc: 0.6113\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7563 - acc: 0.6688 - val_loss: 0.8163 - val_acc: 0.6253\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7572 - acc: 0.6616 - val_loss: 0.8426 - val_acc: 0.6247\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7529 - acc: 0.6713 - val_loss: 0.8068 - val_acc: 0.6393\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7517 - acc: 0.6668 - val_loss: 0.8075 - val_acc: 0.6400\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7493 - acc: 0.6713 - val_loss: 0.8005 - val_acc: 0.6393\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7479 - acc: 0.6728 - val_loss: 0.8087 - val_acc: 0.6373\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7461 - acc: 0.6759 - val_loss: 0.8009 - val_acc: 0.6427\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7450 - acc: 0.6765 - val_loss: 0.7990 - val_acc: 0.6360\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7433 - acc: 0.6719 - val_loss: 0.8145 - val_acc: 0.6320\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7437 - acc: 0.6759 - val_loss: 0.8130 - val_acc: 0.6347\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7390 - acc: 0.6788 - val_loss: 0.8211 - val_acc: 0.6300\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7378 - acc: 0.6808 - val_loss: 0.8020 - val_acc: 0.6407\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7344 - acc: 0.6836 - val_loss: 0.8451 - val_acc: 0.6133\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7359 - acc: 0.6822 - val_loss: 0.8161 - val_acc: 0.6333\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7321 - acc: 0.6828 - val_loss: 0.8812 - val_acc: 0.6173\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7323 - acc: 0.6796 - val_loss: 0.8089 - val_acc: 0.6400\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 0.7315 - acc: 0.6862 - val_loss: 0.8162 - val_acc: 0.6373\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 0.7299 - acc: 0.6785 - val_loss: 0.8365 - val_acc: 0.6127\n"
     ]
    }
   ],
   "source": [
    "tokenisers = [whitespace, ark_twokenize, stanford]\n",
    "tdlstm_tok_results = {}\n",
    "for tokeniser in tokenisers:\n",
    "    model = TDLSTM(tokeniser, sswe, lower=True, pad_size=-1)\n",
    "    fit_params = {'reproducible' : True, 'validation_size' : 0.3, \n",
    "                  'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                  'org_initialisers' : True}\n",
    "    scores, preds = model.cross_val(dong_train.data_dict(), dong_train.sentiment_data(), \n",
    "                                    accuracy_score, kfold_reproducible=True, **fit_params)\n",
    "    tdlstm_tok_results[tokeniser.__name__] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whitespace 62.21216616714634\n",
      "ark_twokenize 63.172038597144706\n",
      "stanford 63.17210256646564\n"
     ]
    }
   ],
   "source": [
    "for name, values in tdlstm_tok_results.items():\n",
    "    sum_values = sum(values)\n",
    "    avg_values = 100 * (sum_values / len(values))\n",
    "    print('{} {}'.format(name, avg_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ark_twokenize': [0.63149480415667469,\n",
       "  0.64319999999999999,\n",
       "  0.61569255404323464,\n",
       "  0.63650920736589267,\n",
       "  0.63170536429143309],\n",
       " 'stanford': [0.62829736211031173,\n",
       "  0.64559999999999995,\n",
       "  0.62449959967974378,\n",
       "  0.64291433146517218,\n",
       "  0.61729383506805446],\n",
       " 'whitespace': [0.61071143085531576,\n",
       "  0.62880000000000003,\n",
       "  0.60848678943154522,\n",
       "  0.63490792634107285,\n",
       "  0.62770216172938353]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdlstm_tok_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def half_average_dataset(dataset):\n",
    "    '''\n",
    "    :param dataset: A training dataset\n",
    "    :type dataset: TargetCollection\n",
    "    :returns: Half the average sentence length of the given dataset\n",
    "    :rtype: int\n",
    "    '''\n",
    "    sentence_lengths = [len(data['text'].split()) for data in dataset.data()]\n",
    "    return math.ceil(sum(sentence_lengths) / len(sentence_lengths) / 2)\n",
    "\n",
    "half_average_dataset(dong_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 5s 1ms/step - loss: 1.0564 - acc: 0.4999 - val_loss: 1.0381 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 2s 472us/step - loss: 1.0359 - acc: 0.5004 - val_loss: 1.0322 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 2s 479us/step - loss: 1.0307 - acc: 0.5004 - val_loss: 1.0280 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 2s 481us/step - loss: 1.0261 - acc: 0.5004 - val_loss: 1.0238 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 2s 472us/step - loss: 1.0214 - acc: 0.5004 - val_loss: 1.0197 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 2s 480us/step - loss: 1.0168 - acc: 0.5004 - val_loss: 1.0155 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 1.0122 - acc: 0.5007 - val_loss: 1.0113 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 2s 481us/step - loss: 1.0075 - acc: 0.5010 - val_loss: 1.0070 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 2s 468us/step - loss: 1.0026 - acc: 0.5010 - val_loss: 1.0025 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 2s 465us/step - loss: 0.9974 - acc: 0.5024 - val_loss: 0.9980 - val_acc: 0.5013\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 0.9924 - acc: 0.5056 - val_loss: 0.9934 - val_acc: 0.5080\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.9870 - acc: 0.5136 - val_loss: 0.9884 - val_acc: 0.5107\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 2s 467us/step - loss: 0.9815 - acc: 0.5190 - val_loss: 0.9835 - val_acc: 0.5147\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 0.9760 - acc: 0.5253 - val_loss: 0.9784 - val_acc: 0.5180\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 0.9702 - acc: 0.5305 - val_loss: 0.9733 - val_acc: 0.5227\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 2s 466us/step - loss: 0.9643 - acc: 0.5345 - val_loss: 0.9682 - val_acc: 0.5280\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 0.9584 - acc: 0.5393 - val_loss: 0.9633 - val_acc: 0.5367\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 2s 481us/step - loss: 0.9526 - acc: 0.5482 - val_loss: 0.9582 - val_acc: 0.5387\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.9471 - acc: 0.5533 - val_loss: 0.9529 - val_acc: 0.5413\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 0.9412 - acc: 0.5596 - val_loss: 0.9477 - val_acc: 0.5480\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 2s 471us/step - loss: 0.9352 - acc: 0.5648 - val_loss: 0.9433 - val_acc: 0.5513\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 2s 478us/step - loss: 0.9295 - acc: 0.5711 - val_loss: 0.9381 - val_acc: 0.5600\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 2s 472us/step - loss: 0.9242 - acc: 0.5768 - val_loss: 0.9337 - val_acc: 0.5600\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 2s 468us/step - loss: 0.9184 - acc: 0.5802 - val_loss: 0.9289 - val_acc: 0.5633\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 2s 472us/step - loss: 0.9132 - acc: 0.5842 - val_loss: 0.9265 - val_acc: 0.5667\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 2s 489us/step - loss: 0.9080 - acc: 0.5879 - val_loss: 0.9208 - val_acc: 0.5593\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 2s 486us/step - loss: 0.9026 - acc: 0.5908 - val_loss: 0.9164 - val_acc: 0.5667\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 2s 471us/step - loss: 0.8983 - acc: 0.5931 - val_loss: 0.9133 - val_acc: 0.5640\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.8934 - acc: 0.5971 - val_loss: 0.9095 - val_acc: 0.5800\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 2s 471us/step - loss: 0.8889 - acc: 0.5997 - val_loss: 0.9054 - val_acc: 0.5807\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.8845 - acc: 0.6005 - val_loss: 0.9017 - val_acc: 0.5800\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 2s 466us/step - loss: 0.8802 - acc: 0.6091 - val_loss: 0.8984 - val_acc: 0.5847\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 2s 483us/step - loss: 0.8754 - acc: 0.6097 - val_loss: 0.8984 - val_acc: 0.5927\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 2s 474us/step - loss: 0.8708 - acc: 0.6062 - val_loss: 0.8955 - val_acc: 0.5907\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 2s 492us/step - loss: 0.8681 - acc: 0.6154 - val_loss: 0.8894 - val_acc: 0.5913\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 2s 482us/step - loss: 0.8645 - acc: 0.6117 - val_loss: 0.8901 - val_acc: 0.5893\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 2s 508us/step - loss: 0.8604 - acc: 0.6145 - val_loss: 0.8844 - val_acc: 0.5960\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 2s 497us/step - loss: 0.8575 - acc: 0.6200 - val_loss: 0.8837 - val_acc: 0.6013\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 2s 478us/step - loss: 0.8541 - acc: 0.6160 - val_loss: 0.8859 - val_acc: 0.5953\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 2s 449us/step - loss: 0.8505 - acc: 0.6185 - val_loss: 0.8853 - val_acc: 0.5967\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 2s 466us/step - loss: 0.8475 - acc: 0.6200 - val_loss: 0.8764 - val_acc: 0.6027\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 2s 448us/step - loss: 0.8447 - acc: 0.6237 - val_loss: 0.8807 - val_acc: 0.5973\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.8416 - acc: 0.6280 - val_loss: 0.8748 - val_acc: 0.6073\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 2s 468us/step - loss: 0.8387 - acc: 0.6248 - val_loss: 0.8737 - val_acc: 0.6067\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 2s 466us/step - loss: 0.8363 - acc: 0.6280 - val_loss: 0.8696 - val_acc: 0.6040\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 2s 500us/step - loss: 0.8337 - acc: 0.6314 - val_loss: 0.8675 - val_acc: 0.6080\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.8298 - acc: 0.6308 - val_loss: 0.8693 - val_acc: 0.6000\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 2s 447us/step - loss: 0.8272 - acc: 0.6343 - val_loss: 0.8705 - val_acc: 0.6040\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 2s 465us/step - loss: 0.8247 - acc: 0.6374 - val_loss: 0.8664 - val_acc: 0.6107\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 2s 478us/step - loss: 0.8222 - acc: 0.6374 - val_loss: 0.8629 - val_acc: 0.6020\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 2s 474us/step - loss: 0.8191 - acc: 0.6340 - val_loss: 0.8644 - val_acc: 0.6007\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 2s 472us/step - loss: 0.8167 - acc: 0.6383 - val_loss: 0.8600 - val_acc: 0.6107\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 2s 470us/step - loss: 0.8158 - acc: 0.6374 - val_loss: 0.8583 - val_acc: 0.6093\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.8125 - acc: 0.6411 - val_loss: 0.8591 - val_acc: 0.6113\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 2s 445us/step - loss: 0.8098 - acc: 0.6437 - val_loss: 0.8607 - val_acc: 0.6100\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 2s 451us/step - loss: 0.8069 - acc: 0.6488 - val_loss: 0.8714 - val_acc: 0.6013\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 2s 464us/step - loss: 0.8061 - acc: 0.6437 - val_loss: 0.8552 - val_acc: 0.6067\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 2s 445us/step - loss: 0.8036 - acc: 0.6451 - val_loss: 0.8665 - val_acc: 0.6107\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 2s 447us/step - loss: 0.8010 - acc: 0.6494 - val_loss: 0.8576 - val_acc: 0.6100\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 2s 461us/step - loss: 0.7987 - acc: 0.6477 - val_loss: 0.8614 - val_acc: 0.6053\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 2s 499us/step - loss: 0.7951 - acc: 0.6551 - val_loss: 0.8526 - val_acc: 0.6107\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 2s 495us/step - loss: 0.7948 - acc: 0.6546 - val_loss: 0.8519 - val_acc: 0.6093\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 2s 475us/step - loss: 0.7910 - acc: 0.6606 - val_loss: 0.8724 - val_acc: 0.6013\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 2s 491us/step - loss: 0.7896 - acc: 0.6557 - val_loss: 0.8517 - val_acc: 0.6200\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 2s 450us/step - loss: 0.7873 - acc: 0.6560 - val_loss: 0.8554 - val_acc: 0.6127\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 2s 466us/step - loss: 0.7851 - acc: 0.6574 - val_loss: 0.8492 - val_acc: 0.6180\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 2s 465us/step - loss: 0.7826 - acc: 0.6580 - val_loss: 0.8500 - val_acc: 0.6100\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 2s 475us/step - loss: 0.7810 - acc: 0.6614 - val_loss: 0.8501 - val_acc: 0.6067\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 2s 489us/step - loss: 0.7786 - acc: 0.6609 - val_loss: 0.8482 - val_acc: 0.6167\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 2s 452us/step - loss: 0.7767 - acc: 0.6611 - val_loss: 0.8489 - val_acc: 0.6220\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.7744 - acc: 0.6620 - val_loss: 0.8466 - val_acc: 0.6167\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 2s 461us/step - loss: 0.7719 - acc: 0.6697 - val_loss: 0.8683 - val_acc: 0.6013\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 2s 476us/step - loss: 0.7715 - acc: 0.6674 - val_loss: 0.8506 - val_acc: 0.6173\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.7688 - acc: 0.6697 - val_loss: 0.8509 - val_acc: 0.6187\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 2s 454us/step - loss: 0.7652 - acc: 0.6689 - val_loss: 0.8546 - val_acc: 0.6267\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.7642 - acc: 0.6726 - val_loss: 0.8485 - val_acc: 0.6140\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 2s 465us/step - loss: 0.7604 - acc: 0.6734 - val_loss: 0.8462 - val_acc: 0.6113\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 2s 474us/step - loss: 0.7613 - acc: 0.6734 - val_loss: 0.8439 - val_acc: 0.6180\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 2s 447us/step - loss: 0.7566 - acc: 0.6772 - val_loss: 0.8482 - val_acc: 0.6167\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.7557 - acc: 0.6737 - val_loss: 0.8451 - val_acc: 0.6107\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 2s 472us/step - loss: 0.7533 - acc: 0.6777 - val_loss: 0.8434 - val_acc: 0.6220\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 2s 475us/step - loss: 0.7513 - acc: 0.6769 - val_loss: 0.8422 - val_acc: 0.6227\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 2s 448us/step - loss: 0.7508 - acc: 0.6800 - val_loss: 0.8510 - val_acc: 0.6067\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 2s 441us/step - loss: 0.7469 - acc: 0.6823 - val_loss: 0.8752 - val_acc: 0.6040\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 2s 448us/step - loss: 0.7474 - acc: 0.6789 - val_loss: 0.8602 - val_acc: 0.6007\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 2s 445us/step - loss: 0.7446 - acc: 0.6849 - val_loss: 0.8609 - val_acc: 0.6087\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 2s 445us/step - loss: 0.7420 - acc: 0.6874 - val_loss: 0.8955 - val_acc: 0.5833\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 2s 447us/step - loss: 0.7400 - acc: 0.6803 - val_loss: 0.8521 - val_acc: 0.6080\n",
      "Epoch 89/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.7393 - acc: 0.6794 - val_loss: 0.8479 - val_acc: 0.6193\n",
      "Epoch 90/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.7371 - acc: 0.6857 - val_loss: 0.8453 - val_acc: 0.6240\n",
      "Epoch 91/300\n",
      "3497/3497 [==============================] - 2s 449us/step - loss: 0.7364 - acc: 0.6886 - val_loss: 0.8504 - val_acc: 0.6300\n",
      "Epoch 92/300\n",
      "3497/3497 [==============================] - 2s 469us/step - loss: 0.7323 - acc: 0.6889 - val_loss: 0.8420 - val_acc: 0.6280\n",
      "Epoch 93/300\n",
      "3497/3497 [==============================] - 2s 446us/step - loss: 0.7306 - acc: 0.6854 - val_loss: 0.8450 - val_acc: 0.6213\n",
      "Epoch 94/300\n",
      "3497/3497 [==============================] - 2s 477us/step - loss: 0.7287 - acc: 0.6903 - val_loss: 0.8416 - val_acc: 0.6240\n",
      "Epoch 95/300\n",
      "3497/3497 [==============================] - 2s 454us/step - loss: 0.7269 - acc: 0.6920 - val_loss: 0.8511 - val_acc: 0.6267\n",
      "Epoch 96/300\n",
      "3497/3497 [==============================] - 2s 450us/step - loss: 0.7238 - acc: 0.6906 - val_loss: 0.8484 - val_acc: 0.6133\n",
      "Epoch 97/300\n",
      "3497/3497 [==============================] - 2s 449us/step - loss: 0.7225 - acc: 0.6909 - val_loss: 0.8665 - val_acc: 0.5947\n",
      "Epoch 98/300\n",
      "3497/3497 [==============================] - 2s 450us/step - loss: 0.7224 - acc: 0.6943 - val_loss: 0.8430 - val_acc: 0.6213\n",
      "Epoch 99/300\n",
      "3497/3497 [==============================] - 2s 450us/step - loss: 0.7195 - acc: 0.6980 - val_loss: 0.8457 - val_acc: 0.6187\n",
      "Epoch 100/300\n",
      "3497/3497 [==============================] - 2s 449us/step - loss: 0.7174 - acc: 0.7012 - val_loss: 0.8472 - val_acc: 0.6233\n",
      "Epoch 101/300\n",
      "3497/3497 [==============================] - 2s 448us/step - loss: 0.7146 - acc: 0.6980 - val_loss: 0.8426 - val_acc: 0.6247\n",
      "Epoch 102/300\n",
      "3497/3497 [==============================] - 2s 458us/step - loss: 0.7116 - acc: 0.6952 - val_loss: 0.8448 - val_acc: 0.6260\n",
      "Epoch 103/300\n",
      "3497/3497 [==============================] - 2s 466us/step - loss: 0.7123 - acc: 0.7009 - val_loss: 0.8660 - val_acc: 0.5967\n",
      "Epoch 104/300\n",
      "3497/3497 [==============================] - 2s 467us/step - loss: 0.7091 - acc: 0.6975 - val_loss: 0.8701 - val_acc: 0.6180\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 5s 2ms/step - loss: 1.0584 - acc: 0.4986 - val_loss: 1.0395 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 2s 468us/step - loss: 1.0369 - acc: 0.5003 - val_loss: 1.0320 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 2s 475us/step - loss: 1.0317 - acc: 0.5003 - val_loss: 1.0279 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 2s 478us/step - loss: 1.0272 - acc: 0.5003 - val_loss: 1.0238 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 2s 472us/step - loss: 1.0230 - acc: 0.5003 - val_loss: 1.0197 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 2s 494us/step - loss: 1.0184 - acc: 0.5003 - val_loss: 1.0155 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 2s 499us/step - loss: 1.0138 - acc: 0.5003 - val_loss: 1.0113 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 2s 483us/step - loss: 1.0092 - acc: 0.5006 - val_loss: 1.0069 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 2s 480us/step - loss: 1.0042 - acc: 0.5026 - val_loss: 1.0022 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 2s 472us/step - loss: 0.9992 - acc: 0.5054 - val_loss: 0.9980 - val_acc: 0.5047\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 2s 477us/step - loss: 0.9942 - acc: 0.5083 - val_loss: 0.9931 - val_acc: 0.5087\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 2s 475us/step - loss: 0.9890 - acc: 0.5109 - val_loss: 0.9887 - val_acc: 0.5167\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 2s 472us/step - loss: 0.9840 - acc: 0.5169 - val_loss: 0.9840 - val_acc: 0.5193\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.9787 - acc: 0.5209 - val_loss: 0.9792 - val_acc: 0.5213\n",
      "Epoch 15/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.9736 - acc: 0.5220 - val_loss: 0.9749 - val_acc: 0.5320\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 2s 473us/step - loss: 0.9687 - acc: 0.5289 - val_loss: 0.9706 - val_acc: 0.5320\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.9638 - acc: 0.5306 - val_loss: 0.9658 - val_acc: 0.5380\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 2s 473us/step - loss: 0.9588 - acc: 0.5400 - val_loss: 0.9616 - val_acc: 0.5407\n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 2s 475us/step - loss: 0.9541 - acc: 0.5440 - val_loss: 0.9580 - val_acc: 0.5480\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 2s 475us/step - loss: 0.9491 - acc: 0.5517 - val_loss: 0.9531 - val_acc: 0.5467\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 2s 472us/step - loss: 0.9448 - acc: 0.5540 - val_loss: 0.9491 - val_acc: 0.5500\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 2s 483us/step - loss: 0.9402 - acc: 0.5575 - val_loss: 0.9457 - val_acc: 0.5527\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 2s 489us/step - loss: 0.9355 - acc: 0.5663 - val_loss: 0.9416 - val_acc: 0.5600\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 2s 479us/step - loss: 0.9315 - acc: 0.5698 - val_loss: 0.9373 - val_acc: 0.5607\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 2s 481us/step - loss: 0.9269 - acc: 0.5720 - val_loss: 0.9342 - val_acc: 0.5613\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 2s 481us/step - loss: 0.9226 - acc: 0.5769 - val_loss: 0.9304 - val_acc: 0.5640\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 2s 469us/step - loss: 0.9186 - acc: 0.5806 - val_loss: 0.9264 - val_acc: 0.5647\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 2s 470us/step - loss: 0.9140 - acc: 0.5826 - val_loss: 0.9254 - val_acc: 0.5680\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 2s 472us/step - loss: 0.9099 - acc: 0.5863 - val_loss: 0.9196 - val_acc: 0.5707\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 2s 475us/step - loss: 0.9056 - acc: 0.5883 - val_loss: 0.9176 - val_acc: 0.5733\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 2s 470us/step - loss: 0.9017 - acc: 0.5921 - val_loss: 0.9130 - val_acc: 0.5733\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.8986 - acc: 0.5966 - val_loss: 0.9094 - val_acc: 0.5760\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 2s 473us/step - loss: 0.8948 - acc: 0.5998 - val_loss: 0.9068 - val_acc: 0.5780\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 2s 471us/step - loss: 0.8905 - acc: 0.6003 - val_loss: 0.9064 - val_acc: 0.5813\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.8872 - acc: 0.6015 - val_loss: 0.9049 - val_acc: 0.5907\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 2s 476us/step - loss: 0.8841 - acc: 0.6055 - val_loss: 0.9007 - val_acc: 0.5853\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 2s 476us/step - loss: 0.8795 - acc: 0.6069 - val_loss: 0.8974 - val_acc: 0.5853\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 2s 479us/step - loss: 0.8771 - acc: 0.6089 - val_loss: 0.8943 - val_acc: 0.5993\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 2s 487us/step - loss: 0.8738 - acc: 0.6103 - val_loss: 0.8922 - val_acc: 0.6007\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 2s 482us/step - loss: 0.8705 - acc: 0.6086 - val_loss: 0.8914 - val_acc: 0.5967\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 2s 482us/step - loss: 0.8675 - acc: 0.6138 - val_loss: 0.8884 - val_acc: 0.5953\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 2s 475us/step - loss: 0.8651 - acc: 0.6146 - val_loss: 0.8868 - val_acc: 0.6000\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 2s 483us/step - loss: 0.8617 - acc: 0.6189 - val_loss: 0.8851 - val_acc: 0.6073\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 2s 456us/step - loss: 0.8585 - acc: 0.6201 - val_loss: 0.8874 - val_acc: 0.6020\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 2s 476us/step - loss: 0.8564 - acc: 0.6186 - val_loss: 0.8821 - val_acc: 0.6093\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 2s 470us/step - loss: 0.8538 - acc: 0.6178 - val_loss: 0.8794 - val_acc: 0.6107\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 2s 469us/step - loss: 0.8502 - acc: 0.6221 - val_loss: 0.8780 - val_acc: 0.6147\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 2s 447us/step - loss: 0.8468 - acc: 0.6198 - val_loss: 0.8856 - val_acc: 0.5973\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 2s 469us/step - loss: 0.8470 - acc: 0.6201 - val_loss: 0.8776 - val_acc: 0.6067\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 2s 456us/step - loss: 0.8436 - acc: 0.6244 - val_loss: 0.8848 - val_acc: 0.5973\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.8412 - acc: 0.6246 - val_loss: 0.8781 - val_acc: 0.6047\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 2s 467us/step - loss: 0.8387 - acc: 0.6258 - val_loss: 0.8726 - val_acc: 0.6060\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.8360 - acc: 0.6252 - val_loss: 0.8712 - val_acc: 0.6073\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 2s 458us/step - loss: 0.8342 - acc: 0.6269 - val_loss: 0.8712 - val_acc: 0.6067\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.8320 - acc: 0.6264 - val_loss: 0.8761 - val_acc: 0.6013\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 2s 488us/step - loss: 0.8298 - acc: 0.6269 - val_loss: 0.8710 - val_acc: 0.6093\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 2s 477us/step - loss: 0.8276 - acc: 0.6292 - val_loss: 0.8759 - val_acc: 0.5993\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 2s 497us/step - loss: 0.8252 - acc: 0.6335 - val_loss: 0.8668 - val_acc: 0.6120\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 2s 492us/step - loss: 0.8232 - acc: 0.6301 - val_loss: 0.8652 - val_acc: 0.6127\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 2s 452us/step - loss: 0.8208 - acc: 0.6309 - val_loss: 0.8656 - val_acc: 0.6073\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 2s 469us/step - loss: 0.8187 - acc: 0.6332 - val_loss: 0.8685 - val_acc: 0.6040\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 2s 469us/step - loss: 0.8173 - acc: 0.6332 - val_loss: 0.8617 - val_acc: 0.6173\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 2s 447us/step - loss: 0.8148 - acc: 0.6341 - val_loss: 0.8644 - val_acc: 0.6167\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 2s 469us/step - loss: 0.8131 - acc: 0.6375 - val_loss: 0.8602 - val_acc: 0.6133\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 2s 467us/step - loss: 0.8105 - acc: 0.6372 - val_loss: 0.8589 - val_acc: 0.6107\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 2s 464us/step - loss: 0.8066 - acc: 0.6401 - val_loss: 0.8642 - val_acc: 0.6107\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 2s 492us/step - loss: 0.8062 - acc: 0.6375 - val_loss: 0.8577 - val_acc: 0.6140\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 2s 450us/step - loss: 0.8041 - acc: 0.6369 - val_loss: 0.8581 - val_acc: 0.6147\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 2s 450us/step - loss: 0.8015 - acc: 0.6432 - val_loss: 0.8583 - val_acc: 0.6133\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 2s 477us/step - loss: 0.8011 - acc: 0.6407 - val_loss: 0.8568 - val_acc: 0.6133\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 2s 450us/step - loss: 0.7993 - acc: 0.6412 - val_loss: 0.8592 - val_acc: 0.6140\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 2s 449us/step - loss: 0.7965 - acc: 0.6427 - val_loss: 0.8596 - val_acc: 0.6060\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 2s 446us/step - loss: 0.7939 - acc: 0.6458 - val_loss: 0.8592 - val_acc: 0.6113\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 2s 470us/step - loss: 0.7916 - acc: 0.6501 - val_loss: 0.8544 - val_acc: 0.6193\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 2s 468us/step - loss: 0.7910 - acc: 0.6495 - val_loss: 0.8543 - val_acc: 0.6167\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 2s 471us/step - loss: 0.7885 - acc: 0.6458 - val_loss: 0.8520 - val_acc: 0.6100\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 2s 467us/step - loss: 0.7872 - acc: 0.6484 - val_loss: 0.8513 - val_acc: 0.6140\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 2s 455us/step - loss: 0.7844 - acc: 0.6524 - val_loss: 0.8632 - val_acc: 0.6087\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 2s 454us/step - loss: 0.7838 - acc: 0.6538 - val_loss: 0.8520 - val_acc: 0.6133\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 2s 455us/step - loss: 0.7798 - acc: 0.6569 - val_loss: 0.8533 - val_acc: 0.6180\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 2s 447us/step - loss: 0.7792 - acc: 0.6575 - val_loss: 0.8565 - val_acc: 0.6200\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 2s 455us/step - loss: 0.7788 - acc: 0.6538 - val_loss: 0.8521 - val_acc: 0.6180\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.7749 - acc: 0.6544 - val_loss: 0.8564 - val_acc: 0.6187\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 2s 473us/step - loss: 0.7716 - acc: 0.6598 - val_loss: 0.8497 - val_acc: 0.6180\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 2s 450us/step - loss: 0.7714 - acc: 0.6652 - val_loss: 0.8533 - val_acc: 0.6227\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.7689 - acc: 0.6624 - val_loss: 0.8466 - val_acc: 0.6227\n",
      "Epoch 87/300\n",
      "3498/3498 [==============================] - 2s 458us/step - loss: 0.7669 - acc: 0.6655 - val_loss: 0.8484 - val_acc: 0.6287\n",
      "Epoch 88/300\n",
      "3498/3498 [==============================] - 2s 480us/step - loss: 0.7651 - acc: 0.6652 - val_loss: 0.8465 - val_acc: 0.6167\n",
      "Epoch 89/300\n",
      "3498/3498 [==============================] - 2s 472us/step - loss: 0.7637 - acc: 0.6655 - val_loss: 0.8491 - val_acc: 0.6207\n",
      "Epoch 90/300\n",
      "3498/3498 [==============================] - 2s 517us/step - loss: 0.7606 - acc: 0.6630 - val_loss: 0.8461 - val_acc: 0.6287\n",
      "Epoch 91/300\n",
      "3498/3498 [==============================] - 2s 459us/step - loss: 0.7592 - acc: 0.6698 - val_loss: 0.8519 - val_acc: 0.6307\n",
      "Epoch 92/300\n",
      "3498/3498 [==============================] - 2s 459us/step - loss: 0.7582 - acc: 0.6672 - val_loss: 0.8635 - val_acc: 0.6080\n",
      "Epoch 93/300\n",
      "3498/3498 [==============================] - 2s 463us/step - loss: 0.7568 - acc: 0.6692 - val_loss: 0.8632 - val_acc: 0.5987\n",
      "Epoch 94/300\n",
      "3498/3498 [==============================] - 2s 521us/step - loss: 0.7553 - acc: 0.6732 - val_loss: 0.8454 - val_acc: 0.6273\n",
      "Epoch 95/300\n",
      "3498/3498 [==============================] - 2s 471us/step - loss: 0.7513 - acc: 0.6735 - val_loss: 0.8454 - val_acc: 0.6247\n",
      "Epoch 96/300\n",
      "3498/3498 [==============================] - 2s 452us/step - loss: 0.7507 - acc: 0.6724 - val_loss: 0.8454 - val_acc: 0.6313\n",
      "Epoch 97/300\n",
      "3498/3498 [==============================] - 2s 451us/step - loss: 0.7481 - acc: 0.6712 - val_loss: 0.8541 - val_acc: 0.6207\n",
      "Epoch 98/300\n",
      "3498/3498 [==============================] - 2s 447us/step - loss: 0.7464 - acc: 0.6804 - val_loss: 0.8474 - val_acc: 0.6267\n",
      "Epoch 99/300\n",
      "3498/3498 [==============================] - 2s 445us/step - loss: 0.7450 - acc: 0.6795 - val_loss: 0.8461 - val_acc: 0.6240\n",
      "Epoch 100/300\n",
      "3498/3498 [==============================] - 2s 468us/step - loss: 0.7435 - acc: 0.6781 - val_loss: 0.8448 - val_acc: 0.6333\n",
      "Epoch 101/300\n",
      "3498/3498 [==============================] - 2s 463us/step - loss: 0.7412 - acc: 0.6761 - val_loss: 0.8445 - val_acc: 0.6280\n",
      "Epoch 102/300\n",
      "3498/3498 [==============================] - 2s 465us/step - loss: 0.7388 - acc: 0.6815 - val_loss: 0.8422 - val_acc: 0.6267\n",
      "Epoch 103/300\n",
      "3498/3498 [==============================] - 2s 461us/step - loss: 0.7369 - acc: 0.6810 - val_loss: 0.8423 - val_acc: 0.6307\n",
      "Epoch 104/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.7348 - acc: 0.6804 - val_loss: 0.8440 - val_acc: 0.6273\n",
      "Epoch 105/300\n",
      "3498/3498 [==============================] - 2s 441us/step - loss: 0.7346 - acc: 0.6838 - val_loss: 0.8445 - val_acc: 0.6273\n",
      "Epoch 106/300\n",
      "3498/3498 [==============================] - 2s 461us/step - loss: 0.7312 - acc: 0.6881 - val_loss: 0.8420 - val_acc: 0.6340\n",
      "Epoch 107/300\n",
      "3498/3498 [==============================] - 2s 451us/step - loss: 0.7291 - acc: 0.6835 - val_loss: 0.8476 - val_acc: 0.6293\n",
      "Epoch 108/300\n",
      "3498/3498 [==============================] - 2s 445us/step - loss: 0.7282 - acc: 0.6838 - val_loss: 0.8667 - val_acc: 0.6093\n",
      "Epoch 109/300\n",
      "3498/3498 [==============================] - 2s 451us/step - loss: 0.7266 - acc: 0.6881 - val_loss: 0.8639 - val_acc: 0.6067\n",
      "Epoch 110/300\n",
      "3498/3498 [==============================] - 2s 466us/step - loss: 0.7223 - acc: 0.6898 - val_loss: 0.8394 - val_acc: 0.6313\n",
      "Epoch 111/300\n",
      "3498/3498 [==============================] - 2s 442us/step - loss: 0.7217 - acc: 0.6904 - val_loss: 0.8443 - val_acc: 0.6333\n",
      "Epoch 112/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.7177 - acc: 0.6924 - val_loss: 0.8442 - val_acc: 0.6347\n",
      "Epoch 113/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.7160 - acc: 0.6918 - val_loss: 0.8477 - val_acc: 0.6380\n",
      "Epoch 114/300\n",
      "3498/3498 [==============================] - 2s 446us/step - loss: 0.7166 - acc: 0.6947 - val_loss: 0.8403 - val_acc: 0.6367\n",
      "Epoch 115/300\n",
      "3498/3498 [==============================] - 2s 445us/step - loss: 0.7126 - acc: 0.6947 - val_loss: 0.8465 - val_acc: 0.6340\n",
      "Epoch 116/300\n",
      "3498/3498 [==============================] - 2s 474us/step - loss: 0.7107 - acc: 0.6898 - val_loss: 0.8543 - val_acc: 0.6167\n",
      "Epoch 117/300\n",
      "3498/3498 [==============================] - 2s 457us/step - loss: 0.7095 - acc: 0.6978 - val_loss: 0.8543 - val_acc: 0.6240\n",
      "Epoch 118/300\n",
      "3498/3498 [==============================] - 2s 448us/step - loss: 0.7066 - acc: 0.6930 - val_loss: 0.8412 - val_acc: 0.6340\n",
      "Epoch 119/300\n",
      "3498/3498 [==============================] - 2s 449us/step - loss: 0.7062 - acc: 0.6993 - val_loss: 0.8476 - val_acc: 0.6247\n",
      "Epoch 120/300\n",
      "3498/3498 [==============================] - 2s 445us/step - loss: 0.7030 - acc: 0.7001 - val_loss: 0.8483 - val_acc: 0.6253\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 1.0580 - acc: 0.4979 - val_loss: 1.0383 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 1.0370 - acc: 0.5004 - val_loss: 1.0319 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 2s 484us/step - loss: 1.0321 - acc: 0.5004 - val_loss: 1.0276 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 1.0278 - acc: 0.5004 - val_loss: 1.0231 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 2s 479us/step - loss: 1.0234 - acc: 0.5004 - val_loss: 1.0190 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 1.0191 - acc: 0.5004 - val_loss: 1.0146 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 1.0147 - acc: 0.5004 - val_loss: 1.0102 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 1.0099 - acc: 0.5007 - val_loss: 1.0056 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 1.0052 - acc: 0.5024 - val_loss: 1.0008 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 1.0003 - acc: 0.5027 - val_loss: 0.9964 - val_acc: 0.5073\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.9955 - acc: 0.5084 - val_loss: 0.9913 - val_acc: 0.5140\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.9903 - acc: 0.5136 - val_loss: 0.9863 - val_acc: 0.5153\n",
      "Epoch 13/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.9853 - acc: 0.5170 - val_loss: 0.9814 - val_acc: 0.5187\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.9798 - acc: 0.5204 - val_loss: 0.9764 - val_acc: 0.5233\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.9751 - acc: 0.5230 - val_loss: 0.9718 - val_acc: 0.5287\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.9699 - acc: 0.5264 - val_loss: 0.9669 - val_acc: 0.5307\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9645 - acc: 0.5307 - val_loss: 0.9631 - val_acc: 0.5340\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.9600 - acc: 0.5370 - val_loss: 0.9576 - val_acc: 0.5380\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 2s 475us/step - loss: 0.9548 - acc: 0.5407 - val_loss: 0.9530 - val_acc: 0.5460\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.9498 - acc: 0.5436 - val_loss: 0.9491 - val_acc: 0.5540\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.9452 - acc: 0.5499 - val_loss: 0.9456 - val_acc: 0.5547\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.9405 - acc: 0.5582 - val_loss: 0.9405 - val_acc: 0.5633\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.9357 - acc: 0.5624 - val_loss: 0.9369 - val_acc: 0.5633\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.9312 - acc: 0.5647 - val_loss: 0.9327 - val_acc: 0.5700\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.9270 - acc: 0.5684 - val_loss: 0.9294 - val_acc: 0.5767\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.9222 - acc: 0.5770 - val_loss: 0.9256 - val_acc: 0.5767\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9181 - acc: 0.5796 - val_loss: 0.9225 - val_acc: 0.5787\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.9139 - acc: 0.5793 - val_loss: 0.9187 - val_acc: 0.5820\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.9094 - acc: 0.5839 - val_loss: 0.9153 - val_acc: 0.5840\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9055 - acc: 0.5907 - val_loss: 0.9123 - val_acc: 0.5887\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 2s 475us/step - loss: 0.9005 - acc: 0.5905 - val_loss: 0.9099 - val_acc: 0.5900\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.8969 - acc: 0.5942 - val_loss: 0.9073 - val_acc: 0.5913\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.8936 - acc: 0.5970 - val_loss: 0.9042 - val_acc: 0.5893\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 2s 464us/step - loss: 0.8899 - acc: 0.6005 - val_loss: 0.9015 - val_acc: 0.5960\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8863 - acc: 0.6019 - val_loss: 0.8983 - val_acc: 0.5973\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.8827 - acc: 0.6056 - val_loss: 0.8965 - val_acc: 0.5913\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 2s 484us/step - loss: 0.8790 - acc: 0.6053 - val_loss: 0.8962 - val_acc: 0.5907\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 0.8758 - acc: 0.6076 - val_loss: 0.8936 - val_acc: 0.5920\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.8731 - acc: 0.6130 - val_loss: 0.8906 - val_acc: 0.6067\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.8706 - acc: 0.6130 - val_loss: 0.8877 - val_acc: 0.6013\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.8672 - acc: 0.6122 - val_loss: 0.8849 - val_acc: 0.6007\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.8642 - acc: 0.6179 - val_loss: 0.8889 - val_acc: 0.5967\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 2s 446us/step - loss: 0.8610 - acc: 0.6162 - val_loss: 0.8883 - val_acc: 0.6000\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.8587 - acc: 0.6210 - val_loss: 0.8829 - val_acc: 0.5973\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.8557 - acc: 0.6176 - val_loss: 0.8884 - val_acc: 0.5987\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.8530 - acc: 0.6222 - val_loss: 0.8798 - val_acc: 0.6020\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.8517 - acc: 0.6173 - val_loss: 0.8757 - val_acc: 0.6040\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.8482 - acc: 0.6279 - val_loss: 0.8740 - val_acc: 0.6047\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.8465 - acc: 0.6308 - val_loss: 0.8730 - val_acc: 0.6073\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 0.8434 - acc: 0.6259 - val_loss: 0.8719 - val_acc: 0.6093\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.8403 - acc: 0.6268 - val_loss: 0.8761 - val_acc: 0.6013\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 2s 491us/step - loss: 0.8384 - acc: 0.6322 - val_loss: 0.8688 - val_acc: 0.6087\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 0.8360 - acc: 0.6296 - val_loss: 0.8675 - val_acc: 0.6133\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.8344 - acc: 0.6290 - val_loss: 0.8659 - val_acc: 0.6093\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.8313 - acc: 0.6390 - val_loss: 0.8671 - val_acc: 0.6040\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.8298 - acc: 0.6362 - val_loss: 0.8675 - val_acc: 0.6080\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.8289 - acc: 0.6336 - val_loss: 0.8672 - val_acc: 0.6113\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 2s 447us/step - loss: 0.8254 - acc: 0.6376 - val_loss: 0.8704 - val_acc: 0.6013\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8242 - acc: 0.6382 - val_loss: 0.8650 - val_acc: 0.6027\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 2s 482us/step - loss: 0.8212 - acc: 0.6368 - val_loss: 0.8618 - val_acc: 0.6113\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.8196 - acc: 0.6359 - val_loss: 0.8613 - val_acc: 0.6120\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 2s 460us/step - loss: 0.8174 - acc: 0.6430 - val_loss: 0.8636 - val_acc: 0.6040\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.8162 - acc: 0.6359 - val_loss: 0.8615 - val_acc: 0.6053\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.8127 - acc: 0.6419 - val_loss: 0.8597 - val_acc: 0.6073\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.8110 - acc: 0.6408 - val_loss: 0.8561 - val_acc: 0.6200\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.8098 - acc: 0.6402 - val_loss: 0.8547 - val_acc: 0.6207\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.8072 - acc: 0.6470 - val_loss: 0.8624 - val_acc: 0.6053\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.8057 - acc: 0.6462 - val_loss: 0.8618 - val_acc: 0.6087\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 2s 502us/step - loss: 0.8039 - acc: 0.6499 - val_loss: 0.8544 - val_acc: 0.6153\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 2s 489us/step - loss: 0.8016 - acc: 0.6476 - val_loss: 0.8512 - val_acc: 0.6127\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7994 - acc: 0.6553 - val_loss: 0.8537 - val_acc: 0.6120\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 2s 451us/step - loss: 0.7972 - acc: 0.6533 - val_loss: 0.8566 - val_acc: 0.6187\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 2s 465us/step - loss: 0.7963 - acc: 0.6505 - val_loss: 0.8494 - val_acc: 0.6280\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.7930 - acc: 0.6522 - val_loss: 0.8526 - val_acc: 0.6207\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.7915 - acc: 0.6490 - val_loss: 0.8491 - val_acc: 0.6193\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 2s 462us/step - loss: 0.7899 - acc: 0.6565 - val_loss: 0.8488 - val_acc: 0.6140\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 2s 461us/step - loss: 0.7882 - acc: 0.6568 - val_loss: 0.8460 - val_acc: 0.6260\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.7854 - acc: 0.6579 - val_loss: 0.8451 - val_acc: 0.6187\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 2s 445us/step - loss: 0.7840 - acc: 0.6545 - val_loss: 0.8469 - val_acc: 0.6167\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 2s 446us/step - loss: 0.7820 - acc: 0.6576 - val_loss: 0.8464 - val_acc: 0.6160\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 2s 488us/step - loss: 0.7821 - acc: 0.6570 - val_loss: 0.8425 - val_acc: 0.6253\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 2s 462us/step - loss: 0.7775 - acc: 0.6679 - val_loss: 0.8511 - val_acc: 0.6113\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.7773 - acc: 0.6599 - val_loss: 0.8635 - val_acc: 0.6067\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7749 - acc: 0.6648 - val_loss: 0.8509 - val_acc: 0.6260\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 2s 483us/step - loss: 0.7724 - acc: 0.6619 - val_loss: 0.8410 - val_acc: 0.6273\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 2s 461us/step - loss: 0.7726 - acc: 0.6642 - val_loss: 0.8449 - val_acc: 0.6227\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 2s 483us/step - loss: 0.7689 - acc: 0.6636 - val_loss: 0.8443 - val_acc: 0.6227\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7673 - acc: 0.6668 - val_loss: 0.8527 - val_acc: 0.6153\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 2s 447us/step - loss: 0.7662 - acc: 0.6685 - val_loss: 0.8442 - val_acc: 0.6253\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7645 - acc: 0.6670 - val_loss: 0.8417 - val_acc: 0.6267\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7620 - acc: 0.6702 - val_loss: 0.8494 - val_acc: 0.6107\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 2s 487us/step - loss: 0.7604 - acc: 0.6705 - val_loss: 0.8405 - val_acc: 0.6200\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.7582 - acc: 0.6685 - val_loss: 0.8421 - val_acc: 0.6200\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 2s 497us/step - loss: 0.7572 - acc: 0.6722 - val_loss: 0.8371 - val_acc: 0.6267\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7544 - acc: 0.6762 - val_loss: 0.8486 - val_acc: 0.6260\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.7523 - acc: 0.6759 - val_loss: 0.8388 - val_acc: 0.6240\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7508 - acc: 0.6748 - val_loss: 0.8390 - val_acc: 0.6240\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 0.7479 - acc: 0.6759 - val_loss: 0.8356 - val_acc: 0.6313\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 2s 443us/step - loss: 0.7470 - acc: 0.6773 - val_loss: 0.8370 - val_acc: 0.6267\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.7464 - acc: 0.6779 - val_loss: 0.8346 - val_acc: 0.6373\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7432 - acc: 0.6802 - val_loss: 0.8387 - val_acc: 0.6347\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 2s 446us/step - loss: 0.7407 - acc: 0.6828 - val_loss: 0.8450 - val_acc: 0.6280\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7397 - acc: 0.6825 - val_loss: 0.8373 - val_acc: 0.6320\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7388 - acc: 0.6845 - val_loss: 0.8446 - val_acc: 0.6280\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 2s 465us/step - loss: 0.7361 - acc: 0.6859 - val_loss: 0.8343 - val_acc: 0.6353\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 0.7332 - acc: 0.6868 - val_loss: 0.8331 - val_acc: 0.6333\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 0.7329 - acc: 0.6816 - val_loss: 0.8329 - val_acc: 0.6333\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7298 - acc: 0.6865 - val_loss: 0.8336 - val_acc: 0.6313\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 2s 446us/step - loss: 0.7281 - acc: 0.6908 - val_loss: 0.8507 - val_acc: 0.6247\n",
      "Epoch 110/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7241 - acc: 0.6925 - val_loss: 0.8457 - val_acc: 0.6180\n",
      "Epoch 111/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7253 - acc: 0.6879 - val_loss: 0.8418 - val_acc: 0.6267\n",
      "Epoch 112/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.7222 - acc: 0.6942 - val_loss: 0.8344 - val_acc: 0.6340\n",
      "Epoch 113/300\n",
      "3499/3499 [==============================] - 2s 505us/step - loss: 0.7175 - acc: 0.6945 - val_loss: 0.8327 - val_acc: 0.6307\n",
      "Epoch 114/300\n",
      "3499/3499 [==============================] - 2s 457us/step - loss: 0.7177 - acc: 0.6933 - val_loss: 0.8409 - val_acc: 0.6287\n",
      "Epoch 115/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.7168 - acc: 0.6948 - val_loss: 0.8306 - val_acc: 0.6347\n",
      "Epoch 116/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 0.7130 - acc: 0.6956 - val_loss: 0.8302 - val_acc: 0.6407\n",
      "Epoch 117/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7127 - acc: 0.6933 - val_loss: 0.8397 - val_acc: 0.6180\n",
      "Epoch 118/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7105 - acc: 0.6982 - val_loss: 0.8353 - val_acc: 0.6393\n",
      "Epoch 119/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7080 - acc: 0.7022 - val_loss: 0.8437 - val_acc: 0.6287\n",
      "Epoch 120/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.7074 - acc: 0.6976 - val_loss: 0.8284 - val_acc: 0.6360\n",
      "Epoch 121/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.7056 - acc: 0.7042 - val_loss: 0.8282 - val_acc: 0.6380\n",
      "Epoch 122/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.7006 - acc: 0.7062 - val_loss: 0.8350 - val_acc: 0.6247\n",
      "Epoch 123/300\n",
      "3499/3499 [==============================] - 2s 446us/step - loss: 0.7017 - acc: 0.7036 - val_loss: 0.8312 - val_acc: 0.6327\n",
      "Epoch 124/300\n",
      "3499/3499 [==============================] - 2s 447us/step - loss: 0.6988 - acc: 0.7053 - val_loss: 0.8289 - val_acc: 0.6427\n",
      "Epoch 125/300\n",
      "3499/3499 [==============================] - 2s 482us/step - loss: 0.6954 - acc: 0.7036 - val_loss: 0.8460 - val_acc: 0.6200\n",
      "Epoch 126/300\n",
      "3499/3499 [==============================] - 2s 462us/step - loss: 0.6939 - acc: 0.7056 - val_loss: 0.8387 - val_acc: 0.6247\n",
      "Epoch 127/300\n",
      "3499/3499 [==============================] - 2s 479us/step - loss: 0.6927 - acc: 0.7099 - val_loss: 0.8362 - val_acc: 0.6313\n",
      "Epoch 128/300\n",
      "3499/3499 [==============================] - 2s 463us/step - loss: 0.6877 - acc: 0.7091 - val_loss: 0.8342 - val_acc: 0.6333\n",
      "Epoch 129/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.6878 - acc: 0.7068 - val_loss: 0.8287 - val_acc: 0.6480\n",
      "Epoch 130/300\n",
      "3499/3499 [==============================] - 2s 449us/step - loss: 0.6847 - acc: 0.7125 - val_loss: 0.8441 - val_acc: 0.6047\n",
      "Epoch 131/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 2s 449us/step - loss: 0.6825 - acc: 0.7145 - val_loss: 0.8468 - val_acc: 0.6100\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 1.0587 - acc: 0.4981 - val_loss: 1.0385 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 1.0379 - acc: 0.5004 - val_loss: 1.0319 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 1.0330 - acc: 0.5004 - val_loss: 1.0276 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 1.0287 - acc: 0.5004 - val_loss: 1.0231 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 1.0242 - acc: 0.5004 - val_loss: 1.0189 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 1.0199 - acc: 0.5004 - val_loss: 1.0146 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 1.0155 - acc: 0.5004 - val_loss: 1.0101 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 1.0107 - acc: 0.5007 - val_loss: 1.0055 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 1.0060 - acc: 0.5024 - val_loss: 1.0007 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 1.0011 - acc: 0.5041 - val_loss: 0.9963 - val_acc: 0.5073\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 2s 482us/step - loss: 0.9962 - acc: 0.5093 - val_loss: 0.9911 - val_acc: 0.5093\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9910 - acc: 0.5113 - val_loss: 0.9861 - val_acc: 0.5133\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.9859 - acc: 0.5164 - val_loss: 0.9810 - val_acc: 0.5220\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.9803 - acc: 0.5210 - val_loss: 0.9759 - val_acc: 0.5273\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 0.9755 - acc: 0.5233 - val_loss: 0.9711 - val_acc: 0.5293\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.9701 - acc: 0.5270 - val_loss: 0.9660 - val_acc: 0.5333\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9647 - acc: 0.5304 - val_loss: 0.9616 - val_acc: 0.5413\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.9599 - acc: 0.5370 - val_loss: 0.9560 - val_acc: 0.5460\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.9545 - acc: 0.5427 - val_loss: 0.9511 - val_acc: 0.5473\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 0.9493 - acc: 0.5504 - val_loss: 0.9468 - val_acc: 0.5560\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.9445 - acc: 0.5567 - val_loss: 0.9431 - val_acc: 0.5527\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 2s 479us/step - loss: 0.9397 - acc: 0.5616 - val_loss: 0.9375 - val_acc: 0.5593\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 2s 482us/step - loss: 0.9347 - acc: 0.5662 - val_loss: 0.9334 - val_acc: 0.5620\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.9300 - acc: 0.5690 - val_loss: 0.9286 - val_acc: 0.5613\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.9255 - acc: 0.5704 - val_loss: 0.9246 - val_acc: 0.5733\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9207 - acc: 0.5750 - val_loss: 0.9204 - val_acc: 0.5767\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 2s 475us/step - loss: 0.9164 - acc: 0.5782 - val_loss: 0.9172 - val_acc: 0.5773\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.9119 - acc: 0.5827 - val_loss: 0.9128 - val_acc: 0.5893\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 0.9075 - acc: 0.5885 - val_loss: 0.9089 - val_acc: 0.5827\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.9035 - acc: 0.5905 - val_loss: 0.9056 - val_acc: 0.5867\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.8986 - acc: 0.5956 - val_loss: 0.9025 - val_acc: 0.5913\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 2s 508us/step - loss: 0.8947 - acc: 0.5962 - val_loss: 0.8998 - val_acc: 0.5927\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 2s 488us/step - loss: 0.8914 - acc: 0.5982 - val_loss: 0.8967 - val_acc: 0.5913\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.8876 - acc: 0.6005 - val_loss: 0.8933 - val_acc: 0.5967\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 0.8838 - acc: 0.6050 - val_loss: 0.8890 - val_acc: 0.5933\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 2s 492us/step - loss: 0.8802 - acc: 0.6073 - val_loss: 0.8871 - val_acc: 0.5987\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 2s 496us/step - loss: 0.8766 - acc: 0.6122 - val_loss: 0.8855 - val_acc: 0.5980\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.8730 - acc: 0.6145 - val_loss: 0.8838 - val_acc: 0.6000\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.8704 - acc: 0.6136 - val_loss: 0.8816 - val_acc: 0.5980\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.8676 - acc: 0.6162 - val_loss: 0.8765 - val_acc: 0.5993\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 2s 475us/step - loss: 0.8641 - acc: 0.6173 - val_loss: 0.8738 - val_acc: 0.5987\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.8609 - acc: 0.6219 - val_loss: 0.8775 - val_acc: 0.5953\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.8579 - acc: 0.6187 - val_loss: 0.8745 - val_acc: 0.6040\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.8554 - acc: 0.6273 - val_loss: 0.8688 - val_acc: 0.6013\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.8522 - acc: 0.6308 - val_loss: 0.8744 - val_acc: 0.6060\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8498 - acc: 0.6305 - val_loss: 0.8654 - val_acc: 0.6060\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8478 - acc: 0.6239 - val_loss: 0.8621 - val_acc: 0.6127\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 2s 449us/step - loss: 0.8445 - acc: 0.6285 - val_loss: 0.8641 - val_acc: 0.6093\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 2s 464us/step - loss: 0.8427 - acc: 0.6308 - val_loss: 0.8593 - val_acc: 0.6153\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.8393 - acc: 0.6342 - val_loss: 0.8593 - val_acc: 0.6120\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 2s 458us/step - loss: 0.8360 - acc: 0.6359 - val_loss: 0.8633 - val_acc: 0.6100\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 2s 465us/step - loss: 0.8343 - acc: 0.6373 - val_loss: 0.8546 - val_acc: 0.6113\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8319 - acc: 0.6353 - val_loss: 0.8532 - val_acc: 0.6113\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 0.8298 - acc: 0.6388 - val_loss: 0.8520 - val_acc: 0.6180\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.8268 - acc: 0.6405 - val_loss: 0.8536 - val_acc: 0.6193\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 2s 445us/step - loss: 0.8254 - acc: 0.6445 - val_loss: 0.8567 - val_acc: 0.6000\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 2s 465us/step - loss: 0.8241 - acc: 0.6436 - val_loss: 0.8517 - val_acc: 0.6140\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.8204 - acc: 0.6413 - val_loss: 0.8529 - val_acc: 0.6140\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 2s 489us/step - loss: 0.8189 - acc: 0.6442 - val_loss: 0.8515 - val_acc: 0.6160\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.8162 - acc: 0.6436 - val_loss: 0.8461 - val_acc: 0.6207\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 2s 498us/step - loss: 0.8142 - acc: 0.6485 - val_loss: 0.8447 - val_acc: 0.6220\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.8125 - acc: 0.6496 - val_loss: 0.8492 - val_acc: 0.6127\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.8104 - acc: 0.6499 - val_loss: 0.8472 - val_acc: 0.6167\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.8081 - acc: 0.6502 - val_loss: 0.8407 - val_acc: 0.6273\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8057 - acc: 0.6545 - val_loss: 0.8420 - val_acc: 0.6200\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 2s 479us/step - loss: 0.8041 - acc: 0.6525 - val_loss: 0.8394 - val_acc: 0.6253\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.8011 - acc: 0.6536 - val_loss: 0.8457 - val_acc: 0.6153\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.8003 - acc: 0.6536 - val_loss: 0.8474 - val_acc: 0.6140\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 2s 466us/step - loss: 0.7978 - acc: 0.6573 - val_loss: 0.8385 - val_acc: 0.6253\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.7957 - acc: 0.6588 - val_loss: 0.8342 - val_acc: 0.6247\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7929 - acc: 0.6579 - val_loss: 0.8403 - val_acc: 0.6213\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.7909 - acc: 0.6550 - val_loss: 0.8372 - val_acc: 0.6247\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.7899 - acc: 0.6579 - val_loss: 0.8323 - val_acc: 0.6253\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.7876 - acc: 0.6590 - val_loss: 0.8321 - val_acc: 0.6247\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.7844 - acc: 0.6628 - val_loss: 0.8314 - val_acc: 0.6273\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 0.7836 - acc: 0.6639 - val_loss: 0.8313 - val_acc: 0.6327\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.7814 - acc: 0.6625 - val_loss: 0.8288 - val_acc: 0.6287\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.7787 - acc: 0.6679 - val_loss: 0.8276 - val_acc: 0.6307\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 0.7764 - acc: 0.6699 - val_loss: 0.8336 - val_acc: 0.6273\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7750 - acc: 0.6693 - val_loss: 0.8280 - val_acc: 0.6307\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.7755 - acc: 0.6642 - val_loss: 0.8257 - val_acc: 0.6320\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.7698 - acc: 0.6693 - val_loss: 0.8376 - val_acc: 0.6193\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 2s 460us/step - loss: 0.7703 - acc: 0.6699 - val_loss: 0.8407 - val_acc: 0.6180\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.7669 - acc: 0.6693 - val_loss: 0.8363 - val_acc: 0.6253\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 0.7653 - acc: 0.6736 - val_loss: 0.8256 - val_acc: 0.6313\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7648 - acc: 0.6751 - val_loss: 0.8267 - val_acc: 0.6280\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 2s 464us/step - loss: 0.7609 - acc: 0.6725 - val_loss: 0.8255 - val_acc: 0.6233\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.7590 - acc: 0.6739 - val_loss: 0.8353 - val_acc: 0.6240\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 2s 491us/step - loss: 0.7577 - acc: 0.6736 - val_loss: 0.8242 - val_acc: 0.6293\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.7561 - acc: 0.6768 - val_loss: 0.8293 - val_acc: 0.6327\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 2s 464us/step - loss: 0.7550 - acc: 0.6768 - val_loss: 0.8263 - val_acc: 0.6207\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.7524 - acc: 0.6796 - val_loss: 0.8201 - val_acc: 0.6380\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 2s 451us/step - loss: 0.7492 - acc: 0.6748 - val_loss: 0.8253 - val_acc: 0.6260\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 2s 493us/step - loss: 0.7488 - acc: 0.6799 - val_loss: 0.8200 - val_acc: 0.6367\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 2s 495us/step - loss: 0.7465 - acc: 0.6836 - val_loss: 0.8296 - val_acc: 0.6307\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 2s 460us/step - loss: 0.7426 - acc: 0.6811 - val_loss: 0.8216 - val_acc: 0.6340\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7417 - acc: 0.6831 - val_loss: 0.8203 - val_acc: 0.6280\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.7387 - acc: 0.6842 - val_loss: 0.8174 - val_acc: 0.6347\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 2s 447us/step - loss: 0.7369 - acc: 0.6828 - val_loss: 0.8180 - val_acc: 0.6327\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 2s 517us/step - loss: 0.7370 - acc: 0.6842 - val_loss: 0.8154 - val_acc: 0.6360\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7349 - acc: 0.6879 - val_loss: 0.8168 - val_acc: 0.6307\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7316 - acc: 0.6911 - val_loss: 0.8275 - val_acc: 0.6367\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7307 - acc: 0.6871 - val_loss: 0.8208 - val_acc: 0.6340\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 2s 451us/step - loss: 0.7297 - acc: 0.6879 - val_loss: 0.8221 - val_acc: 0.6360\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.7275 - acc: 0.6905 - val_loss: 0.8314 - val_acc: 0.6353\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7251 - acc: 0.6882 - val_loss: 0.8206 - val_acc: 0.6407\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7237 - acc: 0.6962 - val_loss: 0.8175 - val_acc: 0.6380\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7205 - acc: 0.6916 - val_loss: 0.8168 - val_acc: 0.6440\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 2s 449us/step - loss: 0.7185 - acc: 0.6953 - val_loss: 0.8394 - val_acc: 0.6380\n",
      "Epoch 110/300\n",
      "3499/3499 [==============================] - 2s 448us/step - loss: 0.7159 - acc: 0.6965 - val_loss: 0.8201 - val_acc: 0.6280\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 6s 2ms/step - loss: 1.0580 - acc: 0.4984 - val_loss: 1.0377 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 1.0369 - acc: 0.5004 - val_loss: 1.0312 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 1.0322 - acc: 0.5004 - val_loss: 1.0270 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 2s 469us/step - loss: 1.0281 - acc: 0.5004 - val_loss: 1.0225 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 2s 500us/step - loss: 1.0238 - acc: 0.5004 - val_loss: 1.0184 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 2s 515us/step - loss: 1.0197 - acc: 0.5004 - val_loss: 1.0141 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 2s 568us/step - loss: 1.0156 - acc: 0.5004 - val_loss: 1.0096 - val_acc: 0.5007\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 2s 527us/step - loss: 1.0111 - acc: 0.5004 - val_loss: 1.0051 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 1.0067 - acc: 0.5010 - val_loss: 1.0004 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 2s 482us/step - loss: 1.0021 - acc: 0.5016 - val_loss: 0.9959 - val_acc: 0.5033\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 2s 488us/step - loss: 0.9976 - acc: 0.5056 - val_loss: 0.9910 - val_acc: 0.5073\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 0.9928 - acc: 0.5099 - val_loss: 0.9862 - val_acc: 0.5087\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.9881 - acc: 0.5130 - val_loss: 0.9813 - val_acc: 0.5180\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.9830 - acc: 0.5173 - val_loss: 0.9764 - val_acc: 0.5207\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 2s 483us/step - loss: 0.9786 - acc: 0.5181 - val_loss: 0.9718 - val_acc: 0.5293\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 2s 472us/step - loss: 0.9737 - acc: 0.5230 - val_loss: 0.9668 - val_acc: 0.5307\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.9688 - acc: 0.5262 - val_loss: 0.9626 - val_acc: 0.5340\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.9645 - acc: 0.5339 - val_loss: 0.9574 - val_acc: 0.5347\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 2s 490us/step - loss: 0.9596 - acc: 0.5379 - val_loss: 0.9529 - val_acc: 0.5393\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 2s 491us/step - loss: 0.9550 - acc: 0.5413 - val_loss: 0.9486 - val_acc: 0.5480\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.9505 - acc: 0.5450 - val_loss: 0.9450 - val_acc: 0.5567\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 0.9463 - acc: 0.5522 - val_loss: 0.9399 - val_acc: 0.5587\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.9417 - acc: 0.5544 - val_loss: 0.9360 - val_acc: 0.5653\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 2s 493us/step - loss: 0.9373 - acc: 0.5627 - val_loss: 0.9315 - val_acc: 0.5673\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 0.9330 - acc: 0.5633 - val_loss: 0.9277 - val_acc: 0.5740\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 2s 493us/step - loss: 0.9286 - acc: 0.5684 - val_loss: 0.9238 - val_acc: 0.5753\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.9244 - acc: 0.5730 - val_loss: 0.9205 - val_acc: 0.5700\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 2s 492us/step - loss: 0.9204 - acc: 0.5750 - val_loss: 0.9160 - val_acc: 0.5800\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 2s 509us/step - loss: 0.9160 - acc: 0.5776 - val_loss: 0.9126 - val_acc: 0.5800\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 2s 513us/step - loss: 0.9122 - acc: 0.5816 - val_loss: 0.9094 - val_acc: 0.5900\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 2s 522us/step - loss: 0.9074 - acc: 0.5859 - val_loss: 0.9067 - val_acc: 0.5907\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 2s 504us/step - loss: 0.9036 - acc: 0.5893 - val_loss: 0.9033 - val_acc: 0.5913\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 0.9003 - acc: 0.5965 - val_loss: 0.9003 - val_acc: 0.5927\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 2s 523us/step - loss: 0.8966 - acc: 0.5962 - val_loss: 0.8961 - val_acc: 0.5973\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 2s 483us/step - loss: 0.8926 - acc: 0.5979 - val_loss: 0.8926 - val_acc: 0.5993\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.8890 - acc: 0.5999 - val_loss: 0.8909 - val_acc: 0.5947\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 2s 475us/step - loss: 0.8854 - acc: 0.6070 - val_loss: 0.8890 - val_acc: 0.5987\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 2s 486us/step - loss: 0.8818 - acc: 0.6056 - val_loss: 0.8867 - val_acc: 0.5967\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 2s 491us/step - loss: 0.8788 - acc: 0.6113 - val_loss: 0.8837 - val_acc: 0.6000\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 2s 492us/step - loss: 0.8757 - acc: 0.6113 - val_loss: 0.8812 - val_acc: 0.5987\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 2s 484us/step - loss: 0.8726 - acc: 0.6107 - val_loss: 0.8763 - val_acc: 0.6007\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 2s 489us/step - loss: 0.8689 - acc: 0.6176 - val_loss: 0.8774 - val_acc: 0.6033\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 2s 457us/step - loss: 0.8656 - acc: 0.6127 - val_loss: 0.8786 - val_acc: 0.5993\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 2s 506us/step - loss: 0.8635 - acc: 0.6210 - val_loss: 0.8715 - val_acc: 0.6040\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 2s 484us/step - loss: 0.8599 - acc: 0.6210 - val_loss: 0.8762 - val_acc: 0.6033\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.8575 - acc: 0.6222 - val_loss: 0.8692 - val_acc: 0.6027\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 2s 498us/step - loss: 0.8553 - acc: 0.6167 - val_loss: 0.8639 - val_acc: 0.6080\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 2s 488us/step - loss: 0.8517 - acc: 0.6256 - val_loss: 0.8656 - val_acc: 0.6133\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 2s 497us/step - loss: 0.8498 - acc: 0.6247 - val_loss: 0.8607 - val_acc: 0.6107\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.8463 - acc: 0.6265 - val_loss: 0.8619 - val_acc: 0.6193\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.8434 - acc: 0.6299 - val_loss: 0.8610 - val_acc: 0.6207\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 2s 503us/step - loss: 0.8408 - acc: 0.6319 - val_loss: 0.8563 - val_acc: 0.6113\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 2s 496us/step - loss: 0.8391 - acc: 0.6293 - val_loss: 0.8554 - val_acc: 0.6180\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 2s 487us/step - loss: 0.8366 - acc: 0.6339 - val_loss: 0.8519 - val_acc: 0.6160\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8334 - acc: 0.6339 - val_loss: 0.8549 - val_acc: 0.6253\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.8322 - acc: 0.6359 - val_loss: 0.8552 - val_acc: 0.6087\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 2s 491us/step - loss: 0.8299 - acc: 0.6342 - val_loss: 0.8495 - val_acc: 0.6233\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 2s 482us/step - loss: 0.8267 - acc: 0.6385 - val_loss: 0.8526 - val_acc: 0.6200\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 2s 490us/step - loss: 0.8252 - acc: 0.6365 - val_loss: 0.8475 - val_acc: 0.6187\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 2s 481us/step - loss: 0.8225 - acc: 0.6342 - val_loss: 0.8452 - val_acc: 0.6233\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 2s 451us/step - loss: 0.8203 - acc: 0.6362 - val_loss: 0.8460 - val_acc: 0.6260\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.8188 - acc: 0.6410 - val_loss: 0.8514 - val_acc: 0.6233\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 2s 475us/step - loss: 0.8162 - acc: 0.6428 - val_loss: 0.8438 - val_acc: 0.6320\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.8138 - acc: 0.6450 - val_loss: 0.8412 - val_acc: 0.6253\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.8116 - acc: 0.6399 - val_loss: 0.8470 - val_acc: 0.6127\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.8103 - acc: 0.6419 - val_loss: 0.8394 - val_acc: 0.6320\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.8063 - acc: 0.6485 - val_loss: 0.8433 - val_acc: 0.6240\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.8065 - acc: 0.6450 - val_loss: 0.8465 - val_acc: 0.6207\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 2s 478us/step - loss: 0.8035 - acc: 0.6453 - val_loss: 0.8392 - val_acc: 0.6287\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.8018 - acc: 0.6490 - val_loss: 0.8339 - val_acc: 0.6360\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7991 - acc: 0.6528 - val_loss: 0.8393 - val_acc: 0.6300\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7975 - acc: 0.6528 - val_loss: 0.8362 - val_acc: 0.6333\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 2s 483us/step - loss: 0.7963 - acc: 0.6548 - val_loss: 0.8320 - val_acc: 0.6347\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.7940 - acc: 0.6522 - val_loss: 0.8324 - val_acc: 0.6380\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 2s 485us/step - loss: 0.7908 - acc: 0.6548 - val_loss: 0.8296 - val_acc: 0.6320\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 2s 499us/step - loss: 0.7899 - acc: 0.6516 - val_loss: 0.8285 - val_acc: 0.6347\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 2s 520us/step - loss: 0.7878 - acc: 0.6599 - val_loss: 0.8278 - val_acc: 0.6453\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 2s 508us/step - loss: 0.7852 - acc: 0.6542 - val_loss: 0.8274 - val_acc: 0.6327\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 2s 462us/step - loss: 0.7829 - acc: 0.6613 - val_loss: 0.8286 - val_acc: 0.6320\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 2s 506us/step - loss: 0.7819 - acc: 0.6602 - val_loss: 0.8276 - val_acc: 0.6307\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 2s 548us/step - loss: 0.7822 - acc: 0.6570 - val_loss: 0.8239 - val_acc: 0.6400\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 2s 524us/step - loss: 0.7774 - acc: 0.6588 - val_loss: 0.8312 - val_acc: 0.6207\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 2s 519us/step - loss: 0.7777 - acc: 0.6650 - val_loss: 0.8305 - val_acc: 0.6273\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 2s 491us/step - loss: 0.7736 - acc: 0.6642 - val_loss: 0.8380 - val_acc: 0.6247\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 2s 546us/step - loss: 0.7723 - acc: 0.6682 - val_loss: 0.8218 - val_acc: 0.6347\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.7714 - acc: 0.6650 - val_loss: 0.8322 - val_acc: 0.6287\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7679 - acc: 0.6659 - val_loss: 0.8224 - val_acc: 0.6267\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 2s 471us/step - loss: 0.7657 - acc: 0.6670 - val_loss: 0.8452 - val_acc: 0.6187\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.7653 - acc: 0.6690 - val_loss: 0.8295 - val_acc: 0.6280\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7636 - acc: 0.6670 - val_loss: 0.8322 - val_acc: 0.6260\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 2s 474us/step - loss: 0.7609 - acc: 0.6685 - val_loss: 0.8203 - val_acc: 0.6333\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 2s 479us/step - loss: 0.7592 - acc: 0.6725 - val_loss: 0.8163 - val_acc: 0.6407\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 2s 461us/step - loss: 0.7568 - acc: 0.6722 - val_loss: 0.8194 - val_acc: 0.6280\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 2s 480us/step - loss: 0.7550 - acc: 0.6725 - val_loss: 0.8149 - val_acc: 0.6413\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 2s 476us/step - loss: 0.7532 - acc: 0.6759 - val_loss: 0.8256 - val_acc: 0.6320\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 2s 464us/step - loss: 0.7497 - acc: 0.6716 - val_loss: 0.8199 - val_acc: 0.6320\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 2s 488us/step - loss: 0.7497 - acc: 0.6791 - val_loss: 0.8147 - val_acc: 0.6333\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 2s 464us/step - loss: 0.7456 - acc: 0.6799 - val_loss: 0.8171 - val_acc: 0.6447\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 2s 477us/step - loss: 0.7440 - acc: 0.6742 - val_loss: 0.8139 - val_acc: 0.6340\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 2s 467us/step - loss: 0.7445 - acc: 0.6788 - val_loss: 0.8145 - val_acc: 0.6320\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 2s 468us/step - loss: 0.7427 - acc: 0.6805 - val_loss: 0.8289 - val_acc: 0.6353\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 2s 457us/step - loss: 0.7392 - acc: 0.6828 - val_loss: 0.8286 - val_acc: 0.6320\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7386 - acc: 0.6831 - val_loss: 0.8156 - val_acc: 0.6400\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 2s 457us/step - loss: 0.7380 - acc: 0.6799 - val_loss: 0.8157 - val_acc: 0.6347\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 2s 465us/step - loss: 0.7351 - acc: 0.6865 - val_loss: 0.8326 - val_acc: 0.6320\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 2s 456us/step - loss: 0.7328 - acc: 0.6833 - val_loss: 0.8208 - val_acc: 0.6340\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 2s 470us/step - loss: 0.7317 - acc: 0.6853 - val_loss: 0.8129 - val_acc: 0.6420\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 2s 473us/step - loss: 0.7274 - acc: 0.6893 - val_loss: 0.8090 - val_acc: 0.6393\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 2s 455us/step - loss: 0.7261 - acc: 0.6931 - val_loss: 0.8300 - val_acc: 0.6333\n",
      "Epoch 110/300\n",
      "3499/3499 [==============================] - 2s 454us/step - loss: 0.7242 - acc: 0.6908 - val_loss: 0.8219 - val_acc: 0.6227\n",
      "Epoch 111/300\n",
      "3499/3499 [==============================] - 2s 452us/step - loss: 0.7247 - acc: 0.6911 - val_loss: 0.8160 - val_acc: 0.6327\n",
      "Epoch 112/300\n",
      "3499/3499 [==============================] - 2s 453us/step - loss: 0.7204 - acc: 0.6962 - val_loss: 0.8151 - val_acc: 0.6340\n",
      "Epoch 113/300\n",
      "3499/3499 [==============================] - 2s 461us/step - loss: 0.7166 - acc: 0.6956 - val_loss: 0.8168 - val_acc: 0.6333\n",
      "Epoch 114/300\n",
      "3499/3499 [==============================] - 2s 465us/step - loss: 0.7178 - acc: 0.6933 - val_loss: 0.8198 - val_acc: 0.6320\n",
      "Epoch 115/300\n",
      "3499/3499 [==============================] - 2s 457us/step - loss: 0.7159 - acc: 0.6959 - val_loss: 0.8134 - val_acc: 0.6320\n",
      "Epoch 116/300\n",
      "3499/3499 [==============================] - 2s 459us/step - loss: 0.7131 - acc: 0.6942 - val_loss: 0.8093 - val_acc: 0.6453\n",
      "Epoch 117/300\n",
      "3499/3499 [==============================] - 2s 462us/step - loss: 0.7124 - acc: 0.7005 - val_loss: 0.8248 - val_acc: 0.6260\n",
      "Epoch 118/300\n",
      "3499/3499 [==============================] - 2s 450us/step - loss: 0.7095 - acc: 0.6991 - val_loss: 0.8213 - val_acc: 0.6380\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 8s 2ms/step - loss: 1.0497 - acc: 0.4987 - val_loss: 1.0387 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 3s 825us/step - loss: 1.0348 - acc: 0.5004 - val_loss: 1.0358 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 3s 802us/step - loss: 1.0307 - acc: 0.5004 - val_loss: 1.0327 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 3s 807us/step - loss: 1.0267 - acc: 0.5004 - val_loss: 1.0296 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 3s 799us/step - loss: 1.0226 - acc: 0.5004 - val_loss: 1.0262 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 3s 805us/step - loss: 1.0184 - acc: 0.5004 - val_loss: 1.0228 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 3s 812us/step - loss: 1.0140 - acc: 0.5007 - val_loss: 1.0187 - val_acc: 0.5007\n",
      "Epoch 8/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497/3497 [==============================] - 3s 815us/step - loss: 1.0094 - acc: 0.5004 - val_loss: 1.0143 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 3s 802us/step - loss: 1.0042 - acc: 0.5027 - val_loss: 1.0095 - val_acc: 0.5013 0s - loss: 1.0043 - acc: \n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 3s 803us/step - loss: 0.9980 - acc: 0.5044 - val_loss: 1.0049 - val_acc: 0.5013\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 3s 806us/step - loss: 0.9922 - acc: 0.5070 - val_loss: 0.9981 - val_acc: 0.5047\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 3s 802us/step - loss: 0.9850 - acc: 0.5133 - val_loss: 0.9910 - val_acc: 0.5080\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 3s 801us/step - loss: 0.9773 - acc: 0.5167 - val_loss: 0.9838 - val_acc: 0.5120\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 3s 828us/step - loss: 0.9693 - acc: 0.5224 - val_loss: 0.9759 - val_acc: 0.5160\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 3s 812us/step - loss: 0.9604 - acc: 0.5293 - val_loss: 0.9666 - val_acc: 0.5227\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 3s 787us/step - loss: 0.9508 - acc: 0.5416 - val_loss: 0.9585 - val_acc: 0.5353 loss: 0.9507 - acc: 0.541\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 3s 786us/step - loss: 0.9423 - acc: 0.5479 - val_loss: 0.9515 - val_acc: 0.5373\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 3s 807us/step - loss: 0.9331 - acc: 0.5585 - val_loss: 0.9435 - val_acc: 0.5527\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 3s 828us/step - loss: 0.9252 - acc: 0.5628 - val_loss: 0.9389 - val_acc: 0.5547\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 3s 800us/step - loss: 0.9174 - acc: 0.5722 - val_loss: 0.9290 - val_acc: 0.5507\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 3s 795us/step - loss: 0.9079 - acc: 0.5805 - val_loss: 0.9267 - val_acc: 0.5553\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 3s 815us/step - loss: 0.9010 - acc: 0.5839 - val_loss: 0.9172 - val_acc: 0.5787\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 3s 803us/step - loss: 0.8947 - acc: 0.5868 - val_loss: 0.9128 - val_acc: 0.5600loss: 0.8985 - acc:  - ETA: 0s - loss: 0.8975 -\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 3s 842us/step - loss: 0.8872 - acc: 0.5954 - val_loss: 0.9046 - val_acc: 0.5667\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 3s 797us/step - loss: 0.8812 - acc: 0.6019 - val_loss: 0.9207 - val_acc: 0.5800\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 3s 803us/step - loss: 0.8744 - acc: 0.6008 - val_loss: 0.8989 - val_acc: 0.5767\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 3s 821us/step - loss: 0.8672 - acc: 0.6045 - val_loss: 0.8900 - val_acc: 0.5840\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 3s 791us/step - loss: 0.8635 - acc: 0.6082 - val_loss: 0.8902 - val_acc: 0.5813\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 3s 797us/step - loss: 0.8572 - acc: 0.6048 - val_loss: 0.8809 - val_acc: 0.5880\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 3s 797us/step - loss: 0.8523 - acc: 0.6142 - val_loss: 0.8964 - val_acc: 0.5820\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 3s 805us/step - loss: 0.8482 - acc: 0.6222 - val_loss: 0.8758 - val_acc: 0.5927\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 3s 798us/step - loss: 0.8430 - acc: 0.6177 - val_loss: 0.8723 - val_acc: 0.5953\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 3s 779us/step - loss: 0.8355 - acc: 0.6240 - val_loss: 0.8850 - val_acc: 0.5947\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 3s 798us/step - loss: 0.8309 - acc: 0.6303 - val_loss: 0.8666 - val_acc: 0.6067\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 3s 774us/step - loss: 0.8284 - acc: 0.6288 - val_loss: 0.8689 - val_acc: 0.6080\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 3s 794us/step - loss: 0.8237 - acc: 0.6317 - val_loss: 0.8647 - val_acc: 0.5973\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 3s 803us/step - loss: 0.8193 - acc: 0.6363 - val_loss: 0.8569 - val_acc: 0.6220\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 3s 787us/step - loss: 0.8156 - acc: 0.6348 - val_loss: 0.8799 - val_acc: 0.5980 acc: \n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 3s 779us/step - loss: 0.8120 - acc: 0.6374 - val_loss: 0.8771 - val_acc: 0.5940\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 3s 801us/step - loss: 0.8086 - acc: 0.6403 - val_loss: 0.8938 - val_acc: 0.5680\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 3s 802us/step - loss: 0.8045 - acc: 0.6477 - val_loss: 0.8556 - val_acc: 0.6047\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 3s 795us/step - loss: 0.8020 - acc: 0.6454 - val_loss: 0.8477 - val_acc: 0.6233\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 3s 788us/step - loss: 0.7969 - acc: 0.6460 - val_loss: 0.8472 - val_acc: 0.6180\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 3s 799us/step - loss: 0.7941 - acc: 0.6466 - val_loss: 0.8510 - val_acc: 0.6133\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 3s 803us/step - loss: 0.7917 - acc: 0.6506 - val_loss: 0.8440 - val_acc: 0.6080\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 3s 805us/step - loss: 0.7882 - acc: 0.6474 - val_loss: 0.8361 - val_acc: 0.6153\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 3s 782us/step - loss: 0.7840 - acc: 0.6511 - val_loss: 0.8685 - val_acc: 0.5987\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 3s 784us/step - loss: 0.7805 - acc: 0.6500 - val_loss: 0.9192 - val_acc: 0.5593\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 3s 793us/step - loss: 0.7782 - acc: 0.6597 - val_loss: 0.8319 - val_acc: 0.6253\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 3s 777us/step - loss: 0.7739 - acc: 0.6583 - val_loss: 0.8481 - val_acc: 0.6187\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 3s 776us/step - loss: 0.7744 - acc: 0.6557 - val_loss: 0.8324 - val_acc: 0.6313\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 3s 790us/step - loss: 0.7695 - acc: 0.6603 - val_loss: 0.8294 - val_acc: 0.6260\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 3s 781us/step - loss: 0.7691 - acc: 0.6603 - val_loss: 0.8304 - val_acc: 0.6293\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 3s 789us/step - loss: 0.7611 - acc: 0.6651 - val_loss: 0.8409 - val_acc: 0.6147\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 3s 793us/step - loss: 0.7590 - acc: 0.6614 - val_loss: 0.8975 - val_acc: 0.5813\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 3s 797us/step - loss: 0.7561 - acc: 0.6694 - val_loss: 0.8767 - val_acc: 0.6113\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 3s 806us/step - loss: 0.7567 - acc: 0.6697 - val_loss: 0.8295 - val_acc: 0.6327\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 3s 803us/step - loss: 0.7534 - acc: 0.6623 - val_loss: 0.8763 - val_acc: 0.6067\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 3s 806us/step - loss: 0.7520 - acc: 0.6729 - val_loss: 0.8238 - val_acc: 0.6313\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 3s 791us/step - loss: 0.7451 - acc: 0.6714 - val_loss: 0.8628 - val_acc: 0.5980\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 3s 786us/step - loss: 0.7426 - acc: 0.6720 - val_loss: 0.8411 - val_acc: 0.6200\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 3s 806us/step - loss: 0.7451 - acc: 0.6729 - val_loss: 0.8231 - val_acc: 0.6347\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 3s 790us/step - loss: 0.7400 - acc: 0.6703 - val_loss: 0.8958 - val_acc: 0.5953\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 3s 818us/step - loss: 0.7393 - acc: 0.6729 - val_loss: 0.8210 - val_acc: 0.6393\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 3s 789us/step - loss: 0.7343 - acc: 0.6754 - val_loss: 0.8447 - val_acc: 0.6300\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 3s 785us/step - loss: 0.7332 - acc: 0.6763 - val_loss: 0.8270 - val_acc: 0.6307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 3s 797us/step - loss: 0.7313 - acc: 0.6792 - val_loss: 0.8172 - val_acc: 0.6360\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 3s 789us/step - loss: 0.7295 - acc: 0.6814 - val_loss: 0.8223 - val_acc: 0.6300\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 3s 801us/step - loss: 0.7270 - acc: 0.6786 - val_loss: 0.8203 - val_acc: 0.6400\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 3s 788us/step - loss: 0.7216 - acc: 0.6843 - val_loss: 0.8398 - val_acc: 0.6187\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 3s 779us/step - loss: 0.7220 - acc: 0.6840 - val_loss: 0.8398 - val_acc: 0.6140\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 3s 768us/step - loss: 0.7180 - acc: 0.6803 - val_loss: 0.8455 - val_acc: 0.6300- loss: \n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 3s 785us/step - loss: 0.7168 - acc: 0.6840 - val_loss: 0.8447 - val_acc: 0.6233\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 3s 796us/step - loss: 0.7139 - acc: 0.6837 - val_loss: 0.8235 - val_acc: 0.6327\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 3s 789us/step - loss: 0.7057 - acc: 0.6886 - val_loss: 0.8633 - val_acc: 0.6127\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 3s 786us/step - loss: 0.7074 - acc: 0.6937 - val_loss: 0.8357 - val_acc: 0.6220\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 3s 784us/step - loss: 0.7031 - acc: 0.6923 - val_loss: 0.8211 - val_acc: 0.6247\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0523 - acc: 0.4983 - val_loss: 1.0397 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 3s 791us/step - loss: 1.0356 - acc: 0.5003 - val_loss: 1.0353 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 3s 804us/step - loss: 1.0311 - acc: 0.5003 - val_loss: 1.0315 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 3s 801us/step - loss: 1.0263 - acc: 0.5003 - val_loss: 1.0278 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 3s 796us/step - loss: 1.0221 - acc: 0.5003 - val_loss: 1.0236 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 3s 809us/step - loss: 1.0170 - acc: 0.5003 - val_loss: 1.0191 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 3s 799us/step - loss: 1.0117 - acc: 0.5003 - val_loss: 1.0142 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 3s 789us/step - loss: 1.0062 - acc: 0.5006 - val_loss: 1.0089 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 3s 783us/step - loss: 1.0000 - acc: 0.5026 - val_loss: 1.0031 - val_acc: 0.5040\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 3s 783us/step - loss: 0.9930 - acc: 0.5060 - val_loss: 0.9975 - val_acc: 0.5060\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 3s 789us/step - loss: 0.9862 - acc: 0.5103 - val_loss: 0.9898 - val_acc: 0.5160\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 3s 802us/step - loss: 0.9782 - acc: 0.5134 - val_loss: 0.9836 - val_acc: 0.5193\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 3s 794us/step - loss: 0.9707 - acc: 0.5203 - val_loss: 0.9760 - val_acc: 0.5220\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 3s 790us/step - loss: 0.9624 - acc: 0.5266 - val_loss: 0.9681 - val_acc: 0.5287\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 3s 789us/step - loss: 0.9549 - acc: 0.5286 - val_loss: 0.9610 - val_acc: 0.5393\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 3s 788us/step - loss: 0.9468 - acc: 0.5392 - val_loss: 0.9573 - val_acc: 0.5433\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 3s 785us/step - loss: 0.9404 - acc: 0.5437 - val_loss: 0.9469 - val_acc: 0.5487\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 3s 801us/step - loss: 0.9329 - acc: 0.5535 - val_loss: 0.9413 - val_acc: 0.5593\n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 3s 800us/step - loss: 0.9262 - acc: 0.5569 - val_loss: 0.9398 - val_acc: 0.5540\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 3s 831us/step - loss: 0.9197 - acc: 0.5655 - val_loss: 0.9309 - val_acc: 0.5567\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 3s 798us/step - loss: 0.9138 - acc: 0.5666 - val_loss: 0.9232 - val_acc: 0.5647\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 3s 795us/step - loss: 0.9078 - acc: 0.5752 - val_loss: 0.9189 - val_acc: 0.5680\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 0.9021 - acc: 0.5772 - val_loss: 0.9193 - val_acc: 0.5740\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 3s 805us/step - loss: 0.8976 - acc: 0.5798 - val_loss: 0.9180 - val_acc: 0.5713\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 3s 796us/step - loss: 0.8927 - acc: 0.5849 - val_loss: 0.9094 - val_acc: 0.5820\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 3s 788us/step - loss: 0.8859 - acc: 0.5929 - val_loss: 0.9097 - val_acc: 0.5733\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 3s 795us/step - loss: 0.8818 - acc: 0.5946 - val_loss: 0.8971 - val_acc: 0.5773\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.8750 - acc: 0.5995 - val_loss: 0.9198 - val_acc: 0.5640\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 3s 800us/step - loss: 0.8710 - acc: 0.6041 - val_loss: 0.8894 - val_acc: 0.5873\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 3s 845us/step - loss: 0.8654 - acc: 0.6046 - val_loss: 0.8880 - val_acc: 0.5827\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 3s 796us/step - loss: 0.8616 - acc: 0.6081 - val_loss: 0.8872 - val_acc: 0.5820\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 3s 806us/step - loss: 0.8589 - acc: 0.6098 - val_loss: 0.8877 - val_acc: 0.5767\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 3s 823us/step - loss: 0.8564 - acc: 0.6098 - val_loss: 0.8790 - val_acc: 0.5853\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 3s 785us/step - loss: 0.8498 - acc: 0.6115 - val_loss: 0.8982 - val_acc: 0.5720\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 3s 785us/step - loss: 0.8470 - acc: 0.6198 - val_loss: 0.8923 - val_acc: 0.5767\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 3s 776us/step - loss: 0.8445 - acc: 0.6149 - val_loss: 0.8792 - val_acc: 0.5780\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 3s 804us/step - loss: 0.8377 - acc: 0.6226 - val_loss: 0.8688 - val_acc: 0.5900\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 0.8367 - acc: 0.6221 - val_loss: 0.8768 - val_acc: 0.5860\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.8336 - acc: 0.6244 - val_loss: 0.8692 - val_acc: 0.5893\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 3s 776us/step - loss: 0.8284 - acc: 0.6238 - val_loss: 0.9001 - val_acc: 0.5727\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 3s 771us/step - loss: 0.8259 - acc: 0.6318 - val_loss: 0.8711 - val_acc: 0.5927\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 3s 805us/step - loss: 0.8241 - acc: 0.6269 - val_loss: 0.8677 - val_acc: 0.5893\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 3s 802us/step - loss: 0.8219 - acc: 0.6284 - val_loss: 0.8650 - val_acc: 0.5933\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 3s 771us/step - loss: 0.8165 - acc: 0.6344 - val_loss: 0.8651 - val_acc: 0.5880\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 3s 789us/step - loss: 0.8133 - acc: 0.6424 - val_loss: 0.8578 - val_acc: 0.5953ss: 0.8149 \n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 3s 789us/step - loss: 0.8127 - acc: 0.6366 - val_loss: 0.8508 - val_acc: 0.59400s - loss: 0.8263\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 3s 788us/step - loss: 0.8082 - acc: 0.6429 - val_loss: 0.8488 - val_acc: 0.6047\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 3s 770us/step - loss: 0.8048 - acc: 0.6378 - val_loss: 0.8765 - val_acc: 0.5893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 3s 782us/step - loss: 0.8044 - acc: 0.6435 - val_loss: 0.8648 - val_acc: 0.5893\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 3s 773us/step - loss: 0.8006 - acc: 0.6478 - val_loss: 0.8816 - val_acc: 0.5767\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 3s 823us/step - loss: 0.7988 - acc: 0.6447 - val_loss: 0.8487 - val_acc: 0.6013\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 3s 782us/step - loss: 0.7941 - acc: 0.6481 - val_loss: 0.8499 - val_acc: 0.6013\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 3s 777us/step - loss: 0.7912 - acc: 0.6515 - val_loss: 0.8577 - val_acc: 0.5980\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 3s 796us/step - loss: 0.7915 - acc: 0.6469 - val_loss: 0.8456 - val_acc: 0.6040\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.7881 - acc: 0.6538 - val_loss: 0.8740 - val_acc: 0.5927\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 3s 771us/step - loss: 0.7856 - acc: 0.6478 - val_loss: 0.8605 - val_acc: 0.5860: 1s - loss: 0.77\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 3s 776us/step - loss: 0.7850 - acc: 0.6518 - val_loss: 0.9038 - val_acc: 0.5727\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.7797 - acc: 0.6561 - val_loss: 0.8861 - val_acc: 0.5827\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 3s 769us/step - loss: 0.7775 - acc: 0.6561 - val_loss: 0.8477 - val_acc: 0.5993\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 3s 767us/step - loss: 0.7763 - acc: 0.6575 - val_loss: 0.8506 - val_acc: 0.6053\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 3s 778us/step - loss: 0.7722 - acc: 0.6604 - val_loss: 0.8702 - val_acc: 0.5973\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 3s 796us/step - loss: 0.7727 - acc: 0.6641 - val_loss: 0.8379 - val_acc: 0.6087\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 3s 786us/step - loss: 0.7676 - acc: 0.6675 - val_loss: 0.8797 - val_acc: 0.5900\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 3s 779us/step - loss: 0.7661 - acc: 0.6644 - val_loss: 0.8543 - val_acc: 0.6013\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 3s 769us/step - loss: 0.7639 - acc: 0.6692 - val_loss: 0.8399 - val_acc: 0.6140\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 3s 776us/step - loss: 0.7582 - acc: 0.6632 - val_loss: 0.8380 - val_acc: 0.6087\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 3s 818us/step - loss: 0.7595 - acc: 0.6695 - val_loss: 0.8488 - val_acc: 0.6147\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 3s 792us/step - loss: 0.7552 - acc: 0.6710 - val_loss: 0.8329 - val_acc: 0.6073\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 3s 797us/step - loss: 0.7523 - acc: 0.6678 - val_loss: 0.8283 - val_acc: 0.6173\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.7548 - acc: 0.6718 - val_loss: 0.8413 - val_acc: 0.6080\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 3s 822us/step - loss: 0.7522 - acc: 0.6812 - val_loss: 0.8304 - val_acc: 0.6180\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 3s 773us/step - loss: 0.7463 - acc: 0.6781 - val_loss: 0.8295 - val_acc: 0.6267s - loss\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 3s 781us/step - loss: 0.7419 - acc: 0.6727 - val_loss: 0.8389 - val_acc: 0.6180\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 3s 785us/step - loss: 0.7409 - acc: 0.6775 - val_loss: 0.8338 - val_acc: 0.6087\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 0.7399 - acc: 0.6801 - val_loss: 0.8378 - val_acc: 0.6127\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 3s 791us/step - loss: 0.7365 - acc: 0.6772 - val_loss: 0.8232 - val_acc: 0.6213\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 3s 783us/step - loss: 0.7328 - acc: 0.6835 - val_loss: 0.8337 - val_acc: 0.6267\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 3s 765us/step - loss: 0.7330 - acc: 0.6832 - val_loss: 0.8505 - val_acc: 0.5893\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 0.7304 - acc: 0.6735 - val_loss: 0.8250 - val_acc: 0.6233\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 3s 776us/step - loss: 0.7263 - acc: 0.6801 - val_loss: 0.8841 - val_acc: 0.5887\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 3s 776us/step - loss: 0.7268 - acc: 0.6872 - val_loss: 0.8874 - val_acc: 0.6040\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 0.7243 - acc: 0.6870 - val_loss: 0.8511 - val_acc: 0.6047\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 3s 819us/step - loss: 0.7186 - acc: 0.6841 - val_loss: 0.8738 - val_acc: 0.5967\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 3s 840us/step - loss: 0.7168 - acc: 0.6933 - val_loss: 0.8230 - val_acc: 0.6307\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 0.7147 - acc: 0.6864 - val_loss: 0.8263 - val_acc: 0.6280\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 3s 773us/step - loss: 0.7100 - acc: 0.6973 - val_loss: 0.8282 - val_acc: 0.6267\n",
      "Epoch 87/300\n",
      "3498/3498 [==============================] - 3s 773us/step - loss: 0.7096 - acc: 0.6938 - val_loss: 0.8326 - val_acc: 0.6300\n",
      "Epoch 88/300\n",
      "3498/3498 [==============================] - 3s 777us/step - loss: 0.7083 - acc: 0.7004 - val_loss: 0.8260 - val_acc: 0.6287\n",
      "Epoch 89/300\n",
      "3498/3498 [==============================] - 3s 787us/step - loss: 0.7046 - acc: 0.6984 - val_loss: 0.8304 - val_acc: 0.6220\n",
      "Epoch 90/300\n",
      "3498/3498 [==============================] - 3s 784us/step - loss: 0.6991 - acc: 0.6984 - val_loss: 0.8330 - val_acc: 0.6160\n",
      "Epoch 91/300\n",
      "3498/3498 [==============================] - 3s 789us/step - loss: 0.7003 - acc: 0.6975 - val_loss: 0.8365 - val_acc: 0.6080s: 0.6970 - acc: 0.69\n",
      "Epoch 92/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.7003 - acc: 0.7024 - val_loss: 0.9221 - val_acc: 0.5853\n",
      "Epoch 93/300\n",
      "3498/3498 [==============================] - 3s 791us/step - loss: 0.6989 - acc: 0.6998 - val_loss: 0.9909 - val_acc: 0.5387\n",
      "Epoch 94/300\n",
      "3498/3498 [==============================] - 3s 779us/step - loss: 0.6944 - acc: 0.7010 - val_loss: 0.8472 - val_acc: 0.6160\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 8s 2ms/step - loss: 1.0521 - acc: 0.4990 - val_loss: 1.0372 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 1.0359 - acc: 0.5004 - val_loss: 1.0333 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 1.0314 - acc: 0.5004 - val_loss: 1.0295 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 1.0271 - acc: 0.5004 - val_loss: 1.0253 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 1.0222 - acc: 0.5004 - val_loss: 1.0215 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 3s 792us/step - loss: 1.0176 - acc: 0.5004 - val_loss: 1.0171 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 3s 807us/step - loss: 1.0125 - acc: 0.5007 - val_loss: 1.0117 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 1.0066 - acc: 0.5016 - val_loss: 1.0064 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 3s 789us/step - loss: 1.0005 - acc: 0.5044 - val_loss: 1.0002 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.9938 - acc: 0.5076 - val_loss: 0.9946 - val_acc: 0.5167\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.9870 - acc: 0.5113 - val_loss: 0.9875 - val_acc: 0.5173\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 3s 806us/step - loss: 0.9795 - acc: 0.5179 - val_loss: 0.9803 - val_acc: 0.5173\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.9722 - acc: 0.5190 - val_loss: 0.9726 - val_acc: 0.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 3s 804us/step - loss: 0.9636 - acc: 0.5262 - val_loss: 0.9660 - val_acc: 0.5340\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 3s 807us/step - loss: 0.9576 - acc: 0.5299 - val_loss: 0.9587 - val_acc: 0.5433\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.9497 - acc: 0.5370 - val_loss: 0.9513 - val_acc: 0.5553\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.9410 - acc: 0.5399 - val_loss: 0.9515 - val_acc: 0.5613\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 3s 789us/step - loss: 0.9370 - acc: 0.5556 - val_loss: 0.9387 - val_acc: 0.5647\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.9298 - acc: 0.5562 - val_loss: 0.9338 - val_acc: 0.5667\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.9226 - acc: 0.5647 - val_loss: 0.9313 - val_acc: 0.5653\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 0.9181 - acc: 0.5682 - val_loss: 0.9443 - val_acc: 0.5647\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.9116 - acc: 0.5664 - val_loss: 0.9184 - val_acc: 0.5747\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 3s 800us/step - loss: 0.9044 - acc: 0.5785 - val_loss: 0.9136 - val_acc: 0.5693\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.8999 - acc: 0.5779 - val_loss: 0.9181 - val_acc: 0.57070s - loss: 0.9032\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 3s 833us/step - loss: 0.8959 - acc: 0.5833 - val_loss: 0.9093 - val_acc: 0.5727\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.8888 - acc: 0.5873 - val_loss: 0.9100 - val_acc: 0.5767\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 3s 792us/step - loss: 0.8843 - acc: 0.5899 - val_loss: 0.8997 - val_acc: 0.5860\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 3s 810us/step - loss: 0.8795 - acc: 0.5976 - val_loss: 0.8920 - val_acc: 0.5833\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 3s 801us/step - loss: 0.8736 - acc: 0.6016 - val_loss: 0.8905 - val_acc: 0.5867\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.8698 - acc: 0.6065 - val_loss: 0.8861 - val_acc: 0.5833\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 3s 798us/step - loss: 0.8623 - acc: 0.6099 - val_loss: 0.8822 - val_acc: 0.5880\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 3s 762us/step - loss: 0.8597 - acc: 0.6067 - val_loss: 0.8909 - val_acc: 0.5733\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 3s 784us/step - loss: 0.8560 - acc: 0.6082 - val_loss: 0.8801 - val_acc: 0.5933\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 0.8519 - acc: 0.6170 - val_loss: 0.8746 - val_acc: 0.5853\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.8459 - acc: 0.6125 - val_loss: 0.8706 - val_acc: 0.5967\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 3s 759us/step - loss: 0.8430 - acc: 0.6233 - val_loss: 0.8706 - val_acc: 0.5867\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 3s 756us/step - loss: 0.8401 - acc: 0.6262 - val_loss: 0.8998 - val_acc: 0.5820\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.8348 - acc: 0.6242 - val_loss: 0.8790 - val_acc: 0.5933\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.8326 - acc: 0.6265 - val_loss: 0.8912 - val_acc: 0.5793\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 3s 792us/step - loss: 0.8325 - acc: 0.6290 - val_loss: 0.8607 - val_acc: 0.6067\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.8268 - acc: 0.6270 - val_loss: 0.8563 - val_acc: 0.6060\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.8258 - acc: 0.6319 - val_loss: 0.9309 - val_acc: 0.5440\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.8209 - acc: 0.6302 - val_loss: 0.8562 - val_acc: 0.6067\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.8176 - acc: 0.6376 - val_loss: 0.8731 - val_acc: 0.5853\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 0.8141 - acc: 0.6462 - val_loss: 0.9526 - val_acc: 0.5187\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 3s 794us/step - loss: 0.8146 - acc: 0.6382 - val_loss: 0.8546 - val_acc: 0.5993\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 3s 793us/step - loss: 0.8110 - acc: 0.6379 - val_loss: 0.8529 - val_acc: 0.6013\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 3s 826us/step - loss: 0.8065 - acc: 0.6448 - val_loss: 0.8445 - val_acc: 0.6147\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 3s 764us/step - loss: 0.8047 - acc: 0.6442 - val_loss: 0.8630 - val_acc: 0.6060\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 3s 789us/step - loss: 0.7986 - acc: 0.6493 - val_loss: 0.8420 - val_acc: 0.6147\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7965 - acc: 0.6528 - val_loss: 0.8480 - val_acc: 0.6120\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 3s 764us/step - loss: 0.7932 - acc: 0.6490 - val_loss: 0.8644 - val_acc: 0.5967\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 3s 793us/step - loss: 0.7934 - acc: 0.6530 - val_loss: 0.8417 - val_acc: 0.6207\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.7905 - acc: 0.6533 - val_loss: 0.8369 - val_acc: 0.6180\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 3s 785us/step - loss: 0.7851 - acc: 0.6599 - val_loss: 0.8585 - val_acc: 0.5980\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 3s 773us/step - loss: 0.7861 - acc: 0.6590 - val_loss: 0.8479 - val_acc: 0.5987: 0.7820 -\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.7847 - acc: 0.6593 - val_loss: 0.8565 - val_acc: 0.5980\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.7794 - acc: 0.6596 - val_loss: 0.8779 - val_acc: 0.5840\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.7789 - acc: 0.6625 - val_loss: 0.8755 - val_acc: 0.5900\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 3s 766us/step - loss: 0.7768 - acc: 0.6602 - val_loss: 0.8369 - val_acc: 0.6173\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.7712 - acc: 0.6639 - val_loss: 0.8383 - val_acc: 0.6173\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.7705 - acc: 0.6642 - val_loss: 0.9035 - val_acc: 0.5687\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 3s 801us/step - loss: 0.7694 - acc: 0.6619 - val_loss: 0.8359 - val_acc: 0.6213\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.7648 - acc: 0.6699 - val_loss: 0.8303 - val_acc: 0.6287\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.7609 - acc: 0.6728 - val_loss: 0.8281 - val_acc: 0.6287\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 3s 782us/step - loss: 0.7632 - acc: 0.6716 - val_loss: 0.8299 - val_acc: 0.6287\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 3s 782us/step - loss: 0.7594 - acc: 0.6745 - val_loss: 0.8392 - val_acc: 0.6087\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7556 - acc: 0.6762 - val_loss: 0.8422 - val_acc: 0.6053\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.7553 - acc: 0.6745 - val_loss: 0.8289 - val_acc: 0.6240\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.7508 - acc: 0.6751 - val_loss: 0.8266 - val_acc: 0.6347\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 3s 782us/step - loss: 0.7490 - acc: 0.6796 - val_loss: 0.8645 - val_acc: 0.59600.7452 \n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 0.7435 - acc: 0.6831 - val_loss: 0.9209 - val_acc: 0.5827\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 3s 773us/step - loss: 0.7485 - acc: 0.6802 - val_loss: 0.8454 - val_acc: 0.6140 acc: 0\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.7400 - acc: 0.6845 - val_loss: 0.8338 - val_acc: 0.6233\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 3s 761us/step - loss: 0.7390 - acc: 0.6839 - val_loss: 0.8476 - val_acc: 0.6220\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 3s 785us/step - loss: 0.7376 - acc: 0.6839 - val_loss: 0.8261 - val_acc: 0.6180\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 3s 798us/step - loss: 0.7335 - acc: 0.6822 - val_loss: 0.8233 - val_acc: 0.6387\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 3s 818us/step - loss: 0.7300 - acc: 0.6905 - val_loss: 0.8247 - val_acc: 0.6287\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 3s 789us/step - loss: 0.7313 - acc: 0.6902 - val_loss: 0.8360 - val_acc: 0.6173\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 3s 794us/step - loss: 0.7294 - acc: 0.6899 - val_loss: 0.8224 - val_acc: 0.6347\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.7254 - acc: 0.6845 - val_loss: 0.8289 - val_acc: 0.6340\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 3s 781us/step - loss: 0.7205 - acc: 0.6942 - val_loss: 0.8416 - val_acc: 0.6067\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.7210 - acc: 0.6925 - val_loss: 0.8639 - val_acc: 0.5973\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7182 - acc: 0.6896 - val_loss: 0.8528 - val_acc: 0.6140\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.7149 - acc: 0.6959 - val_loss: 0.8172 - val_acc: 0.6353\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 0.7143 - acc: 0.6956 - val_loss: 0.8326 - val_acc: 0.6313\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 3s 793us/step - loss: 0.7128 - acc: 0.6973 - val_loss: 0.8291 - val_acc: 0.6253\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7079 - acc: 0.6911 - val_loss: 0.8555 - val_acc: 0.6127\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7081 - acc: 0.6979 - val_loss: 0.8302 - val_acc: 0.6373\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 3s 777us/step - loss: 0.7067 - acc: 0.6953 - val_loss: 0.8202 - val_acc: 0.6393\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.7066 - acc: 0.6991 - val_loss: 0.8635 - val_acc: 0.5993\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.7003 - acc: 0.7002 - val_loss: 0.8605 - val_acc: 0.6073\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 3s 766us/step - loss: 0.6973 - acc: 0.6973 - val_loss: 0.8314 - val_acc: 0.6333\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 3s 764us/step - loss: 0.6992 - acc: 0.7028 - val_loss: 0.8192 - val_acc: 0.6373\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 3s 762us/step - loss: 0.6942 - acc: 0.7036 - val_loss: 0.8317 - val_acc: 0.6333\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0522 - acc: 0.4990 - val_loss: 1.0370 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 1.0360 - acc: 0.5004 - val_loss: 1.0328 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 1.0316 - acc: 0.5004 - val_loss: 1.0288 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 3s 789us/step - loss: 1.0274 - acc: 0.5004 - val_loss: 1.0242 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 3s 784us/step - loss: 1.0226 - acc: 0.5004 - val_loss: 1.0202 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 1.0180 - acc: 0.5004 - val_loss: 1.0156 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 1.0131 - acc: 0.5004 - val_loss: 1.0100 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 3s 793us/step - loss: 1.0074 - acc: 0.5007 - val_loss: 1.0045 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 1.0016 - acc: 0.5030 - val_loss: 0.9983 - val_acc: 0.5027\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 3s 819us/step - loss: 0.9952 - acc: 0.5044 - val_loss: 0.9925 - val_acc: 0.5100\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.9888 - acc: 0.5104 - val_loss: 0.9852 - val_acc: 0.5140 0.9946\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.9814 - acc: 0.5133 - val_loss: 0.9779 - val_acc: 0.5140: 1\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.9743 - acc: 0.5181 - val_loss: 0.9700 - val_acc: 0.5247ss: 0.9757 - acc: 0.51\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 3s 800us/step - loss: 0.9659 - acc: 0.5239 - val_loss: 0.9628 - val_acc: 0.5273\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.9593 - acc: 0.5250 - val_loss: 0.9546 - val_acc: 0.5353\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 3s 790us/step - loss: 0.9515 - acc: 0.5319 - val_loss: 0.9471 - val_acc: 0.5527\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.9435 - acc: 0.5370 - val_loss: 0.9433 - val_acc: 0.5673\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 3s 793us/step - loss: 0.9385 - acc: 0.5442 - val_loss: 0.9324 - val_acc: 0.5653\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.9310 - acc: 0.5473 - val_loss: 0.9280 - val_acc: 0.5693\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 3s 787us/step - loss: 0.9244 - acc: 0.5579 - val_loss: 0.9203 - val_acc: 0.5807\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.9193 - acc: 0.5564 - val_loss: 0.9312 - val_acc: 0.5733\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 3s 784us/step - loss: 0.9126 - acc: 0.5624 - val_loss: 0.9113 - val_acc: 0.5873\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 0.9060 - acc: 0.5702 - val_loss: 0.9017 - val_acc: 0.59400\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 3s 805us/step - loss: 0.9007 - acc: 0.5727 - val_loss: 0.9004 - val_acc: 0.5907\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.8962 - acc: 0.5773 - val_loss: 0.8929 - val_acc: 0.5967\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 3s 805us/step - loss: 0.8896 - acc: 0.5839 - val_loss: 0.8868 - val_acc: 0.5947\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 0.8858 - acc: 0.5853 - val_loss: 0.8838 - val_acc: 0.5973\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.8803 - acc: 0.5925 - val_loss: 0.8783 - val_acc: 0.6027\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.8763 - acc: 0.5922 - val_loss: 0.8758 - val_acc: 0.5980\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.8715 - acc: 0.5970 - val_loss: 0.8735 - val_acc: 0.6020\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.8650 - acc: 0.6039 - val_loss: 0.8631 - val_acc: 0.6180\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.8616 - acc: 0.6025 - val_loss: 0.8711 - val_acc: 0.5927\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.8582 - acc: 0.6059 - val_loss: 0.8580 - val_acc: 0.6220\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.8538 - acc: 0.6105 - val_loss: 0.8523 - val_acc: 0.6093\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 3s 784us/step - loss: 0.8492 - acc: 0.6096 - val_loss: 0.8501 - val_acc: 0.6093\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.8455 - acc: 0.6202 - val_loss: 0.8509 - val_acc: 0.6167\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.8425 - acc: 0.6205 - val_loss: 0.8639 - val_acc: 0.6127\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 3s 768us/step - loss: 0.8374 - acc: 0.6216 - val_loss: 0.8571 - val_acc: 0.6240\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.8349 - acc: 0.6242 - val_loss: 0.8923 - val_acc: 0.5673\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.8349 - acc: 0.6259 - val_loss: 0.8398 - val_acc: 0.6253\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.8297 - acc: 0.6245 - val_loss: 0.8382 - val_acc: 0.6087\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 3s 764us/step - loss: 0.8272 - acc: 0.6279 - val_loss: 0.8749 - val_acc: 0.5840\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 3s 781us/step - loss: 0.8228 - acc: 0.6279 - val_loss: 0.8348 - val_acc: 0.6300\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 3s 765us/step - loss: 0.8192 - acc: 0.6399 - val_loss: 0.8516 - val_acc: 0.6013\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 0.8162 - acc: 0.6399 - val_loss: 0.9693 - val_acc: 0.5140\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 3s 803us/step - loss: 0.8162 - acc: 0.6362 - val_loss: 0.8319 - val_acc: 0.6227\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 3s 814us/step - loss: 0.8122 - acc: 0.6425 - val_loss: 0.8205 - val_acc: 0.6287\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.8090 - acc: 0.6370 - val_loss: 0.8298 - val_acc: 0.6380\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 3s 796us/step - loss: 0.8070 - acc: 0.6462 - val_loss: 0.8508 - val_acc: 0.6260\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 3s 832us/step - loss: 0.8025 - acc: 0.6488 - val_loss: 0.8177 - val_acc: 0.6327\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 3s 804us/step - loss: 0.7989 - acc: 0.6470 - val_loss: 0.8297 - val_acc: 0.6360\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 3s 801us/step - loss: 0.7949 - acc: 0.6539 - val_loss: 0.8334 - val_acc: 0.6127\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 3s 805us/step - loss: 0.7957 - acc: 0.6462 - val_loss: 0.8132 - val_acc: 0.6267\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.7934 - acc: 0.6530 - val_loss: 0.8085 - val_acc: 0.6413s: 0.81 - ETA: 0s - loss: 0.7927 - acc: 0.\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.7880 - acc: 0.6579 - val_loss: 0.8569 - val_acc: 0.6027\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.7898 - acc: 0.6556 - val_loss: 0.8216 - val_acc: 0.6253\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.7873 - acc: 0.6530 - val_loss: 0.8216 - val_acc: 0.6320\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.7831 - acc: 0.6599 - val_loss: 0.8419 - val_acc: 0.6180\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 3s 777us/step - loss: 0.7805 - acc: 0.6505 - val_loss: 0.8375 - val_acc: 0.6147\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.7784 - acc: 0.6585 - val_loss: 0.8069 - val_acc: 0.6473\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 3s 801us/step - loss: 0.7727 - acc: 0.6599 - val_loss: 0.8005 - val_acc: 0.6453\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 0.7725 - acc: 0.6648 - val_loss: 0.8324 - val_acc: 0.6220\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.7703 - acc: 0.6610 - val_loss: 0.8018 - val_acc: 0.6367\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 3s 811us/step - loss: 0.7677 - acc: 0.6668 - val_loss: 0.7985 - val_acc: 0.6400: 0.7709 - acc: \n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.7649 - acc: 0.6656 - val_loss: 0.8041 - val_acc: 0.6353\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 3s 813us/step - loss: 0.7660 - acc: 0.6596 - val_loss: 0.7956 - val_acc: 0.6507\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 3s 765us/step - loss: 0.7617 - acc: 0.6733 - val_loss: 0.8153 - val_acc: 0.6260\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 0.7596 - acc: 0.6676 - val_loss: 0.8119 - val_acc: 0.6227\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7575 - acc: 0.6676 - val_loss: 0.8062 - val_acc: 0.6440\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.7529 - acc: 0.6739 - val_loss: 0.7961 - val_acc: 0.6460\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.7516 - acc: 0.6753 - val_loss: 0.8533 - val_acc: 0.6120\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.7464 - acc: 0.6736 - val_loss: 0.9057 - val_acc: 0.6127\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 3s 777us/step - loss: 0.7535 - acc: 0.6702 - val_loss: 0.8202 - val_acc: 0.6273\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.7435 - acc: 0.6782 - val_loss: 0.7919 - val_acc: 0.6533\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 3s 773us/step - loss: 0.7425 - acc: 0.6802 - val_loss: 0.8127 - val_acc: 0.6347\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 3s 824us/step - loss: 0.7426 - acc: 0.6753 - val_loss: 0.7880 - val_acc: 0.6540\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 3s 781us/step - loss: 0.7350 - acc: 0.6811 - val_loss: 0.7894 - val_acc: 0.6587\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 3s 824us/step - loss: 0.7343 - acc: 0.6833 - val_loss: 0.7868 - val_acc: 0.6547\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 3s 773us/step - loss: 0.7323 - acc: 0.6819 - val_loss: 0.7896 - val_acc: 0.6453\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 0.7301 - acc: 0.6859 - val_loss: 0.8113 - val_acc: 0.6353\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 3s 794us/step - loss: 0.7290 - acc: 0.6839 - val_loss: 0.7862 - val_acc: 0.6527\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 3s 769us/step - loss: 0.7238 - acc: 0.6885 - val_loss: 0.8115 - val_acc: 0.6173\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 3s 777us/step - loss: 0.7237 - acc: 0.6859 - val_loss: 0.8119 - val_acc: 0.6287\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.7195 - acc: 0.6913 - val_loss: 0.8248 - val_acc: 0.6480\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.7164 - acc: 0.6936 - val_loss: 0.7825 - val_acc: 0.6620\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.7152 - acc: 0.6939 - val_loss: 0.7949 - val_acc: 0.6560\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 3s 788us/step - loss: 0.7160 - acc: 0.6951 - val_loss: 0.7888 - val_acc: 0.6467\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.7078 - acc: 0.7022 - val_loss: 0.8149 - val_acc: 0.6427\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.7081 - acc: 0.6993 - val_loss: 0.7879 - val_acc: 0.6540\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.7057 - acc: 0.6953 - val_loss: 0.7809 - val_acc: 0.6680\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 0.7067 - acc: 0.6951 - val_loss: 0.7865 - val_acc: 0.6387 0s - loss: 0.7080 - acc: 0.693\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.6992 - acc: 0.7002 - val_loss: 0.7938 - val_acc: 0.6480\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 3s 766us/step - loss: 0.6968 - acc: 0.7013 - val_loss: 0.8091 - val_acc: 0.6427\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 3s 807us/step - loss: 0.6976 - acc: 0.7033 - val_loss: 0.7791 - val_acc: 0.6527\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.6951 - acc: 0.7028 - val_loss: 0.7863 - val_acc: 0.6580\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 3s 768us/step - loss: 0.6863 - acc: 0.7125 - val_loss: 0.8148 - val_acc: 0.6380\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 3s 768us/step - loss: 0.6869 - acc: 0.7051 - val_loss: 0.7990 - val_acc: 0.6387\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 0.6829 - acc: 0.7085 - val_loss: 0.7932 - val_acc: 0.6580\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.6809 - acc: 0.7108 - val_loss: 0.7815 - val_acc: 0.6547\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 3s 781us/step - loss: 0.6795 - acc: 0.7182 - val_loss: 0.7804 - val_acc: 0.6580\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.6779 - acc: 0.7148 - val_loss: 0.7814 - val_acc: 0.6627cc\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 3s 768us/step - loss: 0.6732 - acc: 0.7188 - val_loss: 0.8037 - val_acc: 0.6533\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.6767 - acc: 0.7173 - val_loss: 0.7985 - val_acc: 0.6587\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.6738 - acc: 0.7196 - val_loss: 0.8132 - val_acc: 0.6367\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0528 - acc: 0.4990 - val_loss: 1.0361 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 3s 802us/step - loss: 1.0370 - acc: 0.5004 - val_loss: 1.0319 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 1.0330 - acc: 0.5004 - val_loss: 1.0281 - val_acc: 0.50075 - acc: 0.501\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 3s 781us/step - loss: 1.0290 - acc: 0.5004 - val_loss: 1.0235 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 3s 774us/step - loss: 1.0246 - acc: 0.5004 - val_loss: 1.0197 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 1.0203 - acc: 0.5004 - val_loss: 1.0151 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 3s 782us/step - loss: 1.0157 - acc: 0.5004 - val_loss: 1.0097 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 1.0103 - acc: 0.5007 - val_loss: 1.0043 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 1.0048 - acc: 0.5027 - val_loss: 0.9983 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.9987 - acc: 0.5036 - val_loss: 0.9924 - val_acc: 0.5107\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 0.9924 - acc: 0.5079 - val_loss: 0.9854 - val_acc: 0.5147\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 3s 873us/step - loss: 0.9853 - acc: 0.5110 - val_loss: 0.9787 - val_acc: 0.5133\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.9785 - acc: 0.5136 - val_loss: 0.9710 - val_acc: 0.5200\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.9705 - acc: 0.5181 - val_loss: 0.9633 - val_acc: 0.5253\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.9642 - acc: 0.5224 - val_loss: 0.9563 - val_acc: 0.5327\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.9566 - acc: 0.5264 - val_loss: 0.9487 - val_acc: 0.5407\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 0.9493 - acc: 0.5304 - val_loss: 0.9459 - val_acc: 0.5607\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 3s 786us/step - loss: 0.9444 - acc: 0.5390 - val_loss: 0.9348 - val_acc: 0.5527\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.9372 - acc: 0.5450 - val_loss: 0.9318 - val_acc: 0.5580\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 3s 801us/step - loss: 0.9314 - acc: 0.5519 - val_loss: 0.9228 - val_acc: 0.5720\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.9259 - acc: 0.5610 - val_loss: 0.9356 - val_acc: 0.5747\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 3s 779us/step - loss: 0.9195 - acc: 0.5616 - val_loss: 0.9161 - val_acc: 0.5847\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.9141 - acc: 0.5676 - val_loss: 0.9066 - val_acc: 0.5993\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 0.9081 - acc: 0.5724 - val_loss: 0.9029 - val_acc: 0.5913\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 3s 782us/step - loss: 0.9036 - acc: 0.5770 - val_loss: 0.8981 - val_acc: 0.5993\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.8978 - acc: 0.5799 - val_loss: 0.8930 - val_acc: 0.6047\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 3s 784us/step - loss: 0.8930 - acc: 0.5816 - val_loss: 0.8872 - val_acc: 0.6013\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 3s 784us/step - loss: 0.8880 - acc: 0.5873 - val_loss: 0.8807 - val_acc: 0.6113\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 3s 811us/step - loss: 0.8837 - acc: 0.5916 - val_loss: 0.8766 - val_acc: 0.6080\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 3s 803us/step - loss: 0.8796 - acc: 0.5916 - val_loss: 0.8807 - val_acc: 0.6047\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 3s 799us/step - loss: 0.8729 - acc: 0.5987 - val_loss: 0.8700 - val_acc: 0.6113\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 3s 765us/step - loss: 0.8689 - acc: 0.5985 - val_loss: 0.8935 - val_acc: 0.5913\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 3s 826us/step - loss: 0.8665 - acc: 0.6047 - val_loss: 0.8607 - val_acc: 0.6213\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 3s 785us/step - loss: 0.8625 - acc: 0.6102 - val_loss: 0.8579 - val_acc: 0.6180\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 3s 788us/step - loss: 0.8559 - acc: 0.6025 - val_loss: 0.8547 - val_acc: 0.6113\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.8529 - acc: 0.6085 - val_loss: 0.8550 - val_acc: 0.6293\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 3s 785us/step - loss: 0.8492 - acc: 0.6119 - val_loss: 0.8661 - val_acc: 0.6247\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.8439 - acc: 0.6182 - val_loss: 0.8578 - val_acc: 0.6307\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.8422 - acc: 0.6159 - val_loss: 0.8745 - val_acc: 0.5920\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 3s 800us/step - loss: 0.8411 - acc: 0.6236 - val_loss: 0.8461 - val_acc: 0.6180\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.8367 - acc: 0.6242 - val_loss: 0.8354 - val_acc: 0.6273\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.8341 - acc: 0.6285 - val_loss: 0.9134 - val_acc: 0.5573\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 3s 790us/step - loss: 0.8280 - acc: 0.6262 - val_loss: 0.8396 - val_acc: 0.6287\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.8264 - acc: 0.6316 - val_loss: 0.8399 - val_acc: 0.6247\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 3s 769us/step - loss: 0.8231 - acc: 0.6236 - val_loss: 0.9902 - val_acc: 0.5020s - loss: 0.8274 -\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.8233 - acc: 0.6270 - val_loss: 0.8370 - val_acc: 0.6147\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 3s 787us/step - loss: 0.8186 - acc: 0.6382 - val_loss: 0.8247 - val_acc: 0.6313\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 3s 798us/step - loss: 0.8141 - acc: 0.6319 - val_loss: 0.8486 - val_acc: 0.6367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 3s 809us/step - loss: 0.8130 - acc: 0.6396 - val_loss: 0.8541 - val_acc: 0.6273\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 3s 846us/step - loss: 0.8085 - acc: 0.6373 - val_loss: 0.8244 - val_acc: 0.6300\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 3s 811us/step - loss: 0.8059 - acc: 0.6342 - val_loss: 0.8229 - val_acc: 0.6380\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 3s 800us/step - loss: 0.7993 - acc: 0.6462 - val_loss: 0.8218 - val_acc: 0.6353\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.8009 - acc: 0.6456 - val_loss: 0.8157 - val_acc: 0.6400\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.7987 - acc: 0.6490 - val_loss: 0.8164 - val_acc: 0.6373\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.7933 - acc: 0.6485 - val_loss: 0.8532 - val_acc: 0.6060\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 3s 764us/step - loss: 0.7951 - acc: 0.6419 - val_loss: 0.8222 - val_acc: 0.6247\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 3s 759us/step - loss: 0.7900 - acc: 0.6468 - val_loss: 0.8199 - val_acc: 0.6320\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7879 - acc: 0.6468 - val_loss: 0.8351 - val_acc: 0.6180\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.7848 - acc: 0.6536 - val_loss: 0.8606 - val_acc: 0.5960\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 3s 800us/step - loss: 0.7826 - acc: 0.6505 - val_loss: 0.8079 - val_acc: 0.6440\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7771 - acc: 0.6545 - val_loss: 0.8335 - val_acc: 0.6220\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.7787 - acc: 0.6536 - val_loss: 0.8408 - val_acc: 0.6180\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.7741 - acc: 0.6508 - val_loss: 0.8047 - val_acc: 0.6427\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 3s 766us/step - loss: 0.7716 - acc: 0.6625 - val_loss: 0.8104 - val_acc: 0.6413\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 3s 777us/step - loss: 0.7679 - acc: 0.6628 - val_loss: 0.8119 - val_acc: 0.6280\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 3s 790us/step - loss: 0.7678 - acc: 0.6610 - val_loss: 0.7999 - val_acc: 0.6453\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7635 - acc: 0.6639 - val_loss: 0.8269 - val_acc: 0.6253\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 3s 758us/step - loss: 0.7653 - acc: 0.6625 - val_loss: 0.8175 - val_acc: 0.6307\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 3s 765us/step - loss: 0.7602 - acc: 0.6670 - val_loss: 0.8123 - val_acc: 0.6393\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7577 - acc: 0.6633 - val_loss: 0.8051 - val_acc: 0.6320\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 3s 783us/step - loss: 0.7556 - acc: 0.6688 - val_loss: 0.8254 - val_acc: 0.6260\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.7483 - acc: 0.6699 - val_loss: 0.8363 - val_acc: 0.6307\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7555 - acc: 0.6733 - val_loss: 0.9203 - val_acc: 0.56407555 - acc: 0.673\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 3s 797us/step - loss: 0.7483 - acc: 0.6648 - val_loss: 0.7983 - val_acc: 0.6467\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 3s 766us/step - loss: 0.7435 - acc: 0.6742 - val_loss: 0.8111 - val_acc: 0.6367\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 3s 760us/step - loss: 0.7450 - acc: 0.6699 - val_loss: 0.8028 - val_acc: 0.6407\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 3s 780us/step - loss: 0.7390 - acc: 0.6753 - val_loss: 0.7979 - val_acc: 0.6420\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 3s 798us/step - loss: 0.7380 - acc: 0.6805 - val_loss: 0.7955 - val_acc: 0.6400\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 3s 778us/step - loss: 0.7360 - acc: 0.6773 - val_loss: 0.7976 - val_acc: 0.6380\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7333 - acc: 0.6862 - val_loss: 0.8309 - val_acc: 0.6213\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.7334 - acc: 0.6762 - val_loss: 0.7962 - val_acc: 0.6480\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 3s 776us/step - loss: 0.7278 - acc: 0.6785 - val_loss: 0.8059 - val_acc: 0.6393\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 3s 768us/step - loss: 0.7282 - acc: 0.6813 - val_loss: 0.8118 - val_acc: 0.6360\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.7226 - acc: 0.6853 - val_loss: 0.8368 - val_acc: 0.6300\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.7206 - acc: 0.6905 - val_loss: 0.7897 - val_acc: 0.6460s: 0.7059\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.7164 - acc: 0.6876 - val_loss: 0.8206 - val_acc: 0.6353\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 3s 781us/step - loss: 0.7210 - acc: 0.6848 - val_loss: 0.8022 - val_acc: 0.6407\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 3s 791us/step - loss: 0.7119 - acc: 0.6945 - val_loss: 0.9573 - val_acc: 0.6007\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 3s 785us/step - loss: 0.7114 - acc: 0.6862 - val_loss: 0.8009 - val_acc: 0.6400\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.7075 - acc: 0.6965 - val_loss: 0.8056 - val_acc: 0.6507\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.7065 - acc: 0.6945 - val_loss: 0.7992 - val_acc: 0.6420cc: 0. - ETA: 0s - loss: 0.7023 - acc: 0.6\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 3s 767us/step - loss: 0.7021 - acc: 0.6971 - val_loss: 0.8073 - val_acc: 0.6447loss\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.7001 - acc: 0.6948 - val_loss: 0.8132 - val_acc: 0.6420\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 3s 793us/step - loss: 0.6973 - acc: 0.6928 - val_loss: 0.7840 - val_acc: 0.6500\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 3s 772us/step - loss: 0.6951 - acc: 0.7031 - val_loss: 0.7928 - val_acc: 0.6487\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.6870 - acc: 0.7073 - val_loss: 0.7975 - val_acc: 0.6427\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 3s 777us/step - loss: 0.6916 - acc: 0.7031 - val_loss: 0.7954 - val_acc: 0.6507\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 3s 769us/step - loss: 0.6830 - acc: 0.7108 - val_loss: 0.8045 - val_acc: 0.64531s - loss: 0.6914 - - ETA: 1s - loss: 0.69\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 3s 832us/step - loss: 0.6818 - acc: 0.7068 - val_loss: 0.7896 - val_acc: 0.6453\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 3s 801us/step - loss: 0.6818 - acc: 0.7096 - val_loss: 0.7963 - val_acc: 0.6527\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 3s 771us/step - loss: 0.6838 - acc: 0.6985 - val_loss: 0.8210 - val_acc: 0.6387\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 3s 775us/step - loss: 0.6766 - acc: 0.7068 - val_loss: 0.8434 - val_acc: 0.6300\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 3s 795us/step - loss: 0.6783 - acc: 0.7116 - val_loss: 0.8002 - val_acc: 0.6507\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.6744 - acc: 0.7179 - val_loss: 0.7895 - val_acc: 0.6573\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0514 - acc: 0.4984 - val_loss: 1.0384 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 3s 752us/step - loss: 1.0360 - acc: 0.5004 - val_loss: 1.0349 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 3s 723us/step - loss: 1.0316 - acc: 0.5004 - val_loss: 1.0316 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 3s 720us/step - loss: 1.0273 - acc: 0.5004 - val_loss: 1.0280 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 3s 738us/step - loss: 1.0228 - acc: 0.5004 - val_loss: 1.0243 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 3s 731us/step - loss: 1.0183 - acc: 0.5004 - val_loss: 1.0205 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 3s 735us/step - loss: 1.0135 - acc: 0.5004 - val_loss: 1.0162 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 3s 744us/step - loss: 1.0085 - acc: 0.5004 - val_loss: 1.0116 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 3s 726us/step - loss: 1.0028 - acc: 0.5019 - val_loss: 1.0066 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 3s 727us/step - loss: 0.9963 - acc: 0.5036 - val_loss: 1.0018 - val_acc: 0.5013\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 3s 772us/step - loss: 0.9902 - acc: 0.5050 - val_loss: 0.9955 - val_acc: 0.5067\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 3s 770us/step - loss: 0.9828 - acc: 0.5130 - val_loss: 0.9888 - val_acc: 0.5087\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 3s 752us/step - loss: 0.9752 - acc: 0.5182 - val_loss: 0.9819 - val_acc: 0.5187\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 3s 734us/step - loss: 0.9673 - acc: 0.5207 - val_loss: 0.9745 - val_acc: 0.5247\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 3s 770us/step - loss: 0.9587 - acc: 0.5293 - val_loss: 0.9665 - val_acc: 0.5327\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 3s 752us/step - loss: 0.9497 - acc: 0.5362 - val_loss: 0.9592 - val_acc: 0.5360\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 3s 736us/step - loss: 0.9414 - acc: 0.5479 - val_loss: 0.9525 - val_acc: 0.5380\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 3s 729us/step - loss: 0.9328 - acc: 0.5585 - val_loss: 0.9461 - val_acc: 0.5520\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.9255 - acc: 0.5613 - val_loss: 0.9404 - val_acc: 0.5487\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 3s 729us/step - loss: 0.9179 - acc: 0.5665 - val_loss: 0.9328 - val_acc: 0.5553\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 3s 755us/step - loss: 0.9091 - acc: 0.5736 - val_loss: 0.9293 - val_acc: 0.5620\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 3s 737us/step - loss: 0.9025 - acc: 0.5831 - val_loss: 0.9214 - val_acc: 0.5733\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 3s 737us/step - loss: 0.8965 - acc: 0.5822 - val_loss: 0.9164 - val_acc: 0.5640\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.8893 - acc: 0.5911 - val_loss: 0.9097 - val_acc: 0.5753\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 3s 719us/step - loss: 0.8835 - acc: 0.5916 - val_loss: 0.9238 - val_acc: 0.5767\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 3s 732us/step - loss: 0.8770 - acc: 0.5985 - val_loss: 0.9030 - val_acc: 0.5800\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.8703 - acc: 0.5997 - val_loss: 0.8964 - val_acc: 0.5793\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 3s 727us/step - loss: 0.8665 - acc: 0.6034 - val_loss: 0.8956 - val_acc: 0.5700\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.8606 - acc: 0.6077 - val_loss: 0.8877 - val_acc: 0.5900\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 3s 729us/step - loss: 0.8556 - acc: 0.6085 - val_loss: 0.8987 - val_acc: 0.5867\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 3s 737us/step - loss: 0.8514 - acc: 0.6140 - val_loss: 0.8809 - val_acc: 0.5920\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 3s 732us/step - loss: 0.8464 - acc: 0.6165 - val_loss: 0.8772 - val_acc: 0.5947\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 3s 716us/step - loss: 0.8395 - acc: 0.6174 - val_loss: 0.8860 - val_acc: 0.5927\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.8347 - acc: 0.6254 - val_loss: 0.8730 - val_acc: 0.6000\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 3s 730us/step - loss: 0.8326 - acc: 0.6191 - val_loss: 0.8700 - val_acc: 0.6013\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 3s 735us/step - loss: 0.8275 - acc: 0.6288 - val_loss: 0.8679 - val_acc: 0.5973\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 3s 723us/step - loss: 0.8236 - acc: 0.6254 - val_loss: 0.8619 - val_acc: 0.6140\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 2s 704us/step - loss: 0.8202 - acc: 0.6314 - val_loss: 0.8797 - val_acc: 0.5973\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 2s 705us/step - loss: 0.8173 - acc: 0.6363 - val_loss: 0.8749 - val_acc: 0.5953\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 2s 708us/step - loss: 0.8129 - acc: 0.6297 - val_loss: 0.8950 - val_acc: 0.5833\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 3s 730us/step - loss: 0.8100 - acc: 0.6388 - val_loss: 0.8567 - val_acc: 0.6113\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 3s 742us/step - loss: 0.8066 - acc: 0.6377 - val_loss: 0.8558 - val_acc: 0.6200\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 3s 735us/step - loss: 0.8023 - acc: 0.6417 - val_loss: 0.8487 - val_acc: 0.6247\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 3s 718us/step - loss: 0.7994 - acc: 0.6400 - val_loss: 0.8510 - val_acc: 0.6147\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 3s 717us/step - loss: 0.7967 - acc: 0.6420 - val_loss: 0.8495 - val_acc: 0.6147\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 3s 746us/step - loss: 0.7936 - acc: 0.6431 - val_loss: 0.8411 - val_acc: 0.6293\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 3s 742us/step - loss: 0.7898 - acc: 0.6474 - val_loss: 0.8662 - val_acc: 0.6027\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 3s 725us/step - loss: 0.7864 - acc: 0.6451 - val_loss: 0.8845 - val_acc: 0.5840\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 3s 745us/step - loss: 0.7831 - acc: 0.6508 - val_loss: 0.8375 - val_acc: 0.6200\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 3s 738us/step - loss: 0.7800 - acc: 0.6557 - val_loss: 0.8534 - val_acc: 0.6120\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 3s 722us/step - loss: 0.7797 - acc: 0.6514 - val_loss: 0.8402 - val_acc: 0.6273\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 3s 760us/step - loss: 0.7752 - acc: 0.6597 - val_loss: 0.8369 - val_acc: 0.6293\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 3s 735us/step - loss: 0.7746 - acc: 0.6566 - val_loss: 0.8334 - val_acc: 0.6287\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.7674 - acc: 0.6589 - val_loss: 0.8390 - val_acc: 0.6160\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 2s 714us/step - loss: 0.7654 - acc: 0.6600 - val_loss: 0.9041 - val_acc: 0.5887\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 3s 722us/step - loss: 0.7624 - acc: 0.6620 - val_loss: 0.8945 - val_acc: 0.6000\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 3s 743us/step - loss: 0.7631 - acc: 0.6680 - val_loss: 0.8292 - val_acc: 0.6360\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 3s 732us/step - loss: 0.7588 - acc: 0.6626 - val_loss: 0.8589 - val_acc: 0.6073\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 2s 708us/step - loss: 0.7566 - acc: 0.6706 - val_loss: 0.8297 - val_acc: 0.6307\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 3s 720us/step - loss: 0.7519 - acc: 0.6706 - val_loss: 0.8602 - val_acc: 0.6073\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 3s 744us/step - loss: 0.7478 - acc: 0.6711 - val_loss: 0.8336 - val_acc: 0.6327\n",
      "Epoch 62/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497/3497 [==============================] - 3s 734us/step - loss: 0.7500 - acc: 0.6700 - val_loss: 0.8287 - val_acc: 0.6327\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 3s 719us/step - loss: 0.7460 - acc: 0.6697 - val_loss: 0.8787 - val_acc: 0.6087\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 3s 758us/step - loss: 0.7444 - acc: 0.6700 - val_loss: 0.8264 - val_acc: 0.6293\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 3s 756us/step - loss: 0.7396 - acc: 0.6734 - val_loss: 0.8542 - val_acc: 0.6180\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 3s 733us/step - loss: 0.7392 - acc: 0.6780 - val_loss: 0.8224 - val_acc: 0.6360\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 3s 757us/step - loss: 0.7359 - acc: 0.6780 - val_loss: 0.8221 - val_acc: 0.6353\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 2s 709us/step - loss: 0.7347 - acc: 0.6786 - val_loss: 0.8277 - val_acc: 0.6327\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 3s 734us/step - loss: 0.7302 - acc: 0.6826 - val_loss: 0.8229 - val_acc: 0.6380\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 3s 716us/step - loss: 0.7268 - acc: 0.6812 - val_loss: 0.8482 - val_acc: 0.6140\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 3s 728us/step - loss: 0.7261 - acc: 0.6843 - val_loss: 0.8297 - val_acc: 0.6247\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 3s 741us/step - loss: 0.7231 - acc: 0.6840 - val_loss: 0.8460 - val_acc: 0.6240\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 3s 743us/step - loss: 0.7211 - acc: 0.6883 - val_loss: 0.8342 - val_acc: 0.6260\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 3s 726us/step - loss: 0.7181 - acc: 0.6897 - val_loss: 0.8292 - val_acc: 0.6293\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 3s 718us/step - loss: 0.7113 - acc: 0.6929 - val_loss: 0.8567 - val_acc: 0.6147\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 3s 717us/step - loss: 0.7124 - acc: 0.6946 - val_loss: 0.8322 - val_acc: 0.6200\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 2s 706us/step - loss: 0.7081 - acc: 0.6957 - val_loss: 0.8323 - val_acc: 0.6313\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 10s 3ms/step - loss: 1.0531 - acc: 0.4980 - val_loss: 1.0395 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 3s 773us/step - loss: 1.0356 - acc: 0.5003 - val_loss: 1.0346 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 3s 775us/step - loss: 1.0308 - acc: 0.5003 - val_loss: 1.0305 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 3s 766us/step - loss: 1.0259 - acc: 0.5003 - val_loss: 1.0265 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 3s 755us/step - loss: 1.0215 - acc: 0.5003 - val_loss: 1.0220 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 3s 767us/step - loss: 1.0163 - acc: 0.5003 - val_loss: 1.0172 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 3s 818us/step - loss: 1.0108 - acc: 0.5003 - val_loss: 1.0121 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 3s 771us/step - loss: 1.0051 - acc: 0.5003 - val_loss: 1.0067 - val_acc: 0.5020\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 3s 826us/step - loss: 0.9988 - acc: 0.5026 - val_loss: 1.0007 - val_acc: 0.5053\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 3s 863us/step - loss: 0.9918 - acc: 0.5063 - val_loss: 0.9951 - val_acc: 0.5060\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 3s 751us/step - loss: 0.9852 - acc: 0.5091 - val_loss: 0.9877 - val_acc: 0.5140\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 3s 735us/step - loss: 0.9777 - acc: 0.5137 - val_loss: 0.9817 - val_acc: 0.5173\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 3s 725us/step - loss: 0.9707 - acc: 0.5192 - val_loss: 0.9747 - val_acc: 0.5207\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 3s 740us/step - loss: 0.9630 - acc: 0.5266 - val_loss: 0.9671 - val_acc: 0.5220\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 3s 725us/step - loss: 0.9557 - acc: 0.5312 - val_loss: 0.9605 - val_acc: 0.5407\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 3s 728us/step - loss: 0.9482 - acc: 0.5383 - val_loss: 0.9561 - val_acc: 0.5407\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 3s 736us/step - loss: 0.9419 - acc: 0.5500 - val_loss: 0.9472 - val_acc: 0.5460\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 3s 755us/step - loss: 0.9349 - acc: 0.5549 - val_loss: 0.9416 - val_acc: 0.5580\n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 3s 747us/step - loss: 0.9286 - acc: 0.5612 - val_loss: 0.9391 - val_acc: 0.5520\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 3s 750us/step - loss: 0.9222 - acc: 0.5663 - val_loss: 0.9313 - val_acc: 0.5600\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 3s 782us/step - loss: 0.9163 - acc: 0.5698 - val_loss: 0.9243 - val_acc: 0.5687\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 3s 740us/step - loss: 0.9108 - acc: 0.5795 - val_loss: 0.9188 - val_acc: 0.5700\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 3s 727us/step - loss: 0.9050 - acc: 0.5783 - val_loss: 0.9206 - val_acc: 0.5833\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 3s 745us/step - loss: 0.9004 - acc: 0.5832 - val_loss: 0.9172 - val_acc: 0.5673\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 3s 743us/step - loss: 0.8955 - acc: 0.5898 - val_loss: 0.9087 - val_acc: 0.5860\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 3s 749us/step - loss: 0.8892 - acc: 0.5923 - val_loss: 0.9046 - val_acc: 0.5827\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 3s 729us/step - loss: 0.8849 - acc: 0.5958 - val_loss: 0.8973 - val_acc: 0.5873\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 2s 714us/step - loss: 0.8782 - acc: 0.6018 - val_loss: 0.9134 - val_acc: 0.5767\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 3s 782us/step - loss: 0.8740 - acc: 0.6023 - val_loss: 0.8891 - val_acc: 0.5967\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 2s 710us/step - loss: 0.8684 - acc: 0.6075 - val_loss: 0.8898 - val_acc: 0.5933\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 3s 729us/step - loss: 0.8650 - acc: 0.6072 - val_loss: 0.8862 - val_acc: 0.5847\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 3s 725us/step - loss: 0.8626 - acc: 0.6135 - val_loss: 0.8859 - val_acc: 0.5800\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 3s 749us/step - loss: 0.8589 - acc: 0.6098 - val_loss: 0.8782 - val_acc: 0.5893\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 2s 710us/step - loss: 0.8525 - acc: 0.6175 - val_loss: 0.8908 - val_acc: 0.5820\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 2s 708us/step - loss: 0.8501 - acc: 0.6181 - val_loss: 0.8828 - val_acc: 0.5873\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 3s 736us/step - loss: 0.8468 - acc: 0.6118 - val_loss: 0.8777 - val_acc: 0.5820\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 3s 739us/step - loss: 0.8407 - acc: 0.6184 - val_loss: 0.8676 - val_acc: 0.5987\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 3s 715us/step - loss: 0.8396 - acc: 0.6229 - val_loss: 0.8705 - val_acc: 0.5960\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 3s 733us/step - loss: 0.8361 - acc: 0.6238 - val_loss: 0.8661 - val_acc: 0.5993\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 2s 709us/step - loss: 0.8306 - acc: 0.6238 - val_loss: 0.8800 - val_acc: 0.5940\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 3s 723us/step - loss: 0.8287 - acc: 0.6289 - val_loss: 0.8696 - val_acc: 0.5987\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 3s 740us/step - loss: 0.8270 - acc: 0.6284 - val_loss: 0.8699 - val_acc: 0.5900\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 3s 767us/step - loss: 0.8244 - acc: 0.6284 - val_loss: 0.8637 - val_acc: 0.5953\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 3s 725us/step - loss: 0.8191 - acc: 0.6324 - val_loss: 0.8642 - val_acc: 0.5913\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 3s 745us/step - loss: 0.8163 - acc: 0.6381 - val_loss: 0.8555 - val_acc: 0.6013\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 3s 767us/step - loss: 0.8152 - acc: 0.6404 - val_loss: 0.8497 - val_acc: 0.6053\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 3s 774us/step - loss: 0.8105 - acc: 0.6455 - val_loss: 0.8486 - val_acc: 0.6067\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 3s 729us/step - loss: 0.8070 - acc: 0.6421 - val_loss: 0.8814 - val_acc: 0.5813\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 3s 716us/step - loss: 0.8083 - acc: 0.6424 - val_loss: 0.8688 - val_acc: 0.5927\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 3s 720us/step - loss: 0.8037 - acc: 0.6472 - val_loss: 0.8685 - val_acc: 0.5980\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 3s 718us/step - loss: 0.8012 - acc: 0.6415 - val_loss: 0.8488 - val_acc: 0.6067\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 3s 742us/step - loss: 0.7977 - acc: 0.6518 - val_loss: 0.8457 - val_acc: 0.6073\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 3s 720us/step - loss: 0.7945 - acc: 0.6507 - val_loss: 0.8458 - val_acc: 0.6120\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 3s 736us/step - loss: 0.7946 - acc: 0.6472 - val_loss: 0.8446 - val_acc: 0.6040\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 2s 702us/step - loss: 0.7921 - acc: 0.6475 - val_loss: 0.8768 - val_acc: 0.6007\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 2s 706us/step - loss: 0.7889 - acc: 0.6441 - val_loss: 0.8553 - val_acc: 0.6013\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 3s 717us/step - loss: 0.7887 - acc: 0.6544 - val_loss: 0.8862 - val_acc: 0.5773\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 3s 717us/step - loss: 0.7833 - acc: 0.6595 - val_loss: 0.8723 - val_acc: 0.5873\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 3s 733us/step - loss: 0.7808 - acc: 0.6535 - val_loss: 0.8421 - val_acc: 0.6087\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 3s 718us/step - loss: 0.7798 - acc: 0.6569 - val_loss: 0.8480 - val_acc: 0.6067\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 2s 708us/step - loss: 0.7748 - acc: 0.6627 - val_loss: 0.8736 - val_acc: 0.6040\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 3s 728us/step - loss: 0.7773 - acc: 0.6578 - val_loss: 0.8338 - val_acc: 0.6120\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 2s 707us/step - loss: 0.7723 - acc: 0.6624 - val_loss: 0.8612 - val_acc: 0.6007\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 2s 714us/step - loss: 0.7708 - acc: 0.6630 - val_loss: 0.8585 - val_acc: 0.6027\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 3s 726us/step - loss: 0.7685 - acc: 0.6661 - val_loss: 0.8329 - val_acc: 0.6160\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 2s 708us/step - loss: 0.7626 - acc: 0.6632 - val_loss: 0.8395 - val_acc: 0.6173\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 3s 728us/step - loss: 0.7642 - acc: 0.6687 - val_loss: 0.8326 - val_acc: 0.6300\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 3s 737us/step - loss: 0.7604 - acc: 0.6707 - val_loss: 0.8292 - val_acc: 0.6180\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 3s 739us/step - loss: 0.7568 - acc: 0.6738 - val_loss: 0.8262 - val_acc: 0.6260\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 3s 723us/step - loss: 0.7588 - acc: 0.6655 - val_loss: 0.8361 - val_acc: 0.6153\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 3s 728us/step - loss: 0.7568 - acc: 0.6738 - val_loss: 0.8305 - val_acc: 0.6207\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 3s 737us/step - loss: 0.7509 - acc: 0.6764 - val_loss: 0.8249 - val_acc: 0.6293\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 3s 727us/step - loss: 0.7470 - acc: 0.6744 - val_loss: 0.8414 - val_acc: 0.6273\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 3s 719us/step - loss: 0.7458 - acc: 0.6715 - val_loss: 0.8263 - val_acc: 0.6233\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 2s 709us/step - loss: 0.7445 - acc: 0.6758 - val_loss: 0.8334 - val_acc: 0.6167\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 3s 749us/step - loss: 0.7411 - acc: 0.6755 - val_loss: 0.8218 - val_acc: 0.6360\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 2s 713us/step - loss: 0.7391 - acc: 0.6761 - val_loss: 0.8287 - val_acc: 0.6227\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 2s 711us/step - loss: 0.7382 - acc: 0.6818 - val_loss: 0.8503 - val_acc: 0.5940\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 3s 727us/step - loss: 0.7357 - acc: 0.6767 - val_loss: 0.8206 - val_acc: 0.6347\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 3s 718us/step - loss: 0.7321 - acc: 0.6801 - val_loss: 0.8597 - val_acc: 0.6007\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 2s 711us/step - loss: 0.7328 - acc: 0.6804 - val_loss: 0.8585 - val_acc: 0.6127\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 3s 720us/step - loss: 0.7303 - acc: 0.6798 - val_loss: 0.8422 - val_acc: 0.6100\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 3s 732us/step - loss: 0.7252 - acc: 0.6804 - val_loss: 0.8577 - val_acc: 0.5920\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 3s 736us/step - loss: 0.7221 - acc: 0.6858 - val_loss: 0.8186 - val_acc: 0.6473\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 3s 718us/step - loss: 0.7209 - acc: 0.6870 - val_loss: 0.8211 - val_acc: 0.6407\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 3s 724us/step - loss: 0.7166 - acc: 0.6895 - val_loss: 0.8215 - val_acc: 0.6460\n",
      "Epoch 87/300\n",
      "3498/3498 [==============================] - 2s 713us/step - loss: 0.7176 - acc: 0.6910 - val_loss: 0.8312 - val_acc: 0.6247\n",
      "Epoch 88/300\n",
      "3498/3498 [==============================] - 2s 715us/step - loss: 0.7144 - acc: 0.6930 - val_loss: 0.8227 - val_acc: 0.6327\n",
      "Epoch 89/300\n",
      "3498/3498 [==============================] - 2s 713us/step - loss: 0.7125 - acc: 0.6907 - val_loss: 0.8187 - val_acc: 0.6433\n",
      "Epoch 90/300\n",
      "3498/3498 [==============================] - 2s 706us/step - loss: 0.7072 - acc: 0.6964 - val_loss: 0.8256 - val_acc: 0.6280\n",
      "Epoch 91/300\n",
      "3498/3498 [==============================] - 2s 705us/step - loss: 0.7066 - acc: 0.6950 - val_loss: 0.8278 - val_acc: 0.6247\n",
      "Epoch 92/300\n",
      "3498/3498 [==============================] - 3s 716us/step - loss: 0.7070 - acc: 0.6998 - val_loss: 0.8922 - val_acc: 0.5847\n",
      "Epoch 93/300\n",
      "3498/3498 [==============================] - 2s 713us/step - loss: 0.7051 - acc: 0.6978 - val_loss: 0.9353 - val_acc: 0.5573\n",
      "Epoch 94/300\n",
      "3498/3498 [==============================] - 3s 722us/step - loss: 0.7021 - acc: 0.6958 - val_loss: 0.8365 - val_acc: 0.6300\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0527 - acc: 0.4990 - val_loss: 1.0380 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 1.0358 - acc: 0.5004 - val_loss: 1.0337 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 1.0312 - acc: 0.5004 - val_loss: 1.0298 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 1.0267 - acc: 0.5004 - val_loss: 1.0254 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 1.0217 - acc: 0.5004 - val_loss: 1.0215 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 1.0170 - acc: 0.5004 - val_loss: 1.0170 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 3s 719us/step - loss: 1.0119 - acc: 0.5004 - val_loss: 1.0115 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 1.0060 - acc: 0.5010 - val_loss: 1.0062 - val_acc: 0.5020\n",
      "Epoch 9/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 3s 722us/step - loss: 1.0000 - acc: 0.5041 - val_loss: 1.0001 - val_acc: 0.5027\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 3s 718us/step - loss: 0.9935 - acc: 0.5070 - val_loss: 0.9945 - val_acc: 0.5113\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.9870 - acc: 0.5130 - val_loss: 0.9878 - val_acc: 0.5147\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.9799 - acc: 0.5173 - val_loss: 0.9811 - val_acc: 0.5133\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 3s 718us/step - loss: 0.9731 - acc: 0.5187 - val_loss: 0.9739 - val_acc: 0.5173\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.9651 - acc: 0.5282 - val_loss: 0.9674 - val_acc: 0.5300\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 3s 719us/step - loss: 0.9592 - acc: 0.5310 - val_loss: 0.9605 - val_acc: 0.5400\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.9518 - acc: 0.5339 - val_loss: 0.9538 - val_acc: 0.5467\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 2s 700us/step - loss: 0.9436 - acc: 0.5416 - val_loss: 0.9547 - val_acc: 0.5513\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 3s 726us/step - loss: 0.9393 - acc: 0.5504 - val_loss: 0.9417 - val_acc: 0.5553\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 3s 736us/step - loss: 0.9324 - acc: 0.5550 - val_loss: 0.9361 - val_acc: 0.5567\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 3s 741us/step - loss: 0.9255 - acc: 0.5616 - val_loss: 0.9324 - val_acc: 0.5580\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.9208 - acc: 0.5670 - val_loss: 0.9386 - val_acc: 0.5687\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 3s 733us/step - loss: 0.9145 - acc: 0.5736 - val_loss: 0.9212 - val_acc: 0.5633\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.9081 - acc: 0.5750 - val_loss: 0.9160 - val_acc: 0.5713\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.9034 - acc: 0.5796 - val_loss: 0.9148 - val_acc: 0.5620\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 3s 738us/step - loss: 0.8994 - acc: 0.5847 - val_loss: 0.9092 - val_acc: 0.5633\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.8928 - acc: 0.5890 - val_loss: 0.9124 - val_acc: 0.5820\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.8885 - acc: 0.5899 - val_loss: 0.9031 - val_acc: 0.5893\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.8839 - acc: 0.5939 - val_loss: 0.8952 - val_acc: 0.5853\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.8781 - acc: 0.6025 - val_loss: 0.8920 - val_acc: 0.5733\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 3s 749us/step - loss: 0.8746 - acc: 0.6013 - val_loss: 0.8897 - val_acc: 0.5840\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 3s 762us/step - loss: 0.8677 - acc: 0.6090 - val_loss: 0.8841 - val_acc: 0.5940\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.8644 - acc: 0.6065 - val_loss: 0.8907 - val_acc: 0.5733\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.8606 - acc: 0.6107 - val_loss: 0.8849 - val_acc: 0.5960\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 3s 738us/step - loss: 0.8568 - acc: 0.6093 - val_loss: 0.8766 - val_acc: 0.5893\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 3s 747us/step - loss: 0.8506 - acc: 0.6127 - val_loss: 0.8729 - val_acc: 0.5860\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.8475 - acc: 0.6185 - val_loss: 0.8729 - val_acc: 0.5980\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.8445 - acc: 0.6207 - val_loss: 0.8972 - val_acc: 0.5813\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.8400 - acc: 0.6222 - val_loss: 0.8836 - val_acc: 0.5927\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.8372 - acc: 0.6213 - val_loss: 0.8979 - val_acc: 0.5653\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.8376 - acc: 0.6253 - val_loss: 0.8622 - val_acc: 0.6007\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.8320 - acc: 0.6190 - val_loss: 0.8584 - val_acc: 0.6047\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 2s 706us/step - loss: 0.8305 - acc: 0.6256 - val_loss: 0.9161 - val_acc: 0.5553\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 3s 736us/step - loss: 0.8257 - acc: 0.6273 - val_loss: 0.8578 - val_acc: 0.6073\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.8231 - acc: 0.6370 - val_loss: 0.8668 - val_acc: 0.5920\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.8188 - acc: 0.6379 - val_loss: 0.9403 - val_acc: 0.5327\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.8186 - acc: 0.6373 - val_loss: 0.8574 - val_acc: 0.6007\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.8156 - acc: 0.6408 - val_loss: 0.8532 - val_acc: 0.6047\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 3s 726us/step - loss: 0.8117 - acc: 0.6399 - val_loss: 0.8465 - val_acc: 0.6073\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.8096 - acc: 0.6465 - val_loss: 0.8635 - val_acc: 0.6073\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 3s 743us/step - loss: 0.8041 - acc: 0.6468 - val_loss: 0.8439 - val_acc: 0.6147\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 3s 763us/step - loss: 0.8016 - acc: 0.6456 - val_loss: 0.8482 - val_acc: 0.6113\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.7987 - acc: 0.6450 - val_loss: 0.8567 - val_acc: 0.6060\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7972 - acc: 0.6533 - val_loss: 0.8400 - val_acc: 0.6167\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 3s 732us/step - loss: 0.7953 - acc: 0.6508 - val_loss: 0.8395 - val_acc: 0.6160\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.7903 - acc: 0.6550 - val_loss: 0.8524 - val_acc: 0.6060\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 3s 743us/step - loss: 0.7911 - acc: 0.6588 - val_loss: 0.8479 - val_acc: 0.6020\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7901 - acc: 0.6530 - val_loss: 0.8471 - val_acc: 0.6107\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 2s 707us/step - loss: 0.7849 - acc: 0.6593 - val_loss: 0.8702 - val_acc: 0.5880\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.7839 - acc: 0.6588 - val_loss: 0.8657 - val_acc: 0.5980\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 3s 723us/step - loss: 0.7814 - acc: 0.6602 - val_loss: 0.8381 - val_acc: 0.6160\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.7771 - acc: 0.6642 - val_loss: 0.8465 - val_acc: 0.6120\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 2s 704us/step - loss: 0.7767 - acc: 0.6625 - val_loss: 0.8680 - val_acc: 0.5913\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.7747 - acc: 0.6579 - val_loss: 0.8370 - val_acc: 0.6187\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.7706 - acc: 0.6670 - val_loss: 0.8296 - val_acc: 0.6173\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 3s 738us/step - loss: 0.7671 - acc: 0.6656 - val_loss: 0.8329 - val_acc: 0.6153\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.7683 - acc: 0.6733 - val_loss: 0.8296 - val_acc: 0.6193\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 2s 704us/step - loss: 0.7649 - acc: 0.6748 - val_loss: 0.8486 - val_acc: 0.5973\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 2s 706us/step - loss: 0.7622 - acc: 0.6690 - val_loss: 0.8429 - val_acc: 0.6107\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 2s 706us/step - loss: 0.7601 - acc: 0.6728 - val_loss: 0.8322 - val_acc: 0.6120\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 3s 723us/step - loss: 0.7578 - acc: 0.6702 - val_loss: 0.8254 - val_acc: 0.6240\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 2s 703us/step - loss: 0.7550 - acc: 0.6768 - val_loss: 0.8575 - val_acc: 0.6080\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7504 - acc: 0.6776 - val_loss: 0.9088 - val_acc: 0.5900\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.7543 - acc: 0.6725 - val_loss: 0.8442 - val_acc: 0.6213\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7467 - acc: 0.6808 - val_loss: 0.8329 - val_acc: 0.6207\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 3s 715us/step - loss: 0.7457 - acc: 0.6819 - val_loss: 0.8332 - val_acc: 0.6347\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.7448 - acc: 0.6785 - val_loss: 0.8259 - val_acc: 0.6113\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 3s 739us/step - loss: 0.7402 - acc: 0.6822 - val_loss: 0.8246 - val_acc: 0.6307\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.7377 - acc: 0.6916 - val_loss: 0.8256 - val_acc: 0.6227\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 3s 715us/step - loss: 0.7387 - acc: 0.6885 - val_loss: 0.8283 - val_acc: 0.6247\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7363 - acc: 0.6811 - val_loss: 0.8244 - val_acc: 0.6240\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.7333 - acc: 0.6822 - val_loss: 0.8281 - val_acc: 0.6287\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.7294 - acc: 0.6876 - val_loss: 0.8345 - val_acc: 0.6167\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.7278 - acc: 0.6842 - val_loss: 0.8454 - val_acc: 0.6040\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 3s 715us/step - loss: 0.7253 - acc: 0.6925 - val_loss: 0.8538 - val_acc: 0.6120\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.7222 - acc: 0.6919 - val_loss: 0.8203 - val_acc: 0.6333\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7226 - acc: 0.6913 - val_loss: 0.8368 - val_acc: 0.6260\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7200 - acc: 0.6939 - val_loss: 0.8223 - val_acc: 0.6247\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7162 - acc: 0.6922 - val_loss: 0.8540 - val_acc: 0.6093\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 2s 707us/step - loss: 0.7160 - acc: 0.6885 - val_loss: 0.8288 - val_acc: 0.6287\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7139 - acc: 0.6951 - val_loss: 0.8193 - val_acc: 0.6360\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.7137 - acc: 0.6922 - val_loss: 0.8627 - val_acc: 0.6047\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.7082 - acc: 0.6976 - val_loss: 0.8413 - val_acc: 0.6187\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 0.7061 - acc: 0.6948 - val_loss: 0.8347 - val_acc: 0.6360\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 3s 736us/step - loss: 0.7075 - acc: 0.6991 - val_loss: 0.8161 - val_acc: 0.6307\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.7023 - acc: 0.7016 - val_loss: 0.8361 - val_acc: 0.6247\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.6953 - acc: 0.7008 - val_loss: 0.9211 - val_acc: 0.5733\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.6994 - acc: 0.7013 - val_loss: 0.8540 - val_acc: 0.6120\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.6931 - acc: 0.7039 - val_loss: 0.8265 - val_acc: 0.6393\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.6927 - acc: 0.7005 - val_loss: 0.8242 - val_acc: 0.6307\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 2s 707us/step - loss: 0.6930 - acc: 0.7088 - val_loss: 0.8272 - val_acc: 0.6367\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.6877 - acc: 0.7076 - val_loss: 0.8436 - val_acc: 0.6373\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.6837 - acc: 0.7093 - val_loss: 0.8743 - val_acc: 0.6167\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.6866 - acc: 0.7031 - val_loss: 0.8331 - val_acc: 0.6320\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.6837 - acc: 0.7093 - val_loss: 0.9142 - val_acc: 0.5827\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 1.0534 - acc: 0.4987 - val_loss: 1.0374 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 1.0366 - acc: 0.5004 - val_loss: 1.0327 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 1.0320 - acc: 0.5004 - val_loss: 1.0285 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 3s 719us/step - loss: 1.0276 - acc: 0.5004 - val_loss: 1.0238 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 3s 726us/step - loss: 1.0226 - acc: 0.5004 - val_loss: 1.0195 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 1.0179 - acc: 0.5004 - val_loss: 1.0147 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 3s 739us/step - loss: 1.0129 - acc: 0.5004 - val_loss: 1.0091 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 1.0071 - acc: 0.5004 - val_loss: 1.0035 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 1.0013 - acc: 0.5030 - val_loss: 0.9973 - val_acc: 0.5020\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.9949 - acc: 0.5036 - val_loss: 0.9915 - val_acc: 0.5087\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.9886 - acc: 0.5099 - val_loss: 0.9843 - val_acc: 0.5140\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 3s 732us/step - loss: 0.9815 - acc: 0.5144 - val_loss: 0.9773 - val_acc: 0.5140\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 3s 742us/step - loss: 0.9747 - acc: 0.5184 - val_loss: 0.9698 - val_acc: 0.5213\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 3s 735us/step - loss: 0.9668 - acc: 0.5233 - val_loss: 0.9627 - val_acc: 0.5287\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 3s 734us/step - loss: 0.9603 - acc: 0.5267 - val_loss: 0.9551 - val_acc: 0.5407\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.9530 - acc: 0.5322 - val_loss: 0.9478 - val_acc: 0.5447\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.9452 - acc: 0.5370 - val_loss: 0.9449 - val_acc: 0.5587\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 3s 752us/step - loss: 0.9401 - acc: 0.5479 - val_loss: 0.9336 - val_acc: 0.5500\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 3s 732us/step - loss: 0.9328 - acc: 0.5502 - val_loss: 0.9285 - val_acc: 0.5620\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.9264 - acc: 0.5616 - val_loss: 0.9213 - val_acc: 0.5667\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 2s 710us/step - loss: 0.9210 - acc: 0.5636 - val_loss: 0.9268 - val_acc: 0.5813\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 3s 736us/step - loss: 0.9147 - acc: 0.5682 - val_loss: 0.9115 - val_acc: 0.5673\n",
      "Epoch 23/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 3s 733us/step - loss: 0.9084 - acc: 0.5739 - val_loss: 0.9033 - val_acc: 0.5840\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.9030 - acc: 0.5739 - val_loss: 0.8989 - val_acc: 0.5773\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.8986 - acc: 0.5810 - val_loss: 0.8931 - val_acc: 0.5887\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.8922 - acc: 0.5845 - val_loss: 0.8882 - val_acc: 0.6007\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 3s 762us/step - loss: 0.8882 - acc: 0.5905 - val_loss: 0.8855 - val_acc: 0.6033\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 3s 740us/step - loss: 0.8830 - acc: 0.5919 - val_loss: 0.8785 - val_acc: 0.6080\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 3s 756us/step - loss: 0.8785 - acc: 0.5965 - val_loss: 0.8765 - val_acc: 0.5913\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 3s 743us/step - loss: 0.8743 - acc: 0.6002 - val_loss: 0.8739 - val_acc: 0.5987\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 3s 735us/step - loss: 0.8680 - acc: 0.6093 - val_loss: 0.8662 - val_acc: 0.6153\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.8645 - acc: 0.6047 - val_loss: 0.8704 - val_acc: 0.5913\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 3s 735us/step - loss: 0.8609 - acc: 0.6056 - val_loss: 0.8621 - val_acc: 0.6160\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.8564 - acc: 0.6110 - val_loss: 0.8546 - val_acc: 0.6127\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.8517 - acc: 0.6139 - val_loss: 0.8521 - val_acc: 0.6107\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.8479 - acc: 0.6147 - val_loss: 0.8541 - val_acc: 0.6147\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.8451 - acc: 0.6242 - val_loss: 0.8624 - val_acc: 0.6153\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.8401 - acc: 0.6245 - val_loss: 0.8625 - val_acc: 0.6133\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 2s 707us/step - loss: 0.8375 - acc: 0.6222 - val_loss: 0.8893 - val_acc: 0.5713\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.8379 - acc: 0.6250 - val_loss: 0.8397 - val_acc: 0.6227\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 2s 706us/step - loss: 0.8326 - acc: 0.6222 - val_loss: 0.8398 - val_acc: 0.6053\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.8295 - acc: 0.6285 - val_loss: 0.8623 - val_acc: 0.5953\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.8255 - acc: 0.6279 - val_loss: 0.8340 - val_acc: 0.6200\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.8223 - acc: 0.6353 - val_loss: 0.8416 - val_acc: 0.6067\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 0.8185 - acc: 0.6310 - val_loss: 0.9576 - val_acc: 0.5173\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 2s 703us/step - loss: 0.8187 - acc: 0.6342 - val_loss: 0.8343 - val_acc: 0.6160\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.8149 - acc: 0.6405 - val_loss: 0.8224 - val_acc: 0.6207\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.8119 - acc: 0.6376 - val_loss: 0.8319 - val_acc: 0.6213\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 2s 710us/step - loss: 0.8104 - acc: 0.6439 - val_loss: 0.8438 - val_acc: 0.6240\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 0.8052 - acc: 0.6496 - val_loss: 0.8221 - val_acc: 0.6287\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 2s 704us/step - loss: 0.8017 - acc: 0.6422 - val_loss: 0.8301 - val_acc: 0.6213\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 2s 703us/step - loss: 0.7983 - acc: 0.6505 - val_loss: 0.8288 - val_acc: 0.6087\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 3s 726us/step - loss: 0.7976 - acc: 0.6459 - val_loss: 0.8131 - val_acc: 0.6300\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.7960 - acc: 0.6516 - val_loss: 0.8115 - val_acc: 0.6293\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7910 - acc: 0.6482 - val_loss: 0.8491 - val_acc: 0.6080\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.7928 - acc: 0.6516 - val_loss: 0.8230 - val_acc: 0.6220\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.7900 - acc: 0.6488 - val_loss: 0.8166 - val_acc: 0.6267\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7861 - acc: 0.6588 - val_loss: 0.8340 - val_acc: 0.6193\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.7840 - acc: 0.6528 - val_loss: 0.8274 - val_acc: 0.6240\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 3s 749us/step - loss: 0.7816 - acc: 0.6525 - val_loss: 0.8094 - val_acc: 0.6293\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 3s 746us/step - loss: 0.7765 - acc: 0.6568 - val_loss: 0.8083 - val_acc: 0.6300\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.7764 - acc: 0.6596 - val_loss: 0.8568 - val_acc: 0.6000\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.7743 - acc: 0.6550 - val_loss: 0.8053 - val_acc: 0.6347\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 3s 734us/step - loss: 0.7717 - acc: 0.6619 - val_loss: 0.8017 - val_acc: 0.6427\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 2s 710us/step - loss: 0.7681 - acc: 0.6628 - val_loss: 0.8044 - val_acc: 0.6353\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 3s 726us/step - loss: 0.7689 - acc: 0.6599 - val_loss: 0.8004 - val_acc: 0.6387\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.7645 - acc: 0.6656 - val_loss: 0.8202 - val_acc: 0.6207\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 2s 706us/step - loss: 0.7641 - acc: 0.6588 - val_loss: 0.8180 - val_acc: 0.6247\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7604 - acc: 0.6679 - val_loss: 0.8080 - val_acc: 0.6393\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 3s 741us/step - loss: 0.7563 - acc: 0.6662 - val_loss: 0.7975 - val_acc: 0.6427\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 3s 734us/step - loss: 0.7543 - acc: 0.6710 - val_loss: 0.8559 - val_acc: 0.6113\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7501 - acc: 0.6702 - val_loss: 0.8796 - val_acc: 0.6153\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.7561 - acc: 0.6650 - val_loss: 0.8152 - val_acc: 0.6293\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.7474 - acc: 0.6733 - val_loss: 0.7977 - val_acc: 0.6427\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.7467 - acc: 0.6719 - val_loss: 0.8055 - val_acc: 0.6407\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 3s 770us/step - loss: 0.7452 - acc: 0.6699 - val_loss: 0.7916 - val_acc: 0.6453\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 3s 756us/step - loss: 0.7393 - acc: 0.6768 - val_loss: 0.7956 - val_acc: 0.6433\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 3s 749us/step - loss: 0.7388 - acc: 0.6751 - val_loss: 0.7918 - val_acc: 0.6480\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 3s 732us/step - loss: 0.7369 - acc: 0.6756 - val_loss: 0.7940 - val_acc: 0.6420\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7343 - acc: 0.6836 - val_loss: 0.7938 - val_acc: 0.6447\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 0.7323 - acc: 0.6751 - val_loss: 0.7905 - val_acc: 0.6473\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 2s 699us/step - loss: 0.7277 - acc: 0.6796 - val_loss: 0.8160 - val_acc: 0.6247\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.7280 - acc: 0.6811 - val_loss: 0.8176 - val_acc: 0.6247\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7248 - acc: 0.6856 - val_loss: 0.8341 - val_acc: 0.6287\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 3s 759us/step - loss: 0.7210 - acc: 0.6836 - val_loss: 0.7860 - val_acc: 0.6500\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.7217 - acc: 0.6899 - val_loss: 0.8036 - val_acc: 0.6360\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.7190 - acc: 0.6865 - val_loss: 0.8009 - val_acc: 0.6387\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.7133 - acc: 0.6916 - val_loss: 0.8174 - val_acc: 0.6247\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.7126 - acc: 0.6913 - val_loss: 0.8001 - val_acc: 0.6433\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 3s 736us/step - loss: 0.7104 - acc: 0.6928 - val_loss: 0.7829 - val_acc: 0.6547\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.7130 - acc: 0.6885 - val_loss: 0.7999 - val_acc: 0.6340\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 2s 700us/step - loss: 0.7062 - acc: 0.6979 - val_loss: 0.7830 - val_acc: 0.6440\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 2s 702us/step - loss: 0.7022 - acc: 0.6916 - val_loss: 0.8221 - val_acc: 0.6327\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.7033 - acc: 0.6913 - val_loss: 0.7834 - val_acc: 0.6447\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.7015 - acc: 0.6985 - val_loss: 0.7918 - val_acc: 0.6400\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 2s 710us/step - loss: 0.6915 - acc: 0.7031 - val_loss: 0.8313 - val_acc: 0.6213\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.6937 - acc: 0.6993 - val_loss: 0.8069 - val_acc: 0.6340\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.6899 - acc: 0.7036 - val_loss: 0.7893 - val_acc: 0.6533\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 0.6877 - acc: 0.7005 - val_loss: 0.7818 - val_acc: 0.6553\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.6855 - acc: 0.7079 - val_loss: 0.7884 - val_acc: 0.6407\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.6846 - acc: 0.7062 - val_loss: 0.7865 - val_acc: 0.6500\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.6790 - acc: 0.7091 - val_loss: 0.8222 - val_acc: 0.6307\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.6832 - acc: 0.7062 - val_loss: 0.7990 - val_acc: 0.6540\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.6812 - acc: 0.7131 - val_loss: 0.8130 - val_acc: 0.6267\n",
      "Epoch 105/300\n",
      "3499/3499 [==============================] - 3s 718us/step - loss: 0.6763 - acc: 0.7122 - val_loss: 0.8045 - val_acc: 0.6340\n",
      "Epoch 106/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.6726 - acc: 0.7128 - val_loss: 0.7881 - val_acc: 0.6460\n",
      "Epoch 107/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.6734 - acc: 0.7116 - val_loss: 0.8408 - val_acc: 0.6267\n",
      "Epoch 108/300\n",
      "3499/3499 [==============================] - 2s 707us/step - loss: 0.6659 - acc: 0.7105 - val_loss: 0.8025 - val_acc: 0.6447\n",
      "Epoch 109/300\n",
      "3499/3499 [==============================] - 2s 707us/step - loss: 0.6656 - acc: 0.7133 - val_loss: 0.8356 - val_acc: 0.6387\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 10s 3ms/step - loss: 1.0533 - acc: 0.4984 - val_loss: 1.0361 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 3s 742us/step - loss: 1.0367 - acc: 0.5004 - val_loss: 1.0315 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 3s 738us/step - loss: 1.0324 - acc: 0.5004 - val_loss: 1.0274 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 3s 742us/step - loss: 1.0282 - acc: 0.5004 - val_loss: 1.0226 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 3s 748us/step - loss: 1.0235 - acc: 0.5004 - val_loss: 1.0186 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 3s 740us/step - loss: 1.0191 - acc: 0.5004 - val_loss: 1.0138 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 3s 768us/step - loss: 1.0142 - acc: 0.5004 - val_loss: 1.0083 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 3s 735us/step - loss: 1.0087 - acc: 0.5004 - val_loss: 1.0028 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 1.0031 - acc: 0.5021 - val_loss: 0.9968 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.9970 - acc: 0.5033 - val_loss: 0.9909 - val_acc: 0.5060\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 3s 732us/step - loss: 0.9909 - acc: 0.5067 - val_loss: 0.9841 - val_acc: 0.5107\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 3s 732us/step - loss: 0.9841 - acc: 0.5096 - val_loss: 0.9777 - val_acc: 0.5100\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.9776 - acc: 0.5133 - val_loss: 0.9704 - val_acc: 0.5180\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.9702 - acc: 0.5179 - val_loss: 0.9633 - val_acc: 0.5247\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 3s 728us/step - loss: 0.9641 - acc: 0.5233 - val_loss: 0.9565 - val_acc: 0.5333\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.9571 - acc: 0.5259 - val_loss: 0.9496 - val_acc: 0.5387\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 3s 738us/step - loss: 0.9500 - acc: 0.5339 - val_loss: 0.9478 - val_acc: 0.5560\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 3s 735us/step - loss: 0.9452 - acc: 0.5387 - val_loss: 0.9363 - val_acc: 0.5500\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 3s 749us/step - loss: 0.9384 - acc: 0.5462 - val_loss: 0.9321 - val_acc: 0.5533\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 3s 739us/step - loss: 0.9328 - acc: 0.5524 - val_loss: 0.9249 - val_acc: 0.5653\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.9274 - acc: 0.5562 - val_loss: 0.9313 - val_acc: 0.5787\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.9215 - acc: 0.5576 - val_loss: 0.9167 - val_acc: 0.5680\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.9160 - acc: 0.5690 - val_loss: 0.9088 - val_acc: 0.5853\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.9103 - acc: 0.5707 - val_loss: 0.9035 - val_acc: 0.5753\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 3s 733us/step - loss: 0.9058 - acc: 0.5767 - val_loss: 0.8991 - val_acc: 0.5860\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.9004 - acc: 0.5810 - val_loss: 0.8957 - val_acc: 0.5900\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.8956 - acc: 0.5850 - val_loss: 0.8919 - val_acc: 0.5940\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.8908 - acc: 0.5847 - val_loss: 0.8843 - val_acc: 0.5967\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 3s 734us/step - loss: 0.8859 - acc: 0.5902 - val_loss: 0.8804 - val_acc: 0.5933\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.8824 - acc: 0.5925 - val_loss: 0.8830 - val_acc: 0.5867\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 3s 740us/step - loss: 0.8759 - acc: 0.5985 - val_loss: 0.8743 - val_acc: 0.6067\n",
      "Epoch 32/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 3s 735us/step - loss: 0.8722 - acc: 0.5945 - val_loss: 0.8893 - val_acc: 0.5913\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 3s 743us/step - loss: 0.8694 - acc: 0.6039 - val_loss: 0.8673 - val_acc: 0.6060\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 3s 739us/step - loss: 0.8654 - acc: 0.6076 - val_loss: 0.8617 - val_acc: 0.6080\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 3s 739us/step - loss: 0.8593 - acc: 0.5996 - val_loss: 0.8590 - val_acc: 0.6060\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.8555 - acc: 0.6050 - val_loss: 0.8589 - val_acc: 0.6207\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.8525 - acc: 0.6119 - val_loss: 0.8673 - val_acc: 0.6173\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.8473 - acc: 0.6230 - val_loss: 0.8601 - val_acc: 0.6247\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.8456 - acc: 0.6133 - val_loss: 0.8833 - val_acc: 0.5887\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 3s 738us/step - loss: 0.8443 - acc: 0.6205 - val_loss: 0.8489 - val_acc: 0.6100\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 3s 737us/step - loss: 0.8396 - acc: 0.6173 - val_loss: 0.8411 - val_acc: 0.6207\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 3s 727us/step - loss: 0.8370 - acc: 0.6270 - val_loss: 0.8875 - val_acc: 0.5787\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.8320 - acc: 0.6230 - val_loss: 0.8412 - val_acc: 0.6173\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 3s 719us/step - loss: 0.8300 - acc: 0.6282 - val_loss: 0.8416 - val_acc: 0.6260\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.8262 - acc: 0.6213 - val_loss: 0.9480 - val_acc: 0.5227\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.8254 - acc: 0.6233 - val_loss: 0.8417 - val_acc: 0.6080\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 3s 734us/step - loss: 0.8218 - acc: 0.6322 - val_loss: 0.8297 - val_acc: 0.6267\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.8175 - acc: 0.6313 - val_loss: 0.8523 - val_acc: 0.6287\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 2s 704us/step - loss: 0.8158 - acc: 0.6356 - val_loss: 0.8482 - val_acc: 0.6320\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 2s 704us/step - loss: 0.8119 - acc: 0.6336 - val_loss: 0.8323 - val_acc: 0.6320\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 3s 737us/step - loss: 0.8091 - acc: 0.6373 - val_loss: 0.8277 - val_acc: 0.6380\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 3s 746us/step - loss: 0.8037 - acc: 0.6459 - val_loss: 0.8274 - val_acc: 0.6200\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 3s 741us/step - loss: 0.8038 - acc: 0.6445 - val_loss: 0.8235 - val_acc: 0.6313\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 3s 736us/step - loss: 0.8018 - acc: 0.6436 - val_loss: 0.8223 - val_acc: 0.6340\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.7972 - acc: 0.6470 - val_loss: 0.8427 - val_acc: 0.6207\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 2s 710us/step - loss: 0.7983 - acc: 0.6482 - val_loss: 0.8223 - val_acc: 0.6260\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 3s 733us/step - loss: 0.7942 - acc: 0.6473 - val_loss: 0.8214 - val_acc: 0.6353\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.7911 - acc: 0.6482 - val_loss: 0.8473 - val_acc: 0.6180\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.7888 - acc: 0.6542 - val_loss: 0.8511 - val_acc: 0.6093\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 3s 741us/step - loss: 0.7867 - acc: 0.6513 - val_loss: 0.8144 - val_acc: 0.6420\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.7816 - acc: 0.6493 - val_loss: 0.8384 - val_acc: 0.6153\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 3s 730us/step - loss: 0.7827 - acc: 0.6562 - val_loss: 0.8440 - val_acc: 0.6180\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.7779 - acc: 0.6548 - val_loss: 0.8208 - val_acc: 0.6300\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.7761 - acc: 0.6619 - val_loss: 0.8263 - val_acc: 0.6260\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.7719 - acc: 0.6573 - val_loss: 0.8215 - val_acc: 0.6247\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7713 - acc: 0.6639 - val_loss: 0.8109 - val_acc: 0.6333\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 2s 710us/step - loss: 0.7680 - acc: 0.6625 - val_loss: 0.8295 - val_acc: 0.6233\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7692 - acc: 0.6559 - val_loss: 0.8183 - val_acc: 0.6253\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.7636 - acc: 0.6670 - val_loss: 0.8184 - val_acc: 0.6327\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 3s 722us/step - loss: 0.7617 - acc: 0.6682 - val_loss: 0.8137 - val_acc: 0.6213\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7590 - acc: 0.6633 - val_loss: 0.8399 - val_acc: 0.6147\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 2s 711us/step - loss: 0.7535 - acc: 0.6688 - val_loss: 0.8375 - val_acc: 0.6233\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7586 - acc: 0.6668 - val_loss: 0.9078 - val_acc: 0.5827\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.7528 - acc: 0.6682 - val_loss: 0.8098 - val_acc: 0.6240\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.7488 - acc: 0.6670 - val_loss: 0.8197 - val_acc: 0.6340\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 3s 734us/step - loss: 0.7492 - acc: 0.6679 - val_loss: 0.8096 - val_acc: 0.6393\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 3s 726us/step - loss: 0.7433 - acc: 0.6730 - val_loss: 0.8050 - val_acc: 0.6353\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7429 - acc: 0.6768 - val_loss: 0.8026 - val_acc: 0.6400\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 3s 723us/step - loss: 0.7397 - acc: 0.6742 - val_loss: 0.8022 - val_acc: 0.6353\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.7372 - acc: 0.6805 - val_loss: 0.8134 - val_acc: 0.6353\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7376 - acc: 0.6768 - val_loss: 0.8009 - val_acc: 0.6400\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 3s 717us/step - loss: 0.7332 - acc: 0.6779 - val_loss: 0.8143 - val_acc: 0.6253\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 3s 729us/step - loss: 0.7329 - acc: 0.6725 - val_loss: 0.8277 - val_acc: 0.6307\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7293 - acc: 0.6793 - val_loss: 0.8356 - val_acc: 0.6213\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 3s 735us/step - loss: 0.7267 - acc: 0.6868 - val_loss: 0.7999 - val_acc: 0.6440\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 3s 721us/step - loss: 0.7227 - acc: 0.6871 - val_loss: 0.8309 - val_acc: 0.6187\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 2s 709us/step - loss: 0.7255 - acc: 0.6802 - val_loss: 0.8119 - val_acc: 0.6280\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 2s 714us/step - loss: 0.7173 - acc: 0.6839 - val_loss: 0.9144 - val_acc: 0.6027\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.7168 - acc: 0.6868 - val_loss: 0.8132 - val_acc: 0.6373\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.7135 - acc: 0.6868 - val_loss: 0.8155 - val_acc: 0.6367\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 2s 702us/step - loss: 0.7132 - acc: 0.6888 - val_loss: 0.8095 - val_acc: 0.6327\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 3s 725us/step - loss: 0.7079 - acc: 0.6933 - val_loss: 0.7994 - val_acc: 0.6400\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.7057 - acc: 0.6959 - val_loss: 0.8114 - val_acc: 0.6353\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 3s 724us/step - loss: 0.7046 - acc: 0.6925 - val_loss: 0.7959 - val_acc: 0.6487\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 2s 706us/step - loss: 0.7016 - acc: 0.6913 - val_loss: 0.7988 - val_acc: 0.6460\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 2s 704us/step - loss: 0.6948 - acc: 0.6945 - val_loss: 0.8411 - val_acc: 0.6287\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 2s 708us/step - loss: 0.6983 - acc: 0.6968 - val_loss: 0.8025 - val_acc: 0.6480\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 2s 712us/step - loss: 0.6890 - acc: 0.7048 - val_loss: 0.8067 - val_acc: 0.6447\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 3s 731us/step - loss: 0.6888 - acc: 0.7008 - val_loss: 0.7975 - val_acc: 0.6453\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 2s 705us/step - loss: 0.6882 - acc: 0.6999 - val_loss: 0.8240 - val_acc: 0.6360\n",
      "Epoch 101/300\n",
      "3499/3499 [==============================] - 3s 720us/step - loss: 0.6896 - acc: 0.7011 - val_loss: 0.8271 - val_acc: 0.6233\n",
      "Epoch 102/300\n",
      "3499/3499 [==============================] - 3s 716us/step - loss: 0.6811 - acc: 0.7028 - val_loss: 0.8470 - val_acc: 0.6213\n",
      "Epoch 103/300\n",
      "3499/3499 [==============================] - 3s 719us/step - loss: 0.6839 - acc: 0.7025 - val_loss: 0.8161 - val_acc: 0.6333\n",
      "Epoch 104/300\n",
      "3499/3499 [==============================] - 2s 713us/step - loss: 0.6809 - acc: 0.7102 - val_loss: 0.8043 - val_acc: 0.6413\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 11s 3ms/step - loss: 1.0477 - acc: 0.4984 - val_loss: 1.0380 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0354 - acc: 0.5004 - val_loss: 1.0357 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0319 - acc: 0.5004 - val_loss: 1.0333 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0286 - acc: 0.5004 - val_loss: 1.0308 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0252 - acc: 0.5004 - val_loss: 1.0281 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0218 - acc: 0.5004 - val_loss: 1.0254 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0182 - acc: 0.5007 - val_loss: 1.0220 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0143 - acc: 0.5007 - val_loss: 1.0181 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0095 - acc: 0.5021 - val_loss: 1.0137 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 1.0033 - acc: 0.5021 - val_loss: 1.0096 - val_acc: 0.5013\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9979 - acc: 0.5033 - val_loss: 1.0022 - val_acc: 0.5073\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9902 - acc: 0.5104 - val_loss: 0.9956 - val_acc: 0.5067\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9825 - acc: 0.5170 - val_loss: 0.9894 - val_acc: 0.5107\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9742 - acc: 0.5273 - val_loss: 0.9826 - val_acc: 0.5107\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9654 - acc: 0.5356 - val_loss: 0.9681 - val_acc: 0.5200\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9545 - acc: 0.5442 - val_loss: 0.9597 - val_acc: 0.5373\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9471 - acc: 0.5536 - val_loss: 0.9533 - val_acc: 0.5267\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9372 - acc: 0.5570 - val_loss: 0.9442 - val_acc: 0.5613\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9302 - acc: 0.5628 - val_loss: 0.9483 - val_acc: 0.5540\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9241 - acc: 0.5685 - val_loss: 0.9295 - val_acc: 0.5640\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9129 - acc: 0.5751 - val_loss: 0.9645 - val_acc: 0.5220\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.9077 - acc: 0.5825 - val_loss: 0.9219 - val_acc: 0.5773\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8996 - acc: 0.5825 - val_loss: 0.9131 - val_acc: 0.5553\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8932 - acc: 0.5954 - val_loss: 0.9156 - val_acc: 0.5613\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8865 - acc: 0.5951 - val_loss: 0.9896 - val_acc: 0.4867\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8797 - acc: 0.5997 - val_loss: 0.9016 - val_acc: 0.5793\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8715 - acc: 0.6011 - val_loss: 0.8882 - val_acc: 0.5847\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8668 - acc: 0.6059 - val_loss: 0.8922 - val_acc: 0.5780\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8599 - acc: 0.6114 - val_loss: 0.8794 - val_acc: 0.5813\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8541 - acc: 0.6128 - val_loss: 0.8961 - val_acc: 0.5847\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8487 - acc: 0.6162 - val_loss: 0.8693 - val_acc: 0.5880\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8441 - acc: 0.6188 - val_loss: 0.8704 - val_acc: 0.5993\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8354 - acc: 0.6231 - val_loss: 0.8797 - val_acc: 0.5927\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8321 - acc: 0.6234 - val_loss: 0.8628 - val_acc: 0.6053\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8279 - acc: 0.6265 - val_loss: 0.8621 - val_acc: 0.5953\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8237 - acc: 0.6311 - val_loss: 0.8668 - val_acc: 0.5873\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8179 - acc: 0.6374 - val_loss: 0.8505 - val_acc: 0.6133\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8136 - acc: 0.6377 - val_loss: 0.8877 - val_acc: 0.5933\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8090 - acc: 0.6388 - val_loss: 0.8755 - val_acc: 0.5933\n",
      "Epoch 40/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8079 - acc: 0.6345 - val_loss: 0.8852 - val_acc: 0.5660\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.8042 - acc: 0.6405 - val_loss: 0.8911 - val_acc: 0.5707\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7993 - acc: 0.6434 - val_loss: 0.8365 - val_acc: 0.6173\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7927 - acc: 0.6480 - val_loss: 0.8649 - val_acc: 0.6000\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7889 - acc: 0.6463 - val_loss: 0.8312 - val_acc: 0.6273\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7882 - acc: 0.6528 - val_loss: 0.8353 - val_acc: 0.6113\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7849 - acc: 0.6517 - val_loss: 0.8257 - val_acc: 0.6240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7773 - acc: 0.6568 - val_loss: 0.8499 - val_acc: 0.6040\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7756 - acc: 0.6574 - val_loss: 1.0121 - val_acc: 0.4767\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7758 - acc: 0.6546 - val_loss: 0.8268 - val_acc: 0.6207\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7690 - acc: 0.6637 - val_loss: 0.8652 - val_acc: 0.6020\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7664 - acc: 0.6617 - val_loss: 0.8252 - val_acc: 0.6307\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7619 - acc: 0.6634 - val_loss: 0.8185 - val_acc: 0.6327\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7614 - acc: 0.6617 - val_loss: 0.8212 - val_acc: 0.6200\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7529 - acc: 0.6689 - val_loss: 0.8391 - val_acc: 0.6160\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7503 - acc: 0.6729 - val_loss: 0.9520 - val_acc: 0.5413\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7484 - acc: 0.6754 - val_loss: 0.8626 - val_acc: 0.6087\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7488 - acc: 0.6703 - val_loss: 0.8141 - val_acc: 0.6200\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7437 - acc: 0.6669 - val_loss: 0.8618 - val_acc: 0.6120\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7445 - acc: 0.6783 - val_loss: 0.8197 - val_acc: 0.6273\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7369 - acc: 0.6812 - val_loss: 0.8766 - val_acc: 0.5707\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7322 - acc: 0.6789 - val_loss: 0.8278 - val_acc: 0.6240\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7352 - acc: 0.6794 - val_loss: 0.8111 - val_acc: 0.6273\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7307 - acc: 0.6763 - val_loss: 0.9088 - val_acc: 0.6013\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7276 - acc: 0.6832 - val_loss: 0.8153 - val_acc: 0.6273\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7235 - acc: 0.6877 - val_loss: 0.9195 - val_acc: 0.5853\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7238 - acc: 0.6829 - val_loss: 0.8077 - val_acc: 0.6287\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7225 - acc: 0.6834 - val_loss: 0.8153 - val_acc: 0.6327\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7180 - acc: 0.6866 - val_loss: 0.8057 - val_acc: 0.6293\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7144 - acc: 0.6906 - val_loss: 0.8159 - val_acc: 0.6347\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7078 - acc: 0.6972 - val_loss: 0.8277 - val_acc: 0.6300\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7078 - acc: 0.6997 - val_loss: 0.8389 - val_acc: 0.6167\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7048 - acc: 0.6997 - val_loss: 0.8453 - val_acc: 0.6200\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.7046 - acc: 0.7006 - val_loss: 0.8475 - val_acc: 0.6287\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6992 - acc: 0.6935 - val_loss: 0.8241 - val_acc: 0.6287\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6920 - acc: 0.7063 - val_loss: 0.8683 - val_acc: 0.6113\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6946 - acc: 0.7069 - val_loss: 0.9105 - val_acc: 0.5873\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6863 - acc: 0.7120 - val_loss: 0.8153 - val_acc: 0.6307\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6901 - acc: 0.7006 - val_loss: 0.8032 - val_acc: 0.6393\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6827 - acc: 0.7109 - val_loss: 0.8272 - val_acc: 0.6167\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6780 - acc: 0.7100 - val_loss: 0.8186 - val_acc: 0.6400\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6810 - acc: 0.7129 - val_loss: 0.8134 - val_acc: 0.6340\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6763 - acc: 0.7092 - val_loss: 0.8174 - val_acc: 0.6220\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6697 - acc: 0.7155 - val_loss: 0.8502 - val_acc: 0.6293\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6688 - acc: 0.7149 - val_loss: 0.9003 - val_acc: 0.6107\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6700 - acc: 0.7195 - val_loss: 0.8710 - val_acc: 0.6147\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6702 - acc: 0.7183 - val_loss: 0.8271 - val_acc: 0.6220\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6699 - acc: 0.7186 - val_loss: 0.8776 - val_acc: 0.5913\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 4s 1ms/step - loss: 0.6601 - acc: 0.7232 - val_loss: 0.8652 - val_acc: 0.6020\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 12s 3ms/step - loss: 1.0502 - acc: 0.4980 - val_loss: 1.0389 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0358 - acc: 0.5003 - val_loss: 1.0354 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0319 - acc: 0.5003 - val_loss: 1.0319 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0275 - acc: 0.5003 - val_loss: 1.0287 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0239 - acc: 0.5003 - val_loss: 1.0249 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0193 - acc: 0.5003 - val_loss: 1.0208 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0145 - acc: 0.5000 - val_loss: 1.0164 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0097 - acc: 0.5003 - val_loss: 1.0115 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 1.0041 - acc: 0.5026 - val_loss: 1.0068 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9978 - acc: 0.5066 - val_loss: 1.0012 - val_acc: 0.5047\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9917 - acc: 0.5109 - val_loss: 0.9936 - val_acc: 0.5100\n",
      "Epoch 12/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9838 - acc: 0.5100 - val_loss: 0.9870 - val_acc: 0.5127\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9755 - acc: 0.5177 - val_loss: 0.9798 - val_acc: 0.5180\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9663 - acc: 0.5254 - val_loss: 0.9699 - val_acc: 0.5180\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9571 - acc: 0.5292 - val_loss: 0.9602 - val_acc: 0.5307\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9477 - acc: 0.5363 - val_loss: 0.9522 - val_acc: 0.5433\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9392 - acc: 0.5395 - val_loss: 0.9422 - val_acc: 0.5480\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9295 - acc: 0.5540 - val_loss: 0.9380 - val_acc: 0.5660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9217 - acc: 0.5635 - val_loss: 0.9363 - val_acc: 0.5513\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9151 - acc: 0.5669 - val_loss: 0.9221 - val_acc: 0.5587\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9079 - acc: 0.5712 - val_loss: 0.9145 - val_acc: 0.5673\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.9023 - acc: 0.5800 - val_loss: 0.9127 - val_acc: 0.5833\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8961 - acc: 0.5840 - val_loss: 0.9077 - val_acc: 0.5867\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8923 - acc: 0.5895 - val_loss: 0.9350 - val_acc: 0.5500\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8860 - acc: 0.5906 - val_loss: 0.9047 - val_acc: 0.5727\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8789 - acc: 0.5923 - val_loss: 0.9083 - val_acc: 0.5780\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8758 - acc: 0.6021 - val_loss: 0.8904 - val_acc: 0.5880\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8692 - acc: 0.6018 - val_loss: 0.9175 - val_acc: 0.5573\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8637 - acc: 0.6021 - val_loss: 0.8838 - val_acc: 0.5960\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8591 - acc: 0.6069 - val_loss: 0.8814 - val_acc: 0.5933\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8555 - acc: 0.6095 - val_loss: 0.9091 - val_acc: 0.5567\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8517 - acc: 0.6089 - val_loss: 0.8963 - val_acc: 0.5800\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8506 - acc: 0.6135 - val_loss: 0.8720 - val_acc: 0.6020\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8408 - acc: 0.6198 - val_loss: 0.9136 - val_acc: 0.5693\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8389 - acc: 0.6255 - val_loss: 0.8983 - val_acc: 0.5620\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8386 - acc: 0.6232 - val_loss: 0.8795 - val_acc: 0.5840\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8306 - acc: 0.6218 - val_loss: 0.8653 - val_acc: 0.6000\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8301 - acc: 0.6221 - val_loss: 0.8806 - val_acc: 0.5767\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8249 - acc: 0.6309 - val_loss: 0.8833 - val_acc: 0.5793\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8212 - acc: 0.6284 - val_loss: 0.9837 - val_acc: 0.4947\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8182 - acc: 0.6321 - val_loss: 0.8736 - val_acc: 0.5873\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8155 - acc: 0.6369 - val_loss: 0.8569 - val_acc: 0.6013\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8155 - acc: 0.6344 - val_loss: 0.8682 - val_acc: 0.5873\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8057 - acc: 0.6384 - val_loss: 0.8676 - val_acc: 0.5900\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8039 - acc: 0.6409 - val_loss: 0.8774 - val_acc: 0.5913\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.8036 - acc: 0.6461 - val_loss: 0.8532 - val_acc: 0.5993\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7993 - acc: 0.6449 - val_loss: 0.8463 - val_acc: 0.6013\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7956 - acc: 0.6432 - val_loss: 0.8812 - val_acc: 0.5880\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7940 - acc: 0.6475 - val_loss: 0.8589 - val_acc: 0.5873\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7902 - acc: 0.6432 - val_loss: 0.8605 - val_acc: 0.5900\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7875 - acc: 0.6475 - val_loss: 0.8481 - val_acc: 0.5953\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7828 - acc: 0.6549 - val_loss: 0.8975 - val_acc: 0.5860\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7798 - acc: 0.6549 - val_loss: 0.8576 - val_acc: 0.6000\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7811 - acc: 0.6544 - val_loss: 0.8449 - val_acc: 0.6093\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7753 - acc: 0.6572 - val_loss: 0.8704 - val_acc: 0.5993\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7747 - acc: 0.6561 - val_loss: 0.8522 - val_acc: 0.5973\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7709 - acc: 0.6670 - val_loss: 0.9413 - val_acc: 0.5407\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7673 - acc: 0.6630 - val_loss: 0.8850 - val_acc: 0.5953\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7653 - acc: 0.6621 - val_loss: 0.9185 - val_acc: 0.5707\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7636 - acc: 0.6615 - val_loss: 0.8530 - val_acc: 0.5960\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7580 - acc: 0.6695 - val_loss: 0.8870 - val_acc: 0.5940\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7604 - acc: 0.6658 - val_loss: 0.8339 - val_acc: 0.6053\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7559 - acc: 0.6712 - val_loss: 0.9285 - val_acc: 0.5533\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7548 - acc: 0.6712 - val_loss: 0.8913 - val_acc: 0.5793\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7500 - acc: 0.6747 - val_loss: 0.8416 - val_acc: 0.6100\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7433 - acc: 0.6755 - val_loss: 0.8343 - val_acc: 0.6120\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7443 - acc: 0.6761 - val_loss: 0.8550 - val_acc: 0.6100\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7442 - acc: 0.6712 - val_loss: 0.8515 - val_acc: 0.6087\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7349 - acc: 0.6835 - val_loss: 0.8311 - val_acc: 0.6200\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7403 - acc: 0.6781 - val_loss: 0.8345 - val_acc: 0.6180\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7354 - acc: 0.6855 - val_loss: 0.8331 - val_acc: 0.6187\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7298 - acc: 0.6844 - val_loss: 0.8329 - val_acc: 0.6147\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7261 - acc: 0.6827 - val_loss: 0.8250 - val_acc: 0.6207\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7268 - acc: 0.6841 - val_loss: 0.8565 - val_acc: 0.6020\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7222 - acc: 0.6832 - val_loss: 0.8351 - val_acc: 0.6180\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7190 - acc: 0.6861 - val_loss: 0.8286 - val_acc: 0.6120\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7158 - acc: 0.6890 - val_loss: 0.8451 - val_acc: 0.6060\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7187 - acc: 0.6887 - val_loss: 0.8544 - val_acc: 0.6027\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7130 - acc: 0.6890 - val_loss: 0.8195 - val_acc: 0.6207\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7076 - acc: 0.6955 - val_loss: 0.9354 - val_acc: 0.5620\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7106 - acc: 0.6887 - val_loss: 0.8729 - val_acc: 0.6173\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7101 - acc: 0.6961 - val_loss: 0.8781 - val_acc: 0.5873\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.7040 - acc: 0.6930 - val_loss: 0.8403 - val_acc: 0.6080\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.6992 - acc: 0.7050 - val_loss: 0.8198 - val_acc: 0.6213\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.6983 - acc: 0.7024 - val_loss: 0.8258 - val_acc: 0.6180\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.6940 - acc: 0.7041 - val_loss: 0.8495 - val_acc: 0.6247\n",
      "Epoch 87/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.6935 - acc: 0.6981 - val_loss: 0.8287 - val_acc: 0.6213\n",
      "Epoch 88/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.6928 - acc: 0.7084 - val_loss: 0.8220 - val_acc: 0.6213\n",
      "Epoch 89/300\n",
      "3498/3498 [==============================] - 4s 1ms/step - loss: 0.6883 - acc: 0.7067 - val_loss: 0.8253 - val_acc: 0.6240\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 12s 3ms/step - loss: 1.0501 - acc: 0.4987 - val_loss: 1.0367 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0363 - acc: 0.5004 - val_loss: 1.0338 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0326 - acc: 0.5004 - val_loss: 1.0304 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0289 - acc: 0.5004 - val_loss: 1.0264 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0246 - acc: 0.5004 - val_loss: 1.0233 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0206 - acc: 0.5004 - val_loss: 1.0194 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0162 - acc: 0.5004 - val_loss: 1.0143 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0112 - acc: 0.5007 - val_loss: 1.0093 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0059 - acc: 0.5024 - val_loss: 1.0038 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9998 - acc: 0.5056 - val_loss: 0.9993 - val_acc: 0.5107\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9940 - acc: 0.5107 - val_loss: 0.9912 - val_acc: 0.5107\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9863 - acc: 0.5136 - val_loss: 0.9838 - val_acc: 0.5127\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9784 - acc: 0.5156 - val_loss: 0.9747 - val_acc: 0.5180\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9685 - acc: 0.5213 - val_loss: 0.9667 - val_acc: 0.5267\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9613 - acc: 0.5273 - val_loss: 0.9583 - val_acc: 0.5320\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9504 - acc: 0.5342 - val_loss: 0.9492 - val_acc: 0.5547\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9407 - acc: 0.5422 - val_loss: 0.9411 - val_acc: 0.5607\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9357 - acc: 0.5522 - val_loss: 0.9301 - val_acc: 0.5613\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9276 - acc: 0.5627 - val_loss: 0.9249 - val_acc: 0.5727\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9189 - acc: 0.5593 - val_loss: 0.9260 - val_acc: 0.5633\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9145 - acc: 0.5730 - val_loss: 0.9638 - val_acc: 0.5400\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9076 - acc: 0.5727 - val_loss: 0.9074 - val_acc: 0.5780\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8999 - acc: 0.5793 - val_loss: 0.9044 - val_acc: 0.5820\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8956 - acc: 0.5776 - val_loss: 0.9568 - val_acc: 0.5340\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8930 - acc: 0.5813 - val_loss: 0.9116 - val_acc: 0.5560\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8823 - acc: 0.5910 - val_loss: 0.9115 - val_acc: 0.5733\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8775 - acc: 0.5919 - val_loss: 0.8857 - val_acc: 0.5913\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8730 - acc: 0.5859 - val_loss: 0.8869 - val_acc: 0.5900\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8666 - acc: 0.6025 - val_loss: 0.8824 - val_acc: 0.5853\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8643 - acc: 0.5979 - val_loss: 0.8778 - val_acc: 0.5860\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8544 - acc: 0.6130 - val_loss: 0.8928 - val_acc: 0.5720\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8534 - acc: 0.6102 - val_loss: 0.9063 - val_acc: 0.5567\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8492 - acc: 0.6079 - val_loss: 0.8809 - val_acc: 0.5967\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8469 - acc: 0.6167 - val_loss: 0.8710 - val_acc: 0.5980\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8385 - acc: 0.6130 - val_loss: 0.8641 - val_acc: 0.5960\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8352 - acc: 0.6199 - val_loss: 0.8703 - val_acc: 0.5847\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8323 - acc: 0.6239 - val_loss: 0.9027 - val_acc: 0.5920\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8281 - acc: 0.6265 - val_loss: 0.8755 - val_acc: 0.5907\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8251 - acc: 0.6330 - val_loss: 0.9050 - val_acc: 0.5587\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8252 - acc: 0.6262 - val_loss: 0.8633 - val_acc: 0.5887\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8164 - acc: 0.6322 - val_loss: 0.8536 - val_acc: 0.6013\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8163 - acc: 0.6319 - val_loss: 0.8959 - val_acc: 0.5633\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8123 - acc: 0.6319 - val_loss: 0.8489 - val_acc: 0.6100\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8091 - acc: 0.6425 - val_loss: 0.8715 - val_acc: 0.5820\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8065 - acc: 0.6433 - val_loss: 0.9645 - val_acc: 0.5020\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8054 - acc: 0.6408 - val_loss: 0.8578 - val_acc: 0.5920\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8010 - acc: 0.6465 - val_loss: 0.8460 - val_acc: 0.6020\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7963 - acc: 0.6510 - val_loss: 0.8399 - val_acc: 0.6133\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7970 - acc: 0.6539 - val_loss: 0.8789 - val_acc: 0.5880\n",
      "Epoch 50/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7883 - acc: 0.6602 - val_loss: 0.8477 - val_acc: 0.6073\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7866 - acc: 0.6568 - val_loss: 0.8473 - val_acc: 0.5987\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7816 - acc: 0.6590 - val_loss: 0.8757 - val_acc: 0.5833\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7828 - acc: 0.6562 - val_loss: 0.8438 - val_acc: 0.6020\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7806 - acc: 0.6590 - val_loss: 0.8335 - val_acc: 0.6213\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7715 - acc: 0.6725 - val_loss: 0.8578 - val_acc: 0.5913\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7754 - acc: 0.6639 - val_loss: 0.8495 - val_acc: 0.5980\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7727 - acc: 0.6659 - val_loss: 0.8541 - val_acc: 0.6027\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7680 - acc: 0.6648 - val_loss: 0.8883 - val_acc: 0.5733\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7687 - acc: 0.6722 - val_loss: 0.8640 - val_acc: 0.5867\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7658 - acc: 0.6679 - val_loss: 0.8341 - val_acc: 0.6207\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7600 - acc: 0.6642 - val_loss: 0.8343 - val_acc: 0.6207\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7587 - acc: 0.6748 - val_loss: 0.8884 - val_acc: 0.5753\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7591 - acc: 0.6771 - val_loss: 0.8399 - val_acc: 0.6093\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7542 - acc: 0.6705 - val_loss: 0.8345 - val_acc: 0.6173\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 12s 3ms/step - loss: 1.0500 - acc: 0.4990 - val_loss: 1.0371 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0362 - acc: 0.5004 - val_loss: 1.0337 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0327 - acc: 0.5004 - val_loss: 1.0302 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0291 - acc: 0.5004 - val_loss: 1.0260 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0248 - acc: 0.5004 - val_loss: 1.0228 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0209 - acc: 0.5004 - val_loss: 1.0186 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0167 - acc: 0.5004 - val_loss: 1.0132 - val_acc: 0.5000\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0118 - acc: 0.5004 - val_loss: 1.0079 - val_acc: 0.5000\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0067 - acc: 0.5021 - val_loss: 1.0023 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0010 - acc: 0.5033 - val_loss: 0.9974 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9955 - acc: 0.5087 - val_loss: 0.9896 - val_acc: 0.5073\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9886 - acc: 0.5124 - val_loss: 0.9827 - val_acc: 0.5127\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9815 - acc: 0.5153 - val_loss: 0.9743 - val_acc: 0.5180\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9725 - acc: 0.5210 - val_loss: 0.9653 - val_acc: 0.5220\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9651 - acc: 0.5236 - val_loss: 0.9569 - val_acc: 0.5320\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9549 - acc: 0.5307 - val_loss: 0.9478 - val_acc: 0.5473\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9454 - acc: 0.5342 - val_loss: 0.9387 - val_acc: 0.5587\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9394 - acc: 0.5467 - val_loss: 0.9275 - val_acc: 0.5593\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9306 - acc: 0.5456 - val_loss: 0.9197 - val_acc: 0.5693\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9227 - acc: 0.5533 - val_loss: 0.9153 - val_acc: 0.5733\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9185 - acc: 0.5616 - val_loss: 0.9571 - val_acc: 0.5373\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9093 - acc: 0.5713 - val_loss: 0.9101 - val_acc: 0.5760\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9026 - acc: 0.5739 - val_loss: 0.8927 - val_acc: 0.5887\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8971 - acc: 0.5770 - val_loss: 0.9012 - val_acc: 0.5800\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8924 - acc: 0.5850 - val_loss: 0.8882 - val_acc: 0.5940\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8859 - acc: 0.5867 - val_loss: 0.8830 - val_acc: 0.5840\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8810 - acc: 0.5942 - val_loss: 0.8723 - val_acc: 0.5960\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8755 - acc: 0.5870 - val_loss: 0.8714 - val_acc: 0.6040\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8719 - acc: 0.5939 - val_loss: 0.8721 - val_acc: 0.5880\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8677 - acc: 0.5939 - val_loss: 0.8708 - val_acc: 0.5960\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8599 - acc: 0.6027 - val_loss: 0.8582 - val_acc: 0.5967\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8574 - acc: 0.6053 - val_loss: 0.8704 - val_acc: 0.5980\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8541 - acc: 0.6036 - val_loss: 0.8507 - val_acc: 0.6127\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8484 - acc: 0.6045 - val_loss: 0.8457 - val_acc: 0.6120\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8421 - acc: 0.6099 - val_loss: 0.8456 - val_acc: 0.6093\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8394 - acc: 0.6145 - val_loss: 0.8465 - val_acc: 0.6073\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8372 - acc: 0.6213 - val_loss: 0.8749 - val_acc: 0.6013\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8322 - acc: 0.6187 - val_loss: 0.8543 - val_acc: 0.6087\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8291 - acc: 0.6202 - val_loss: 0.9473 - val_acc: 0.5300\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8281 - acc: 0.6268 - val_loss: 0.8333 - val_acc: 0.6167\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8223 - acc: 0.6305 - val_loss: 0.8302 - val_acc: 0.6187\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8214 - acc: 0.6279 - val_loss: 0.8691 - val_acc: 0.5900\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8155 - acc: 0.6305 - val_loss: 0.8276 - val_acc: 0.6153\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8124 - acc: 0.6350 - val_loss: 0.8410 - val_acc: 0.6060\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8104 - acc: 0.6325 - val_loss: 0.9430 - val_acc: 0.5313\n",
      "Epoch 46/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8093 - acc: 0.6359 - val_loss: 0.8309 - val_acc: 0.6193\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8030 - acc: 0.6419 - val_loss: 0.8157 - val_acc: 0.6353\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7999 - acc: 0.6442 - val_loss: 0.8204 - val_acc: 0.6307\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8004 - acc: 0.6448 - val_loss: 0.8466 - val_acc: 0.6180\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7937 - acc: 0.6525 - val_loss: 0.8138 - val_acc: 0.6340\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7910 - acc: 0.6453 - val_loss: 0.8326 - val_acc: 0.6193\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7857 - acc: 0.6545 - val_loss: 0.8444 - val_acc: 0.6033\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7863 - acc: 0.6499 - val_loss: 0.8135 - val_acc: 0.6293\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7833 - acc: 0.6548 - val_loss: 0.8117 - val_acc: 0.6333\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7773 - acc: 0.6579 - val_loss: 0.8573 - val_acc: 0.5913\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7812 - acc: 0.6553 - val_loss: 0.8254 - val_acc: 0.6167\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7780 - acc: 0.6513 - val_loss: 0.8230 - val_acc: 0.6200\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7722 - acc: 0.6619 - val_loss: 0.8481 - val_acc: 0.6067\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7705 - acc: 0.6588 - val_loss: 0.8390 - val_acc: 0.6147\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7688 - acc: 0.6599 - val_loss: 0.8116 - val_acc: 0.6320\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7639 - acc: 0.6605 - val_loss: 0.8030 - val_acc: 0.6433\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7634 - acc: 0.6633 - val_loss: 0.8441 - val_acc: 0.6047\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7615 - acc: 0.6639 - val_loss: 0.7993 - val_acc: 0.6440\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7569 - acc: 0.6656 - val_loss: 0.7990 - val_acc: 0.6400\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7537 - acc: 0.6725 - val_loss: 0.7982 - val_acc: 0.6367\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7546 - acc: 0.6653 - val_loss: 0.8054 - val_acc: 0.6307\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7494 - acc: 0.6696 - val_loss: 0.8220 - val_acc: 0.6280\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7480 - acc: 0.6676 - val_loss: 0.8405 - val_acc: 0.5967\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7458 - acc: 0.6759 - val_loss: 0.8206 - val_acc: 0.6353\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7430 - acc: 0.6659 - val_loss: 0.7904 - val_acc: 0.6440\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7393 - acc: 0.6765 - val_loss: 0.8164 - val_acc: 0.6227\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7367 - acc: 0.6768 - val_loss: 0.8684 - val_acc: 0.6220\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7406 - acc: 0.6710 - val_loss: 0.8217 - val_acc: 0.6253\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7311 - acc: 0.6768 - val_loss: 0.7895 - val_acc: 0.6433\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7303 - acc: 0.6819 - val_loss: 0.8198 - val_acc: 0.6293\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7296 - acc: 0.6813 - val_loss: 0.7929 - val_acc: 0.6487\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7214 - acc: 0.6902 - val_loss: 0.7906 - val_acc: 0.6500\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7223 - acc: 0.6816 - val_loss: 0.7917 - val_acc: 0.6560\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7178 - acc: 0.6876 - val_loss: 0.8143 - val_acc: 0.6413\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7165 - acc: 0.6902 - val_loss: 0.8052 - val_acc: 0.6353\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7147 - acc: 0.6913 - val_loss: 0.7888 - val_acc: 0.6473\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7076 - acc: 0.6962 - val_loss: 0.8343 - val_acc: 0.6000\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7144 - acc: 0.6919 - val_loss: 0.8099 - val_acc: 0.6320\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7064 - acc: 0.6925 - val_loss: 0.8251 - val_acc: 0.6407\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7025 - acc: 0.6999 - val_loss: 0.7836 - val_acc: 0.6507\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7000 - acc: 0.7031 - val_loss: 0.8023 - val_acc: 0.6367\n",
      "Epoch 87/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7000 - acc: 0.7036 - val_loss: 0.8240 - val_acc: 0.6320\n",
      "Epoch 88/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6929 - acc: 0.7011 - val_loss: 0.8085 - val_acc: 0.6400\n",
      "Epoch 89/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6922 - acc: 0.6991 - val_loss: 0.7979 - val_acc: 0.6440\n",
      "Epoch 90/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6915 - acc: 0.6985 - val_loss: 0.7835 - val_acc: 0.6553\n",
      "Epoch 91/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6911 - acc: 0.6933 - val_loss: 0.8533 - val_acc: 0.6047\n",
      "Epoch 92/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6852 - acc: 0.7028 - val_loss: 0.7923 - val_acc: 0.6393\n",
      "Epoch 93/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6814 - acc: 0.7045 - val_loss: 0.7946 - val_acc: 0.6440\n",
      "Epoch 94/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6827 - acc: 0.7096 - val_loss: 0.7882 - val_acc: 0.6547\n",
      "Epoch 95/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6826 - acc: 0.7033 - val_loss: 0.8061 - val_acc: 0.6440\n",
      "Epoch 96/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6669 - acc: 0.7193 - val_loss: 0.8509 - val_acc: 0.6260\n",
      "Epoch 97/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6714 - acc: 0.7071 - val_loss: 0.8028 - val_acc: 0.6413\n",
      "Epoch 98/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6673 - acc: 0.7131 - val_loss: 0.7929 - val_acc: 0.6527\n",
      "Epoch 99/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6646 - acc: 0.7162 - val_loss: 0.7947 - val_acc: 0.6433\n",
      "Epoch 100/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.6643 - acc: 0.7139 - val_loss: 0.7927 - val_acc: 0.6480\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 13s 4ms/step - loss: 1.0498 - acc: 0.4990 - val_loss: 1.0358 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0361 - acc: 0.5004 - val_loss: 1.0322 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0327 - acc: 0.5004 - val_loss: 1.0288 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0293 - acc: 0.5004 - val_loss: 1.0246 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0253 - acc: 0.5004 - val_loss: 1.0216 - val_acc: 0.5007\n",
      "Epoch 6/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0215 - acc: 0.5004 - val_loss: 1.0174 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0173 - acc: 0.5004 - val_loss: 1.0125 - val_acc: 0.5000\n",
      "Epoch 8/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0127 - acc: 0.5007 - val_loss: 1.0070 - val_acc: 0.5000\n",
      "Epoch 9/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0077 - acc: 0.5013 - val_loss: 1.0016 - val_acc: 0.5013\n",
      "Epoch 10/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 1.0020 - acc: 0.5033 - val_loss: 0.9960 - val_acc: 0.5067\n",
      "Epoch 11/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9963 - acc: 0.5053 - val_loss: 0.9886 - val_acc: 0.5080\n",
      "Epoch 12/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9891 - acc: 0.5101 - val_loss: 0.9825 - val_acc: 0.5113\n",
      "Epoch 13/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9815 - acc: 0.5144 - val_loss: 0.9739 - val_acc: 0.5167\n",
      "Epoch 14/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9724 - acc: 0.5233 - val_loss: 0.9639 - val_acc: 0.5180\n",
      "Epoch 15/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9649 - acc: 0.5241 - val_loss: 0.9567 - val_acc: 0.5373\n",
      "Epoch 16/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9545 - acc: 0.5322 - val_loss: 0.9473 - val_acc: 0.5447\n",
      "Epoch 17/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9454 - acc: 0.5342 - val_loss: 0.9415 - val_acc: 0.5540\n",
      "Epoch 18/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9403 - acc: 0.5444 - val_loss: 0.9286 - val_acc: 0.5473\n",
      "Epoch 19/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9324 - acc: 0.5459 - val_loss: 0.9228 - val_acc: 0.5593\n",
      "Epoch 20/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9252 - acc: 0.5530 - val_loss: 0.9155 - val_acc: 0.5660\n",
      "Epoch 21/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9201 - acc: 0.5659 - val_loss: 0.9686 - val_acc: 0.5367\n",
      "Epoch 22/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9115 - acc: 0.5722 - val_loss: 0.9196 - val_acc: 0.5733\n",
      "Epoch 23/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9071 - acc: 0.5736 - val_loss: 0.8997 - val_acc: 0.5867\n",
      "Epoch 24/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.9007 - acc: 0.5793 - val_loss: 0.9117 - val_acc: 0.5800\n",
      "Epoch 25/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8953 - acc: 0.5773 - val_loss: 0.8937 - val_acc: 0.5947\n",
      "Epoch 26/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8910 - acc: 0.5785 - val_loss: 0.8876 - val_acc: 0.5887\n",
      "Epoch 27/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8848 - acc: 0.5865 - val_loss: 0.8829 - val_acc: 0.5907\n",
      "Epoch 28/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8791 - acc: 0.5873 - val_loss: 0.8772 - val_acc: 0.6013\n",
      "Epoch 29/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8752 - acc: 0.5893 - val_loss: 0.8793 - val_acc: 0.5920\n",
      "Epoch 30/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8711 - acc: 0.5956 - val_loss: 0.8862 - val_acc: 0.5940\n",
      "Epoch 31/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8637 - acc: 0.5959 - val_loss: 0.8673 - val_acc: 0.5893\n",
      "Epoch 32/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8605 - acc: 0.6030 - val_loss: 0.8982 - val_acc: 0.5827\n",
      "Epoch 33/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8583 - acc: 0.6022 - val_loss: 0.8560 - val_acc: 0.6053\n",
      "Epoch 34/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8541 - acc: 0.6062 - val_loss: 0.8558 - val_acc: 0.6173\n",
      "Epoch 35/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8461 - acc: 0.6039 - val_loss: 0.8551 - val_acc: 0.5993\n",
      "Epoch 36/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8439 - acc: 0.6087 - val_loss: 0.8497 - val_acc: 0.6153\n",
      "Epoch 37/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8400 - acc: 0.6159 - val_loss: 0.8624 - val_acc: 0.6040\n",
      "Epoch 38/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8344 - acc: 0.6193 - val_loss: 0.8565 - val_acc: 0.6180\n",
      "Epoch 39/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8315 - acc: 0.6193 - val_loss: 0.8911 - val_acc: 0.5813\n",
      "Epoch 40/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8294 - acc: 0.6196 - val_loss: 0.8491 - val_acc: 0.6100\n",
      "Epoch 41/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8272 - acc: 0.6239 - val_loss: 0.8372 - val_acc: 0.6200\n",
      "Epoch 42/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8234 - acc: 0.6256 - val_loss: 0.9263 - val_acc: 0.5500\n",
      "Epoch 43/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8173 - acc: 0.6302 - val_loss: 0.8356 - val_acc: 0.6200\n",
      "Epoch 44/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8169 - acc: 0.6325 - val_loss: 0.8433 - val_acc: 0.6133\n",
      "Epoch 45/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8133 - acc: 0.6305 - val_loss: 0.9743 - val_acc: 0.5067\n",
      "Epoch 46/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8135 - acc: 0.6299 - val_loss: 0.8469 - val_acc: 0.6087\n",
      "Epoch 47/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8064 - acc: 0.6348 - val_loss: 0.8297 - val_acc: 0.6227\n",
      "Epoch 48/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8025 - acc: 0.6436 - val_loss: 0.8432 - val_acc: 0.6240\n",
      "Epoch 49/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.8035 - acc: 0.6416 - val_loss: 0.8550 - val_acc: 0.6133\n",
      "Epoch 50/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7979 - acc: 0.6425 - val_loss: 0.8303 - val_acc: 0.6247\n",
      "Epoch 51/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7950 - acc: 0.6408 - val_loss: 0.8321 - val_acc: 0.6200\n",
      "Epoch 52/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7891 - acc: 0.6436 - val_loss: 0.8344 - val_acc: 0.6213\n",
      "Epoch 53/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7900 - acc: 0.6502 - val_loss: 0.8205 - val_acc: 0.6273\n",
      "Epoch 54/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7874 - acc: 0.6505 - val_loss: 0.8228 - val_acc: 0.6307\n",
      "Epoch 55/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7805 - acc: 0.6522 - val_loss: 0.8482 - val_acc: 0.6147\n",
      "Epoch 56/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7839 - acc: 0.6522 - val_loss: 0.8392 - val_acc: 0.6173\n",
      "Epoch 57/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7784 - acc: 0.6559 - val_loss: 0.8295 - val_acc: 0.6153\n",
      "Epoch 58/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7755 - acc: 0.6565 - val_loss: 0.8312 - val_acc: 0.6193\n",
      "Epoch 59/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7724 - acc: 0.6616 - val_loss: 0.8693 - val_acc: 0.5933\n",
      "Epoch 60/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7714 - acc: 0.6576 - val_loss: 0.8119 - val_acc: 0.6367\n",
      "Epoch 61/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7674 - acc: 0.6553 - val_loss: 0.8131 - val_acc: 0.6433\n",
      "Epoch 62/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7678 - acc: 0.6616 - val_loss: 0.8366 - val_acc: 0.6147\n",
      "Epoch 63/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7627 - acc: 0.6659 - val_loss: 0.8160 - val_acc: 0.6380\n",
      "Epoch 64/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7580 - acc: 0.6673 - val_loss: 0.8306 - val_acc: 0.6227\n",
      "Epoch 65/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7559 - acc: 0.6699 - val_loss: 0.8214 - val_acc: 0.6313\n",
      "Epoch 66/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7563 - acc: 0.6625 - val_loss: 0.8135 - val_acc: 0.6440\n",
      "Epoch 67/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7500 - acc: 0.6736 - val_loss: 0.8324 - val_acc: 0.6220\n",
      "Epoch 68/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7504 - acc: 0.6636 - val_loss: 0.8823 - val_acc: 0.5880\n",
      "Epoch 69/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7480 - acc: 0.6702 - val_loss: 0.8242 - val_acc: 0.6387\n",
      "Epoch 70/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7448 - acc: 0.6708 - val_loss: 0.8028 - val_acc: 0.6360\n",
      "Epoch 71/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7416 - acc: 0.6742 - val_loss: 0.8264 - val_acc: 0.6307\n",
      "Epoch 72/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7362 - acc: 0.6773 - val_loss: 0.8220 - val_acc: 0.6347\n",
      "Epoch 73/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7432 - acc: 0.6719 - val_loss: 0.8607 - val_acc: 0.6047\n",
      "Epoch 74/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7362 - acc: 0.6728 - val_loss: 0.8095 - val_acc: 0.6340\n",
      "Epoch 75/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7319 - acc: 0.6788 - val_loss: 0.8335 - val_acc: 0.6247\n",
      "Epoch 76/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7324 - acc: 0.6813 - val_loss: 0.8016 - val_acc: 0.6460\n",
      "Epoch 77/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7271 - acc: 0.6793 - val_loss: 0.8016 - val_acc: 0.6360\n",
      "Epoch 78/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7265 - acc: 0.6879 - val_loss: 0.8060 - val_acc: 0.6467\n",
      "Epoch 79/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7213 - acc: 0.6865 - val_loss: 0.8083 - val_acc: 0.6400\n",
      "Epoch 80/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7192 - acc: 0.6945 - val_loss: 0.8387 - val_acc: 0.6200\n",
      "Epoch 81/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7193 - acc: 0.6856 - val_loss: 0.8094 - val_acc: 0.6393\n",
      "Epoch 82/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7142 - acc: 0.6939 - val_loss: 0.8198 - val_acc: 0.6320\n",
      "Epoch 83/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7169 - acc: 0.6919 - val_loss: 0.8067 - val_acc: 0.6500\n",
      "Epoch 84/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7091 - acc: 0.6885 - val_loss: 0.8564 - val_acc: 0.6247\n",
      "Epoch 85/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7087 - acc: 0.6951 - val_loss: 0.8049 - val_acc: 0.6367\n",
      "Epoch 86/300\n",
      "3499/3499 [==============================] - 4s 1ms/step - loss: 0.7037 - acc: 0.6996 - val_loss: 0.8357 - val_acc: 0.6247\n",
      "Train on 3497 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3497/3497 [==============================] - 18s 5ms/step - loss: 1.0467 - acc: 0.4984 - val_loss: 1.0378 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0380 - acc: 0.5004 - val_loss: 1.0356 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0352 - acc: 0.5004 - val_loss: 1.0334 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0324 - acc: 0.5004 - val_loss: 1.0309 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0294 - acc: 0.5004 - val_loss: 1.0285 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0266 - acc: 0.5004 - val_loss: 1.0262 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0236 - acc: 0.5004 - val_loss: 1.0237 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0209 - acc: 0.5004 - val_loss: 1.0211 - val_acc: 0.5007\n",
      "Epoch 9/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0175 - acc: 0.5004 - val_loss: 1.0186 - val_acc: 0.5007\n",
      "Epoch 10/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0138 - acc: 0.5004 - val_loss: 1.0165 - val_acc: 0.5007\n",
      "Epoch 11/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0108 - acc: 0.5004 - val_loss: 1.0132 - val_acc: 0.5020\n",
      "Epoch 12/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0067 - acc: 0.5016 - val_loss: 1.0091 - val_acc: 0.5033\n",
      "Epoch 13/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 1.0027 - acc: 0.5050 - val_loss: 1.0054 - val_acc: 0.5053\n",
      "Epoch 14/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9987 - acc: 0.5076 - val_loss: 1.0005 - val_acc: 0.5053\n",
      "Epoch 15/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9935 - acc: 0.5116 - val_loss: 0.9953 - val_acc: 0.5087\n",
      "Epoch 16/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9870 - acc: 0.5156 - val_loss: 0.9908 - val_acc: 0.5127\n",
      "Epoch 17/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9819 - acc: 0.5202 - val_loss: 0.9843 - val_acc: 0.5140\n",
      "Epoch 18/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9749 - acc: 0.5247 - val_loss: 0.9867 - val_acc: 0.5427\n",
      "Epoch 19/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9688 - acc: 0.5347 - val_loss: 0.9737 - val_acc: 0.5440\n",
      "Epoch 20/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9636 - acc: 0.5327 - val_loss: 0.9630 - val_acc: 0.5273\n",
      "Epoch 21/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9550 - acc: 0.5433 - val_loss: 0.9549 - val_acc: 0.5380\n",
      "Epoch 22/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9485 - acc: 0.5462 - val_loss: 0.9558 - val_acc: 0.5400\n",
      "Epoch 23/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9404 - acc: 0.5530 - val_loss: 0.9750 - val_acc: 0.5360\n",
      "Epoch 24/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9336 - acc: 0.5631 - val_loss: 0.9348 - val_acc: 0.5600\n",
      "Epoch 25/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9315 - acc: 0.5665 - val_loss: 0.9727 - val_acc: 0.5500\n",
      "Epoch 26/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9254 - acc: 0.5699 - val_loss: 0.9385 - val_acc: 0.5527\n",
      "Epoch 27/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9135 - acc: 0.5728 - val_loss: 0.9157 - val_acc: 0.5587\n",
      "Epoch 28/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9035 - acc: 0.5891 - val_loss: 0.9099 - val_acc: 0.5593\n",
      "Epoch 29/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.9001 - acc: 0.5768 - val_loss: 0.9269 - val_acc: 0.5747\n",
      "Epoch 30/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8904 - acc: 0.5914 - val_loss: 0.8945 - val_acc: 0.5727\n",
      "Epoch 31/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8841 - acc: 0.6011 - val_loss: 0.9179 - val_acc: 0.5740\n",
      "Epoch 32/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8784 - acc: 0.6011 - val_loss: 0.9395 - val_acc: 0.5567\n",
      "Epoch 33/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8699 - acc: 0.6048 - val_loss: 0.9233 - val_acc: 0.5613\n",
      "Epoch 34/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8691 - acc: 0.6002 - val_loss: 0.8838 - val_acc: 0.5820\n",
      "Epoch 35/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8678 - acc: 0.6077 - val_loss: 0.8839 - val_acc: 0.5973\n",
      "Epoch 36/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8590 - acc: 0.6057 - val_loss: 0.8844 - val_acc: 0.5893\n",
      "Epoch 37/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8549 - acc: 0.6108 - val_loss: 0.8810 - val_acc: 0.5867\n",
      "Epoch 38/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8491 - acc: 0.6140 - val_loss: 0.8700 - val_acc: 0.5867\n",
      "Epoch 39/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8472 - acc: 0.6122 - val_loss: 0.8792 - val_acc: 0.5920\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8441 - acc: 0.6100 - val_loss: 0.8850 - val_acc: 0.5767\n",
      "Epoch 41/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8382 - acc: 0.6197 - val_loss: 0.8579 - val_acc: 0.5993\n",
      "Epoch 42/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8337 - acc: 0.6277 - val_loss: 0.8879 - val_acc: 0.5800\n",
      "Epoch 43/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8294 - acc: 0.6194 - val_loss: 0.8583 - val_acc: 0.5973\n",
      "Epoch 44/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8261 - acc: 0.6191 - val_loss: 0.8490 - val_acc: 0.5947\n",
      "Epoch 45/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8261 - acc: 0.6237 - val_loss: 0.8574 - val_acc: 0.5860\n",
      "Epoch 46/300\n",
      "3497/3497 [==============================] - 9s 2ms/step - loss: 0.8219 - acc: 0.6225 - val_loss: 0.8511 - val_acc: 0.5900\n",
      "Epoch 47/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8151 - acc: 0.6317 - val_loss: 0.8495 - val_acc: 0.5853\n",
      "Epoch 48/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8135 - acc: 0.6331 - val_loss: 0.8853 - val_acc: 0.5720\n",
      "Epoch 49/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8113 - acc: 0.6340 - val_loss: 0.8382 - val_acc: 0.6053\n",
      "Epoch 50/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8063 - acc: 0.6360 - val_loss: 0.8554 - val_acc: 0.6040\n",
      "Epoch 51/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.8053 - acc: 0.6414 - val_loss: 0.8554 - val_acc: 0.6067\n",
      "Epoch 52/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7998 - acc: 0.6354 - val_loss: 0.8375 - val_acc: 0.6040\n",
      "Epoch 53/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7987 - acc: 0.6354 - val_loss: 0.8324 - val_acc: 0.5987\n",
      "Epoch 54/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7939 - acc: 0.6437 - val_loss: 0.8388 - val_acc: 0.6067\n",
      "Epoch 55/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7909 - acc: 0.6448 - val_loss: 0.8712 - val_acc: 0.5873\n",
      "Epoch 56/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7891 - acc: 0.6440 - val_loss: 0.8431 - val_acc: 0.6060\n",
      "Epoch 57/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7872 - acc: 0.6454 - val_loss: 0.8267 - val_acc: 0.6047\n",
      "Epoch 58/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7838 - acc: 0.6397 - val_loss: 0.8437 - val_acc: 0.6073\n",
      "Epoch 59/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7819 - acc: 0.6471 - val_loss: 0.8540 - val_acc: 0.6107\n",
      "Epoch 60/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7777 - acc: 0.6503 - val_loss: 0.8404 - val_acc: 0.6033\n",
      "Epoch 61/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7748 - acc: 0.6551 - val_loss: 0.8193 - val_acc: 0.6167\n",
      "Epoch 62/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7745 - acc: 0.6520 - val_loss: 0.8185 - val_acc: 0.6133\n",
      "Epoch 63/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7737 - acc: 0.6474 - val_loss: 0.8893 - val_acc: 0.5967\n",
      "Epoch 64/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7710 - acc: 0.6557 - val_loss: 0.8243 - val_acc: 0.6100\n",
      "Epoch 65/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7691 - acc: 0.6557 - val_loss: 0.8528 - val_acc: 0.6107\n",
      "Epoch 66/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7650 - acc: 0.6600 - val_loss: 0.8371 - val_acc: 0.6120\n",
      "Epoch 67/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7608 - acc: 0.6600 - val_loss: 0.8222 - val_acc: 0.6087\n",
      "Epoch 68/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7609 - acc: 0.6586 - val_loss: 0.8130 - val_acc: 0.6193\n",
      "Epoch 69/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7588 - acc: 0.6600 - val_loss: 0.8131 - val_acc: 0.6220\n",
      "Epoch 70/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7544 - acc: 0.6680 - val_loss: 0.8424 - val_acc: 0.5980\n",
      "Epoch 71/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7578 - acc: 0.6591 - val_loss: 0.8457 - val_acc: 0.6067\n",
      "Epoch 72/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7521 - acc: 0.6683 - val_loss: 0.8434 - val_acc: 0.6147\n",
      "Epoch 73/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7519 - acc: 0.6657 - val_loss: 0.8240 - val_acc: 0.6107\n",
      "Epoch 74/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7475 - acc: 0.6663 - val_loss: 0.8151 - val_acc: 0.6180\n",
      "Epoch 75/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7419 - acc: 0.6729 - val_loss: 0.8426 - val_acc: 0.6060\n",
      "Epoch 76/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7415 - acc: 0.6749 - val_loss: 0.8355 - val_acc: 0.6227\n",
      "Epoch 77/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7356 - acc: 0.6789 - val_loss: 0.8294 - val_acc: 0.6280\n",
      "Epoch 78/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7375 - acc: 0.6714 - val_loss: 0.8083 - val_acc: 0.6253\n",
      "Epoch 79/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7316 - acc: 0.6752 - val_loss: 0.8115 - val_acc: 0.6273\n",
      "Epoch 80/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7294 - acc: 0.6803 - val_loss: 0.8342 - val_acc: 0.6287\n",
      "Epoch 81/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7305 - acc: 0.6829 - val_loss: 0.8428 - val_acc: 0.6153\n",
      "Epoch 82/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7285 - acc: 0.6814 - val_loss: 0.8115 - val_acc: 0.6333\n",
      "Epoch 83/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7248 - acc: 0.6843 - val_loss: 0.8713 - val_acc: 0.5980\n",
      "Epoch 84/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7218 - acc: 0.6814 - val_loss: 0.8464 - val_acc: 0.6187\n",
      "Epoch 85/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7248 - acc: 0.6794 - val_loss: 0.8685 - val_acc: 0.6107\n",
      "Epoch 86/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7213 - acc: 0.6843 - val_loss: 0.8297 - val_acc: 0.6227\n",
      "Epoch 87/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7199 - acc: 0.6877 - val_loss: 0.8954 - val_acc: 0.5693\n",
      "Epoch 88/300\n",
      "3497/3497 [==============================] - 9s 3ms/step - loss: 0.7176 - acc: 0.6829 - val_loss: 0.8220 - val_acc: 0.6273\n",
      "Train on 3498 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3498/3498 [==============================] - 17s 5ms/step - loss: 1.0478 - acc: 0.4983 - val_loss: 1.0377 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0364 - acc: 0.5003 - val_loss: 1.0345 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 1.0329 - acc: 0.5003 - val_loss: 1.0313 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0287 - acc: 0.5003 - val_loss: 1.0286 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 1.0257 - acc: 0.5003 - val_loss: 1.0252 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      "3498/3498 [==============================] - 9s 3ms/step - loss: 1.0215 - acc: 0.5003 - val_loss: 1.0215 - val_acc: 0.5007\n",
      "Epoch 7/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0170 - acc: 0.5003 - val_loss: 1.0175 - val_acc: 0.5007\n",
      "Epoch 8/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0129 - acc: 0.5009 - val_loss: 1.0135 - val_acc: 0.5013\n",
      "Epoch 9/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 1.0077 - acc: 0.5020 - val_loss: 1.0103 - val_acc: 0.5047\n",
      "Epoch 10/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 1.0029 - acc: 0.5054 - val_loss: 1.0059 - val_acc: 0.5060\n",
      "Epoch 11/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.9980 - acc: 0.5074 - val_loss: 0.9986 - val_acc: 0.5073\n",
      "Epoch 12/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9925 - acc: 0.5100 - val_loss: 1.0029 - val_acc: 0.5147\n",
      "Epoch 13/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9867 - acc: 0.5169 - val_loss: 0.9927 - val_acc: 0.5167\n",
      "Epoch 14/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.9806 - acc: 0.5163 - val_loss: 0.9786 - val_acc: 0.5167\n",
      "Epoch 15/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.9728 - acc: 0.5229 - val_loss: 0.9774 - val_acc: 0.5227\n",
      "Epoch 16/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9694 - acc: 0.5283 - val_loss: 0.9647 - val_acc: 0.5267\n",
      "Epoch 17/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9627 - acc: 0.5389 - val_loss: 0.9562 - val_acc: 0.5313\n",
      "Epoch 18/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9573 - acc: 0.5369 - val_loss: 0.9549 - val_acc: 0.5793\n",
      "Epoch 19/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9513 - acc: 0.5503 - val_loss: 0.9449 - val_acc: 0.5487\n",
      "Epoch 20/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9415 - acc: 0.5466 - val_loss: 0.9370 - val_acc: 0.5500\n",
      "Epoch 21/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9342 - acc: 0.5495 - val_loss: 0.9287 - val_acc: 0.5740\n",
      "Epoch 22/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9273 - acc: 0.5563 - val_loss: 0.9245 - val_acc: 0.5660\n",
      "Epoch 23/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9175 - acc: 0.5718 - val_loss: 0.9254 - val_acc: 0.5747\n",
      "Epoch 24/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9110 - acc: 0.5698 - val_loss: 0.9310 - val_acc: 0.5673\n",
      "Epoch 25/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.9032 - acc: 0.5780 - val_loss: 0.9310 - val_acc: 0.5573\n",
      "Epoch 26/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8987 - acc: 0.5726 - val_loss: 0.9029 - val_acc: 0.5900\n",
      "Epoch 27/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8925 - acc: 0.5812 - val_loss: 0.8915 - val_acc: 0.5893\n",
      "Epoch 28/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8879 - acc: 0.5832 - val_loss: 0.9168 - val_acc: 0.5587\n",
      "Epoch 29/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8815 - acc: 0.5778 - val_loss: 0.8867 - val_acc: 0.5867\n",
      "Epoch 30/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8765 - acc: 0.5883 - val_loss: 0.8819 - val_acc: 0.5940\n",
      "Epoch 31/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8721 - acc: 0.5955 - val_loss: 0.8969 - val_acc: 0.5840\n",
      "Epoch 32/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8714 - acc: 0.5935 - val_loss: 0.8962 - val_acc: 0.5853\n",
      "Epoch 33/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8670 - acc: 0.5929 - val_loss: 0.8727 - val_acc: 0.6027\n",
      "Epoch 34/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8606 - acc: 0.5989 - val_loss: 0.9147 - val_acc: 0.5567\n",
      "Epoch 35/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8570 - acc: 0.6015 - val_loss: 0.8989 - val_acc: 0.5600\n",
      "Epoch 36/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8542 - acc: 0.5998 - val_loss: 0.8782 - val_acc: 0.5973\n",
      "Epoch 37/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8483 - acc: 0.6081 - val_loss: 0.8626 - val_acc: 0.6040\n",
      "Epoch 38/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8451 - acc: 0.6118 - val_loss: 0.8644 - val_acc: 0.5900\n",
      "Epoch 39/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8424 - acc: 0.6118 - val_loss: 0.8620 - val_acc: 0.6007\n",
      "Epoch 40/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.8370 - acc: 0.6132 - val_loss: 0.8847 - val_acc: 0.5660\n",
      "Epoch 41/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8339 - acc: 0.6144 - val_loss: 0.8596 - val_acc: 0.6007\n",
      "Epoch 42/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.8316 - acc: 0.6115 - val_loss: 0.8558 - val_acc: 0.6120\n",
      "Epoch 43/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8297 - acc: 0.6121 - val_loss: 0.8526 - val_acc: 0.5953\n",
      "Epoch 44/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8229 - acc: 0.6189 - val_loss: 0.8705 - val_acc: 0.5900\n",
      "Epoch 45/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8211 - acc: 0.6252 - val_loss: 0.8578 - val_acc: 0.6000\n",
      "Epoch 46/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.8194 - acc: 0.6252 - val_loss: 0.8470 - val_acc: 0.6133\n",
      "Epoch 47/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8145 - acc: 0.6186 - val_loss: 0.8449 - val_acc: 0.6147\n",
      "Epoch 48/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8110 - acc: 0.6252 - val_loss: 0.8582 - val_acc: 0.5920\n",
      "Epoch 49/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8096 - acc: 0.6318 - val_loss: 0.8826 - val_acc: 0.5787\n",
      "Epoch 50/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8067 - acc: 0.6326 - val_loss: 0.8637 - val_acc: 0.5873\n",
      "Epoch 51/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.8044 - acc: 0.6264 - val_loss: 0.8617 - val_acc: 0.5953\n",
      "Epoch 52/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7982 - acc: 0.6312 - val_loss: 0.8423 - val_acc: 0.6127\n",
      "Epoch 53/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7956 - acc: 0.6375 - val_loss: 0.8470 - val_acc: 0.5913\n",
      "Epoch 54/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7963 - acc: 0.6384 - val_loss: 0.8478 - val_acc: 0.5993\n",
      "Epoch 55/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7918 - acc: 0.6415 - val_loss: 0.9006 - val_acc: 0.5853\n",
      "Epoch 56/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7897 - acc: 0.6381 - val_loss: 0.8428 - val_acc: 0.6093\n",
      "Epoch 57/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7875 - acc: 0.6412 - val_loss: 0.8714 - val_acc: 0.5787\n",
      "Epoch 58/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7837 - acc: 0.6387 - val_loss: 0.8573 - val_acc: 0.5933\n",
      "Epoch 59/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7816 - acc: 0.6409 - val_loss: 0.8621 - val_acc: 0.5953\n",
      "Epoch 60/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7790 - acc: 0.6424 - val_loss: 0.8375 - val_acc: 0.6060\n",
      "Epoch 61/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7786 - acc: 0.6529 - val_loss: 0.8494 - val_acc: 0.6100\n",
      "Epoch 62/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7787 - acc: 0.6461 - val_loss: 0.8247 - val_acc: 0.6180\n",
      "Epoch 63/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7712 - acc: 0.6552 - val_loss: 0.8460 - val_acc: 0.5967\n",
      "Epoch 64/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7730 - acc: 0.6532 - val_loss: 0.8483 - val_acc: 0.6040\n",
      "Epoch 65/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7703 - acc: 0.6495 - val_loss: 0.8253 - val_acc: 0.6200\n",
      "Epoch 66/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7609 - acc: 0.6607 - val_loss: 0.8399 - val_acc: 0.6047\n",
      "Epoch 67/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7633 - acc: 0.6498 - val_loss: 0.8591 - val_acc: 0.6047\n",
      "Epoch 68/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7625 - acc: 0.6552 - val_loss: 0.8370 - val_acc: 0.6120\n",
      "Epoch 69/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7576 - acc: 0.6635 - val_loss: 0.8326 - val_acc: 0.6113\n",
      "Epoch 70/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7569 - acc: 0.6564 - val_loss: 0.8345 - val_acc: 0.6233\n",
      "Epoch 71/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7549 - acc: 0.6609 - val_loss: 0.8291 - val_acc: 0.6087\n",
      "Epoch 72/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7494 - acc: 0.6670 - val_loss: 0.8215 - val_acc: 0.6120\n",
      "Epoch 73/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7476 - acc: 0.6624 - val_loss: 0.8334 - val_acc: 0.6207\n",
      "Epoch 74/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.7492 - acc: 0.6664 - val_loss: 0.8203 - val_acc: 0.6173\n",
      "Epoch 75/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7437 - acc: 0.6664 - val_loss: 0.8347 - val_acc: 0.6140\n",
      "Epoch 76/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7411 - acc: 0.6712 - val_loss: 0.8181 - val_acc: 0.6140\n",
      "Epoch 77/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7431 - acc: 0.6632 - val_loss: 0.8255 - val_acc: 0.6093\n",
      "Epoch 78/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7400 - acc: 0.6744 - val_loss: 0.8632 - val_acc: 0.5860\n",
      "Epoch 79/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7413 - acc: 0.6707 - val_loss: 0.8414 - val_acc: 0.6160\n",
      "Epoch 80/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.7345 - acc: 0.6821 - val_loss: 0.8343 - val_acc: 0.6080\n",
      "Epoch 81/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7346 - acc: 0.6741 - val_loss: 0.8431 - val_acc: 0.6140\n",
      "Epoch 82/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7339 - acc: 0.6704 - val_loss: 0.8336 - val_acc: 0.6047\n",
      "Epoch 83/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7291 - acc: 0.6787 - val_loss: 0.8259 - val_acc: 0.6140\n",
      "Epoch 84/300\n",
      "3498/3498 [==============================] - 9s 2ms/step - loss: 0.7250 - acc: 0.6798 - val_loss: 0.8251 - val_acc: 0.6267\n",
      "Epoch 85/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7257 - acc: 0.6792 - val_loss: 0.8191 - val_acc: 0.6220\n",
      "Epoch 86/300\n",
      "3498/3498 [==============================] - 8s 2ms/step - loss: 0.7196 - acc: 0.6850 - val_loss: 0.8245 - val_acc: 0.6227\n",
      "Train on 3499 samples, validate on 1500 samples\n",
      "Epoch 1/300\n",
      "3499/3499 [==============================] - 18s 5ms/step - loss: 1.0478 - acc: 0.4987 - val_loss: 1.0373 - val_acc: 0.5007\n",
      "Epoch 2/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0369 - acc: 0.5004 - val_loss: 1.0352 - val_acc: 0.5007\n",
      "Epoch 3/300\n",
      "3499/3499 [==============================] - 9s 2ms/step - loss: 1.0336 - acc: 0.5004 - val_loss: 1.0326 - val_acc: 0.5007\n",
      "Epoch 4/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0304 - acc: 0.5004 - val_loss: 1.0288 - val_acc: 0.5007\n",
      "Epoch 5/300\n",
      "3499/3499 [==============================] - 9s 3ms/step - loss: 1.0265 - acc: 0.5004 - val_loss: 1.0273 - val_acc: 0.5007\n",
      "Epoch 6/300\n",
      " 704/3499 [=====>........................] - ETA: 6s - loss: 1.0269 - acc: 0.4986"
     ]
    }
   ],
   "source": [
    "pad_sizes = [5, 10, half_average_dataset(dong_train), 15, -1]\n",
    "tdlstm_padsize_results = {}\n",
    "for pad_size in pad_sizes:\n",
    "    model = TDLSTM(stanford, sswe, lower=True, pad_size=pad_size)\n",
    "    fit_params = {'reproducible' : True, 'validation_size' : 0.3, \n",
    "                  'patience' : 10, 'epochs' : 300, 'verbose' : 1, \n",
    "                  'org_initialisers' : True}\n",
    "    scores, preds = model.cross_val(dong_train.data_dict(), dong_train.sentiment_data(), \n",
    "                                    accuracy_score, kfold_reproducible=True, **fit_params)\n",
    "    tdlstm_padsize_results[pad_size] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdlstm_padsize_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embeddings = [sswe, glove_50, glove_100, glove_200]\n",
    "for word_embedding in word_embeddinga:\n",
    "    model = LSTM(stanford, word_embedding, lower=True, pad_size=-1)\n",
    "    model.fit(dong_train.data_dict(), dong_train.sentiment_data(), reproducible=True,\n",
    "              validation_size=0.3, patience=10, epochs=300, verbose=1, org_initialisers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General results folder for the method\n",
    "result_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results', 'TDLstm'))\n",
    "# Results folder for trying different pad sizes on different embeddings on different \n",
    "# datasets. Where the method is kept the same which is TCLSTM method\n",
    "pad_size_results_folder = os.path.join(result_folder, 'TCLstm Pad Sizes')\n",
    "os.makedirs(pad_size_results_folder, exist_ok=True)\n",
    "\n",
    "def half_average_dataset(dataset):\n",
    "    '''\n",
    "    :param dataset: A training dataset\n",
    "    :type dataset: TargetCollection\n",
    "    :returns: Half the average sentence length of the given dataset\n",
    "    :rtype: int\n",
    "    '''\n",
    "    sentence_lengths = [len(data['text'].split()) for data in dataset.data()]\n",
    "    return math.ceil(sum(sentence_lengths) / len(sentence_lengths) / 2)\n",
    "\n",
    "def pad_size_prediction(embedding_path, pad_size, reproducible, train_data, \n",
    "                        test_data, result_path, index_column, tokenizer=ark_twokenize):\n",
    "    '''\n",
    "    Works out the preiction of \n",
    "    '''\n",
    "\n",
    "    embedding = None\n",
    "    with open(embedding_path, 'rb') as embedding_file:\n",
    "        embedding = pickle.load(embedding_file, encoding='utf-8')\n",
    "    \n",
    "    embedding_name = '{}'.format(embedding)\n",
    "    saved_data = notebook_helper.get_pandas_data(result_path, pad_size, \n",
    "                                                 embedding_name, index_column)\n",
    "    if saved_data is not None:\n",
    "        return saved_data\n",
    "    model = TCLSTM(tokenizer, embedding, lower=True, pad_size=pad_size)\n",
    "    model.fit(train_data.data_dict(), train_data.sentiment_data(), reproducible=True,\n",
    "              validation_size=0.3, patience=10, epochs=300, verbose=1,\n",
    "              org_initialisers=True)\n",
    "    predictions = model.predict(test_data.data_dict())\n",
    "    score = TCLSTM.score(test_data.sentiment_data(), predictions, accuracy_score)\n",
    "    notebook_helper.save_pandas_data(result_path, pad_size, \n",
    "                                     embedding_name, index_column, score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding pad results done sswe\n",
      "Embedding pad results done glove twitter 50d\n",
      "Embedding pad results done glove twitter 100d\n",
      "Embedding pad results done glove twitter 200d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>15</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sswe</th>\n",
       "      <td>0.606936</td>\n",
       "      <td>0.628613</td>\n",
       "      <td>0.614162</td>\n",
       "      <td>0.647399</td>\n",
       "      <td>0.660405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove twitter 50d</th>\n",
       "      <td>0.644509</td>\n",
       "      <td>0.645954</td>\n",
       "      <td>0.667630</td>\n",
       "      <td>0.654624</td>\n",
       "      <td>0.609827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove twitter 100d</th>\n",
       "      <td>0.663295</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>0.661850</td>\n",
       "      <td>0.674855</td>\n",
       "      <td>0.624277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glove twitter 200d</th>\n",
       "      <td>0.643064</td>\n",
       "      <td>0.673410</td>\n",
       "      <td>0.669075</td>\n",
       "      <td>0.669075</td>\n",
       "      <td>0.635838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           5        10         9        15        -1\n",
       "embeddings                                                          \n",
       "sswe                0.606936  0.628613  0.614162  0.647399  0.660405\n",
       "glove twitter 50d   0.644509  0.645954  0.667630  0.654624  0.609827\n",
       "glove twitter 100d  0.663295  0.670520  0.661850  0.674855  0.624277\n",
       "glove twitter 200d  0.643064  0.673410  0.669075  0.669075  0.635838"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = [sswe, glove_50, glove_100, glove_200]\n",
    "embedding_names = ['{}'.format(embedding) for embedding in embeddings]\n",
    "pad_sizes = [5, 10, half_average_dataset(dong_train), 15, -1]\n",
    "reproducible = [True]\n",
    "train_data = [dong_train]\n",
    "test_data = [dong_test]\n",
    "pad_results = []\n",
    "\n",
    "index_column = 'embeddings'\n",
    "dong_pad_size_res_file = os.path.join(pad_size_results_folder, 'Dong Twitter.csv')\n",
    "notebook_helper.create_pandas_file(dong_pad_size_res_file, pad_sizes, index_column, \n",
    "                                   embedding_names, re_write=False)\n",
    "for embedding in embeddings:\n",
    "    with tempfile.NamedTemporaryFile() as embedding_file:\n",
    "        embedding_path = embedding_file.name\n",
    "        pickle.dump(embedding, embedding_file)\n",
    "        pred_params = list(itertools.product([embedding_path], pad_sizes, reproducible, \n",
    "                                             train_data, test_data, \n",
    "                                             [dong_pad_size_res_file], \n",
    "                                             [index_column]))\n",
    "        for pred_param in pred_params: \n",
    "            pad_size_prediction(*pred_param)\n",
    "        #with Pool(3) as pool:\n",
    "        #    pool.starmap(pad_size_prediction, pred_params)\n",
    "        print('Embedding pad results done {}'.format(embedding))\n",
    "dong_pad_df_results = pd.read_csv(open(dong_pad_size_res_file, 'r'))\n",
    "dong_pad_df_results = dong_pad_df_results.set_index('embeddings')\n",
    "dong_pad_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2521 samples, validate on 1081 samples\n",
      "Epoch 1/300\n",
      "2521/2521 [==============================] - 104s 41ms/step - loss: 0.9795 - acc: 0.5982 - val_loss: 0.9552 - val_acc: 0.6004\n",
      "Epoch 2/300\n",
      "2521/2521 [==============================] - 99s 39ms/step - loss: 0.9465 - acc: 0.6010 - val_loss: 0.9414 - val_acc: 0.6004\n",
      "Epoch 3/300\n",
      "2521/2521 [==============================] - 94s 37ms/step - loss: 0.9336 - acc: 0.6010 - val_loss: 0.9298 - val_acc: 0.6004\n",
      "Epoch 4/300\n",
      "2521/2521 [==============================] - 96s 38ms/step - loss: 0.9223 - acc: 0.6013 - val_loss: 0.9203 - val_acc: 0.6004\n",
      "Epoch 5/300\n",
      "2521/2521 [==============================] - 96s 38ms/step - loss: 0.9122 - acc: 0.6017 - val_loss: 0.9117 - val_acc: 0.6004\n",
      "Epoch 6/300\n",
      "2521/2521 [==============================] - 96s 38ms/step - loss: 0.9035 - acc: 0.6045 - val_loss: 0.9031 - val_acc: 0.6041\n",
      "Epoch 7/300\n",
      "2521/2521 [==============================] - 95s 37ms/step - loss: 0.8947 - acc: 0.6109 - val_loss: 0.8962 - val_acc: 0.6041\n",
      "Epoch 8/300\n",
      "2521/2521 [==============================] - 95s 38ms/step - loss: 0.8862 - acc: 0.6129 - val_loss: 0.8874 - val_acc: 0.6189\n",
      "Epoch 9/300\n",
      "2521/2521 [==============================] - 95s 38ms/step - loss: 0.8787 - acc: 0.6232 - val_loss: 0.8805 - val_acc: 0.6198\n",
      "Epoch 10/300\n",
      "2521/2521 [==============================] - 95s 38ms/step - loss: 0.8714 - acc: 0.6275 - val_loss: 0.8741 - val_acc: 0.6207\n",
      "Epoch 11/300\n",
      "2521/2521 [==============================] - 94s 37ms/step - loss: 0.8635 - acc: 0.6307 - val_loss: 0.8658 - val_acc: 0.6189\n",
      "Epoch 12/300\n",
      "2521/2521 [==============================] - 95s 38ms/step - loss: 0.8561 - acc: 0.6370 - val_loss: 0.8599 - val_acc: 0.6207\n",
      "Epoch 13/300\n",
      "2521/2521 [==============================] - 92s 36ms/step - loss: 0.8476 - acc: 0.6398 - val_loss: 0.8537 - val_acc: 0.6189\n",
      "Epoch 14/300\n",
      "2521/2521 [==============================] - 92s 36ms/step - loss: 0.8396 - acc: 0.6466 - val_loss: 0.8454 - val_acc: 0.6300\n",
      "Epoch 15/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.8318 - acc: 0.6482 - val_loss: 0.8389 - val_acc: 0.6420\n",
      "Epoch 16/300\n",
      "2521/2521 [==============================] - 92s 36ms/step - loss: 0.8229 - acc: 0.6497 - val_loss: 0.8344 - val_acc: 0.6466\n",
      "Epoch 17/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.8139 - acc: 0.6537 - val_loss: 0.8263 - val_acc: 0.6475\n",
      "Epoch 18/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.8058 - acc: 0.6549 - val_loss: 0.8207 - val_acc: 0.6457\n",
      "Epoch 19/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7958 - acc: 0.6640 - val_loss: 0.8209 - val_acc: 0.6411\n",
      "Epoch 20/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.7873 - acc: 0.6628 - val_loss: 0.8124 - val_acc: 0.6531\n",
      "Epoch 21/300\n",
      "2521/2521 [==============================] - 92s 36ms/step - loss: 0.7785 - acc: 0.6767 - val_loss: 0.8052 - val_acc: 0.6568\n",
      "Epoch 22/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.7705 - acc: 0.6735 - val_loss: 0.8028 - val_acc: 0.6549\n",
      "Epoch 23/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7635 - acc: 0.6779 - val_loss: 0.8121 - val_acc: 0.6448\n",
      "Epoch 24/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7553 - acc: 0.6827 - val_loss: 0.8043 - val_acc: 0.6503\n",
      "Epoch 25/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.7484 - acc: 0.6942 - val_loss: 0.7976 - val_acc: 0.6596\n",
      "Epoch 26/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7431 - acc: 0.6886 - val_loss: 0.7986 - val_acc: 0.6586\n",
      "Epoch 27/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7345 - acc: 0.6981 - val_loss: 0.8030 - val_acc: 0.6457\n",
      "Epoch 28/300\n",
      "2521/2521 [==============================] - 87s 34ms/step - loss: 0.7304 - acc: 0.6997 - val_loss: 0.7981 - val_acc: 0.6577\n",
      "Epoch 29/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.7263 - acc: 0.6993 - val_loss: 0.7931 - val_acc: 0.6531\n",
      "Epoch 30/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7195 - acc: 0.7009 - val_loss: 0.8080 - val_acc: 0.6577\n",
      "Epoch 31/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7158 - acc: 0.6969 - val_loss: 0.8088 - val_acc: 0.6531\n",
      "Epoch 32/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7082 - acc: 0.6969 - val_loss: 0.7985 - val_acc: 0.6559\n",
      "Epoch 33/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.7039 - acc: 0.7053 - val_loss: 0.7953 - val_acc: 0.6577\n",
      "Epoch 34/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.6983 - acc: 0.7033 - val_loss: 0.7934 - val_acc: 0.6596\n",
      "Epoch 35/300\n",
      "2521/2521 [==============================] - 91s 36ms/step - loss: 0.6933 - acc: 0.7132 - val_loss: 0.7875 - val_acc: 0.6596\n",
      "Epoch 36/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.6902 - acc: 0.7112 - val_loss: 0.7887 - val_acc: 0.6577\n",
      "Epoch 37/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.6823 - acc: 0.7152 - val_loss: 0.7912 - val_acc: 0.6614\n",
      "Epoch 38/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.6775 - acc: 0.7160 - val_loss: 0.8208 - val_acc: 0.6420\n",
      "Epoch 39/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.6809 - acc: 0.7108 - val_loss: 0.7883 - val_acc: 0.6679\n",
      "Epoch 40/300\n",
      "2521/2521 [==============================] - 87s 34ms/step - loss: 0.6660 - acc: 0.7255 - val_loss: 0.7988 - val_acc: 0.6688\n",
      "Epoch 41/300\n",
      "2521/2521 [==============================] - 86s 34ms/step - loss: 0.6687 - acc: 0.7219 - val_loss: 0.7987 - val_acc: 0.6596\n",
      "Epoch 42/300\n",
      "2521/2521 [==============================] - 90s 36ms/step - loss: 0.6593 - acc: 0.7251 - val_loss: 0.7958 - val_acc: 0.6596\n",
      "Epoch 43/300\n",
      "2521/2521 [==============================] - 89s 35ms/step - loss: 0.6509 - acc: 0.7315 - val_loss: 0.8010 - val_acc: 0.6623\n",
      "Epoch 44/300\n",
      "2521/2521 [==============================] - 88s 35ms/step - loss: 0.6476 - acc: 0.7291 - val_loss: 0.9329 - val_acc: 0.5652\n",
      "Epoch 45/300\n",
      "2521/2521 [==============================] - 88s 35ms/step - loss: 0.6427 - acc: 0.7346 - val_loss: 0.8004 - val_acc: 0.6642\n",
      "Train on 2521 samples, validate on 1081 samples\n",
      "Epoch 1/300\n",
      "2521/2521 [==============================] - 320s 127ms/step - loss: 0.9802 - acc: 0.5974 - val_loss: 0.9561 - val_acc: 0.6004\n",
      "Epoch 2/300\n",
      "2521/2521 [==============================] - 318s 126ms/step - loss: 0.9478 - acc: 0.6010 - val_loss: 0.9425 - val_acc: 0.6004\n",
      "Epoch 3/300\n",
      "2521/2521 [==============================] - 307s 122ms/step - loss: 0.9357 - acc: 0.6010 - val_loss: 0.9310 - val_acc: 0.6004\n",
      "Epoch 4/300\n",
      "2521/2521 [==============================] - 305s 121ms/step - loss: 0.9250 - acc: 0.6010 - val_loss: 0.9216 - val_acc: 0.6004\n",
      "Epoch 5/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.9153 - acc: 0.6010 - val_loss: 0.9131 - val_acc: 0.6004\n",
      "Epoch 6/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.9070 - acc: 0.6010 - val_loss: 0.9044 - val_acc: 0.6013\n",
      "Epoch 7/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.8985 - acc: 0.6081 - val_loss: 0.8976 - val_acc: 0.6022\n",
      "Epoch 8/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.8901 - acc: 0.6077 - val_loss: 0.8889 - val_acc: 0.6161\n",
      "Epoch 9/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8827 - acc: 0.6208 - val_loss: 0.8821 - val_acc: 0.6161\n",
      "Epoch 10/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8757 - acc: 0.6240 - val_loss: 0.8758 - val_acc: 0.6179\n",
      "Epoch 11/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8680 - acc: 0.6228 - val_loss: 0.8675 - val_acc: 0.6179\n",
      "Epoch 12/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8606 - acc: 0.6244 - val_loss: 0.8616 - val_acc: 0.6189\n",
      "Epoch 13/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8522 - acc: 0.6315 - val_loss: 0.8555 - val_acc: 0.6207\n",
      "Epoch 14/300\n",
      "2521/2521 [==============================] - 301s 119ms/step - loss: 0.8443 - acc: 0.6374 - val_loss: 0.8475 - val_acc: 0.6272\n",
      "Epoch 15/300\n",
      "2521/2521 [==============================] - 301s 120ms/step - loss: 0.8366 - acc: 0.6414 - val_loss: 0.8412 - val_acc: 0.6383\n",
      "Epoch 16/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8275 - acc: 0.6438 - val_loss: 0.8378 - val_acc: 0.6420\n",
      "Epoch 17/300\n",
      "2521/2521 [==============================] - 304s 121ms/step - loss: 0.8184 - acc: 0.6541 - val_loss: 0.8295 - val_acc: 0.6420\n",
      "Epoch 18/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.8105 - acc: 0.6553 - val_loss: 0.8249 - val_acc: 0.6392\n",
      "Epoch 19/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.8004 - acc: 0.6601 - val_loss: 0.8263 - val_acc: 0.6355\n",
      "Epoch 20/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.7923 - acc: 0.6557 - val_loss: 0.8196 - val_acc: 0.6512\n",
      "Epoch 21/300\n",
      "2521/2521 [==============================] - 302s 120ms/step - loss: 0.7841 - acc: 0.6708 - val_loss: 0.8124 - val_acc: 0.6531\n",
      "Epoch 22/300\n",
      "2521/2521 [==============================] - 304s 120ms/step - loss: 0.7771 - acc: 0.6720 - val_loss: 0.8108 - val_acc: 0.6466\n",
      "Epoch 23/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.7707 - acc: 0.6692 - val_loss: 0.8332 - val_acc: 0.6485\n",
      "Epoch 24/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.7633 - acc: 0.6767 - val_loss: 0.8151 - val_acc: 0.6494\n",
      "Epoch 25/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.7574 - acc: 0.6767 - val_loss: 0.8130 - val_acc: 0.6485\n",
      "Epoch 26/300\n",
      "2521/2521 [==============================] - 305s 121ms/step - loss: 0.7528 - acc: 0.6811 - val_loss: 0.8137 - val_acc: 0.6494\n",
      "Epoch 27/300\n",
      "2521/2521 [==============================] - 305s 121ms/step - loss: 0.7425 - acc: 0.6882 - val_loss: 0.8211 - val_acc: 0.6337\n",
      "Epoch 28/300\n",
      "2521/2521 [==============================] - 312s 124ms/step - loss: 0.7405 - acc: 0.6894 - val_loss: 0.8120 - val_acc: 0.6494\n",
      "Epoch 29/300\n",
      "2521/2521 [==============================] - 320s 127ms/step - loss: 0.7359 - acc: 0.6894 - val_loss: 0.8096 - val_acc: 0.6559\n",
      "Epoch 30/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.7288 - acc: 0.6910 - val_loss: 0.8277 - val_acc: 0.6457\n",
      "Epoch 31/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.7248 - acc: 0.6894 - val_loss: 0.8346 - val_acc: 0.6318\n",
      "Epoch 32/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.7183 - acc: 0.6969 - val_loss: 0.8168 - val_acc: 0.6494\n",
      "Epoch 33/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.7131 - acc: 0.6946 - val_loss: 0.8133 - val_acc: 0.6531\n",
      "Epoch 34/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.7081 - acc: 0.6977 - val_loss: 0.8160 - val_acc: 0.6540\n",
      "Epoch 35/300\n",
      "2521/2521 [==============================] - 303s 120ms/step - loss: 0.7036 - acc: 0.7065 - val_loss: 0.8085 - val_acc: 0.6531\n",
      "Epoch 36/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6994 - acc: 0.7045 - val_loss: 0.8128 - val_acc: 0.6531\n",
      "Epoch 37/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.6916 - acc: 0.6985 - val_loss: 0.8134 - val_acc: 0.6559\n",
      "Epoch 38/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6854 - acc: 0.7120 - val_loss: 0.8671 - val_acc: 0.6281\n",
      "Epoch 39/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6907 - acc: 0.7073 - val_loss: 0.8129 - val_acc: 0.6512\n",
      "Epoch 40/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6756 - acc: 0.7160 - val_loss: 0.8561 - val_acc: 0.6512\n",
      "Epoch 41/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6787 - acc: 0.7108 - val_loss: 0.8375 - val_acc: 0.6420\n",
      "Epoch 42/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6678 - acc: 0.7207 - val_loss: 0.8318 - val_acc: 0.6577\n",
      "Epoch 43/300\n",
      "2521/2521 [==============================] - 298s 118ms/step - loss: 0.6578 - acc: 0.7307 - val_loss: 0.8343 - val_acc: 0.6586\n",
      "Epoch 44/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.6581 - acc: 0.7251 - val_loss: 0.9558 - val_acc: 0.5495\n",
      "Epoch 45/300\n",
      "2521/2521 [==============================] - 297s 118ms/step - loss: 0.6514 - acc: 0.7243 - val_loss: 0.8486 - val_acc: 0.6494\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>9</th>\n",
       "      <th>15</th>\n",
       "      <th>-1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embeddings</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>glove 300d 42B common crawl</th>\n",
       "      <td>0.699107</td>\n",
       "      <td>0.683036</td>\n",
       "      <td>0.705357</td>\n",
       "      <td>0.683929</td>\n",
       "      <td>0.679464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    5        10         9        15        -1\n",
       "embeddings                                                                   \n",
       "glove 300d 42B common crawl  0.699107  0.683036  0.705357  0.683929  0.679464"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del embeddings\n",
    "del embedding_names\n",
    "\n",
    "semeval_14_rest_train = semeval_14(full_path(read_config('semeval_2014_rest_train')))\n",
    "semeval_14_rest_test = semeval_14(full_path(read_config('semeval_2014_rest_test')))\n",
    "train_data = [semeval_14_rest_train]\n",
    "test_data = [semeval_14_rest_test]\n",
    "# We also use the Glove 300d vectors trained on the common crawl and used in the following paper\n",
    "# http://www.anthology.aclweb.org/D/D16/D16-1021.pdf\n",
    "glove_300 = GloveCommonCrawl42()\n",
    "embedding = glove_300\n",
    "embedding_names = ['{}'.format(embedding)]\n",
    "pad_sizes = [5, 10, half_average_dataset(semeval_14_rest_train), 15, -1]\n",
    "\n",
    "index_column = 'embeddings'\n",
    "sem_rest_pad_size_res_file = os.path.join(pad_size_results_folder, 'Semeval Restaurant 14.csv')\n",
    "notebook_helper.create_pandas_file(sem_rest_pad_size_res_file, pad_sizes, index_column, \n",
    "                                   embedding_names, re_write=False)\n",
    "with tempfile.NamedTemporaryFile() as embedding_file:\n",
    "    embedding_path = embedding_file.name\n",
    "    pickle.dump(embedding, embedding_file)\n",
    "    pred_params = list(itertools.product([embedding_path], pad_sizes, reproducible, \n",
    "                                         train_data, test_data, \n",
    "                                         [sem_rest_pad_size_res_file], \n",
    "                                         [index_column], [whitespace]))\n",
    "    for pred_param in pred_params: \n",
    "        pad_size_prediction(*pred_param)\n",
    "sem_rest_pad_df_results = pd.read_csv(open(sem_rest_pad_size_res_file, 'r'))\n",
    "sem_rest_pad_df_results = sem_rest_pad_df_results.set_index('embeddings')\n",
    "sem_rest_pad_df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_14_lap_train = semeval_14(full_path(read_config('semeval_2014_lap_train')))\n",
    "semeval_14_lap_test = semeval_14(full_path(read_config('semeval_2014_lap_test')))\n",
    "train_data = [semeval_14_lap_train]\n",
    "test_data = [semeval_14_lap_test]\n",
    "\n",
    "pad_sizes = [5, half_average_dataset(semeval_14_lap_train), 15, -1]\n",
    "\n",
    "index_column = 'embeddings'\n",
    "sem_lap_pad_size_res_file = os.path.join(pad_size_results_folder, 'Semeval Laptop 14.csv')\n",
    "notebook_helper.create_pandas_file(sem_lap_pad_size_res_file, pad_sizes, index_column, \n",
    "                                   embedding_names, re_write=False)\n",
    "with tempfile.NamedTemporaryFile() as embedding_file:\n",
    "    embedding_path = embedding_file.name\n",
    "    pickle.dump(embedding, embedding_file)\n",
    "    pred_params = list(itertools.product([embedding_path], pad_sizes, reproducible, \n",
    "                                         train_data, test_data, \n",
    "                                         [sem_lap_pad_size_res_file], \n",
    "                                         [index_column], [whitespace]))\n",
    "    for pred_param in pred_params: \n",
    "        pad_size_prediction(*pred_param)\n",
    "sem_lap_pad_df_results = pd.read_csv(open(sem_lap_pad_size_res_file, 'r'))\n",
    "sem_lap_pad_df_results = sem_lap_pad_df_results.set_index('embeddings')\n",
    "sem_lap_pad_df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "This is an implementation of the LSTM model that is shown in [Tang et al. paper](https://aclanthology.info/papers/C16-1311/c16-1311).\n",
    "\n",
    "The LSTM is a single LSTM layer that outputs to a softmax function. The LSTM hidden layer dimension is the same as the embedding layer dimension. The optimiser is Stochastic Gradient Descent with a learning rate of 0.01.\n",
    "\n",
    "The number of epochs to run the model is unknown and Early Stopping is not mentioned in the paper. As we do not know the number of epochs used we are going to use Early Stopping with a patience of 10.\n",
    "\n",
    "This notebook is going to perform the following experiments:\n",
    "1. The affect of lower casing the words - This should cause some affect as all of the word embeddings only contain lower cased words.\n",
    "2. Tokeniser - the affect of using a simple Whitespace tokeniser and a data set specific tokeniser [ark tokenizer](https://www.cs.cmu.edu/~ark/TweetNLP/gimpel+etal.acl11.pdf) for Twitter data\n",
    "3. Different Validation set size affect - As we are using Early Stopping we require a validation set within the training data therefore we are going to see the affect of this on the Test set.\n",
    "\n",
    "\n",
    "All of the experiments above will be performed with the [Sentiment Specfic Word Embeddings (SSWE)](https://www.aclweb.org/anthology/P14-1146) which are 50 dimension word embeddings which we ctreated by jointly learning sentiment and semantics.\n",
    "\n",
    "After these experiments we will use the best settings to run over all the word embeddings used in the paper:\n",
    "1. SSWE 50 Dimensions In the paper these are called SSWE -u\n",
    "2. Twitter Glove 50 Dimensions\n",
    "3. Twitter Glove 100 Dimensions\n",
    "4. Twitter Glove 200 Dimensions\n",
    "\n",
    "All of the experiments above will be performed on [Dong et al. Twitter dataset](https://aclanthology.info/papers/P14-2009/p14-2009) as used in the original paper. The dataset we used can be found [here](https://github.com/bluemonk482/tdparse/tree/master/data/lidong), this was used as the original dataset had been pre-processed thus containg symbols such as: -LRB- and -RRB-\n",
    "\n",
    "The Twitter glove vectors can be found [here](https://nlp.stanford.edu/projects/glove/)\n",
    "\n",
    "### Affect of initialiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in here\n"
     ]
    }
   ],
   "source": [
    "tclstm_model = TCLSTM(ark_twokenize, sswe, lower=True)\n",
    "tclstm_model.fit(dong_train.data_dict(), dong_train.sentiment_data(), reproducible=True,\n",
    "                 validation_size=0.3, patience=10, epochs=300, verbose=0,\n",
    "                 org_initialisers=True)\n",
    "predictions_keras = tclstm_model.predict(dong_test.data_dict())\n",
    "score_keras = TCLSTM.score(dong_test.sentiment_data(), predictions_keras, accuracy_score)\n",
    "\n",
    "tclstm_model.fit(dong_train.data_dict(), dong_train.sentiment_data(), reproducible=True,\n",
    "               validation_size=0.3, patience=10, epochs=300, verbose=0,\n",
    "               org_initialisers=True)\n",
    "predictions_original = tclstm_model.predict(dong_test.data_dict())\n",
    "score_original = TCLSTM.score(dong_test.sentiment_data(), predictions_original, accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affect of lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_case_options = [True, False]\n",
    "lower_case_results = {}\n",
    "for lower_case_option in lower_case_options:\n",
    "    tclstm_model = TCLSTM(ark_twokenize, glove_200, lower=lower_case_option)\n",
    "    tclstm_model.fit(dong_train.data_dict(), dong_train.sentiment_data(), reproducible=True,\n",
    "                     validation_size=0.3, patience=10, epochs=300, verbose=0,\n",
    "                     org_initialisers=True)\n",
    "    predictions = tclstm_model.predict(dong_test.data_dict())\n",
    "    score = TCLSTM.score(dong_test.sentiment_data(), predictions, accuracy_score)\n",
    "    lower_case_results['Lower case option {}'.format(lower_case_option)] = score\n",
    "pd.DataFrame(lower_case_results, index=['LSTM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The affect of the tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenisers = [whitespace, ark_twokenize]\n",
    "tokeniser_results = {}\n",
    "for tokeniser in tokenisers:\n",
    "    tclstm_model = TCLSTM(tokeniser, glove_200, lower=True)\n",
    "    tclstm_model.fit(dong_train.data_dict(), dong_train.sentiment_data(), reproducible=True,\n",
    "                     validation_size=0.1, patience=10, epochs=300, verbose=0,\n",
    "                     org_initialisers=True)\n",
    "    predictions = tclstm_model.predict(dong_test.data_dict())\n",
    "    score = TCLSTM.score(dong_test.sentiment_data(), predictions, accuracy_score)\n",
    "    tokeniser_results['Tokeniser {}'.format(tokeniser.__name__)] = score\n",
    "pd.DataFrame(tokeniser_results, index=['LSTM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Validation set sizes\n",
    "\n",
    "Using 5 processors uses around ~22GB of RAM this is due to the size of the Glove Vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 30 jobs 2\n",
      "start glove twitter 200d\n",
      "start glove twitter 200d\n",
      "end glove twitter 200d\n",
      "score 0.6791907514450867\n",
      "end glove twitter 200d\n",
      "score 0.6661849710982659\n",
      "done\n",
      "start glove twitter 200d\n",
      "start glove twitter 200d\n",
      "end glove twitter 200d\n",
      "score 0.6604046242774566\n",
      "end glove twitter 200d\n",
      "score 0.6647398843930635\n",
      "done\n",
      "start glove twitter 200d\n",
      "start glove twitter 200d\n"
     ]
    }
   ],
   "source": [
    "def validation_prediction(train_data, test_data, embedding_path, validation_size, reproducible):\n",
    "    embedding = None\n",
    "    with open(embedding_path, 'rb') as embedding_file:\n",
    "        embedding = pickle.load(embedding_file, encoding='utf-8')\n",
    "    print('start {}'.format(embedding))\n",
    "    pad_size = half_average_dataset(train_data)\n",
    "    tclstm_model = TCLSTM(ark_twokenize, embedding, lower=True, pad_size=pad_size)\n",
    "    tclstm_model.fit(train_data.data_dict(), train_data.sentiment_data(), reproducible=reproducible,\n",
    "                     validation_size=validation_size, patience=10, epochs=300, verbose=0,\n",
    "                     org_initialisers=True)\n",
    "    predictions = tclstm_model.predict(test_data.data_dict())\n",
    "    embedding_name = '{}'.format(embedding)\n",
    "    score = TCLSTM.score(test_data.sentiment_data(), predictions, accuracy_score)\n",
    "    print('end {}'.format(embedding))\n",
    "    print('score {}'.format(score))\n",
    "    return score\n",
    "\n",
    "def repeated_results(n_results, n_jobs, train_data, test_data, embedding, validation_size):\n",
    "    '''\n",
    "    n_results number of result samples to produce. n_jobs number of \n",
    "    processors to use the more processors the more memory required \n",
    "    10 = ~36GB Ram for Glove 50 memory very much depends on the word \n",
    "    vectors and Glove vectors are large. embedding the embedding to \n",
    "    use e.g. Glove 50. validation size, size of the validation \n",
    "    set e.g. 0.3\n",
    "    '''\n",
    "    batch_size = math.ceil(n_results / n_jobs)\n",
    "    train_data = [train_data]\n",
    "    test_data = [test_data]\n",
    "    reproducible = [False]\n",
    "    results = []\n",
    "    print('batch size {} jobs {}'.format(batch_size, n_jobs))\n",
    "    for i in range(batch_size):\n",
    "        num_results = n_jobs\n",
    "        left_to_process = n_results - len(results)\n",
    "        if n_jobs > left_to_process:\n",
    "            num_results = left_to_process\n",
    "        with tempfile.NamedTemporaryFile() as embedding_file:\n",
    "            embedding_path = embedding_file.name\n",
    "            pickle.dump(embedding, embedding_file)\n",
    "            val_pred_params = list(itertools.product(train_data, test_data, [embedding_path], \n",
    "                                                     [validation_size] * num_results, reproducible))\n",
    "            with Pool(n_jobs) as pool:\n",
    "                results.extend(pool.starmap(validation_prediction, val_pred_params))\n",
    "                print('done')\n",
    "    return results\n",
    "\n",
    "\n",
    "results_30_glove_200 = repeated_results(60, 2, dong_train, dong_test, glove_200, 0.3)\n",
    "results_30_sswe = repeated_results(60, 3, dong_train, dong_test, sswe, 0.3)\n",
    "#results_30_glove_100 = repeated_results(30, 3, dong_train, dong_test, glove_100, 0.3)\n",
    "#results_30_glove_50 = repeated_results(30, 3, dong_train, dong_test, glove_50, 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f504716d630>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f504716db00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(results_30_glove_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f503c02d278>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuIyCXUTEZf4/1bCdw4c25WEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f504716deb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(results_30_sswe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 20 jobs 3\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6358381502890174\n",
      "end sswe\n",
      "score 0.6257225433526011\n",
      "end sswe\n",
      "score 0.6517341040462428\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6286127167630058\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6372832369942196\n",
      "end sswe\n",
      "score 0.6098265895953757\n",
      "end sswe\n",
      "score 0.630057803468208\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6445086705202312\n",
      "end sswe\n",
      "score 0.6213872832369942\n",
      "end sswe\n",
      "score 0.653179190751445\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6401734104046243\n",
      "end sswe\n",
      "score 0.638728323699422\n",
      "end sswe\n",
      "score 0.6372832369942196\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6271676300578035\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "end sswe\n",
      "score 0.6271676300578035\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6546242774566474\n",
      "end sswe\n",
      "score 0.6286127167630058\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6473988439306358\n",
      "end sswe\n",
      "score 0.6372832369942196\n",
      "end sswe\n",
      "score 0.6257225433526011\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.634393063583815\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "end sswe\n",
      "score 0.634393063583815\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.634393063583815\n",
      "end sswe\n",
      "score 0.6416184971098265\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6416184971098265\n",
      "end sswe\n",
      "score 0.6488439306358381\n",
      "end sswe\n",
      "score 0.6488439306358381\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.638728323699422\n",
      "end sswe\n",
      "score 0.6286127167630058\n",
      "end sswe\n",
      "score 0.6459537572254336\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6473988439306358\n",
      "end sswe\n",
      "score 0.6286127167630058\n",
      "end sswe\n",
      "score 0.638728323699422\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6445086705202312\n",
      "end sswe\n",
      "score 0.6213872832369942\n",
      "end sswe\n",
      "score 0.634393063583815\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6416184971098265\n",
      "end sswe\n",
      "score 0.6459537572254336\n",
      "end sswe\n",
      "score 0.634393063583815\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.611271676300578\n",
      "end sswe\n",
      "score 0.6416184971098265\n",
      "end sswe\n",
      "score 0.6459537572254336\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6372832369942196\n",
      "end sswe\n",
      "score 0.630057803468208\n",
      "end sswe\n",
      "score 0.634393063583815\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6416184971098265\n",
      "end sswe\n",
      "score 0.6430635838150289\n",
      "end sswe\n",
      "score 0.6242774566473989\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6329479768786127\n",
      "end sswe\n",
      "score 0.6401734104046243\n",
      "end sswe\n",
      "score 0.638728323699422\n",
      "done\n",
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "end sswe\n",
      "score 0.6372832369942196\n",
      "end sswe\n",
      "score 0.6401734104046243\n",
      "end sswe\n",
      "score 0.6546242774566474\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#results_30_glove_200 = repeated_results(60, 2, dong_train, dong_test, glove_200, 0.1)\n",
    "results_30_sswe = repeated_results(60, 3, dong_train, dong_test, sswe, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5039005ba8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3Xd4nXd99/H39xztvYcly7K8Z7wd\nZzmDJA4JxEASssCshpSWp5RSoOXp0z7tUwqUDjYNYSSFbEJiQprlOLETxzNe8ZZtWZKHhmVZe/+e\nP3QCjrEtWTrSfcbndV2+dPb9uY7P+eine/xuc84hIiKRy+d1ABERGVkqehGRCKeiFxGJcCp6EZEI\np6IXEYlwKnoRkQinohcRiXAqehGRCKeiFxGJcDGjubCcnBxXWlo6mosUEQl7W7ZsqXfO5Q71+aNa\n9KWlpWzevHk0FykiEvbM7Mhwnq9VNyIiEU5FLyIS4VT0IiIRTkUvIhLhVPQiIhFORS8iEuFU9CIi\nEU5FLyIS4VT0IiIRblSPjBUJVY9sqAzq6929uCSorycyHBrRi4hEOBW9iEiEU9GLiES4Qa2jN7MK\noBnoBXqccwvMLAt4HCgFKoA7nHOnRiamiIgM1cWM6K9xzs1xzi0IXP8qsMo5NwlYFbguIiIhZjir\nbm4FHgpcfghYPvw4IiISbIMtege8ZGZbzOy+wG35zrnjgcsngPygpxMRkWEb7H70VzjnjppZHvCy\nme09807nnDMzd64nBn4x3AdQUqJ9i0VERtugRvTOuaOBn7XAb4BFQI2ZFQIEftae57kPOOcWOOcW\n5OYO+ZSHIiIyRAMWvZklm1nqu5eBG4B3gJXAisDDVgDPjlRIEREZusGsuskHfmNm7z7+EefcC2a2\nCXjCzD4NHAHuGLmYIiIyVAMWvXPuEHDJOW4/CVw3EqFERCR4dGSsiEiEU9GLiEQ4Fb2ISIRT0YuI\nRDgVvYhIhFPRi4hEOBW9iEiEU9GLiEQ4Fb2ISIRT0YuIRDgVvYhIhFPRi4hEOBW9iEiEU9GLiEQ4\nFb2ISIRT0YuIRLjBnhxcRC7CIxsqg/p6dy8uCerrSXTRiF5EJMKp6EVEIpyKXkQkwqnoRUQinIpe\nRCTCqehFRCKcil5EJMKp6EVEIpwOmBIZhrauHipPtlFxso22rh4yk+PISoqjMCOBvNQEr+OJACp6\nkSGpb+7kuZ3H2F/TAoDfjMQ4Py2dPb9/zNSCVK6ZksfYrCSvYooAKnqRi9LV08dr+2tZe6CeWL9x\n7dQ8ynKTKc5IIi7GR1dPH6fauth1rIk3y+v50esHmZyfwkfmFZOaEOt1fIlSKnqRQWru6Obnb1Zw\noqmDuWMzWDaz4I/KOy7GR35aAvlpCVw+MZsNhxpYtbeGH752kHsWl1CcqdG9jD5tjBUZhKb2bh5c\ne5iTrZ2sWFLK7QvGDjhCj4/xc9XkXD571QQMeGDNIbZVnRqdwCJnUNGLDKCxrYufrD3E6Y5uPnHZ\neKYUpF7U88dkJPK5ayZSnJnEE5urefuIyl5G16CL3sz8ZrbVzJ4LXB9vZhvMrNzMHjezuJGLKeKN\nju5efvbmYVo6e/jUZaWMz0ke0uukxMfwqStKmZibwtNbq9l3oinISUXO72JG9H8B7Dnj+jeB/3DO\nTQROAZ8OZjARrznneHrrURpau/jYknGUZA+t5N8V4/Nxz+ISCtITeGRjJZUNbUFKKnJhgyp6MysG\nbgYeDFw34FrgqcBDHgKWj0RAEa+sP9zAO0dPc/30AspyUoLymvGxflYsKSU1IZaH1lXQ0NoVlNcV\nuZDBjuj/E/gy0Be4ng00Oufe3Wm4GigKcjYRz1SfauP5HceZkp/KlZNygvraqQmxfPKyUvqc4/FN\nlfT2uaC+vsjZBix6M7sFqHXObRnKAszsPjPbbGab6+rqhvISIqOqq6ePxzZVkZoQw+3zi/GZBX0Z\n2SnxfGhuEVWn2nllT03QX1/kTIMZ0V8OfNDMKoDH6F9l8x0gw8ze3Q+/GDh6ric75x5wzi1wzi3I\nzc0NQmSRkfXavloaWru4bX4xSfEjd6jJ7OIMFozLZM3+OsprW0ZsOSIDFr1z7m+cc8XOuVLgTuBV\n59w9wGrgtsDDVgDPjlhKkVFS29zB2gP1zB2bQVlucNbLX8gts8eQkxrPk5ur3jN9gkgwDWc/+q8A\nXzSzcvrX2f80OJFEvOGcY+W2Y8TGGDfNKhyVZcbF+Lhz4Vjaunp5fufxUVmmRJ+L+rvUOfca8Frg\n8iFgUfAjiXhje3Ujh+pbuXXOGFJGcJXN2QrTE7lqcg6r99UxtySDSXkXd0CWyEB0ZKwI0NnTy/M7\nT1CcmcjC0qxRX/7VU/LITo7j2W3H6O7tG/gJIhdBRS8CrDt4kpbOHm6ZVTgie9kMJNbvY/ncIhpa\nu3h1b+2oL18im4peol5jWxdrD9QxrSB12Ee/DseE3BTmlWSw9kAdNU0dnuWQyKOil6j349cP0dnd\nx/XTC7yOwk0zC4mP8WvDrASVil6iWm1TB79Yd5hLxmZQkO79qf+S42O4dmoeB2pb2F/T7HUciRAq\neolq33u1nJ5ex3VT87yO8nuLy7LITo7j+Z3HNT2CBIWKXqLW0cZ2HttUyR0Lx5KdEu91nN+L8fm4\naWYBtc2dbKpo8DqORAAVvUStB9cewjn4s2smeh3lj0wrTGN8TjKv7Kmho7vX6zgS5lT0EpUaWrt4\nbGMVt84poigj0es4f8TMuHlWIe1dvazZr8kAZXhU9BKVfrGugvbuXu5fWuZ1lPMak5HIrOJ01h08\nSV1zp9dxJIyp6CXqtHb28NC6Cm6Yns+k/NCebuB9U/Pp6evjh6+Vex1FwpiKXqLOoxsrOd3ezf1X\nT/A6yoByUuOZW5LJr9ZXcrSx3es4EqZU9BJVunr6eHDtYS4ty2JeSabXcQbl2sCun99bdcDjJBKu\nVPQSVX638xgnmjq4f2noj+bflZkUx92LS3hySzWH61u9jiNhSEUvUcM5x8/eqGBCbjJLJ4fX2c4+\nd80EYv3GdzWqlyFQ0UvU2HLkFDuPnuYTl4/HPJihcjjyUhO4d/E4nt12lAqN6uUiqeglavz8zQrS\nEmL4yLwir6MMyX1Ly4j1+/jBau2BIxdHRS9R4WhjOy/sOsFdi0pIihu9s0cFU15qAncvLuHprUep\namjzOo6EERW9RIWH36rAOcfHlozzOsqw3L90An6faVQvF0VFLxGvrauHxzZWsWxmAcWZSV7HGZb8\ntATuWjiWp7ZUU31Ko3oZHBW9RLyV245xur2bT1w23usoQXH/1RPwmfGj1w56HUXChIpeIppzjoff\nOsLUglQWlobHAVIDKUxP5CPzi3lySzW1OuWgDIKKXiLa1qpGdh9v4p5Lx4XdLpUXcv/SMnp6+/jp\nG4e9jiJhQEUvEe2X64+QHOfnQ3PDc5fK8xmXncwHLhnDL9cfobGty+s4EuJU9BKxTrV28dyO43x4\nXjEp8eG5S+WF/OnVE2jt6uWhdUe8jiIhTkUvEevJLVV09fRx76XhvUvl+UwtSON90/L4+brDtHb2\neB1HQpiKXiJSX5/jl+srWVSaxZSC0J5zfjg+d81EGtu6eXRjpddRJISp6CUirS2vp7KhjXsuLfE6\nyoiaV5LJkrJsHlx7mK6ePq/jSIhS0UtEenRDJVnJcSybWeB1lBF3/9UTONHUwTPbjnodRUKUil4i\nTm1TB6/sqeH2+cXEx/i9jjPirpqUw/TCNH78+kH6+pzXcSQEqegl4jy5pZqePsdHF471OsqoMDP+\n9OoJHKpr5aXdNV7HkRA0YNGbWYKZbTSz7Wa2y8z+b+D28Wa2wczKzexxM4sb+bgiF9bX53h0YyVL\nyrIpy03xOs6ouWlmASVZSfzo9YM4p1G9vNdgRvSdwLXOuUuAOcAyM7sU+CbwH865icAp4NMjF1Nk\ncN4or6f6VDt3LY7sjbBni/H7uO+qMrZXNbL+UIPXcSTEDFj0rl9L4Gps4J8DrgWeCtz+ELB8RBKK\nXIRHN/ZvhL1xRr7XUUbdbfOLyUmJ50eva7Izea9BraM3M7+ZbQNqgZeBg0Cjc+7dozSqgcg6xlzC\nTm1zBy/vruG2KNkIe7aEWD+fvLyUNfvr2H2syes4EkIGdVy4c64XmGNmGcBvgKmDXYCZ3QfcB1BS\nEl1/TsvoeiqCN8I+smFwB0QlxPiJi/HxN0/v4KMLz/19uzvKVmvJRe5145xrBFYDS4AMM3v3F0Ux\ncM6deJ1zDzjnFjjnFuTm5g4rrMj5OOd4fFMVi8ZnMSGKNsKeLTHOz6LSLHYePc2pVk12Jv0Gs9dN\nbmAkj5klAtcDe+gv/NsCD1sBPDtSIUUGsv5QA0dOtnFnBI7mL9blE3MwjDfK672OIiFiMCP6QmC1\nme0ANgEvO+eeA74CfNHMyoFs4KcjF1Pkwh7fVElqQgzvn1XodRTPpSfGcsnYDDYfadBkZwIMYh29\nc24HMPcctx8CFo1EKJGLcbqtm+ffOcGdC8eSEBt9G2HP5cpJObxdeYr1h05y3bTo2wNJ3ktHxkrY\ne2bbUbp6+iJyI+xQ5aclMLUglbcOndRkZ6Kil/DmXP+RsLOK0pkxJt3rOCFl6eRc2rp62XxEB1BF\nOxW9hLUd1afZe6JZo/lzGJedzLisJN4or6dXk51FNRW9hLXHNlWREOvjg3PGeB0lJF01OZfGtm52\nHm30Oop4SEUvYautq4ffbj/GzbPGkJYQ63WckDSlIJW81HjW7K/XZGdRTEUvYet3O47T0tmj1TYX\n4DPjykm5nGjqYH9Ny8BPkIikopew9cTmKspykllYmul1lJB2ydh00hNjWXOgzuso4hEVvYSl8toW\nNlWc4o6FYzEzr+OEtBifj8sn5nC4vpXKhjav44gHVPQSlp7cXIXfZ3x4niZNHYyFpZkkxvpZs1+j\n+mikopew093bx6/frua6qXnkpSZ4HScsxMf4WTIhm93HmyivbfY6joyyQU1TLBJKVu2ppb6lSxth\nL9KSsmzWHqjjy0/t5Lb5xUF7XU17HPo0opew88TmKvLT4lk6WdNeX4zk+BgWlGaxreoUjW2awjia\nqOglrJw43cFr+2q5bX4xMX59fC/WFRNzAHhTUxhHFX1TJKw8taWKPgd3LNBqm6HITIrjkuIMNlZo\nCuNooqKXsNHX53h8cxVLyrIZl53sdZywtXRyLj29jnUHT3odRUaJil7CxvpDJ6lqaOfORRrND0de\nWgLTx6Tx1qF6Orp7vY4jo0BFL2HjsU1VpCXEcOOMAq+jhL2lk3Pp6O5jw2FNYRwNVPQSFhrbunhh\n1wk+NLdIZ5EKguLMJCblpfBGeT3dvToxSaRT0UtYeGZr/1mk7tC+80Fz9ZQ8Wjt72FyhUX2kU9FL\nyHPO8dimKmYWpeksUkFUmp3EuKwk1hyop6dPo/pIpqKXkLc9cBapOxfqCMxgMjOunpLH6fZutlXq\nxCSRTEUvIe/xTZUkxvq5VWeRCrrJ+SkUZSTy2v46nW4wgqnoJaS1dvawctsxbp5dSKrOIhV0ZsY1\nU/JoaO1iR7VG9ZFKRS8h7bkdx2jt6uUu7Ts/YqYVplKQlsDqfXX06XSDEUlFLyHtsU1VTMxLYV6J\nziI1UsyMa6bmUd/SyTtHT3sdR0aApimWkLXvRDNbKxv53zdPO+dZpB7ZUOlBqsg0Y0wauanxrN5X\ny8yidHw6a1dE0YheQtZjmyqJ8/v48LzgzZ0u5+YLrKuvaepk17Emr+NIkKnoJSR1dPfy9NtHuWFG\nPlnJcV7HiQqzi9PJTYnn1b01WlcfYVT0EpJeeOcEp9u7uXuR9p0fLT4zrp3aP6rXuvrIoqKXkPTI\nxkpKs5O4tCzb6yhRZVZxOrmp8by6t1aj+giiopeQU17bwsbDDdy5qASfTxsFR5PPjOum5lHb3MlO\njeojxoBFb2ZjzWy1me02s11m9heB27PM7GUzOxD4qf3fJCge21hJjM/4iDbCemJmUTp5qfG8ukej\n+kgxmBF9D/BXzrnpwKXAn5nZdOCrwCrn3CRgVeC6yLB09vTy67eruWFGPrmp8V7HiUo+M66blk9d\nSyfbq3S0bCQYsOidc8edc28HLjcDe4Ai4FbgocDDHgKWj1RIiR4v7qrhVFs3d2kjrKdmjEmjMD2B\nVXtrNQdOBLiodfRmVgrMBTYA+c6544G7TgD553nOfWa22cw219XVDSOqRINHNhxhbFYil0/I8TpK\nVPOZcf30fBpau9h8RPPVh7tBF72ZpQC/Br7gnHvPERXOOQec89e+c+4B59wC59yC3NzcYYWVyFZe\n28L6Qw3cpY2wIWFKfiolWUms3lurs1CFuUEVvZnF0l/yv3LOPR24ucbMCgP3FwK1IxNRosUjGyqJ\n9Rt3LNAEZqHAzLhhej5NHT1sOHTS6zgyDIPZ68aAnwJ7nHP/fsZdK4EVgcsrgGeDH0+iRXtXL09t\nqWLZzEJyUrQRNlSU5aYwMS+F1/bX0dnd63UcGaLBjOgvBz4GXGtm2wL/3g98A7jezA4A7wtcFxmS\n53Yco6mjh3sWayNsqLlhej5tXb2sLa/3OooM0YCzVzrn3gDOt8L0uuDGkWj1qw2VTMhNZvH4LK+j\nyFmKM5OYWZTOGwfqWTw+SyeACUOaplhGzfmmFT7W2M62qkZunlXIoxurRjmVDMaN0/PZfew0q/bW\nsnxOkddx5CJpCgTx3IbDDcT6TScXCWHZKfEsGp/F5ooG6po7vY4jF0lFL55q7+plW9UpZhdlkBjn\n9zqOXMC1U/OJ8ft4afcJr6PIRVLRi6ferjxFd6/TLJVhICU+hisn5bDrWBNHTrZ6HUcugopePNPn\nHBsOn2RsZiJFmYlex5FBuGJiDqkJMfxu53FNeBZGVPTimYN1LdS3dGk0H0biY/zcOL2A6lPt7KjW\nhGfhQkUvnll/8CTJcX5mFaV7HUUuwpySDIoyEnlxVw1dPZoaIRyo6MUTp1q72HuimYWlWcT49TEM\nJz4z3j+rkNPt3awt10SF4UDfMPHEhsP9MyIu0gFSYWl8TjIzi9JZs7+O46fbvY4jA1DRy6jr7u1j\n85EGphWmkZEU53UcGaJlMwpwDv7l+b1eR5EBqOhl1G2raqStq5fLJmojbDjLSo7jqsm5rNx+jLcO\nanbLUKail1HlnOPN8noK0xMYn53sdRwZpqWTcynOTOQfVu7SnPUhTEUvo+pgXSu1zZ1cNiGH/hmw\nJZzF+n383S3T2VfTzMNvHfE6jpyHil5G1Zvl9STHxzC7WLtURoobpuezdHIu//nyfmqbO7yOI+eg\nopdRU9/Syb6aZhaPzyJWu1RGDDPjHz44g86ePv7fc3u8jiPnoGmKZdSsO3gSv88053yEeXf66Ssm\n5bBy+zGyk+OYlJ865Ne7WyefCToNq2RUnG7r5u0jp5hdlK4TV0SopZNzyUmJ49ntx7RhNsSo6GVU\n/HLDEbp6+7hiUo7XUWSExPp93DqniIbWLlbvrfU6jpxBRS8jrqO7l5+/WcHk/BQK0zVLZSSbkJvC\nvJIM1hyo40STNsyGChW9jLjfbD1KfUsnV07K9TqKjIKbZhaSEOvnN29XayrjEKGilxHV1+f4yZpD\nzCpKpyxHB0hFg+T4GG6ZPYaqU+2sK6/3Oo6gopcR9vKeGg7Vt/LZpWU6QCqKXFKcztSCVF7eU8PJ\nFp1j1msqehkxzjn+6/WDjM1KZNmMAq/jyCgyM26dU4TfZzy99ahW4XhMRS8jZv2hBt6ubORPrizT\nnPNRKD0xlvfPLORwfSsbA9NSizf07ZMR871XD5CbGs8dC8Z6HUU8Mn9cJhPzUnjhnRM0tHZ5HSdq\nqehlRGyuaGDdwZN89qoyEmL9XscRj5gZH55bhBk8taVKq3A8oqKXEfHdV8vJSo7T4exCRlIcH5g9\nhoqTbdoLxyMqegm6bVWNrNlfx2euHE9SnKZTEphbksG0glRe2l1DrQ6kGnUqegm67796gPTEWD6+\npNTrKBIizIzlc4uIi/Hx5JZqevu0Cmc0qeglqHZWn+aVPbV86vLxpMRrNC9/kJoQy/I5RRxtbGfV\n3hqv40SVAYvezH5mZrVm9s4Zt2WZ2ctmdiDwM3NkY0q4+NaLe8lIiuWTV5R6HUVC0MyidOaXZPL6\nvjoq6lu9jhM1BjOi/wWw7Kzbvgqscs5NAlYFrkuUe+vgSdYeqOdzV08gTVMRy3ncMruQzOQ4ntxS\nRUd3r9dxosKARe+cWwOcfbTDrcBDgcsPAcuDnEvCjHOOb724l4K0BK2blwuKj/Vz+/xiGtu6+e32\nY17HiQpDXUef75w7Hrh8AsgPUh4JU6/sqWVrZSP/67pJ2m9eBjQuO5lrpuaxtaqRbVWNXseJeMPe\nGOucc8B5N6Gb2X1mttnMNtfV1Q13cRKCevsc335xH6XZSdy+oNjrOBImrpmSR0lWEs9uO6qjZkfY\nUIu+xswKAQI/z3s6GefcA865Bc65Bbm5mo88Ev16SzX7apr54g1TdNJvGTS/z/jogrGYweObKrXL\n5Qga6rdyJbAicHkF8Gxw4ki4ae7o5lsv7mX+uEw+MLvQ6zgSZjKT41g+p4iqU+28ql0uR8yAOzqb\n2aPA1UCOmVUDfw98A3jCzD4NHAHuGMmQErq+v7qc+pYufvaJhZpvXoZkdnEGB2paeG1fHWW5KV7H\niUgDFr1z7q7z3HVdkLNImDlc38rP3jjM7fOLmV2c4XUcCWMfuGQMlQ1tPLGpivuXTiA3Nd7rSBFF\nK1RlyP75d3uI8/v462VTvI4iYS4uxsddi0po7+7li09so0/r64NKRS9DsnpfLa/sqeHz100iLzXB\n6zgSAQrSE7hl9hjWHqjnR68f9DpORNFkJHLRWjp7+NrTO5mUl8InLy/1Oo5EkIWlmfT09fHvL+9n\nwbhMFpdlex0pImhELxftX1/Yy/GmDr7xkdnEx+jgKAkeM+NfPjyLkqwkPv/oVuqadWLxYFDRy0XZ\nXNHAw+uPsGJJKfPHaS47Cb7UhFh+eM88Trd38xePbdX+9UGgVTcee2RDZVBfL5hndDo7W3dvH99/\ntZz0xFjGZScFPbvIu6YVpvFPy2fy5ad28J1X9vPFG7TBfzg0opdBe2nXCepaOlk+p0irbGTE3bFg\nLLfPL+a7r5azao8OphoOFb0Myt7jTbx58CSXlmUzOT/V6zgSJf5p+UxmjEnjC49v0/z1w6CilwGd\nbu/myS3VFKYncNPMAq/jSBRJiPXz43vn4/cZn/3vLbR19XgdKSyp6OWCevvc7yecumthiSYtk1E3\nNiuJ7901lwO1zXz5qR30T5grF0PfWrmgF3edoOJkG7fOGUOODksXj1w5KZcv3TiF53Yc54ev6WCq\ni6W9buS83jpYzxvl9Swpy2ZuiXalFG/96dIJ7D3ezL++uI9JeSncMEOrEQdLI3o5p1d21/DcjuNM\nK0jlZk0/LCHAzPjWbbO5pDidLzy+jT3Hm7yOFDZU9PJHtlU18vlHtzImI5GPLizBp+mHJUQkxPp5\n4OMLSE2I4TMPbaa2ucPrSGFBRS/vsf7QSe59cAO5qfF8fMk44mL0EZHQkp+WwIMfX0hDaxef/sVm\nWju1J85A9C2W33t1bw0rfraRgvQEnvjsElITYr2OJHJOs4rT+cE9c9l9vInP/eptunv7vI4U0lT0\ngnOOJzZVcd/DW5icn8oTn11CQbqmHpbQdu3UfP55+Uxe31/H3z69U7tdXoD2uolyzR3dfO0377By\n+zEum5DNjz82nzSN5CVM3LmohGOnO/juqgOkJ8bytZun6ZSW56Cij2IbDzfwpSe3c7Sxnb+6fjKf\nu2Yifp++JBJe/vJ9k2hq7+bBNw6TEOvnSzdqArSzqeij0K5jp/n2i/tYva+OooxEHr/vUhaUZnkd\nS2RIzIz/c8t0Ont6+f7qcuJjfHz+uklexwopKvoQ4Zyju9fR0dOL0f/h9RnEx/iDMspu7ujmlT01\n/Hb7cV7dW0taQgxfWTaVFZeNIylOHwMJbz6f8c/LZ9HZ3ce/vbyf7j7HX75vklbjBOgbPsp6evvY\nefQ0WysbKa9rYV35SRpaO2nr6qXnPCdYSIj1kRjrJzUhlrSEGFITY0mNjyE1IZbUhBgSYnzExfiJ\ni/FxqK6Ftq5eWjt7qGxoY9+JZvaeaGZjRQNdPX0Upifw+Wsn8pkrykhP0rp4iRw+X/8BVX6f8d1V\nBzjd1sXff2AGPq2OVNGPhuOn23nxnROs3lfH5ooGWrt6AUhPjCU9MZaJeakkx/tJivUTH+vHDJzr\nn1Cso7uXtq5e2rp6aO7soaapkwO1LXT2nHt3sm+/tO891+NjfEzOT+XuRSXcMruQeSWZ+uBLxIrx\n+/jWbbPJSIrlJ2sPc6qtm2/ffknUHw+ioh8hDa1dPLP1KCu3H2NbVSMAE3KT+fC8YhaXZbGwNIu8\n1Hge3Vg1pNfv6umjpbOH5o5uOnv66Ozpo7unjysm5ZAU5ycpLobCjARKs5O1gVWiipnxt++fRmZy\nHN96YR8nTnfwg3vmkRvFk/Kp6IOot8+x5kAdj2+sYtXeGrp7HTPGpPHXN05h2cwCJuSmBG1ZcTE+\nsmLiyEqOe8/ty+cWBW0ZIuHKzPjc1RMpykjkK7/ewQe//wb/9bH5zC7O8DqaJ1T0QXCypZMnNlfz\nyMYjVDW0k50cx4olpdy+YCxTCnQ2JhGv3DqniAm5KXz2v7dw24/f4u9unsa9l46Luo20Kvph2FbV\nyMPrKnhux3G6evu4tCyLryybyg3TC6J+naBIqJhZlM7KP7+cLzy+jb97dhcv7a7hW7fNpjA90eto\no0ZFf5Haunr47fZj/GpDJTuqT5Mc5+euRWO599JxTNK5VEVCUnZKPA9/ahG/3FDJ13+3hxv+Yw1f\nXjaVuxaOJSYKzpqmoh8E5xw7j57myc3VPLP1KM2dPUzOT+Efb53Bh+YWafIvkTBgZnzs0nFcOTGH\nrz69g7975h0eXlfB3948jWum5Hkdb0Sp6C+gqqGN3+08ztNvV7O/poX4GB83zSzg3kvHMX9cZtSt\n5xOJBKU5yTz6J5fy0u4a/uX5PXzy55tYMC6Tz1xZxvXT8yNyLzUV/Rmcc+yraWb13jr+553j7Kg+\nDcDckgy+/qFZ3Dy7kPREjd7zLeaZAAAG6klEQVRFwp2ZceOMAq6ZksejGyv5ydpD3P/LLZRmJ3H3\n4hJumT2GMRmRsw5/WEVvZsuA7wB+4EHn3DeCkmqUOOc4VN/KlopTbKxoYO2BOmqaOgGYXZzO39w0\nlffPKmRsVpLHSUVkJMTF+FhxWSn3LC7hxV01/PSNQ3z9+b18/fm9LCrN4saZBVw+MZsp+alh/Rf8\nkIvezPzAD4DrgWpgk5mtdM7tDla4YHHO0dDaxZGGNg7VtbL3eBN7TzSz+3gTDa1dAGQkxXL5hByW\nTs7lqsm5mo9dJIrE+H3cPLuQm2cXUlHfym+3H2Pl9mP803P9dZaTEsfC0ixmjEljxph0phSkUpCW\nEDZHmQ9nRL8IKHfOHQIws8eAW4GgF31Hdy+d3X109/XR3dtHV08fHd19dPb00t7VS2tXD80dPbR0\n9tDY1k1jWxcnW7uobeqkpqmDE6c7aD7jdGNxMT6m5Kfyvml5zCvJZEFpJmU5KWHznyYiI6c0J5nP\nXzeJz183iaON7bxZXs+68nq2VjXyP++c+P3j4mJ8jM1MpCgzibzUeHJT48lOjiMtMZa0wDxUiXF+\nkuL8JMb6KUxP9Gy36+EUfRFw5vH71cDi4cU5t/t/uYXX9tUN+vGJsX4yk2LJS0tgQm4Kl0/MYWxW\nEqXZSYzLTqY0OykqdqkSkeEpykjkjgVjuWPBWACaOrrZc6yJA7UtVDW0ceRkG0cb2zlQ00x9Syfd\nvec/y9UrX7yKiXne7II94htjzew+4L7A1RYz23ehxwdJDlA/CssJlqDlvScYLzKwcHp/wykrKO9I\nf4Y9e38nfXNIT3s377jhLHs4RX8UGHvG9eLAbe/hnHsAeGAYy7loZrbZObdgNJc5HMo7csIpKyjv\nSIvWvMNZf7EJmGRm480sDrgTWDncQCIiElxDHtE753rM7M+BF+nfvfJnzrldQUsmIiJBMax19M65\n54Hng5QlmEZ1VVEQKO/ICaesoLwjLSrzmnPn30osIiLhT/sYiohEuLAqejNbZmb7zKzczL56nsfc\nYWa7zWyXmT1yxu0rzOxA4N+KMMj7gpk1mtlzo5F1OHnNbI6ZvRW4bYeZfTTE844zs7fNbFvg9vtD\nOe8Z96WZWbWZfT/U85pZb+D93WZmo7KTxjDzlpjZS2a2J3B/aajmNbNrznhvt5lZh5ktv+DCnHNh\n8Y/+Db4HgTIgDtgOTD/rMZOArUBm4Hpe4GcWcCjwMzNwOTNU8wYuXwd8AHguDN7fycCkwOUxwHEg\nI4TzxgHxgcspQAUwJlTznnH/d4BHgO+H8uchcLllND63Qcz7GnD9GZ+JpFDOe8ZjsoCGgfKG04j+\n91MuOOe6gHenXDjTnwA/cM6dAnDO1QZuvxF42TnXELjvZWBZCOfFObcKaB7hjGcacl7n3H7n3IHA\n5WNALZAbwnm7nHOdgcfEMzp/2Q7r82Bm84F84KVRyDrsvB4Ycl4zmw7EOOdeDtze4pxrC9W8Z7kN\n+J+B8oZT0Z9ryoWzz4Q9GZhsZm+a2frA7JqDfW6wDSevF4KS18wW0T9COThiSfsNK6+ZjTWzHYHX\n+GbgF1RI5jUzH/BvwJdGOOOZhvt5SDCzzYHbL7xaITiGk3cy0GhmT5vZVjP7V+uftDFU857pTuDR\ngRYWafPRx9D/587V9B+pu8bMZnma6MLOmdc51+hpqvO7YF4zKwT+G1jhnOvzLOUfnDevc64KmG1m\nY4BnzOwp51yNh1nh/J/fe4HnnXPVFlpT5V7o8zDOOXfUzMqAV81sp3NupH/5D+R8728McCUwF6gE\nHgc+AfzUk5R/MJjv2yz6j2W6oHAa0Q9myoVqYKVzrts5dxjYT/8bNajpGoJsOHm9MKy8ZpYG/A74\nmnNufajnfVdgJP8O/V/0kTScvEuAPzezCuDbwMfNbKTP/TCs99c5dzTw8xD967/nhnDeamBbYDVK\nD/AMMC+E877rDuA3zrnuAZc2khscgvmP/t9uh4Dx/GHjxYyzHrMMeChwOYf+P42y6d9gcZj+DbGZ\ngctZoZr3jPuvZvQ2xg7n/Y0DVgFfCJPPQzGQGLg9M/AFmhWqec96zCcYnY2xw3l/M/nDxu4c4ABn\nbWgMsbz+wONzA/f9HPizUM17xv3rgWsGtbyR/sAE+c15f+BLeZD+kSPAPwIfDFw24N/pnxN/J3Dn\nGc/9FFAe+PfJMMi7FqgD2un/zX5jqOalf9VCN7DtjH9zQjjv9cCOwJdrB3BfqH8ezniNTzAKRT/M\n9/eywPXtgZ+fDuW8Z30mdgK/AOJCPG8p/X8B+AazLB0ZKyIS4cJpHb2IiAyBil5EJMKp6EVEIpyK\nXkQkwqnoRUQinIpeRCTCqehFRCKcil5EJML9fwftr8mkDLa2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5036000eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(results_30_sswe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "repeated_results_folder = os.path.join(result_folder, 'TCLstm Repeated Results')\n",
    "os.makedirs(repeated_results_folder, exist_ok=True)\n",
    "repeated_results_file = os.path.join(repeated_results_folder, 'Glove 200.json')\n",
    "with open(repeated_results_file, 'w') as fp:\n",
    "    json.dump(results_30_glove_200, fp)\n",
    "repeated_results_file = os.path.join(repeated_results_folder, 'sswe.json')\n",
    "with open(repeated_results_file, 'w') as fp:\n",
    "    json.dump(results_30_sswe, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0034035908>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f002d00e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.distplot(results_30_sswe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclstm_model = TCLSTM(ark_twokenize, sswe, lower=True)\n",
    "tclstm_model.fit(dong_train.data_dict(), dong_train.sentiment_data(), reproducible=True,\n",
    "                 validation_size=0.3, patience=10, epochs=300, verbose=0,\n",
    "                 org_initialisers=True, lstm_dimension=100)\n",
    "predictions_keras = tclstm_model.predict(dong_test.data_dict())\n",
    "score_keras = TCLSTM.score(dong_test.sentiment_data(), predictions_keras, accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"476pt\" viewBox=\"0.00 0.00 1401.00 476.00\" width=\"1401pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-472 1397,-472 1397,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139638748900432 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139638748900432</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-421 31.5,-467 326.5,-467 326.5,-421 31.5,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"113.5\" y=\"-440.3\">left_text_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-421 195.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-444 250.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"250.5,-421 250.5,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-451.8\">(None, 33)</text>\n",
       "<polyline fill=\"none\" points=\"250.5,-444 326.5,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"288.5\" y=\"-428.8\">(None, 33)</text>\n",
       "</g>\n",
       "<!-- 139638751686384 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139638751686384</title>\n",
       "<polygon fill=\"none\" points=\"0,-337 0,-383 358,-383 358,-337 0,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"103\" y=\"-356.3\">left_embedding_layer: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"206,-337 206,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"206,-360 261,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"261,-337 261,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-367.8\">(None, 33)</text>\n",
       "<polyline fill=\"none\" points=\"261,-360 358,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"309.5\" y=\"-344.8\">(None, 33, 50)</text>\n",
       "</g>\n",
       "<!-- 139638748900432&#45;&gt;139638751686384 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139638748900432-&gt;139638751686384</title>\n",
       "<path d=\"M179,-420.593C179,-412.118 179,-402.297 179,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"182.5,-393.096 179,-383.096 175.5,-393.096 182.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638634319320 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139638634319320</title>\n",
       "<polygon fill=\"none\" points=\"742,-421 742,-467 1044,-467 1044,-421 742,-421\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"827.5\" y=\"-440.3\">right_text_input: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"913,-421 913,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"940.5\" y=\"-451.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"913,-444 968,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"940.5\" y=\"-428.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"968,-421 968,-467 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006\" y=\"-451.8\">(None, 37)</text>\n",
       "<polyline fill=\"none\" points=\"968,-444 1044,-444 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1006\" y=\"-428.8\">(None, 37)</text>\n",
       "</g>\n",
       "<!-- 139638634317024 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139638634317024</title>\n",
       "<polygon fill=\"none\" points=\"710,-337 710,-383 1076,-383 1076,-337 710,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"817\" y=\"-356.3\">right_embedding_layer: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"924,-337 924,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"951.5\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"924,-360 979,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"951.5\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"979,-337 979,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1027.5\" y=\"-367.8\">(None, 37)</text>\n",
       "<polyline fill=\"none\" points=\"979,-360 1076,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1027.5\" y=\"-344.8\">(None, 37, 50)</text>\n",
       "</g>\n",
       "<!-- 139638634319320&#45;&gt;139638634317024 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139638634319320-&gt;139638634317024</title>\n",
       "<path d=\"M893,-420.593C893,-412.118 893,-402.297 893,-393.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"896.5,-393.096 893,-383.096 889.5,-393.096 896.5,-393.096\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638698690992 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139638698690992</title>\n",
       "<polygon fill=\"none\" points=\"286,-253 286,-299 708,-299 708,-253 286,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.5\" y=\"-272.3\">left_text_target: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"459,-253 459,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"486.5\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"459,-276 514,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"486.5\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"514,-253 514,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611\" y=\"-283.8\">[(None, 33, 50), (None, 33, 50)]</text>\n",
       "<polyline fill=\"none\" points=\"514,-276 708,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"611\" y=\"-260.8\">(None, 33, 100)</text>\n",
       "</g>\n",
       "<!-- 139638751686384&#45;&gt;139638698690992 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139638751686384-&gt;139638698690992</title>\n",
       "<path d=\"M264.636,-336.918C306.965,-326.003 358.178,-312.797 401.741,-301.564\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"402.677,-304.937 411.487,-299.051 400.929,-298.159 402.677,-304.937\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638698692056 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139638698692056</title>\n",
       "<polygon fill=\"none\" points=\"376,-337 376,-383 668,-383 668,-337 376,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"446\" y=\"-356.3\">left_target: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"516,-337 516,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"543.5\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"516,-360 571,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"543.5\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"571,-337 571,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-367.8\">(None, 33, 50)</text>\n",
       "<polyline fill=\"none\" points=\"571,-360 668,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"619.5\" y=\"-344.8\">(None, 33, 50)</text>\n",
       "</g>\n",
       "<!-- 139638698692056&#45;&gt;139638698690992 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139638698692056-&gt;139638698690992</title>\n",
       "<path d=\"M515.169,-336.593C512.557,-328.027 509.526,-318.086 506.697,-308.808\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"510.001,-307.64 503.737,-299.096 503.305,-309.682 510.001,-307.64\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638869191872 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139638869191872</title>\n",
       "<polygon fill=\"none\" points=\"726,-253 726,-299 1156,-299 1156,-253 726,-253\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"816.5\" y=\"-272.3\">right_text_target: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"907,-253 907,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"934.5\" y=\"-283.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"907,-276 962,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"934.5\" y=\"-260.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"962,-253 962,-299 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1059\" y=\"-283.8\">[(None, 37, 50), (None, 37, 50)]</text>\n",
       "<polyline fill=\"none\" points=\"962,-276 1156,-276 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1059\" y=\"-260.8\">(None, 37, 100)</text>\n",
       "</g>\n",
       "<!-- 139638634317024&#45;&gt;139638869191872 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139638634317024-&gt;139638869191872</title>\n",
       "<path d=\"M906.116,-336.593C911.291,-327.753 917.322,-317.45 922.9,-307.921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"926.035,-309.494 928.066,-299.096 919.993,-305.958 926.035,-309.494\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638715380176 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139638715380176</title>\n",
       "<polygon fill=\"none\" points=\"1094.5,-337 1094.5,-383 1393.5,-383 1393.5,-337 1094.5,-337\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1168\" y=\"-356.3\">right_target: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1241.5,-337 1241.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1269\" y=\"-367.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1241.5,-360 1296.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1269\" y=\"-344.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1296.5,-337 1296.5,-383 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1345\" y=\"-367.8\">(None, 37, 50)</text>\n",
       "<polyline fill=\"none\" points=\"1296.5,-360 1393.5,-360 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1345\" y=\"-344.8\">(None, 37, 50)</text>\n",
       "</g>\n",
       "<!-- 139638715380176&#45;&gt;139638869191872 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139638715380176-&gt;139638869191872</title>\n",
       "<path d=\"M1162.4,-336.918C1122.24,-326.049 1073.68,-312.908 1032.29,-301.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1033.05,-298.285 1022.48,-299.051 1031.22,-305.041 1033.05,-298.285\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638751684144 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139638751684144</title>\n",
       "<polygon fill=\"none\" points=\"438.5,-169 438.5,-215 707.5,-215 707.5,-169 438.5,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"493.5\" y=\"-188.3\">left_lstm: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"548.5,-169 548.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"548.5,-192 603.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"576\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"603.5,-169 603.5,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-199.8\">(None, 33, 100)</text>\n",
       "<polyline fill=\"none\" points=\"603.5,-192 707.5,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"655.5\" y=\"-176.8\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 139638698690992&#45;&gt;139638751684144 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139638698690992-&gt;139638751684144</title>\n",
       "<path d=\"M517.767,-252.593C526.383,-243.297 536.498,-232.384 545.701,-222.454\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"548.29,-224.809 552.521,-215.096 543.156,-220.051 548.29,-224.809\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638648357272 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139638648357272</title>\n",
       "<polygon fill=\"none\" points=\"764,-169 764,-215 1040,-215 1040,-169 764,-169\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"822.5\" y=\"-188.3\">right_lstm: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"881,-169 881,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"908.5\" y=\"-199.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"881,-192 936,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"908.5\" y=\"-176.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"936,-169 936,-215 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"988\" y=\"-199.8\">(None, 37, 100)</text>\n",
       "<polyline fill=\"none\" points=\"936,-192 1040,-192 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"988\" y=\"-176.8\">(None, 100)</text>\n",
       "</g>\n",
       "<!-- 139638869191872&#45;&gt;139638648357272 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139638869191872-&gt;139638648357272</title>\n",
       "<path d=\"M930.343,-252.593C926.182,-243.844 921.339,-233.662 916.847,-224.216\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"919.965,-222.623 912.509,-215.096 913.643,-225.63 919.965,-222.623\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638785457792 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139638785457792</title>\n",
       "<polygon fill=\"none\" points=\"520.5,-85 520.5,-131 953.5,-131 953.5,-85 520.5,-85\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"627\" y=\"-104.3\">left_right_lstm_merge: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"733.5,-85 733.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"761\" y=\"-115.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"733.5,-108 788.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"761\" y=\"-92.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"788.5,-85 788.5,-131 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"871\" y=\"-115.8\">[(None, 100), (None, 100)]</text>\n",
       "<polyline fill=\"none\" points=\"788.5,-108 953.5,-108 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"871\" y=\"-92.8\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 139638751684144&#45;&gt;139638785457792 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139638751684144-&gt;139638785457792</title>\n",
       "<path d=\"M617.381,-168.81C637.883,-158.559 662.391,-146.305 683.869,-135.565\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"685.489,-138.669 692.868,-131.066 682.359,-132.408 685.489,-138.669\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638648357272&#45;&gt;139638785457792 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139638648357272-&gt;139638785457792</title>\n",
       "<path d=\"M857.349,-168.81C836.722,-158.559 812.064,-146.305 790.455,-135.565\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"791.914,-132.382 781.401,-131.066 788.798,-138.651 791.914,-132.382\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139638678411976 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139638678411976</title>\n",
       "<polygon fill=\"none\" points=\"622,-1 622,-47 852,-47 852,-1 622,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"668\" y=\"-20.3\">output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"714,-1 714,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-31.8\">input:</text>\n",
       "<polyline fill=\"none\" points=\"714,-24 769,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"741.5\" y=\"-8.8\">output:</text>\n",
       "<polyline fill=\"none\" points=\"769,-1 769,-47 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810.5\" y=\"-31.8\">(None, 200)</text>\n",
       "<polyline fill=\"none\" points=\"769,-24 852,-24 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810.5\" y=\"-8.8\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 139638785457792&#45;&gt;139638678411976 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139638785457792-&gt;139638678411976</title>\n",
       "<path d=\"M737,-84.5931C737,-76.1177 737,-66.2974 737,-57.104\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"740.5,-57.0958 737,-47.0959 733.5,-57.0959 740.5,-57.0958\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tclstm_model.visulaise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66040462427745661"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8c5d9f14a1e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_sizes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0membedding_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresults_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(np.zeros((len(embeddings), len(validation_sizes))))\n",
    "results_df.index = ['{}'.format(embedding) for  embedding in embeddings]\n",
    "results_df.columns = ['{}'.format(int(val_size * 100)) for val_size in validation_sizes]\n",
    "for result in results:\n",
    "    embedding_name, val_size, score = result\n",
    "    results_df[val_size][embedding_name] = score\n",
    "round(results_df * 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the results above the validation set matters however we can see 20% validation appears to be the worse. I should imagine this is due to the 30 and 15% sets containing data that is more representive of the test data therefore allowing the model to find features/weights that can better sperate the classes within the test data.\n",
    "\n",
    "However it could just be due to the random seed we used and that the validation split that was found is just not very reprenative of the test data. We think this is the case as it is unusall that a smaller sample size 0.1 is better representative of the test data than a large sample size 0.2. Therefore below we use the Glove 50 dimension vectors and re-run the experiment using a different random validation split each time to see the affect over a larger sample size to see what the affect of validation size is with a larger sample size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start sswe\n",
      "start sswe\n",
      "start sswe\n",
      "start glove twitter 50d\n",
      "start glove twitter 50d\n",
      "end glove twitter 50d\n",
      "start glove twitter 50d\n",
      "end sswe\n",
      "start glove twitter 100d\n",
      "end glove twitter 50d\n",
      "end sswe\n",
      "start glove twitter 100d\n",
      "start glove twitter 100d\n",
      "end sswe\n",
      "start glove twitter 200d\n",
      "end glove twitter 50d\n",
      "start glove twitter 200d\n",
      "end glove twitter 100d\n",
      "start glove twitter 200d\n",
      "end glove twitter 100d\n",
      "end glove twitter 100d\n"
     ]
    }
   ],
   "source": [
    "def validation_prediction(train_data, test_data, embedding, validation_size, reproducible):\n",
    "    print('start {}'.format(embedding))\n",
    "    pad_size = half_average_dataset(train_data)\n",
    "    tclstm_model = TCLSTM(ark_twokenize, embedding, lower=True, pad_size=pad_size)\n",
    "    tclstm_model.fit(train_data.data_dict(), train_data.sentiment_data(), reproducible=reproducible,\n",
    "                     validation_size=validation_size, patience=10, epochs=300, verbose=0,\n",
    "                     org_initialisers=True)\n",
    "    predictions = tclstm_model.predict(test_data.data_dict())\n",
    "    embedding_name = '{}'.format(embedding)\n",
    "    score = TCLSTM.score(test_data.sentiment_data(), predictions, accuracy_score)\n",
    "    print('end {}'.format(embedding))\n",
    "    return score\n",
    "def val_pred_wrapper(train_data, test_data, embedding, validation_size, reproducible):\n",
    "    score = validation_prediction(embedding, validation_size, reproducible)\n",
    "    return ('{}'.format(embedding), \n",
    "            'Validation Size {}%'.format(int(validation_size * 100)),\n",
    "            score)\n",
    "\n",
    "train_data = [dong_train]\n",
    "test_data = [dong_test]\n",
    "embeddings = [sswe, glove_50, glove_100, glove_200]\n",
    "validation_sizes = [0.3, 0.2, 0.1]\n",
    "reproducible = [True]\n",
    "val_pred_params = list(itertools.product(train_data, test_data, embeddings, validation_sizes, reproducible))\n",
    "results = None\n",
    "time_taken = time.time()\n",
    "#print(val_pred_wrapper(*val_pred_params[0]))\n",
    "with Pool(10) as pool:\n",
    "    results = pool.starmap(val_pred_wrapper, val_pred_params)\n",
    "time_taken = time.time() - time_taken\n",
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_20 = repeated_results(100, 3, glove_200, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10 = repeated_results(100, 3, glove_200, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results_30' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f111b3c617ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'results_30' is not defined"
     ]
    }
   ],
   "source": [
    "results_30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_repeated_df = pd.DataFrame({'Validation 10%' : results_10,\n",
    "                                    'Validation 20%' : results_20,\n",
    "                                    'Validation 30%' : results_30})\n",
    "results_repeated_df = round(results_repeated_df * 100, 2)\n",
    "ax = sns.boxplot(data=results_repeated_df)\n",
    "ax = sns.swarmplot(data=results_repeated_df, color=\".25\")\n",
    "ax.set_ylabel('Test Accuracy (%)')\n",
    "ax.set_title('Comparison of Validation Set Sizes')\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_repeated_summary = results_repeated_df.describe().T.round(2)\n",
    "results_repeated_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the different between the two validation sets is slight. The 30% has a higher minimum and maximum value as well as it deviate less suggesting that on average this set better represents the test data. Even though the training set of the LSTM will be 10% lower it is worth having a better validation set for training the LSTM algorthim."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
