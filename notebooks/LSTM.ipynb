{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random as rn\n",
    "from typing import List, Tuple, Union, Any, Dict\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras import initializers, optimizers\n",
    "\n",
    "# Splitting the datasets\n",
    "from bella.data_types import TargetCollection, Target\n",
    "# Models\n",
    "from bella.models.tdlstm import LSTM, TDLSTM, TCLSTM\n",
    "# Tokenisers\n",
    "from bella.tokenisers import ark_twokenize\n",
    "# Word Vectors\n",
    "from bella.word_vectors import SSWE, GloveTwitterVectors\n",
    "# Get the data\n",
    "from bella.helper import read_config\n",
    "# Parse the data\n",
    "from bella.parsers import dong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def train_val_split(train: 'bella.data_types.TargetCollection', \n",
    "                    split_size: float = 0.2, seed: Union[None, int] = 42\n",
    "                   ) -> Tuple[Tuple[np.ndarray, np.ndarray],\n",
    "                              Tuple[np.ndarray, np.ndarray]]:\n",
    "    '''\n",
    "    Splits the training dataset into a train and validation set in a\n",
    "    stratified split.\n",
    "    \n",
    "    :param train: The training dataset that needs to be split into\n",
    "    :param split_size: Fraction of the dataset to assign to the \n",
    "                       validation set.\n",
    "    :param seed: Seed value to give to the stratified splitter. If \n",
    "                 None then it uses the radnom state of numpy.\n",
    "    :return: Two tuples of length two where each tuple is the train \n",
    "             and validation splits respectively, and each tuple contains \n",
    "             the data (X) and class labels (y) respectively. Returns \n",
    "             ((X_train, y_train), (X_val, y_val))\n",
    "    '''\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=split_size, random_state=seed)\n",
    "    data = np.asarray(train.data_dict())\n",
    "    sentiment = np.asarray(train.sentiment_data())\n",
    "    for train_indexs, test_indexs in splitter.split(data, sentiment):\n",
    "        train_data = data[train_indexs]\n",
    "        test_data = data[test_indexs]\n",
    "\n",
    "    convert_to_targets = lambda data: [Target(**target) for target in data]\n",
    "    train = TargetCollection(convert_to_targets(train_data))\n",
    "    val = TargetCollection(convert_to_targets(test_data))\n",
    "\n",
    "    X_train = np.array(train.data_dict())\n",
    "    y_train = np.array(train.sentiment_data())\n",
    "    X_val = np.array(val.data_dict())\n",
    "    y_val = np.array(val.sentiment_data())\n",
    "    return (X_train, y_train), (X_val, y_val)\n",
    "\n",
    "def evaluate_model(model_class: 'bella.models.KerasModel', \n",
    "                   model_kwargs: Dict[str, Any], \n",
    "                   word_vectors: 'bella.word_vectors.WordVectors', \n",
    "                   result_folder: Path, random_values: List[int]):\n",
    "    '''\n",
    "    Given a model class it will fit and predict for each different \n",
    "    random value and word vector. These predictions are then saved \n",
    "    in the model specific results folder that is created based on \n",
    "    name of the model within the result folder.\n",
    "    \n",
    "    :param model_class: The class of the model to evaluate e.g. LSTM\n",
    "    :param model_kwargs: The keyword arguments to give to the model \n",
    "                         class construction e.g. `optimiser`\n",
    "    :param word_vectors: The word vectors to evaluate over.\n",
    "    :param result_folder: The folder to save the results to\n",
    "    :param random_values: The random values to evaluate each word \n",
    "                          vector over.\n",
    "    :return: Nothing but saves the results as a json file for each \n",
    "             word vector. Where the json file contains a List of \n",
    "             tuples where each tuple is (random_value, predictions)\n",
    "    '''\n",
    "    for word_vector in word_vectors:\n",
    "        model = model_class(ark_twokenize, word_vector, **model_kwargs)\n",
    "        model_result_folder = result_folder.joinpath(f'{str(model)}')\n",
    "        model_result_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        word_vector_fp = model_result_folder.joinpath(f'{str(model)} {str(word_vector)} '\n",
    "                                                      'Repeated Results.json')\n",
    "        # Do not re-write over exisiting data\n",
    "        if word_vector_fp.is_file():\n",
    "            print('File already exists, therefore assuming the data exists '\n",
    "                  f'for file path {word_vector_fp}')\n",
    "            continue\n",
    "        param_predictions = model.evaluate_parameters(model, (X_train, y_train), (X_val, y_val), \n",
    "                                                X_test, 'reproducible', random_values, n_cpus)\n",
    "        # Change the class labels back to original labels\n",
    "        temp_param_predictions = []\n",
    "        for random_value, predictions in param_predictions:\n",
    "            predictions = [sent_vals_inv[prediction] for prediction in predictions]\n",
    "            temp_param_predictions.append((random_value, predictions))\n",
    "\n",
    "        with word_vector_fp.open('w') as word_vector_file:\n",
    "            json.dump(temp_param_predictions, word_vector_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#  ADD YOUR CONFIG FILE PATH HERE \n",
    "##\n",
    "CONFIG_FP = Path('..', 'config.yaml')\n",
    "\n",
    "#\n",
    "# Data set up\n",
    "#\n",
    "\n",
    "results_folder = Path(read_config('results_folder', CONFIG_FP))\n",
    "results_folder = results_folder.joinpath('TDLstm')\n",
    "\n",
    "# Load the datasets\n",
    "dong_train = dong(read_config('dong_twit_train_data', CONFIG_FP))\n",
    "dong_test = dong(read_config('dong_twit_test_data', CONFIG_FP))\n",
    "\n",
    "(X_train, y_train), (X_val, y_val) = train_val_split(dong_train)\n",
    "# The models do not accepts class labels that are less than 0\n",
    "sent_vals = {-1: 0, 0: 1, 1: 2}\n",
    "sent_vals_inv = {0: -1, 1: 0, 2: 1}\n",
    "y_val = np.array([sent_vals[val] for val in y_val])\n",
    "y_train = np.array([sent_vals[val] for val in y_train])\n",
    "\n",
    "X_test = dong_test.data_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove twitter 50d from file\n",
      "Loading glove twitter 100d from file\n",
      "Loading glove twitter 200d from file\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# WORD VECTORS\n",
    "#\n",
    "# Get all the words from the train and test data so that we \n",
    "# can filter words from the Word Vectors so that all the \n",
    "# word vectors can be loaded into reasonable amount of memory\n",
    "train_words = dong_train.word_list(ark_twokenize)\n",
    "test_words = dong_test.word_list(ark_twokenize)\n",
    "all_words = list(set(train_words + test_words))\n",
    "# Load the word vectors\n",
    "sswe = SSWE(filter_words=all_words)\n",
    "glove_50 = GloveTwitterVectors(50, filter_words=all_words)\n",
    "glove_100 = GloveTwitterVectors(100, filter_words=all_words)\n",
    "glove_200 = GloveTwitterVectors(200, filter_words=all_words)\n",
    "word_vectors = [sswe, glove_50, glove_100, glove_200]\n",
    "n_cpus = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# All the model keyword arguments to match the original paper\n",
    "#\n",
    "uniform_init = initializers.RandomUniform(minval=-0.003, maxval=0.003)\n",
    "lstm_layer_kwargs = {'kernel_initializer' : uniform_init,\n",
    "                     'recurrent_initializer' : uniform_init,\n",
    "                     'bias_initializer' : uniform_init}\n",
    "dense_layer_kwargs = {'kernel_initializer' : uniform_init,\n",
    "                      'bias_initializer' : uniform_init}\n",
    "embedding_layer_kwargs = {'embeddings_initializer' : uniform_init}\n",
    "model_kwargs = {'lstm_layer_kwargs': lstm_layer_kwargs,\n",
    "                'dense_layer_kwargs': dense_layer_kwargs,\n",
    "                'embedding_layer_kwargs': embedding_layer_kwargs,\n",
    "                'optimiser': optimizers.SGD,\n",
    "                'optimiser_params': {'lr': 0.01}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does the random seed affect the LSTM based models\n",
    "\n",
    "It is known that chagning the random seed value in neural sequence labelling cause the results to statistically significantly change [Reimers and Gurevych](https://aclanthology.info/papers/D17-1035/d17-1035). Therefore in this notebook we show the affect of changing the random seed value with respect to training the 3 LSTM based models that [Tang et al.](https://www.aclweb.org/anthology/C16-1311) presented in his paper. We then show if we can replicate their results. The models that they created are the following:\n",
    "\n",
    "1. **LSTM** - Standard single layered LSTM where the hidden layer output is equal to the size of the input vector dimensions e.g. if the words vectors are 50 dimensions in size then the LSTM hidden state and output is 50 dimensions.\n",
    "2. **TDLSTM** - Target Dependent LSTM. This consists of 2 LSTMs either side of the target word that the sentiment is with respect to. The Left LSTM reads words in from left to right and goes up to the last word in the target word. The right LSTM reads words right to left and goes up to the last word in the target word as well. Again the LSTM hidden state and output is the same as the dimension of the input.\n",
    "3. **TCLSTM** - Target Context LSTM is the same as the TDLSTM but the input instead of being just the word vectors it reads in and word vectors are concatenated with the vector representation of the target word. If the target word is multiple words then it is the average of those word vectors.\n",
    "\n",
    "The names of these models are direct matches to the class names that represent these models in our code base.\n",
    "\n",
    "In [Tang et al.](https://www.aclweb.org/anthology/C16-1311) paper they never state the number of Epochs that they train for and instead of guessing the number we decided to use Early Stopping to find the optimal number of Epochs to train for.\n",
    "\n",
    "However using Early Stopping comes with other drawbacks. As the dataset that they used for this paper (and all of the other datasets we look at) does not contain a validation set we have to create a train and validation set from the original training data. This creation of the validation set could cause some differences in ours and their results.\n",
    "\n",
    "## Dataset used\n",
    "\n",
    "The dataset we use is the same as [Tang et al.](https://www.aclweb.org/anthology/C16-1311) used in their paper which is [Dong et al](https://aclanthology.coli.uni-saarland.de/papers/P14-2009/p14-2009) Twitter dataset which is a general domain dataset.\n",
    "\n",
    "## Word vectors used\n",
    "\n",
    "We use the same word vectors as those shown in the paper apart from the SSWE-h and SSWE-r which we could not find, the *SSWE-u* is the equivalent to *SSWE* in our code base. We got the *SSWE* word vectors from the following [code base](https://github.com/bluemonk482/tdparse) and the Gove Twitter vectors from [here](https://nlp.stanford.edu/projects/glove/). However in our code base the word vectors will download automatically and then be saved within your user directory under the directory `.Bella`\n",
    "\n",
    "## The experiment\n",
    "\n",
    "Below we run each of the 3 models 30 times with different random seeds and then repeat this for each word vector. This can take a long time but can be speed up signifcantly if you use more than one CPU. The number of cpus to use can be changed by changing the `n_cpus` variable above, default is `1`. \n",
    "\n",
    "**The results from these experiments have been saved and therefore do not need to be repeated.** They have been saved under:\n",
    "\n",
    "`../results/{model_name}/{model_name} {word_vector_name} Repeated Results.json`\n",
    "\n",
    "where the variables could be: model_name = 'LSTM' and word_vector_name = 'SSWE' e.g. \n",
    "\n",
    "`../results/LSTM/LSTM SSWE Repeated Results.json`\n",
    "\n",
    "\n",
    "### LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(42)\n",
    "random_values = [int(rn.uniform(0, 1000)) for i in range(30)] \n",
    "evaluate_model(LSTM, model_kwargs, word_vectors, results_folder, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TDLSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(42)\n",
    "random_values = [int(rn.uniform(0, 1000)) for i in range(30)] \n",
    "evaluate_model(TDLSTM, model_kwargs, word_vectors, results_folder, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TCLSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(42)\n",
    "random_values = [int(rn.uniform(0, 1000)) for i in range(30)] \n",
    "evaluate_model(TCLSTM, model_kwargs, word_vectors, results_folder, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the evaluations\n",
    "\n",
    "Now we have all of the data saved in the respective result files we shall analysis it to see how much the results vary and how close we get to the result stated in Tang et al. paper.\n",
    "\n",
    "A note on how the data is stored. We have the raw predictions for each model, for each of the 4 word vectors, and for each random seed in the 30 random seeds drawn from a uniform distribution. Therefore we have in total 3 \\* 4 \\* 30 raw predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAElCAYAAADEC3XRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4c78ccfe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [LSTM, TDLSTM, TCLSTM]\n",
    "model_data = defaultdict(list)\n",
    "y_test = dong_test.sentiment_data()\n",
    "for model in models:\n",
    "    model_name = model.__name__\n",
    "    model_result_folder = results_folder.joinpath(model_name)\n",
    "    for word_vector in word_vectors:\n",
    "        word_vector_name = str(word_vector).capitalize()\n",
    "        if word_vector_name == 'Sswe':\n",
    "            word_vector_name = 'SSWE'\n",
    "        result_fp = model_result_folder.joinpath(f'{model_name} {str(word_vector)} '\n",
    "                                                 'Repeated Results.json')\n",
    "        with result_fp.open('r') as result_file:\n",
    "            random_predictions = json.load(result_file)\n",
    "        \n",
    "        accuracies = []\n",
    "        f1_scores = []\n",
    "        for random_value, predictions in random_predictions:\n",
    "            accuracies.append(accuracy_score(y_test, predictions) * 100)\n",
    "            f1_scores.append(f1_score(y_test, predictions, average='macro') * 100)\n",
    "        num_scores = len(accuracies)\n",
    "        model_data['Model'].extend([model_name] * num_scores)\n",
    "        model_data['Word Vector'].extend([word_vector_name] * num_scores)\n",
    "        model_data['Macro F1 Score'].extend(f1_scores)\n",
    "        model_data['Accuracy'].extend(accuracies)\n",
    "model_data = pd.DataFrame(model_data)\n",
    "fig, axs = plt.subplots(ncols=2)\n",
    "axs[0] = sns.boxplot(x=\"Model\", y=\"Macro F1 Score\", hue=\"Word Vector\", \n",
    "                 data=model_data, palette='BuGn', ax=axs[0])\n",
    "axs[1] = sns.boxplot(x=\"Model\", y=\"Accuracy\", hue=\"Word Vector\", \n",
    "                 data=model_data, palette='BuGn', ax=axs[1])\n",
    "for ax in axs:\n",
    "    ax.figure.set_size_inches(12,3.9)\n",
    "    leg = ax.legend(loc=9, bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "axs[0].figure.savefig('TDLSTM dist results.png', bbox_extra_artists=(leg,), bbox_inches='tight', dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above using different seed values affects the results quite a lot, more so for smaller embedding sizes when using the macro F1 score. These results come to the same conclusion as the original paper for both the ranking of the embeddings and the models.\n",
    "\n",
    "### Overall results\n",
    "\n",
    "Below we show the mean and maximum values of the repeated experiments above and state these as our reported results and compared them to the original results from Tang et al paper. As can be seen the maximum results are very close to the original, and the maximum results show the same ranking of the models when using the Macro F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Metric</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Macro F1</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>TDLSTM</th>\n",
       "      <th>TCLSTM</th>\n",
       "      <th>LSTM</th>\n",
       "      <th>TDLSTM</th>\n",
       "      <th>TCLSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>64.70</td>\n",
       "      <td>69.00</td>\n",
       "      <td>69.50</td>\n",
       "      <td>66.50</td>\n",
       "      <td>70.8</td>\n",
       "      <td>71.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reproduced Mean</th>\n",
       "      <td>60.69</td>\n",
       "      <td>65.63</td>\n",
       "      <td>65.23</td>\n",
       "      <td>64.60</td>\n",
       "      <td>68.7</td>\n",
       "      <td>67.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reproduced Max</th>\n",
       "      <td>64.34</td>\n",
       "      <td>67.04</td>\n",
       "      <td>67.66</td>\n",
       "      <td>66.91</td>\n",
       "      <td>69.8</td>\n",
       "      <td>69.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metric          Macro F1               Accuracy              \n",
       "Model               LSTM TDLSTM TCLSTM     LSTM TDLSTM TCLSTM\n",
       "Original           64.70  69.00  69.50    66.50   70.8  71.50\n",
       "Reproduced Mean    60.69  65.63  65.23    64.60   68.7  67.98\n",
       "Reproduced Max     64.34  67.04  67.66    66.91   69.8  69.65"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_glove_200_results = {('Macro F1', 'LSTM'): [64.7], ('Macro F1', 'TDLSTM'): [69.0], \n",
    "                          ('Macro F1', 'TCLSTM'): [69.5], ('Accuracy', 'LSTM'): [66.5], \n",
    "                          ('Accuracy', 'TDLSTM'): [70.8], ('Accuracy', 'TCLSTM'): [71.5]}\n",
    "glove_vectors = model_data['Word Vector'] == 'Glove twitter 200d'\n",
    "for model in models:\n",
    "    model_name = model.__name__\n",
    "    model_specific_data = model_data['Model'] == model_name\n",
    "    model_vec_query = model_specific_data & glove_vectors\n",
    "    refined_data = model_data[model_vec_query]\n",
    "    f1_data = refined_data['Macro F1 Score']\n",
    "    acc_data = refined_data['Accuracy']\n",
    "    mean_glove_200_results[('Macro F1', f'{model_name}')].append(f1_data.mean())\n",
    "    mean_glove_200_results[('Macro F1', f'{model_name}')].append(f1_data.max())\n",
    "    mean_glove_200_results[('Accuracy', f'{model_name}')].append(acc_data.mean())\n",
    "    mean_glove_200_results[('Accuracy', f'{model_name}')].append(acc_data.max())\n",
    "columns = pd.MultiIndex.from_tuples(list(mean_glove_200_results.keys()), names=['Metric', 'Model'])\n",
    "pd.DataFrame(mean_glove_200_results, \n",
    "             index=['Original', 'Reproduced Mean', 'Reproduced Max'],\n",
    "             columns=columns\n",
    "            ).astype(float).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Here we are going to look at the number of Out Of Vocabularly (OOV) words the different word vectors have for the sentence text and target text for each sample in the Dong Twitter dataset. Just as a reminder that the LSTM only takes into account the sentence text and not the target text of which the sentiment is with respect to.\n",
    "\n",
    "For the Glove Twitter vectors as they were trained on the same text we look at them as a group rather than indivdually as each one would have the same result. Therefore below we are only going to compare Glove Twitter to SSWE vectors.\n",
    "\n",
    "Below are some handy functions to calculate the OOV stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_target_oov(target_data, word_list, tokenizer=ark_twokenize, whole_target=False):\n",
    "    all_oov_count = []\n",
    "    target_words_list = [ark_twokenize(data['target'].lower()) for data in target_data.data()]\n",
    "    for target_words in target_words_list:\n",
    "        count = 0\n",
    "        oov_count = 0\n",
    "        for word in target_words:\n",
    "            if word not in word_list:\n",
    "                oov_count += 1\n",
    "            count += 1\n",
    "        average_oov = oov_count / count\n",
    "        if whole_target:\n",
    "            all_oov_count.append(math.ceil(average_oov))\n",
    "        else:\n",
    "            all_oov_count.append(average_oov)\n",
    "    return sum(all_oov_count) / len(all_oov_count)\n",
    "\n",
    "def average_oov(target_data, word_list, tokenizer=ark_twokenize, whole_text=False):\n",
    "    all_oov_count = []\n",
    "    words_list = [ark_twokenize(data['text'].lower()) for data in target_data.data()]\n",
    "    for words in words_list:\n",
    "        count = 0\n",
    "        oov_count = 0\n",
    "        for word in words:\n",
    "            if word not in word_list:\n",
    "                oov_count += 1\n",
    "            count += 1\n",
    "        average_oov = oov_count / count\n",
    "        if whole_text:\n",
    "            all_oov_count.append(math.ceil(average_oov))\n",
    "        else:\n",
    "            all_oov_count.append(average_oov)\n",
    "    return sum(all_oov_count) / len(all_oov_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_word_list = [('SSWE', sswe._word_list), ('Glove', glove_200._word_list)]\n",
    "train_results = pd.DataFrame(columns=['Average Target OOV', 'Target OOV', \n",
    "                                      'Average Text OOV', 'Text OOV'],\n",
    "                             index=['SSWE', 'Glove'])\n",
    "for name, word_list in name_word_list:\n",
    "    train_results['Average Target OOV'][name] = avg_target_oov(dong_train, word_list)\n",
    "    train_results['Target OOV'][name] = avg_target_oov(dong_train, word_list, whole_target=True)\n",
    "    train_results['Average Text OOV'][name] = average_oov(dong_train, word_list)\n",
    "    train_results['Text OOV'][name] = average_oov(dong_train, word_list, whole_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Target OOV</th>\n",
       "      <th>Target OOV</th>\n",
       "      <th>Average Text OOV</th>\n",
       "      <th>Text OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSWE</th>\n",
       "      <td>1.15</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.24</td>\n",
       "      <td>47.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove</th>\n",
       "      <td>1.49</td>\n",
       "      <td>2.88</td>\n",
       "      <td>9.22</td>\n",
       "      <td>78.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Target OOV  Target OOV  Average Text OOV  Text OOV\n",
       "SSWE                 1.15        2.06              4.24     47.81\n",
       "Glove                1.49        2.88              9.22     78.89"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_train_results = (train_results * 100).astype(float).round(2)\n",
    "rounded_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_word_list = [('SSWE', sswe._word_list), ('Glove', glove_200._word_list)]\n",
    "test_results = pd.DataFrame(columns=['Average Target OOV', 'Target OOV', \n",
    "                                     'Average Text OOV', 'Text OOV'],\n",
    "                            index=['SSWE', 'Glove'])\n",
    "for name, word_list in name_word_list:\n",
    "    test_results['Average Target OOV'][name] = avg_target_oov(dong_test, word_list)\n",
    "    test_results['Target OOV'][name] = avg_target_oov(dong_test, word_list, whole_target=True)\n",
    "    test_results['Average Text OOV'][name] = average_oov(dong_test, word_list)\n",
    "    test_results['Text OOV'][name] = average_oov(dong_test, word_list, whole_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Target OOV</th>\n",
       "      <th>Target OOV</th>\n",
       "      <th>Average Text OOV</th>\n",
       "      <th>Text OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSWE</th>\n",
       "      <td>1.13</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.25</td>\n",
       "      <td>46.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove</th>\n",
       "      <td>2.02</td>\n",
       "      <td>3.76</td>\n",
       "      <td>9.02</td>\n",
       "      <td>78.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Target OOV  Target OOV  Average Text OOV  Text OOV\n",
       "SSWE                 1.13        2.02              4.25     46.97\n",
       "Glove                2.02        3.76              9.02     78.76"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_test_results = (test_results * 100).astype(float).round(2)\n",
    "rounded_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above the number of OOV words in the SSWE is far fewer than the Glove vectors, espically for the number of texts that have no OOV words at all. However from what we can see from the result it would appear that the TCLSTM and TDLSTM require as few OOV words in the Target text as possible to make them work better than a sentence level classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
