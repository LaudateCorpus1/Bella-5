{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import random as rn\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras import initializers, optimizers\n",
    "\n",
    "from bella.data_types import TargetCollection, Target\n",
    "# Notebook helper methods\n",
    "from bella import notebook_helper\n",
    "# Models\n",
    "from bella.models.tdlstm import LSTM, TDLSTM, TCLSTM\n",
    "# Tokenisers\n",
    "from bella.tokenisers import ark_twokenize\n",
    "# Word Vectors\n",
    "from bella.word_vectors import SSWE, GloveTwitterVectors, GloveCommonCrawl\n",
    "# Get the data\n",
    "from bella.helper import read_config\n",
    "from bella.parsers import dong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#  ADD YOUR CONFIG FILE PATH HERE \n",
    "##\n",
    "CONFIG_FP = Path('..', 'config.yaml')\n",
    "\n",
    "results_folder = Path(read_config('results_folder', CONFIG_FP))\n",
    "results_folder = results_folder.joinpath('TDLstm')\n",
    "\n",
    "# Load the datasets\n",
    "dong_train = dong(read_config('dong_twit_train_data', CONFIG_FP))\n",
    "dong_test = dong(read_config('dong_twit_test_data', CONFIG_FP))\n",
    "\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "data = np.asarray(dong_train.data_dict())\n",
    "sentiment = np.asarray(dong_train.sentiment_data())\n",
    "for train_indexs, test_indexs in splitter.split(data, sentiment):\n",
    "    train_data = data[train_indexs]\n",
    "    test_data = data[test_indexs]\n",
    "    \n",
    "convert_to_targets = lambda data: [Target(**target) for target in data]\n",
    "dong_train = TargetCollection(convert_to_targets(train_data))\n",
    "dong_val = TargetCollection(convert_to_targets(test_data))\n",
    "\n",
    "X_train = np.array(dong_train.data_dict())\n",
    "y_train = np.array(dong_train.sentiment_data())\n",
    "X_val = np.array(dong_val.data_dict())\n",
    "y_val = np.array(dong_val.sentiment_data())\n",
    "# The models do not accepts class labels that are less than 0\n",
    "sent_vals = {-1: 0, 0: 1, 1: 2}\n",
    "sent_vals_inv = {0: -1, 1: 0, 2: 1}\n",
    "y_val = np.array([sent_vals[val] for val in y_val])\n",
    "y_train = np.array([sent_vals[val] for val in y_train])\n",
    "\n",
    "X_test = dong_test.data_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the words from the train and test data so that we \n",
    "# can filter words from the Word Vectors so that all the \n",
    "# word vectors can be loaded into reasonable amount of memory\n",
    "train_words = dong_train.word_list(ark_twokenize)\n",
    "val_words = dong_val.word_list(ark_twokenize)\n",
    "test_words = dong_test.word_list(ark_twokenize)\n",
    "all_words = list(set(train_words + val_words + test_words))\n",
    "# Load the word vectors\n",
    "sswe = SSWE(filter_words=all_words)\n",
    "glove_50 = GloveTwitterVectors(50, filter_words=all_words)\n",
    "glove_100 = GloveTwitterVectors(100, filter_words=all_words)\n",
    "glove_200 = GloveTwitterVectors(200, filter_words=all_words)\n",
    "word_vectors = [sswe, glove_50, glove_100, glove_200]\n",
    "n_cpus = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_class, model_kwargs, word_vectors, result_folder, random_values):\n",
    "    for word_vector in word_vectors:\n",
    "        model = model_class(ark_twokenize, word_vector, **model_kwargs)\n",
    "        model_result_folder = result_folder.joinpath(f'{str(model)}')\n",
    "        model_result_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        word_vector_fp = model_result_folder.joinpath(f'{str(model)} {str(word_vector)} '\n",
    "                                                      'Repeated Results.json')\n",
    "        predictions = model.evaluate_parameters(model, (X_train, y_train), (X_val, y_val), \n",
    "                                                X_test, 'reproducible', random_values, n_cpus)\n",
    "        predictions = [(random_value, prediction.tolist()) \n",
    "                       for random_value, prediction in predictions]\n",
    "        with word_vector_fp.open('w') as word_vector_file:\n",
    "            json.dump(predictions, word_vector_file)\n",
    "        \n",
    "\n",
    "uniform_init = initializers.RandomUniform(minval=-0.003, maxval=0.003)\n",
    "lstm_layer_kwargs = {'kernel_initializer' : uniform_init,\n",
    "                     'recurrent_initializer' : uniform_init,\n",
    "                     'bias_initializer' : uniform_init}\n",
    "dense_layer_kwargs = {'kernel_initializer' : uniform_init,\n",
    "                      'bias_initializer' : uniform_init}\n",
    "embedding_layer_kwargs = {'embeddings_initializer' : uniform_init}\n",
    "model_kwargs = {'lstm_layer_kwargs': lstm_layer_kwargs,\n",
    "                'dense_layer_kwargs': dense_layer_kwargs,\n",
    "                'embedding_layer_kwargs': embedding_layer_kwargs,\n",
    "                'optimiser': optimizers.SGD,\n",
    "                'optimiser_params': {'lr': 0.01}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing LSTM for the effect of validation set variation\n",
    "\n",
    "In this notebook we show the effect of change in train and validation set with respect to training the 3 LSTM based models that [Tang et al.](https://www.aclweb.org/anthology/C16-1311) presented in his paper and show how close our implementation of his models come compared to the results stated in their paper. The models that they created are the following:\n",
    "\n",
    "1. **LSTM** - Standard single layered LSTM where the hidden layer output is equal to the size of the input vector dimensions e.g. if the words vectors are 50 dimensions in size then the LSTM hidden state and output is 50 dimensions.\n",
    "2. **TDLSTM** - Target Dependent LSTM. This consists of 2 LSTMs either side of the target word that the sentiment is with respect to. The Left LSTM reads words in from left to right and goes up to the last word in the target word. The right LSTM reads words right to left and goes up to the last word in the target word as well. Again the LSTM hidden state and output is the same as the dimension of the input.\n",
    "3. **TCLSTM** - Target Context LSTM is the same as the TDLSTM but the input instead of being just the word vectors it reads in and word vectors are concatenated with the vector representation of the target word. If the target word is multiple words then it is the average of those word vectors.\n",
    "\n",
    "The names of these models are direct matches to the class names that represent these models in our code base.\n",
    "\n",
    "In [Tang et al.](https://www.aclweb.org/anthology/C16-1311) paper they never state the number of Epochs that they train for and instead of guessing the number we decided to use Early Stopping to find the optimal number of Epochs to train for.\n",
    "\n",
    "However using Early Stopping comes with other drawbacks. As the dataset that they used for this paper (and all of the other datasets we look at) does not contain a validation set we have to create a train and validation set from the original training data. **We show in this notebook the effect of randomly splitting the training dataset into train and validation sets on the models result and how close we can reproduce the results of Tang et al.**\n",
    "\n",
    "**NOTE** The splitting is not quiet random we use Strattified splitting therefore keeping the dataset representative with respect to the labels.\n",
    "\n",
    "\n",
    "### Dataset used\n",
    "\n",
    "The dataset we use is the same as [Tang et al.](https://www.aclweb.org/anthology/C16-1311) used in their paper which is [Dong et al](https://aclanthology.coli.uni-saarland.de/papers/P14-2009/p14-2009) Twitter dataset which is a general domain dataset.\n",
    "\n",
    "### Word vectors used\n",
    "\n",
    "We use the same word vectors as those shown in the paper apart from the SSWE-h and SSWE-r which we could not find, the *SSWE-u* is the equivalent to *SSWE* in our code base. We got the *SSWE* word vectors from the following [code base](https://github.com/bluemonk482/tdparse) and the Gove Twitter vectors from [here](https://nlp.stanford.edu/projects/glove/). However in our code base the word vectors will download automatically and then be saved without your user directory under the directory `.Bella`\n",
    "\n",
    "### The experiment\n",
    "\n",
    "Below we run each of the 3 models 30 times with different random strattified splitting and then repeat this for each word vector. **THIS TAKES A LONG TIME** therefore we have saved all of the result and if you would like to repeat the experiments set *re_write* to True\n",
    "\n",
    "**Last Note on configurations** The pad size parameter that has to be set for each model this states how many words our LSTM model takes into accout. Setting it to -1 means that we use the length of the largest sentence (tweet) in the training set which is what was stated in the paper.\n",
    "\n",
    "#### LSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(42)\n",
    "random_values = [int(rn.uniform(0, 1000)) for i in range(30)] \n",
    "evaluate_model(LSTM, model_kwargs, word_vectors, results_folder, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TDLSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(42)\n",
    "random_values = [int(rn.uniform(0, 1000)) for i in range(30)] \n",
    "evaluate_model(TDLSTM, model_kwargs, word_vectors, results_folder, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TCLSTM Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn.seed(42)\n",
    "random_values = [int(rn.uniform(0, 1000)) for i in range(30)] \n",
    "evaluate_model(TCLSTM, model_kwargs, word_vectors, results_folder, random_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the evaluations\n",
    "\n",
    "Now we have all of the data saved in the respective result files we shall analysis it to see how much the results vary and how close we get to the result stated in Tang et al. paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAElCAYAAADp4+XfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb90c1084e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_folder = {'lstm' : lstm_result_folder, 'tdlstm' : tdlstm_result_folder,\n",
    "                'tclstm' : tclstm_result_folder}\n",
    "model_word_vector_results = pd.DataFrame()\n",
    "\n",
    "# Original results inputted first and then add the result we found\n",
    "mean_glove_200_results = {'LSTM' : [64.7], 'TDLSTM' : [69.0], 'TCLSTM' : [69.5]}\n",
    "\n",
    "word_vector_type = []\n",
    "word_vector_results = []\n",
    "model_result = []\n",
    "word_vector_names = ['{}'.format(word_vector) for word_vector in word_vectors]\n",
    "for model, folder in model_folder.items():\n",
    "    \n",
    "    for word_vector_name in word_vector_names:\n",
    "        result_file = f'{str(model).upper()} {word_vector_name} Pad Size {pad_size} Repeated Results.json'\n",
    "        if model == 'lstm':\n",
    "            result_file = f'{str(model).upper()} {word_vector_name} Repeated Results.json'\n",
    "        result_file = os.path.join(folder, result_file)\n",
    "        results = notebook_helper.get_json_data(result_file, 'Dong Twitter')\n",
    "        num_results = len(results)\n",
    "        word_vector_results.extend(results)\n",
    "        \n",
    "        if word_vector_name == 'glove twitter 200d':\n",
    "            mean_glove_200_results[model.upper()].append(np.array(results).mean() * 100)\n",
    "        \n",
    "        if word_vector_name == 'sswe':\n",
    "            word_vector_name = 'SSWE'\n",
    "            word_vector_type.extend([word_vector_name] * num_results)\n",
    "        else:\n",
    "            word_vector_type.extend([word_vector_name.capitalize()] * num_results)\n",
    "        model_result.extend([model.upper()] * num_results)\n",
    "\n",
    "model_word_vector_results['Macro F1 Score'] = np.array(word_vector_results) * 100\n",
    "model_word_vector_results['Model'] =  model_result\n",
    "model_word_vector_results['Word Vector'] = word_vector_type\n",
    "\n",
    "#model_word_vector_results.columns = columns\n",
    "model_word_vector_results\n",
    "ax = sns.boxplot(x=\"Model\", y=\"Macro F1 Score\", hue=\"Word Vector\", \n",
    "                 data=model_word_vector_results, palette='BuGn')\n",
    "ax.figure.set_size_inches(6,3.9)\n",
    "leg = ax.legend(loc=9, bbox_to_anchor=(0.5, -0.12), ncol=2)\n",
    "ax.figure.savefig('TDLSTM dist results.png', bbox_extra_artists=(leg,), bbox_inches='tight', dpi=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above the results vary by quiet a lot but interestingly the LSTM method performed the best which is a different result to the original paper which states that the LSTM method performs worse than all of the other models. \n",
    "\n",
    "The TCLSTM method performs better than the TDLSTM for the SSWE and the 200D Glove Twitter vectors.\n",
    "\n",
    "The order of the word vectors remains the same to the original paper when using the LSTM method. However the TD(TC)LSTM methods found the SSWE word vectors the best. We believe this could be due to the SSWE embedding having fewer OOV words than the Glove Twitter vectors even though they were originally trained on the same type of data (Twitter) they could have come from different domains. \n",
    "\n",
    "We can see all of the model tend to vary a lot and are therefore quiet suseptiable to change in training and validation splitting. However we can see that as the word vector size increase the amount the result deviate reduces. This result shows without specifying a Training and Validation split it is very difficult to reproduce the results of an experiment. Furthermore as you can see we never reach the values reported in the original paper thus leaving us in the dark on how they produced those results.\n",
    "\n",
    "### Overall results\n",
    "\n",
    "Below we show the mean values of the repeated experiments above and state these as our reported results and compared them to the original results from Tang et al paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM</th>\n",
       "      <th>TCLSTM</th>\n",
       "      <th>TDLSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original</th>\n",
       "      <td>64.7</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reproduced</th>\n",
       "      <td>61.4</td>\n",
       "      <td>58.7</td>\n",
       "      <td>58.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            LSTM  TCLSTM  TDLSTM\n",
       "Original    64.7    69.5    69.0\n",
       "Reproduced  61.4    58.7    58.2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_glove_200_results, index=['Original', 'Reproduced']).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Here we are going to look at the number of Out Of Vocabularly (OOV) words the different word vectors have for the sentence text and target text for each sample in the Dong Twitter dataset. Just as a reminder that the LSTM only takes into account the sentence text and not the target text of which the sentiment is with respect to.\n",
    "\n",
    "For the Glove Twitter vectors as they were trained on the same text we look at them as a group rather than indivdually as each one would have the same result. Therefore below we are only going to compare Glove Twitter to SSWE vectors.\n",
    "\n",
    "Below are some handy functions to calculate the OOV stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_target_oov(target_data, word_list, tokenizer=ark_twokenize, whole_target=False):\n",
    "    all_oov_count = []\n",
    "    target_words_list = [ark_twokenize(data['target'].lower()) for data in target_data.data()]\n",
    "    for target_words in target_words_list:\n",
    "        count = 0\n",
    "        oov_count = 0\n",
    "        for word in target_words:\n",
    "            if word not in word_list:\n",
    "                oov_count += 1\n",
    "            count += 1\n",
    "        average_oov = oov_count / count\n",
    "        if whole_target:\n",
    "            all_oov_count.append(math.ceil(average_oov))\n",
    "        else:\n",
    "            all_oov_count.append(average_oov)\n",
    "    return sum(all_oov_count) / len(all_oov_count)\n",
    "\n",
    "def average_oov(target_data, word_list, tokenizer=ark_twokenize, whole_text=False):\n",
    "    all_oov_count = []\n",
    "    words_list = [ark_twokenize(data['text'].lower()) for data in target_data.data()]\n",
    "    for words in words_list:\n",
    "        count = 0\n",
    "        oov_count = 0\n",
    "        for word in words:\n",
    "            if word not in word_list:\n",
    "                oov_count += 1\n",
    "            count += 1\n",
    "        average_oov = oov_count / count\n",
    "        if whole_text:\n",
    "            all_oov_count.append(math.ceil(average_oov))\n",
    "        else:\n",
    "            all_oov_count.append(average_oov)\n",
    "    return sum(all_oov_count) / len(all_oov_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_word_list = [('SSWE', sswe._word_list), ('Glove', glove_200._word_list)]\n",
    "train_results = pd.DataFrame(columns=['Average Target OOV', 'Target OOV', \n",
    "                                      'Average Text OOV', 'Text OOV'],\n",
    "                             index=['SSWE', 'Glove'])\n",
    "for name, word_list in name_word_list:\n",
    "    train_results['Average Target OOV'][name] = avg_target_oov(dong_train, word_list)\n",
    "    train_results['Target OOV'][name] = avg_target_oov(dong_train, word_list, whole_target=True)\n",
    "    train_results['Average Text OOV'][name] = average_oov(dong_train, word_list)\n",
    "    train_results['Text OOV'][name] = average_oov(dong_train, word_list, whole_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Target OOV</th>\n",
       "      <th>Target OOV</th>\n",
       "      <th>Average Text OOV</th>\n",
       "      <th>Text OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSWE</th>\n",
       "      <td>1.15</td>\n",
       "      <td>2.06</td>\n",
       "      <td>4.24</td>\n",
       "      <td>47.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove</th>\n",
       "      <td>1.49</td>\n",
       "      <td>2.88</td>\n",
       "      <td>9.22</td>\n",
       "      <td>78.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Target OOV  Target OOV  Average Text OOV  Text OOV\n",
       "SSWE                 1.15        2.06              4.24     47.81\n",
       "Glove                1.49        2.88              9.22     78.89"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_train_results = (train_results * 100).astype(float).round(2)\n",
    "rounded_train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_word_list = [('SSWE', sswe._word_list), ('Glove', glove_200._word_list)]\n",
    "test_results = pd.DataFrame(columns=['Average Target OOV', 'Target OOV', \n",
    "                                     'Average Text OOV', 'Text OOV'],\n",
    "                            index=['SSWE', 'Glove'])\n",
    "for name, word_list in name_word_list:\n",
    "    test_results['Average Target OOV'][name] = avg_target_oov(dong_test, word_list)\n",
    "    test_results['Target OOV'][name] = avg_target_oov(dong_test, word_list, whole_target=True)\n",
    "    test_results['Average Text OOV'][name] = average_oov(dong_test, word_list)\n",
    "    test_results['Text OOV'][name] = average_oov(dong_test, word_list, whole_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Target OOV</th>\n",
       "      <th>Target OOV</th>\n",
       "      <th>Average Text OOV</th>\n",
       "      <th>Text OOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SSWE</th>\n",
       "      <td>1.13</td>\n",
       "      <td>2.02</td>\n",
       "      <td>4.25</td>\n",
       "      <td>46.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove</th>\n",
       "      <td>2.02</td>\n",
       "      <td>3.76</td>\n",
       "      <td>9.02</td>\n",
       "      <td>78.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Average Target OOV  Target OOV  Average Text OOV  Text OOV\n",
       "SSWE                 1.13        2.02              4.25     46.97\n",
       "Glove                2.02        3.76              9.02     78.76"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rounded_test_results = (test_results * 100).astype(float).round(2)\n",
    "rounded_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above the number of OOV words in the SSWE is far fewer than the Glove vectors, espically for the number of texts that have no OOV words at all. However from what we can see from the result it would appear that the TCLSTM and TDLSTM require as few OOV words in the Target text as possible to make them work better than a sentence level classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
