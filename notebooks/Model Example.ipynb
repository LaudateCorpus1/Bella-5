{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from bella.parsers import semeval_14\n",
    "from bella.helper import read_config\n",
    "from bella.tokenisers import ark_twokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use the pre-trained models\n",
    "\n",
    "A lot of the models trained in the model zoo took a long time to train espically the Neural Network models which include LSTM, TDLSTM, and TCLSTM. In this notebook we are going to show you how to:\n",
    "1. Load the models\n",
    "2. Use the models to predict on some of the test data\n",
    "\n",
    "First we need the path to the model zoo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TCLSTM Election Twitter weights',\n",
       " 'TDParse Mitchel',\n",
       " 'LSTM Dong Twitter weights',\n",
       " 'TDParse SemEval 14 Laptop',\n",
       " 'TCLSTM SemEval 14 Restaurant weights',\n",
       " 'TDLSTM SemEval 14 Restaurant weights',\n",
       " 'TDLSTM SemEval 14 Restaurant architecture',\n",
       " 'TDParse Plus YouTuBean',\n",
       " 'LSTM SemEval 14 Restaurant weights',\n",
       " 'Target Dependent Dong Twitter',\n",
       " 'Target Dependent Plus Mitchel',\n",
       " 'TDParse Election Twitter',\n",
       " 'LSTM YouTuBean weights',\n",
       " 'TDParse Plus Mitchel',\n",
       " 'TDParse Plus SemEval 14 Laptop',\n",
       " 'TDLSTM Mitchel weights',\n",
       " 'TCLSTM YouTuBean architecture',\n",
       " 'Target Dependent Mitchel',\n",
       " 'Target Dependent Plus SemEval 14 Laptop',\n",
       " 'TCLSTM YouTuBean weights',\n",
       " 'LSTM Mitchel architecture',\n",
       " 'TDLSTM YouTuBean weights',\n",
       " 'TDLSTM Mitchel architecture',\n",
       " 'TDParse Plus Election Twitter',\n",
       " 'Target Dependent Plus SemEval 14 Restaurant',\n",
       " 'Target Dependent SemEval 14 Laptop',\n",
       " 'Target Dependent Plus YouTuBean',\n",
       " 'LSTM YouTuBean architecture',\n",
       " 'TDParse Plus Dong Twitter',\n",
       " 'TCLSTM Dong Twitter architecture',\n",
       " 'Target Dependent Election Twitter',\n",
       " 'LSTM Election Twitter weights',\n",
       " 'Target Dependent SemEval 14 Restaurant',\n",
       " 'TCLSTM Mitchel architecture',\n",
       " 'TDLSTM Election Twitter architecture',\n",
       " 'TDLSTM Dong Twitter architecture',\n",
       " 'TDLSTM Election Twitter weights',\n",
       " 'LSTM Mitchel weights',\n",
       " 'TDLSTM SemEval 14 Laptop weights',\n",
       " 'TCLSTM SemEval 14 Restaurant architecture',\n",
       " 'TDParse Plus SemEval 14 Restaurant',\n",
       " 'TCLSTM SemEval 14 Laptop architecture',\n",
       " 'LSTM Dong Twitter architecture',\n",
       " 'LSTM Election Twitter architecture',\n",
       " 'TDParse Dong Twitter',\n",
       " 'TCLSTM Dong Twitter weights',\n",
       " 'TDLSTM Dong Twitter weights',\n",
       " 'Target Dependent Plus Dong Twitter',\n",
       " 'LSTM SemEval 14 Restaurant architecture',\n",
       " 'TDLSTM SemEval 14 Laptop architecture',\n",
       " 'TDParse YouTuBean',\n",
       " 'Target Dependent Plus Election Twitter',\n",
       " 'TDLSTM YouTuBean architecture',\n",
       " 'TDParse SemEval 14 Restaurant',\n",
       " 'Target Dependent YouTuBean',\n",
       " 'TCLSTM SemEval 14 Laptop weights',\n",
       " 'LSTM SemEval 14 Laptop architecture',\n",
       " 'TCLSTM Election Twitter architecture',\n",
       " 'LSTM SemEval 14 Laptop weights',\n",
       " 'TCLSTM Mitchel weights']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change this to the directory of your model zoo\n",
    "model_zoo_dir = os.path.abspath('../model zoo')\n",
    "os.listdir(model_zoo_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the model zoo you should be able to see the list of models as shown above. The models in there can be broken up into different methods which are the following: 1. Target Dependent, 2. Target Dependent Plus, 3. TDParse, 4. TDParse Plus, 5. LSTM, 6. TDLSTM, 7. TCLSTM. Each one of these methods was trained on the datasets which can be found in the [Dataset notebook](./datasets.ipynb). Therefore we have a model for each method on each dataset, if you would like to see how these models were trained look at the following Mass Evaluation notebooks: 1. [Target Dependent methods](./Mass Evaluation - Target Dependent.ipynb), 2. [TDParse methods](./Mass Evaluation - TDParse.ipynb), 3. [LSTM methods](./Mass Evaluation LSTM.ipynb)\n",
    "\n",
    "We are going to show how to load a model from each of the methods on the [SemEval 2014 Resturant dataset](http://alt.qcri.org/semeval2014/task4/index.php?id=data-and-tools).\n",
    "\n",
    "We are going to load one model at a time as each model can take:\n",
    "1. A long time to load\n",
    "2. Take up a lot of memory\n",
    "\n",
    "For each model we will:\n",
    "1. Load it\n",
    "2. Predict the sentiment of the test data on the SemEval 2014 Resturant dataset\n",
    "3. Evaluate the performance using Accuracy and Macro F1 score.\n",
    "\n",
    "But before going through each model we need to load the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FP = Path('..', 'config.yaml')\n",
    "\n",
    "train_data = semeval_14(read_config('semeval_2014_rest_train', CONFIG_FP))\n",
    "test_data = semeval_14(read_config('semeval_2014_rest_test', CONFIG_FP))\n",
    "y_test = test_data.sentiment_data()\n",
    "# Need to load the word vectors that were used to train the LSTM models \n",
    "# therefore we need to filter the word vectors down to only the train and test \n",
    "# dataset words as these were used during training the model because if you \n",
    "# load the word vectors whole it will use a lot of memory up to ~6GB\n",
    "train_words = train_data.word_list(ark_twokenize)\n",
    "test_words = test_data.word_list(ark_twokenize)\n",
    "all_words = train_words + test_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the test data has been loaded all the cells grouped by models can be run independently.\n",
    "\n",
    "## Target Dependent and Target Dependent Plus Models\n",
    "\n",
    "These two methods come from [Vo and Zhang's paper](https://www.ijcai.org/Proceedings/15/Papers/194.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/andrew/Desktop/Bella/model zoo/Target Dependent SemEval 14 Restaurant\n",
      "Model successfully loaded. Load time 0.63\n",
      "Target Dependent scores:\n",
      "Macro F1 score: 56.15868320061148\n",
      "Accuracy: 73.83928571428572\n"
     ]
    }
   ],
   "source": [
    "from bella.models.target import TargetDep\n",
    "\n",
    "target_dep = TargetDep()\n",
    "model_path = [model_zoo_dir, \n",
    "              'Target Dependent SemEval 14 Restaurant']\n",
    "target_dep_model_path = os.path.join(*model_path)\n",
    "# Loads the model\n",
    "target_dep.load_model(target_dep_model_path, verbose=1)\n",
    "# Predicts the class on the test data\n",
    "target_dep_preds = target_dep.predict(test_data.data())\n",
    "# Evaluates the results\n",
    "target_dep_f1 = f1_score(y_test, target_dep_preds, average='macro')\n",
    "target_dep_acc = accuracy_score(y_test, target_dep_preds)\n",
    "print('Target Dependent scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(target_dep_f1 * 100, target_dep_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/andrew/Desktop/Bella/model zoo/Target Dependent Plus SemEval 14 Restaurant\n",
      "Model successfully loaded. Load time 0.69\n",
      "Target Dependent Plus scores:\n",
      "Macro F1 score: 57.71114226900386\n",
      "Accuracy: 74.64285714285714\n"
     ]
    }
   ],
   "source": [
    "from bella.models.target import TargetDepSent\n",
    "\n",
    "target_dep_plus = TargetDepSent()\n",
    "model_path = [model_zoo_dir, \n",
    "              'Target Dependent Plus SemEval 14 Restaurant']\n",
    "target_dep_plus_model_path = os.path.join(*model_path)\n",
    "# Loads the model\n",
    "target_dep_plus.load_model(target_dep_plus_model_path, verbose=1)\n",
    "# Predicts the class on the test data\n",
    "target_dep_plus_preds = target_dep_plus.predict(test_data.data())\n",
    "# Evaluates the results\n",
    "target_dep_plus_f1 = f1_score(y_test, target_dep_plus_preds, average='macro')\n",
    "target_dep_plus_acc = accuracy_score(y_test, target_dep_plus_preds)\n",
    "print('Target Dependent Plus scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(target_dep_plus_f1 * 100, target_dep_plus_acc * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TDParse and TDParse Plus Models\n",
    "\n",
    "These two methods come from [Wang et al.'s paper](https://www.aclweb.org/anthology/E17-1046). Just a note that these models use the Tweebo dependency parser. If they are not working this could be due to Tweebo not being installed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/andrew/Desktop/Bella/model zoo/TDParse SemEval 14 Restaurant\n",
      "Model successfully loaded. Load time 0.69\n",
      "TDParse scores:\n",
      "Macro F1 score: 59.49185457979117\n",
      "Accuracy: 73.39285714285714\n"
     ]
    }
   ],
   "source": [
    "from bella.models.tdparse import TDParse\n",
    "\n",
    "tdparse = TDParse()\n",
    "model_path = [model_zoo_dir, \n",
    "              'TDParse SemEval 14 Restaurant']\n",
    "tdparse_model_path = os.path.join(*model_path)\n",
    "# Loads the model\n",
    "tdparse.load_model(tdparse_model_path, verbose=1)\n",
    "# Predicts the class on the test data\n",
    "tdparse_preds = tdparse.predict(test_data.data())\n",
    "# Evaluates the results\n",
    "tdparse_f1 = f1_score(y_test, tdparse_preds, average='macro')\n",
    "tdparse_acc = accuracy_score(y_test, tdparse_preds)\n",
    "print('TDParse scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(tdparse_f1 * 100, tdparse_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from /home/andrew/Desktop/Bella/model zoo/TDParse Plus SemEval 14 Restaurant\n",
      "Model successfully loaded. Load time 0.7\n",
      "TDParse Plus scores:\n",
      "Macro F1 score: 60.979583726818774\n",
      "Accuracy: 76.16071428571428\n"
     ]
    }
   ],
   "source": [
    "from bella.models.tdparse import TDParsePlus\n",
    "\n",
    "tdparse_plus = TDParsePlus()\n",
    "model_path = [model_zoo_dir, \n",
    "              'TDParse Plus SemEval 14 Restaurant']\n",
    "tdparse_plus_model_path = os.path.join(*model_path)\n",
    "# Loads the model\n",
    "tdparse_plus.load_model(tdparse_plus_model_path, verbose=1)\n",
    "# Predicts the class on the test data\n",
    "tdparse_plus_preds = tdparse_plus.predict(test_data.data())\n",
    "# Evaluates the results\n",
    "tdparse_plus_f1 = f1_score(y_test, tdparse_plus_preds, average='macro')\n",
    "tdparse_plus_acc = accuracy_score(y_test, tdparse_plus_preds)\n",
    "print('TDParse Plus scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(tdparse_plus_f1 * 100, tdparse_plus_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM, TDLSTM and TCLSTM Models\n",
    "\n",
    "These three methods come from [Tang et al.'s paper](https://aclweb.org/anthology/C16-1311). These models do require you knowing what embeddings they were trained on, this can only be done currently by looking at the relevent methods word vector results file e.g. for the LSTM method the word vector results file can be found [here](../results/TDLstm/lstm/word vector results.json). **NOTE** all the methods were trained using the Ark Tokeniser which is a Twitter specific tokeniser and all words lower cased\n",
    "\n",
    "**NOTE** Padding value when loading the word vectors means that when converting words into word vectors if there is a word that is not in the word embedding it gets that embedding value of <unk> which in the case of SSWE has been learnt and the value of the padding vectors will be equal to the Padding value. If this is not set then the value of the unknown vectors will be used for both padding and unknown words. **We are not in this case going to use the padding value as we did not use it while training the networks**\n",
    "    \n",
    "All the neural network models require two file paths: \n",
    "1. To the network architecture\n",
    "2. To the network's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture loaded /home/andrew/Desktop/Bella/model zoo/LSTM SemEval 14 Restaurant architecture\n",
      "Model weights loaded /home/andrew/Desktop/Bella/model zoo/LSTM SemEval 14 Restaurant weights\n",
      "Load time 0.29\n",
      "LSTM scores:\n",
      "Macro F1 score: 48.7152129456744\n",
      "Accuracy: 73.30357142857142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/Envs/Bella/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from bella.models.tdlstm import LSTM\n",
    "from bella.word_vectors import SSWE\n",
    "\n",
    "# Load the SSWE word vector\n",
    "sswe = SSWE(filter_words=all_words)\n",
    "\n",
    "lstm = LSTM(tokeniser=ark_twokenize, embeddings=sswe, lower=True)\n",
    "model_arch_path = [model_zoo_dir, \n",
    "                   'LSTM SemEval 14 Restaurant architecture']\n",
    "model_weights_path = [model_zoo_dir, \n",
    "                      'LSTM SemEval 14 Restaurant weights']\n",
    "# Loads the model\n",
    "lstm.load_model(model_arch_fp=os.path.join(*model_arch_path), \n",
    "                model_weights_fp=os.path.join(*model_weights_path), \n",
    "                verbose=1)\n",
    "lstm.test_pad_size = 78\n",
    "# Predicts the class on the test data\n",
    "sentiment_mapper = {0 : 0, 1 : 1, 2 : -1}\n",
    "\n",
    "lstm_preds = lstm.predict(test_data.data_dict())\n",
    "lstm_preds =  lstm.prediction_to_cats(y_test, lstm_preds, \n",
    "                                      mapper=sentiment_mapper)\n",
    "# Evaluates the results\n",
    "lstm_f1 = f1_score(y_test, lstm_preds, average='macro')\n",
    "lstm_acc = accuracy_score(y_test, lstm_preds)\n",
    "print('LSTM scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(lstm_f1 * 100, lstm_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove 300d 42b common crawl from file\n",
      "Model architecture loaded /home/andrew/Desktop/Bella/model zoo/TDLSTM SemEval 14 Restaurant architecture\n",
      "Model weights loaded /home/andrew/Desktop/Bella/model zoo/TDLSTM SemEval 14 Restaurant weights\n",
      "Load time 0.74\n",
      "TDLSTM scores:\n",
      "Macro F1 score: 59.833699184621736\n",
      "Accuracy: 74.46428571428572\n"
     ]
    }
   ],
   "source": [
    "from bella.models.tdlstm import TDLSTM\n",
    "from bella.word_vectors import GloveCommonCrawl\n",
    "\n",
    "# Load the Glove word vector\n",
    "glove_300 = GloveCommonCrawl(version=42, filter_words=all_words)\n",
    "\n",
    "tdlstm = TDLSTM(tokeniser=ark_twokenize, embeddings=glove_300, lower=True)\n",
    "model_arch_path = [model_zoo_dir, \n",
    "                   'TDLSTM SemEval 14 Restaurant architecture']\n",
    "model_weights_path = [model_zoo_dir, \n",
    "                      'TDLSTM SemEval 14 Restaurant weights']\n",
    "# Loads the model\n",
    "tdlstm.load_model(model_arch_fp=os.path.join(*model_arch_path), \n",
    "                  model_weights_fp=os.path.join(*model_weights_path), \n",
    "                  verbose=1)\n",
    "# Predicts the class on the test data\n",
    "sentiment_mapper = {0 : 0, 1 : 1, 2 : -1}\n",
    "\n",
    "tdlstm_preds = tdlstm.predict(test_data.data_dict())\n",
    "tdlstm_preds =  tdlstm.prediction_to_cats(y_test, tdlstm_preds, \n",
    "                                          mapper=sentiment_mapper)\n",
    "# Evaluates the results\n",
    "tdlstm_f1 = f1_score(y_test, tdlstm_preds, average='macro')\n",
    "tdlstm_acc = accuracy_score(y_test, tdlstm_preds)\n",
    "print('TDLSTM scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(tdlstm_f1 * 100, tdlstm_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove 300d 42b common crawl from file\n",
      "Model architecture loaded /home/andrew/Desktop/Bella/model zoo/TCLSTM SemEval 14 Restaurant architecture\n",
      "Model weights loaded /home/andrew/Desktop/Bella/model zoo/TCLSTM SemEval 14 Restaurant weights\n",
      "Load time 2.04\n",
      "TCLSTM scores:\n",
      "Macro F1 score: 49.58447514820157\n",
      "Accuracy: 68.39285714285714\n"
     ]
    }
   ],
   "source": [
    "from bella.models.tdlstm import TCLSTM\n",
    "from bella.word_vectors import GloveCommonCrawl\n",
    "\n",
    "# Load the Glove word vector\n",
    "glove_300 = GloveCommonCrawl(version=42, filter_words=all_words)\n",
    "\n",
    "tclstm = TCLSTM(tokeniser=ark_twokenize, embeddings=glove_300, lower=True)\n",
    "model_arch_path = [model_zoo_dir, \n",
    "                   'TCLSTM SemEval 14 Restaurant architecture']\n",
    "model_weights_path = [model_zoo_dir, \n",
    "                      'TCLSTM SemEval 14 Restaurant weights']\n",
    "# Loads the model\n",
    "tclstm.load_model(model_arch_fp=os.path.join(*model_arch_path), \n",
    "                        model_weights_fp=os.path.join(*model_weights_path), \n",
    "                        verbose=1)\n",
    "# Predicts the class on the test data\n",
    "sentiment_mapper = {0 : 0, 1 : 1, 2 : -1}\n",
    "\n",
    "tclstm_preds = tclstm.predict(test_data.data_dict())\n",
    "tclstm_preds =  tclstm.prediction_to_cats(y_test, tclstm_preds, \n",
    "                                                mapper=sentiment_mapper)\n",
    "# Evaluates the results\n",
    "tclstm_f1 = f1_score(y_test, tclstm_preds, average='macro')\n",
    "tclstm_acc = accuracy_score(y_test, tclstm_preds)\n",
    "print('TCLSTM scores:\\nMacro F1 score: {}\\n'\n",
    "      'Accuracy: {}'\n",
    "      .format(tclstm_f1 * 100, tclstm_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
