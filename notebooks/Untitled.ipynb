{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "a_path = str(Path('..').resolve())\n",
    "sys.path.insert(0, a_path)\n",
    "from bella.parsers import semeval_14\n",
    "from bella.preprocessing import tokeniser\n",
    "from bella.tokenisers import moses\n",
    "from bella.word_embeddings import GloveCommonEmbedding\n",
    "from bella.dataloaders import TargetSequence, LeftRightTargetSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_sem_dir = Path('..', '..', 'aspect datasets', 'semeval_2014')\n",
    "rest_train = semeval_14(Path(rest_sem_dir, 'restaurants_train.xml'))\n",
    "rest_test = semeval_14(Path(rest_sem_dir, 'restaurants_test.xml'))\n",
    "\n",
    "rest_train_fp, rest_dev_fp = rest_train.to_json_file(['restaurants train', 'restaurants dev'], \n",
    "                                                     0.2, cache=False, random_state=42)\n",
    "rest_test_fp = rest_test.to_json_file('restaurants test', cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = tokeniser(rest_train_fp, rest_dev_fp, rest_test_fp, \n",
    "                tokeniser_function=moses, \n",
    "                lower=True, filters='', oov_token='<UNK>')\n",
    "train_data = TargetSequence(rest_train_fp, 32, tok, moses)\n",
    "val_data = TargetSequence(rest_dev_fp, 32, tok, moses)\n",
    "\n",
    "glove_rest = GloveCommonEmbedding(840, tok.word_index)\n",
    "num_words, embedding_dim = glove_rest.embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target_data = LeftRightTargetSequence(rest_train_fp, 32, tok, moses)\n",
    "val_target_data = LeftRightTargetSequence(rest_dev_fp, 32, tok, moses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "class Average(Layer):\n",
    "    def __init__(self, mask_zero=True, **kwargs):\n",
    "        self.mask_zero = mask_zero\n",
    "        self.supports_masking = True\n",
    "        super(Average, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x = K.print_tensor(x, message=\"Value of mask\")\n",
    "        tf.Print(x, [x])\n",
    "        print(x)\n",
    "        mask = K.print_tensor(mask, message=\"Value of mask\")\n",
    "        print(mask)\n",
    "        if self.mask_zero:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            mask = K.expand_dims(mask)\n",
    "            x = x * mask\n",
    "            return K.sum(x, axis=1) / (K.sum(mask, axis=1) + K.epsilon())\n",
    "        else:\n",
    "            return K.mean(x, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def compute_mask(self, x, mask):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"average_25/Print:0\", shape=(?, ?, 300), dtype=float32)\n",
      "Tensor(\"average_25/Print_2:0\", shape=(?, ?), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Bidirectional, concatenate, Dense, TimeDistributed\n",
    "from keras.models import Model\n",
    "target_text_input = Input(batch_shape=(None, None), dtype='int32',\n",
    "                              name='target_text')\n",
    "target_embedding = Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
    "                             mask_zero=True, weights=[glove_rest.embedding], \n",
    "                             trainable=False, name='target_embedding')(target_text_input)\n",
    "average = Average()(target_embedding)\n",
    "out = Dense(3, activation='softmax')(average)\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=target_text_input, outputs=out)\n",
    "model.compile('adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_input = train_data[0][0][1]\n",
    "fun = K.function([model.layers[0].input],[model.layers[2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 9], dtype=int32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "\r",
      "1/1 [==============================] - 0s 79ms/step - loss: 1.3313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f54b014ae80>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=target_input[0:1], y=train_data[0][1][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  1.69799998e-02,  -2.80155018e-02,  -3.17294970e-02,\n",
       "          -1.85609013e-01,  -1.89264998e-01,   2.23354995e-01,\n",
       "          -3.69859993e-01,   1.31480008e-01,   1.11800998e-01,\n",
       "           1.18706501e+00,  -5.07764995e-01,   1.48595003e-02,\n",
       "          -6.45980000e-01,  -2.37771988e-01,   4.52085018e-01,\n",
       "          -2.33445004e-01,  -5.35239995e-01,   7.84284949e-01,\n",
       "           1.98040009e-01,  -1.86841503e-01,  -3.29239994e-01,\n",
       "          -9.70500037e-02,  -1.54610008e-01,   2.87600234e-03,\n",
       "           9.70600024e-02,  -6.95900023e-01,  -5.02749998e-03,\n",
       "          -1.33509994e-01,  -1.48579508e-01,  -8.21910024e-01,\n",
       "           2.16110006e-01,   1.95395008e-01,  -1.62875995e-01,\n",
       "          -4.64625001e-01,  -2.96939999e-01,   3.75808030e-01,\n",
       "           3.47629994e-01,   1.38065502e-01,  -2.68836021e-01,\n",
       "           1.19214997e-01,  -5.51974997e-02,   4.66300100e-02,\n",
       "           2.93199942e-02,   4.57815006e-02,   5.08894995e-02,\n",
       "           4.13325012e-01,  -1.58317998e-01,   5.65224998e-02,\n",
       "           1.80884991e-02,  -6.88555017e-02,  -2.61975005e-02,\n",
       "           7.96049982e-02,  -1.80878997e-01,   2.95745015e-01,\n",
       "           2.98835009e-01,  -7.54189968e-01,  -1.11284986e-01,\n",
       "          -2.08389997e-01,  -2.46283010e-01,  -8.49649981e-02,\n",
       "          -1.35895997e-01,  -2.58899927e-02,   3.43439996e-01,\n",
       "           3.79415005e-01,  -3.28235000e-01,   1.53995026e-02,\n",
       "           8.03624988e-02,   4.24834996e-01,  -1.71709493e-01,\n",
       "          -2.64964998e-01,  -3.27096999e-01,   7.57349968e-01,\n",
       "           5.36379993e-01,  -6.73020005e-01,   3.50849003e-01,\n",
       "           5.25065005e-01,   7.49825016e-02,   2.70879984e-01,\n",
       "          -5.06574988e-01,  -3.28105003e-01,  -4.45694983e-01,\n",
       "          -1.51127011e-01,  -1.66900009e-02,   3.08620501e-02,\n",
       "          -5.22119999e-01,  -2.01300010e-01,   8.28060031e-01,\n",
       "           1.15759993e+00,  -5.52700043e-01,  -9.79135036e-02,\n",
       "           4.29340005e-01,   1.51181504e-01,   3.32585007e-01,\n",
       "           3.89135003e-01,  -1.07246503e-01,   1.71745002e-01,\n",
       "          -1.27854005e-01,  -5.23599982e-01,  -3.76590014e-01,\n",
       "          -4.07799989e-01,  -1.14854999e-01,  -5.54749966e-02,\n",
       "          -4.52499986e-02,  -5.26820004e-01,  -5.67629993e-01,\n",
       "          -9.54249978e-01,   5.00594974e-01,  -4.06709999e-01,\n",
       "           7.39929974e-01,   1.02114998e-01,  -3.53069991e-01,\n",
       "          -2.23175004e-01,  -1.55539498e-01,   2.80369997e-01,\n",
       "           3.04345012e-01,   7.71849900e-02,  -6.30240023e-01,\n",
       "          -1.42607003e-01,   4.85550016e-02,   8.11965019e-02,\n",
       "           7.74824992e-02,   3.45389992e-01,  -3.51933509e-01,\n",
       "          -2.46680006e-01,   1.39225945e-01,  -2.34740004e-01,\n",
       "          -3.50279994e-02,   3.69080007e-01,   1.64604992e-01,\n",
       "           3.21420014e-01,   6.29549921e-02,  -5.41810036e-01,\n",
       "           3.06654990e-01,   2.53309995e-01,  -2.48305008e-01,\n",
       "          -1.52869999e-01,   2.98014998e-01,   2.20245004e-01,\n",
       "           3.29500437e-03,  -2.47934997e-01,  -1.98800004e+00,\n",
       "           2.91480005e-01,   4.21265006e-01,   6.81299865e-02,\n",
       "          -3.03899981e-02,   8.15539956e-02,  -4.03044999e-01,\n",
       "          -1.03628993e-01,   2.74309993e-01,  -3.08134973e-01,\n",
       "           1.75893009e-01,   2.81875014e-01,   4.90415007e-01,\n",
       "           7.70879984e-01,  -1.63105011e-01,  -9.32603478e-02,\n",
       "           2.59658992e-01,   1.21130005e-01,   1.27349943e-02,\n",
       "           4.96739984e-01,   4.70843501e-02,   6.38684988e-01,\n",
       "          -2.49791995e-01,  -3.78150046e-02,   4.53754961e-02,\n",
       "          -4.13334996e-01,  -1.34766400e-01,  -3.76130998e-01,\n",
       "          -1.50399998e-01,   8.49049985e-02,   2.13870004e-01,\n",
       "          -3.01865011e-01,  -1.65219992e-01,  -2.88999975e-02,\n",
       "          -5.69055021e-01,  -3.87189984e-01,   2.59389997e-01,\n",
       "          -4.43700016e-01,  -1.40767008e-01,  -5.29940009e-01,\n",
       "          -3.41772497e-01,  -6.28659964e-01,   8.91509503e-02,\n",
       "          -6.62549973e-01,   3.30164991e-02,   2.07585007e-01,\n",
       "           4.55610044e-02,   5.20910025e-01,   2.33319998e-01,\n",
       "           2.38999724e-03,  -5.40984988e-01,  -2.44894996e-01,\n",
       "          -2.40177900e-01,   9.72314999e-02,   1.65033996e-01,\n",
       "          -1.15192004e-01,   1.09849989e-01,   3.78854990e-01,\n",
       "           2.97625005e-01,  -2.31743991e-01,   1.69597000e-01,\n",
       "           2.36168995e-01,  -3.82584989e-01,  -5.55050001e-02,\n",
       "          -1.83058500e-01,   9.18399990e-02,   9.79845002e-02,\n",
       "           8.30650032e-02,   3.25374991e-01,  -1.64446011e-01,\n",
       "          -3.15549999e-01,   3.34704995e-01,   5.45854986e-01,\n",
       "          -7.83195049e-02,  -4.17879999e-01,  -1.35154501e-01,\n",
       "          -5.56500033e-02,  -1.31220013e-01,  -4.18294966e-01,\n",
       "           3.19804996e-01,  -6.42430007e-01,   1.19870007e-01,\n",
       "           1.83899999e-02,   4.28985000e-01,   1.23099983e-02,\n",
       "           2.51999944e-02,   1.32178500e-01,  -1.13396503e-01,\n",
       "          -4.30869997e-01,   3.53505015e-01,  -1.44758999e-01,\n",
       "          -3.29205006e-01,  -6.36699796e-03,  -2.01804996e-01,\n",
       "          -3.13315004e-01,  -2.59144992e-01,   7.82004952e-01,\n",
       "          -4.31025028e-01,   4.89960015e-01,  -1.31810009e-01,\n",
       "          -3.29894006e-01,   1.04911998e-01,  -4.59524989e-01,\n",
       "          -3.28819990e-01,  -8.73999670e-03,   1.35349005e-01,\n",
       "          -3.82650048e-02,   1.01180002e-03,  -5.43020010e-01,\n",
       "           6.14494979e-02,  -1.96254998e-01,  -3.44635010e-01,\n",
       "          -1.88649997e-01,   4.77864981e-01,  -2.36049995e-01,\n",
       "           4.35314506e-01,  -4.32794988e-01,   1.68787494e-01,\n",
       "          -1.34784989e-02,   5.43394983e-02,   9.36560035e-02,\n",
       "          -2.85750031e-02,  -7.19384998e-02,   6.27349973e-01,\n",
       "          -4.75350022e-02,   2.94748485e-01,   1.09290503e-01,\n",
       "           7.12485015e-01,  -4.78410006e-01,   3.81325006e-01,\n",
       "          -5.01754999e-01,   2.98029989e-01,  -5.77600040e-02,\n",
       "           1.25254989e-01,   3.08870018e-01,   7.14964986e-01,\n",
       "          -5.56524992e-02,   4.21929985e-01,   4.00054991e-01,\n",
       "           4.86663520e-01,   1.07567996e-01,  -1.68529496e-01,\n",
       "           2.21884996e-01,   1.73235491e-01,   3.82594988e-02,\n",
       "           2.59374976e-01,   7.05505013e-01,  -4.59054997e-03,\n",
       "          -3.16181004e-01,   3.80239993e-01,   4.37964976e-01,\n",
       "           8.60185027e-02,   2.78764993e-01,  -2.95674980e-01,\n",
       "           3.42100039e-02,  -7.97950029e-02,   1.15542009e-01,\n",
       "          -2.12785006e-01,  -7.19614998e-02,   2.49529988e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun([target_input[-1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[   0,    0,    0,    0,    9],\n",
       "         [   0,    0,    0, 3607,   85],\n",
       "         [   0,    0,    0,  282,   16],\n",
       "         [   0,    0,    0, 2289,   67],\n",
       "         [   0,    0,    0,   22,  248],\n",
       "         [   0,    0,    0,  204,   67],\n",
       "         [   0,    0,    0, 1035,   16],\n",
       "         [   0,    0,    0, 3919,   67],\n",
       "         [   0,    0,    0,   22,    9],\n",
       "         [   0,    0,    0,   22,    9],\n",
       "         [   0,    0,    0,    0, 4143],\n",
       "         [   0,    0,    0,  614, 4171],\n",
       "         [   0,    0,    0,    0,  207],\n",
       "         [   0,    0,    5,  162,   38],\n",
       "         [   0,   22,    2,  282,   16],\n",
       "         [   0,    0,    0,    0,   16],\n",
       "         [   0,    0,  106, 1057,  127],\n",
       "         [   0,    0,  111,    1, 2375],\n",
       "         [   0,    0,   78,  720,  248],\n",
       "         [   0,    0,  177,    1,    9],\n",
       "         [   0,    0,    0,    0,    9],\n",
       "         [   0,    0,  223, 3133,    9],\n",
       "         [   0,    0,   91,   19,   16],\n",
       "         [   0,    0,    0,   19,   85],\n",
       "         [   0,    0,    0,    0,   16],\n",
       "         [   0,    0,    0,    0,    9],\n",
       "         [   0,   26,  220,    1,   67],\n",
       "         [ 361,    2,  152,  100,   60],\n",
       "         [   0,    0,    0,    1, 1603],\n",
       "         [   0,    0,    0,    1,   16],\n",
       "         [   0,  377,    4,   83,   16],\n",
       "         [   0,   29,    1, 2334,  900]], dtype=int32),\n",
       "  array([[4012,    3,    0,    0],\n",
       "         [  85,   36,    0,    0],\n",
       "         [  16,    3,    0,    0],\n",
       "         [  67,    3,    0,    0],\n",
       "         [ 248,    3,    0,    0],\n",
       "         [  67,    3,    0,    0],\n",
       "         [  16,    3,    0,    0],\n",
       "         [  67,    3,    0,    0],\n",
       "         [   9,    3,    0,    0],\n",
       "         [   9,    3,    0,    0],\n",
       "         [4143,   56,   36,    0],\n",
       "         [4171,    3,    0,    0],\n",
       "         [ 207,   34,  292,    3],\n",
       "         [  38,   36,    0,    0],\n",
       "         [  16,    3,    0,    0],\n",
       "         [  16,    8,  377,    3],\n",
       "         [ 127,   36,    0,    0],\n",
       "         [2375,   36,    0,    0],\n",
       "         [ 248,    3,    0,    0],\n",
       "         [   9,    3,    0,    0],\n",
       "         [   9,    6,   55,    3],\n",
       "         [3133,    9,    3,    0],\n",
       "         [  16,   36,    0,    0],\n",
       "         [  85,  161,    3,    0],\n",
       "         [  16,    6,  173,    3],\n",
       "         [   9,    6,   19,    3],\n",
       "         [  67,    3,    0,    0],\n",
       "         [ 100,   60,    3,    0],\n",
       "         [1603,    6,  169,   36],\n",
       "         [  16,    8,  152,    3],\n",
       "         [  16,    3,    0,    0],\n",
       "         [2334,  900,    3,    0]], dtype=int32),\n",
       "  array([[   0,    9],\n",
       "         [   0,   85],\n",
       "         [   0,   16],\n",
       "         [   0,   67],\n",
       "         [   0,  248],\n",
       "         [   0,   67],\n",
       "         [   0,   16],\n",
       "         [   0,   67],\n",
       "         [   0,    9],\n",
       "         [   0,    9],\n",
       "         [   0, 4143],\n",
       "         [   0, 4171],\n",
       "         [   0,  207],\n",
       "         [   0,   38],\n",
       "         [   0,   16],\n",
       "         [   0,   16],\n",
       "         [   0,  127],\n",
       "         [   0, 2375],\n",
       "         [   0,  248],\n",
       "         [   0,    9],\n",
       "         [   0,    9],\n",
       "         [3133,    9],\n",
       "         [   0,   16],\n",
       "         [   0,   85],\n",
       "         [   0,   16],\n",
       "         [   0,    9],\n",
       "         [   0,   67],\n",
       "         [ 100,   60],\n",
       "         [   0, 1603],\n",
       "         [   0,   16],\n",
       "         [   0,   16],\n",
       "         [2334,  900]], dtype=int32)],\n",
       " array([[ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.],\n",
       "        [ 0.,  1.,  0.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Bidirectional, concatenate, Dense, TimeDistributed\n",
    "from keras.models import Model\n",
    "def tclstm_method():\n",
    "    target_text_input = Input(batch_shape=(None, None), dtype='int32',\n",
    "                              name='target_text')\n",
    "    target_embedding = Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
    "                                 mask_zero=True, weights=[glove_rest.embedding], \n",
    "                                 trainable=True, name='target_embedding')\n",
    "    left_text_input = Input(batch_shape=(None, None), dtype='int32',\n",
    "                             name='left_text')\n",
    "    \n",
    "    sentence_embedding = Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
    "                                   mask_zero=True, weights=[glove_rest.embedding], \n",
    "                                   trainable=True, name='sentence_embedding')\n",
    "\n",
    "    model = Model(inputs=[left_text_input, target_text_input], outputs=softmax)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Bidirectional, concatenate, Dense\n",
    "from keras.models import Model\n",
    "text_sequences = Input(batch_shape=(None, None), dtype='int32',\n",
    "                        name='Text_Input')\n",
    "text_embedding = Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
    "                           mask_zero=True, weights=[glove_rest.embedding], \n",
    "                           trainable=True, name='Text_Embedding')(text_sequences)\n",
    "text_lstm = Bidirectional(LSTM(300, name='Text_LSTM'))(text_embedding)\n",
    "target_sequences = Input(batch_shape=(None, None), dtype='int32',\n",
    "                         name='Target_Input')\n",
    "target_embedding = Embedding(input_dim=num_words, output_dim=embedding_dim,\n",
    "                             mask_zero=True, weights=[glove_rest.embedding], \n",
    "                             trainable=True, name='Target_Embedding')(target_sequences)\n",
    "target_lstm = Bidirectional(LSTM(300, name='Target_LSTM'))(target_embedding)\n",
    "combo = concatenate([text_lstm, target_lstm], name='Text_Target_Merge')\n",
    "softmax = Dense(3, activation='softmax', name='Softmax')(combo)\n",
    "\n",
    "model = Model(inputs=[text_sequences, target_sequences], outputs=softmax)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "text_input = train_data[0][0][0]\n",
    "target_input = train_data[0][0][1]\n",
    "fun = K.function([model.layers[0].input],[model.layers[2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "91/91 [==============================] - 32s 356ms/step - loss: 0.7914 - acc: 0.6522 - val_loss: 0.6667 - val_acc: 0.7295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f121cd49160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data, validation_data=val_data, use_multiprocessing=True, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "91/91 [==============================] - 30s 325ms/step - loss: 0.5709 - acc: 0.7678 - val_loss: 0.6401 - val_acc: 0.7351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f11507dee10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_data, validation_data=val_data, use_multiprocessing=True, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "targets = []\n",
    "labels = []\n",
    "for i in range(len(train_data)):\n",
    "    texts.extend(train_data[i][0][0].tolist())\n",
    "    targets.extend(train_data[i][0][1].tolist())\n",
    "    labels.extend(train_data[i][1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "texts = pad_sequences(texts)\n",
    "targets = pad_sequences(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "2881/2881 [==============================] - 70s 24ms/step - loss: 0.4315 - acc: 0.8285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1215e2f9e8>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[texts, targets], y=np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['They did not have mayonnaise, forgot our toast, left out ingredients (ie cheese in an omelet), below hot temperatures and the bacon was so over cooked it crumbled on the plate']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bella.contexts import context\n",
    "con = {\"spans\": [[170, 175]], \"target\": \"plate\", \"text\": \"They did not have mayonnaise, forgot our toast, left out ingredients (ie cheese in an omelet), below hot temperatures and the bacon was so over cooked it crumbled on the plate when you touched it.\", \"sentiment\": 0, \"sentence_id\": \"restaurants_train296\", \"target_id\": \"restaurants_train2965\"}\n",
    "context(con, 'left', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-e4d929688462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "text_input = data[0][0]\n",
    "target_input = data[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Text_Input',\n",
       " 'Target_Input',\n",
       " 'Text_Embedding',\n",
       " 'Target_Embedding',\n",
       " 'bidirectional_3',\n",
       " 'bidirectional_4',\n",
       " 'Text_Target_Merge',\n",
       " 'Softmax']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[layer.name for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = K.function([model.layers[0].input, model.layers[1].input],[model.layers[7].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Target_Input_4' with dtype int32 and shape [32,?]\n\t [[Node: Target_Input_4 = Placeholder[dtype=DT_INT32, shape=[32,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Target_Input_4', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-59-1ab0cbb50a60>\", line 10, in <module>\n    name='Target_Input')\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\", line 1455, in Input\n    input_tensor=tensor)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\", line 1364, in __init__\n    name=self.name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 504, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Target_Input_4' with dtype int32 and shape [32,?]\n\t [[Node: Target_Input_4 = Placeholder[dtype=DT_INT32, shape=[32,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Target_Input_4' with dtype int32 and shape [32,?]\n\t [[Node: Target_Input_4 = Placeholder[dtype=DT_INT32, shape=[32,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-8647ec34de60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Target_Input_4' with dtype int32 and shape [32,?]\n\t [[Node: Target_Input_4 = Placeholder[dtype=DT_INT32, shape=[32,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'Target_Input_4', defined at:\n  File \"/usr/local/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/usr/local/lib/python3.6/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/usr/local/lib/python3.6/asyncio/events.py\", line 126, in _run\n    self._callback(*self._args)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-59-1ab0cbb50a60>\", line 10, in <module>\n    name='Target_Input')\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\", line 1455, in Input\n    input_tensor=tensor)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\", line 1364, in __init__\n    name=self.name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 504, in placeholder\n    x = tf.placeholder(dtype, shape=shape, name=name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1548, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 2094, in _placeholder\n    name=name)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/andrew/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Target_Input_4' with dtype int32 and shape [32,?]\n\t [[Node: Target_Input_4 = Placeholder[dtype=DT_INT32, shape=[32,?], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "fun([*[data[0][0], data[0][1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-6d7173252f9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Text_Input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Target_Input'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "fun([{'Text_Input': data[0][0], 'Target_Input': data[0][1]}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        ..., \n",
       "        [ -9.38460007e-02,   5.82960010e-01,  -1.92709994e-02, ...,\n",
       "          -9.88039970e-02,   2.75379997e-02,   3.00419986e-01],\n",
       "        [ -2.19049994e-02,  -1.89789996e-01,   3.55529994e-01, ...,\n",
       "           2.54469998e-02,  -2.61300001e-02,  -9.11479965e-02],\n",
       "        [  1.20010003e-02,   2.07509995e-01,  -1.25780001e-01, ...,\n",
       "           1.38710007e-01,  -3.60489994e-01,  -3.50000001e-02]],\n",
       "\n",
       "       [[  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        ..., \n",
       "        [  3.81301977e-02,   1.39759108e-02,   1.70470756e-02, ...,\n",
       "           4.19012792e-02,  -5.19786915e-03,  -2.47451328e-02],\n",
       "        [ -2.78010011e-01,  -1.45190001e-01,   4.94529992e-01, ...,\n",
       "          -9.77670014e-01,   1.84430003e-01,   2.50230014e-01],\n",
       "        [ -2.65540004e-01,   3.35310012e-01,   2.18600005e-01, ...,\n",
       "          -1.78590000e-01,  -6.28779978e-02,   1.62320003e-01]],\n",
       "\n",
       "       [[  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        ..., \n",
       "        [ -4.53489989e-01,   2.27950007e-01,  -4.13199991e-01, ...,\n",
       "          -1.18620001e-01,  -1.96370006e-01,   3.76260012e-01],\n",
       "        [  1.71759993e-01,   5.16650021e-01,   3.55599999e-01, ...,\n",
       "          -2.29070000e-02,  -2.18329996e-01,   1.87260002e-01],\n",
       "        [  1.20010003e-02,   2.07509995e-01,  -1.25780001e-01, ...,\n",
       "           1.38710007e-01,  -3.60489994e-01,  -3.50000001e-02]],\n",
       "\n",
       "       ..., \n",
       "       [[  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  2.72040009e-01,  -6.20299987e-02,  -1.88400000e-01, ...,\n",
       "           1.30150005e-01,  -1.83170006e-01,   1.32300004e-01],\n",
       "        ..., \n",
       "        [ -4.40579988e-02,   3.66109997e-01,   1.80319995e-01, ...,\n",
       "           1.86250001e-01,  -9.78169963e-02,  -6.71040034e-05],\n",
       "        [ -9.38460007e-02,   5.82960010e-01,  -1.92709994e-02, ...,\n",
       "          -9.88039970e-02,   2.75379997e-02,   3.00419986e-01],\n",
       "        [  1.20010003e-02,   2.07509995e-01,  -1.25780001e-01, ...,\n",
       "           1.38710007e-01,  -3.60489994e-01,  -3.50000001e-02]],\n",
       "\n",
       "       [[ -1.38819998e-03,   3.12930010e-02,  -5.24789989e-01, ...,\n",
       "          -1.85230002e-01,   3.60130012e-01,   1.86480001e-01],\n",
       "        [  2.72040009e-01,  -6.20299987e-02,  -1.88400000e-01, ...,\n",
       "           1.30150005e-01,  -1.83170006e-01,   1.32300004e-01],\n",
       "        [ -7.23680034e-02,   2.33199999e-01,   1.37260005e-01, ...,\n",
       "          -1.11550003e-01,   5.32930017e-01,   7.12679982e-01],\n",
       "        ..., \n",
       "        [ -2.65540004e-01,   3.35310012e-01,   2.18600005e-01, ...,\n",
       "          -1.78590000e-01,  -6.28779978e-02,   1.62320003e-01],\n",
       "        [ -2.65540004e-01,   3.35310012e-01,   2.18600005e-01, ...,\n",
       "          -1.78590000e-01,  -6.28779978e-02,   1.62320003e-01],\n",
       "        [ -2.65540004e-01,   3.35310012e-01,   2.18600005e-01, ...,\n",
       "          -1.78590000e-01,  -6.28779978e-02,   1.62320003e-01]],\n",
       "\n",
       "       [[  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [  4.42023985e-02,  -2.87089404e-02,   1.30871320e-02, ...,\n",
       "          -4.66016456e-02,   1.05595612e-03,  -5.87926060e-03],\n",
       "        [ -1.85670003e-01,   6.60080016e-02,  -2.52090007e-01, ...,\n",
       "          -2.34520007e-02,   1.23020001e-01,   3.31200004e-01],\n",
       "        ..., \n",
       "        [ -1.14540003e-01,  -7.69810006e-02,  -9.05179977e-02, ...,\n",
       "          -3.12229991e-01,   6.56789988e-02,  -7.47170001e-02],\n",
       "        [  8.84390026e-02,  -3.29910010e-01,   4.86440003e-01, ...,\n",
       "          -4.97579992e-01,   1.47839993e-01,  -2.56260008e-01],\n",
       "        [  1.20010003e-02,   2.07509995e-01,  -1.25780001e-01, ...,\n",
       "           1.38710007e-01,  -3.60489994e-01,  -3.50000001e-02]]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fun([data[0][0]])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TargetSequence(rest_train_fp, 32, tok, moses)\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,   19,   60,    3],\n",
       "       [   0,    0,    0,    0, 3701,   56,   36],\n",
       "       [   0,    0,    0,    0,  289,   16,    3],\n",
       "       [   0,    0,    0,    0, 3841,   67,    3],\n",
       "       [   0,    0,    0,    0,   22,    9,    3],\n",
       "       [   0,    0,    0,    0,  619, 3952,    3],\n",
       "       [   0,    0,    0,    0, 1416,  169,    3],\n",
       "       [   0,    0,    0,    0, 1072,   16,    3],\n",
       "       [   0,    0,    0,    0,   22,  247,    3],\n",
       "       [   0,    0,    0,    0, 2626,   67,    3],\n",
       "       [   0,    0,    0,    0,   22,    9,    3],\n",
       "       [   0,    0,    0,    0, 4118,   85,   36],\n",
       "       [   0,    0,    0,   16,    8,  370,    3],\n",
       "       [   0,    0,    0,    5,  162,   38,   36],\n",
       "       [   0,    0,    0,  151,    6, 1155,    3],\n",
       "       [   0,    0,    0,  111,    1, 2367,   36],\n",
       "       [   0,    0,    0,   79,  712,  247,    3],\n",
       "       [   0,    0,    0,   93,   19,   16,   36],\n",
       "       [   0,    0,    0,   16,    6,  173,    3],\n",
       "       [   0,    0,    0,  180,    1,    9,    3],\n",
       "       [   0,    0,    0,    0,   47,   55,   16],\n",
       "       [   0,    0,    0,  209,   34,  299,    3],\n",
       "       [   0,    0,    0,   19,   85,  161,    3],\n",
       "       [   0,    0,    0,    9,    6,   55,    3],\n",
       "       [   0,    0,   22,    2,  289,   16,    3],\n",
       "       [   0,    0,   94,  254, 3580,  995,    3],\n",
       "       [   0,    0,   26,  222,    1,   67,    3],\n",
       "       [   0,    0,   29,    1, 2269,  890,    3],\n",
       "       [   0,   19,   16,    2,   19,    9,    3],\n",
       "       [   0,    0,    1,    9,    8,   19,    3],\n",
       "       [ 111,    1,  452,  320,   36,   36,   36],\n",
       "       [   0,    0,    4,   94,  192,  127,    3]], dtype=int32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer model_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[   0,    0,    0,    0,   19,   60,    3],\n        [   0,    0,    0,    0, 3701,   56,   36],\n        [   0,    0,    0,    0,  289,   16,    3],\n        [   0,    0,    0,    0, 3841,   67,    3],\n        [   0,    0,    0,    0,   22,    9,    3],\n        [   0,    0,    0,    0,  619, 3952,    3],\n        [   0,    0,    0,    0, 1416,  169,    3],\n        [   0,    0,    0,    0, 1072,   16,    3],\n        [   0,    0,    0,    0,   22,  247,    3],\n        [   0,    0,    0,    0, 2626,   67,    3],\n        [   0,    0,    0,    0,   22,    9,    3],\n        [   0,    0,    0,    0, 4118,   85,   36],\n        [   0,    0,    0,   16,    8,  370,    3],\n        [   0,    0,    0,    5,  162,   38,   36],\n        [   0,    0,    0,  151,    6, 1155,    3],\n        [   0,    0,    0,  111,    1, 2367,   36],\n        [   0,    0,    0,   79,  712,  247,    3],\n        [   0,    0,    0,   93,   19,   16,   36],\n        [   0,    0,    0,   16,    6,  173,    3],\n        [   0,    0,    0,  180,    1,    9,    3],\n        [   0,    0,    0,    0,   47,   55,   16],\n        [   0,    0,    0,  209,   34,  299,    3],\n        [   0,    0,    0,   19,   85,  161,    3],\n        [   0,    0,    0,    9,    6,   55,    3],\n        [   0,    0,   22,    2,  289,   16,    3],\n        [   0,    0,   94,  254, 3580,  995,    3],\n        [   0,    0,   26,  222,    1,   67,    3],\n        [   0,    0,   29,    1, 2269,  890,    3],\n        [   0,   19,   16,    2,   19,    9,    3],\n        [   0,    0,    1,    9,    8,   19,    3],\n        [ 111,    1,  452,  320,   36,   36,   36],\n        [   0,    0,    4,   94,  192,  127,    3]]], dtype=int32)]. All inputs to the layer should be tensors.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    464\u001b[0m                           tf.SparseTensor)):\n\u001b[0;32m--> 465\u001b[0;31m         raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) + '`. '\n\u001b[0m\u001b[1;32m    466\u001b[0m                          'Expected a symbolic tensor instance.')\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'numpy.ndarray'>`. Expected a symbolic tensor instance.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-57aec20d1b30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    599\u001b[0m             \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m             \u001b[0;31m# with the input_spec set at build time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;31m# Handle mask propagation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/Bella/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                                  \u001b[0;34m'Received type: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Full input: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                                  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. All inputs to the layer '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m                                  'should be tensors.')\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer model_1 was called with an input that isn't a symbolic tensor. Received type: <class 'numpy.ndarray'>. Full input: [array([[[   0,    0,    0,    0,   19,   60,    3],\n        [   0,    0,    0,    0, 3701,   56,   36],\n        [   0,    0,    0,    0,  289,   16,    3],\n        [   0,    0,    0,    0, 3841,   67,    3],\n        [   0,    0,    0,    0,   22,    9,    3],\n        [   0,    0,    0,    0,  619, 3952,    3],\n        [   0,    0,    0,    0, 1416,  169,    3],\n        [   0,    0,    0,    0, 1072,   16,    3],\n        [   0,    0,    0,    0,   22,  247,    3],\n        [   0,    0,    0,    0, 2626,   67,    3],\n        [   0,    0,    0,    0,   22,    9,    3],\n        [   0,    0,    0,    0, 4118,   85,   36],\n        [   0,    0,    0,   16,    8,  370,    3],\n        [   0,    0,    0,    5,  162,   38,   36],\n        [   0,    0,    0,  151,    6, 1155,    3],\n        [   0,    0,    0,  111,    1, 2367,   36],\n        [   0,    0,    0,   79,  712,  247,    3],\n        [   0,    0,    0,   93,   19,   16,   36],\n        [   0,    0,    0,   16,    6,  173,    3],\n        [   0,    0,    0,  180,    1,    9,    3],\n        [   0,    0,    0,    0,   47,   55,   16],\n        [   0,    0,    0,  209,   34,  299,    3],\n        [   0,    0,    0,   19,   85,  161,    3],\n        [   0,    0,    0,    9,    6,   55,    3],\n        [   0,    0,   22,    2,  289,   16,    3],\n        [   0,    0,   94,  254, 3580,  995,    3],\n        [   0,    0,   26,  222,    1,   67,    3],\n        [   0,    0,   29,    1, 2269,  890,    3],\n        [   0,   19,   16,    2,   19,    9,    3],\n        [   0,    0,    1,    9,    8,   19,    3],\n        [ 111,    1,  452,  320,   36,   36,   36],\n        [   0,    0,    4,   94,  192,  127,    3]]], dtype=int32)]. All inputs to the layer should be tensors."
     ]
    }
   ],
   "source": [
    "model(data[0][0].reshape(1,32,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.embedding.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.embedding = a.embedding.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.embedding.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-89d6ce7bfdf7>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-89d6ce7bfdf7>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    a.\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.uniform(1, 2, size=(2,3), dtype=np.float32)\n",
    "a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = TargetSequence(rest_train_fp, 32, tok, moses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 7)\n",
      "(32, 2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (32,7) into shape (32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8de47de7af6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (32,7) into shape (32)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(a[0][0].shape)\n",
    "print(a[0][1].shape)\n",
    "a[0][2]\n",
    "np.array([a[0][0], a[0][1], np.array(a[0][2]).reshape(32,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a[0][2]).reshape(32,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Killer Sushi!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text[1:\n",
    "          2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"Where tanks in other Chinatown restaurants display a lurking myriad of sad-looking marine life in their murky waters, the tanks at Ping's are clear as glass with healthy-looking creatures who do not yet know that they will be part of some dim sum lover's brunch.\",\n",
       "  \"Where tanks in other Chinatown restaurants display a lurking myriad of sad-looking marine life in their murky waters, the tanks at Ping's are clear as glass with healthy-looking creatures who do not yet know that they will be part of some dim sum lover's brunch.\",\n",
       "  \"From the complimentary chef app of a delicate butternut squash ravioli in a delicious truffle sauce to an amazing buttery and tender langostine entree to a dessert that I can't remember because of the fabulous Cakebread Cabernet we were drinking -- the whole evening was amazing.\",\n",
       "  \"From the complimentary chef app of a delicate butternut squash ravioli in a delicious truffle sauce to an amazing buttery and tender langostine entree to a dessert that I can't remember because of the fabulous Cakebread Cabernet we were drinking -- the whole evening was amazing.\",\n",
       "  \"From the complimentary chef app of a delicate butternut squash ravioli in a delicious truffle sauce to an amazing buttery and tender langostine entree to a dessert that I can't remember because of the fabulous Cakebread Cabernet we were drinking -- the whole evening was amazing.\",\n",
       "  \"From the complimentary chef app of a delicate butternut squash ravioli in a delicious truffle sauce to an amazing buttery and tender langostine entree to a dessert that I can't remember because of the fabulous Cakebread Cabernet we were drinking -- the whole evening was amazing.\",\n",
       "  \"From the complimentary chef app of a delicate butternut squash ravioli in a delicious truffle sauce to an amazing buttery and tender langostine entree to a dessert that I can't remember because of the fabulous Cakebread Cabernet we were drinking -- the whole evening was amazing.\",\n",
       "  \"We live in New Jersey and whenever we go into New York City we buy bagels to eat hot and then to freeze (they told me that if I call in the order, they'd bring it out to the car so I wouldn't have to look for parking).\",\n",
       "  \"When asked about how a certain dish was prepared in comparison to a similar at other thai restaurants, he replied this is not Mcdonald's, every place makes things differently While it is understandable that every place is indeed different, there was not a need to be uncourteous to customers and downright rude.\",\n",
       "  \"The Italian food has flavor (that can be sort of surprising on the UES), and the service turns from a nightmare to attentive,they sort of remind me of the NY Yankees of the late 90's, no matter how bad it look, you knew that there was a rally just around the corner...\",\n",
       "  \"- the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\",\n",
       "  \"- the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\",\n",
       "  \"- the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\",\n",
       "  \"- the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\",\n",
       "  \"- the bread at the beginning is super tasty and makes you want more - the pizza is delicious and comes in personal sizes, however be warned that the Peter's Favourite pizza with prosciutto and baby arugula is actually a margarite pizza with cold prosciutto and baby arugula on top, like a salad.\",\n",
       "  \"my picks are:  - Scallion Pancake (fried with vegetable juice, very special and tasty)  - Guizhou Chicken  - Shredded Squid Family Style (one of my personal favorites)  - Sichuan Spicy Soft Shell Crab  - Shuizhu Fish (this one is for hardcore Sichuan food fans, I wouldn't recommend to my American friends as it's very spicy.\",\n",
       "  \"my picks are:  - Scallion Pancake (fried with vegetable juice, very special and tasty)  - Guizhou Chicken  - Shredded Squid Family Style (one of my personal favorites)  - Sichuan Spicy Soft Shell Crab  - Shuizhu Fish (this one is for hardcore Sichuan food fans, I wouldn't recommend to my American friends as it's very spicy.\",\n",
       "  \"my picks are:  - Scallion Pancake (fried with vegetable juice, very special and tasty)  - Guizhou Chicken  - Shredded Squid Family Style (one of my personal favorites)  - Sichuan Spicy Soft Shell Crab  - Shuizhu Fish (this one is for hardcore Sichuan food fans, I wouldn't recommend to my American friends as it's very spicy.\",\n",
       "  \"my picks are:  - Scallion Pancake (fried with vegetable juice, very special and tasty)  - Guizhou Chicken  - Shredded Squid Family Style (one of my personal favorites)  - Sichuan Spicy Soft Shell Crab  - Shuizhu Fish (this one is for hardcore Sichuan food fans, I wouldn't recommend to my American friends as it's very spicy.\",\n",
       "  \"my picks are:  - Scallion Pancake (fried with vegetable juice, very special and tasty)  - Guizhou Chicken  - Shredded Squid Family Style (one of my personal favorites)  - Sichuan Spicy Soft Shell Crab  - Shuizhu Fish (this one is for hardcore Sichuan food fans, I wouldn't recommend to my American friends as it's very spicy.\",\n",
       "  \"my picks are:  - Scallion Pancake (fried with vegetable juice, very special and tasty)  - Guizhou Chicken  - Shredded Squid Family Style (one of my personal favorites)  - Sichuan Spicy Soft Shell Crab  - Shuizhu Fish (this one is for hardcore Sichuan food fans, I wouldn't recommend to my American friends as it's very spicy.\",\n",
       "  \"Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\",\n",
       "  \"Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\",\n",
       "  \"Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\",\n",
       "  \"Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\",\n",
       "  \"Besides having the table we had been promised given to other restaurant patrons twice before we were actually seated, we were served dishes we hadn't ordered three times, received one of our orders 20 minutes after the rest of the table had been served (and that order was undercooked), and charged $45 more than we should have been on our bill.\",\n",
       "  \"I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\",\n",
       "  \"I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\",\n",
       "  \"I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\",\n",
       "  \"I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\",\n",
       "  \"I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\",\n",
       "  \"I must warn the reader that the portions sizes are very small (especially the appetizers), so if you plan to eat until you are full and do not intend to order the chef's special tasting menu, prepare to order and pay for an appetizer (1 dish for each person because the portions are not for sharing), a main entree, and the cold udon at the end of the meal.\"],\n",
       " ['dim sum',\n",
       "  'brunch',\n",
       "  'dessert',\n",
       "  'chef app',\n",
       "  'delicate butternut squash ravioli in a delicious truffle sauce',\n",
       "  'Cakebread Cabernet',\n",
       "  'buttery and tender langostine entree',\n",
       "  'bagels',\n",
       "  'dish',\n",
       "  'Italian food',\n",
       "  'margarite pizza with cold prosciutto and baby arugula on top',\n",
       "  'salad',\n",
       "  'bread',\n",
       "  \"Peter's Favourite pizza with prosciutto and baby arugula\",\n",
       "  'pizza',\n",
       "  'Shuizhu Fish',\n",
       "  'Sichuan Spicy Soft Shell Crab',\n",
       "  'vegetable juice',\n",
       "  'Guizhou Chicken',\n",
       "  'Scallion Pancake',\n",
       "  'Shredded Squid Family Style',\n",
       "  'table',\n",
       "  'dishes',\n",
       "  'served',\n",
       "  'served',\n",
       "  'table',\n",
       "  'menu',\n",
       "  'main entree',\n",
       "  'chef',\n",
       "  'cold udon',\n",
       "  'appetizer',\n",
       "  'portions'],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  -1,\n",
       "  -1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.token_index[',']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a._embedding_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import linecache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'####\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linecache.getline('/home/andrew/Desktop/config.yaml', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', '50', '50', '50']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'hello 50 50 50\\n'\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_word_line_index = {}\n",
    "with b.open('r') as embedding_file:\n",
    "    for index, line in enumerate(embedding_file):\n",
    "        embedding_word = line.split()[0]\n",
    "        embedding_word_line_index[embedding_word] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", -0.082752 0.67204 -0.14987 -0.064983 0.056491 0.40228 0.0027747 -0.3311 -0.30691 2.0817 0.031819 0.013643 0.30265 0.0071297 -0.5819 -0.2774 -0.062254 1.1451 -0.24232 0.1235 -0.12243 0.33152 -0.006162 -0.30541 -0.13057 -0.054601 0.037083 -0.070552 0.5893 -0.30385 0.2898 -0.14653 -0.27052 0.37161 0.32031 -0.29125 0.0052483 -0.13212 -0.052736 0.087349 -0.26668 -0.16897 0.015162 -0.0083746 -0.14871 0.23413 -0.20719 -0.091386 0.40075 -0.17223 0.18145 0.37586 -0.28682 0.37289 -0.16185 0.18008 0.3032 -0.13216 0.18352 0.095759 0.094916 0.008289 0.11761 0.34046 0.03677 -0.29077 0.058303 -0.027814 0.082941 0.1862 -0.031494 0.27985 -0.074412 -0.13762 -0.21866 0.18138 0.040855 -0.113 0.24107 0.3657 -0.27525 -0.05684 0.34872 0.011884 0.14517 -0.71395 0.48497 0.14807 0.62287 0.20599 0.58379 -0.13438 0.40207 0.18311 0.28021 -0.42349 -0.25626 0.17715 -0.54095 0.16596 -0.036058 0.08499 -0.64989 0.075549 -0.28831 0.40626 -0.2802 0.094062 0.32406 0.28437 -0.26341 0.11553 0.071918 -0.47215 -0.18366 -0.34709 0.29964 -0.66514 0.002516 -0.42333 0.27512 0.36012 0.16311 0.23964 -0.05923 0.3261 0.20559 0.038677 -0.045816 0.089764 0.43151 -0.15954 0.08532 -0.26572 -0.15001 0.084286 -0.16714 -0.43004 0.060807 0.13121 -0.24112 0.66554 0.4453 -0.18019 -0.13919 0.56252 0.21457 -0.46443 -0.012211 0.029988 -0.051094 -0.20135 0.80788 0.47377 -0.057647 0.46216 0.16084 -0.20954 -0.05452 0.15572 -0.13712 0.12972 -0.011936 -0.003378 -0.13595 -0.080711 0.20065 0.054056 0.046816 0.059539 0.046265 0.17754 -0.31094 0.28119 -0.24355 0.085252 -0.21011 -0.19472 0.0027297 -0.46341 0.14789 -0.31517 -0.065939 0.036106 0.42903 -0.33759 0.16432 0.32568 -0.050392 -0.054297 0.24074 0.41923 0.13012 -0.17167 -0.37808 -0.23089 -0.019477 -0.29291 -0.30824 0.30297 -0.22659 0.081574 -0.18516 -0.21408 0.40616 -0.28974 0.074174 -0.17795 0.28595 -0.039626 -0.2339 -0.36054 -0.067503 -0.091065 0.23438 -0.0041331 0.003232 0.0072134 0.008697 0.21614 0.049904 0.35582 0.13748 0.073361 0.14166 0.2412 -0.013322 0.15613 0.083381 0.088146 -0.019357 0.43795 0.083961 0.45309 -0.50489 -0.10865 -0.2527 -0.18251 0.20441 0.13319 0.1294 0.050594 -0.15612 -0.39543 0.12538 0.24881 -0.1927 -0.31847 -0.12719 0.4341 0.31177 -0.0040946 -0.2094 -0.079961 0.1161 -0.050794 0.015266 -0.2803 -0.12486 0.23587 0.2339 -0.14023 0.028462 0.56923 -0.1649 -0.036429 0.010051 -0.17107 -0.042608 0.044965 -0.4393 -0.26137 0.30088 -0.060772 -0.45312 -0.19076 -0.20288 0.27694 -0.060888 0.11944 0.62206 -0.19343 0.47849 -0.30113 0.059389 0.074901 0.061068 -0.4662 0.40054 -0.19099 -0.14331 0.018267 -0.18643 0.20709 -0.35598 0.05338 -0.050821 -0.1918 -0.37846 -0.06589\n",
      "\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "with b.open('r') as embedding_file:\n",
    "    for index, line in enumerate(embedding_file):\n",
    "        print(line)\n",
    "        print('-----')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', -0.082752 0.67204 -0.14987 -0.064983 0.056491 0.40228 0.0027747 -0.3311 -0.30691 2.0817 0.031819 0.013643 0.30265 0.0071297 -0.5819 -0.2774 -0.062254 1.1451 -0.24232 0.1235 -0.12243 0.33152 -0.006162 -0.30541 -0.13057 -0.054601 0.037083 -0.070552 0.5893 -0.30385 0.2898 -0.14653 -0.27052 0.37161 0.32031 -0.29125 0.0052483 -0.13212 -0.052736 0.087349 -0.26668 -0.16897 0.015162 -0.0083746 -0.14871 0.23413 -0.20719 -0.091386 0.40075 -0.17223 0.18145 0.37586 -0.28682 0.37289 -0.16185 0.18008 0.3032 -0.13216 0.18352 0.095759 0.094916 0.008289 0.11761 0.34046 0.03677 -0.29077 0.058303 -0.027814 0.082941 0.1862 -0.031494 0.27985 -0.074412 -0.13762 -0.21866 0.18138 0.040855 -0.113 0.24107 0.3657 -0.27525 -0.05684 0.34872 0.011884 0.14517 -0.71395 0.48497 0.14807 0.62287 0.20599 0.58379 -0.13438 0.40207 0.18311 0.28021 -0.42349 -0.25626 0.17715 -0.54095 0.16596 -0.036058 0.08499 -0.64989 0.075549 -0.28831 0.40626 -0.2802 0.094062 0.32406 0.28437 -0.26341 0.11553 0.071918 -0.47215 -0.18366 -0.34709 0.29964 -0.66514 0.002516 -0.42333 0.27512 0.36012 0.16311 0.23964 -0.05923 0.3261 0.20559 0.038677 -0.045816 0.089764 0.43151 -0.15954 0.08532 -0.26572 -0.15001 0.084286 -0.16714 -0.43004 0.060807 0.13121 -0.24112 0.66554 0.4453 -0.18019 -0.13919 0.56252 0.21457 -0.46443 -0.012211 0.029988 -0.051094 -0.20135 0.80788 0.47377 -0.057647 0.46216 0.16084 -0.20954 -0.05452 0.15572 -0.13712 0.12972 -0.011936 -0.003378 -0.13595 -0.080711 0.20065 0.054056 0.046816 0.059539 0.046265 0.17754 -0.31094 0.28119 -0.24355 0.085252 -0.21011 -0.19472 0.0027297 -0.46341 0.14789 -0.31517 -0.065939 0.036106 0.42903 -0.33759 0.16432 0.32568 -0.050392 -0.054297 0.24074 0.41923 0.13012 -0.17167 -0.37808 -0.23089 -0.019477 -0.29291 -0.30824 0.30297 -0.22659 0.081574 -0.18516 -0.21408 0.40616 -0.28974 0.074174 -0.17795 0.28595 -0.039626 -0.2339 -0.36054 -0.067503 -0.091065 0.23438 -0.0041331 0.003232 0.0072134 0.008697 0.21614 0.049904 0.35582 0.13748 0.073361 0.14166 0.2412 -0.013322 0.15613 0.083381 0.088146 -0.019357 0.43795 0.083961 0.45309 -0.50489 -0.10865 -0.2527 -0.18251 0.20441 0.13319 0.1294 0.050594 -0.15612 -0.39543 0.12538 0.24881 -0.1927 -0.31847 -0.12719 0.4341 0.31177 -0.0040946 -0.2094 -0.079961 0.1161 -0.050794 0.015266 -0.2803 -0.12486 0.23587 0.2339 -0.14023 0.028462 0.56923 -0.1649 -0.036429 0.010051 -0.17107 -0.042608 0.044965 -0.4393 -0.26137 0.30088 -0.060772 -0.45312 -0.19076 -0.20288 0.27694 -0.060888 0.11944 0.62206 -0.19343 0.47849 -0.30113 0.059389 0.074901 0.061068 -0.4662 0.40054 -0.19099 -0.14331 0.018267 -0.18643 0.20709 -0.35598 0.05338 -0.050821 -0.1918 -0.37846 -0.06589\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linecache.getline(str(b.resolve()), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_word = {line: word for word, line in embedding_word_line_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'People -0.20997 -0.15582 -0.073606 -0.34189 -0.32032 0.28008 0.0033769 -0.079931 0.083 1.8469 -0.86466 -0.27001 -0.021629 -0.24913 -0.13378 0.19822 -0.57364 0.051489 -0.53949 0.23011 0.084569 0.20623 -0.18806 -0.054685 -4.9371e-05 -0.051435 0.44651 -0.022856 0.063644 -0.3956 0.2458 -0.15545 -0.45205 -0.1106 0.59292 0.24084 0.0793 -0.023429 0.084101 0.10123 0.51899 0.10656 -0.34206 0.22535 0.064097 -0.49653 -0.45743 0.05437 -0.058989 0.11791 -0.44047 0.051933 0.12841 -0.30195 0.14694 -0.084461 0.097706 -0.24829 0.068971 -0.074712 -0.032083 -0.073342 -0.20079 0.025478 0.11357 -0.24824 -0.27349 -0.10392 -0.068701 0.13297 -0.10657 0.34653 0.29558 -0.068083 0.4593 -0.4312 0.074127 0.19135 0.24887 -0.027464 -0.021497 0.27891 0.087313 -0.2332 0.059522 -0.20898 -0.99762 -0.030772 0.32078 -0.37599 -0.19092 -0.2672 0.10873 0.082608 0.01813 -0.098694 -0.084005 -0.39826 0.055193 -0.55441 -0.013784 0.35865 0.17683 -0.034674 0.52994 1.3731 0.10275 -0.38158 -0.046285 0.67172 0.14183 -0.1328 0.2049 -0.62953 0.0053594 -0.13495 0.21289 0.012791 -0.17989 0.16667 -0.34284 -0.16991 -0.013486 -0.40956 0.28941 -0.24155 0.40463 0.052107 -0.011551 -0.43172 0.38662 0.21057 -0.28074 -0.24326 0.19268 -0.30781 0.21911 0.034297 0.14394 -0.21612 -0.55196 0.193 -0.59961 0.13983 0.024705 0.046542 0.39624 0.18107 -0.4979 -0.33874 0.23018 0.19114 0.046907 0.35068 -0.12866 0.436 0.012605 0.05831 -0.066111 0.073692 0.20323 -0.18725 -0.042434 0.61619 -0.14774 0.11141 0.51054 -0.17116 -0.35132 -0.0017939 0.30489 0.037996 0.058134 -0.10263 0.022071 -0.18124 0.15027 0.36692 0.40436 -0.071555 -0.042268 0.18854 -0.45101 0.0077172 0.22623 0.19466 -0.15171 -0.22521 0.1171 -0.11741 0.094154 -0.23987 0.13846 0.027278 -0.021765 0.62539 -0.2978 -0.36547 0.070478 -0.0068226 -0.098899 0.0077785 0.4017 -0.053492 -0.079052 0.43794 -0.33839 -0.28357 -0.010716 0.026872 0.41999 0.0925 -0.22666 0.054565 -0.021008 -0.044228 -0.25385 0.27523 -0.36685 -0.53499 0.25619 0.25608 -0.1062 0.013995 -0.019169 -0.414 0.04527 0.15548 -0.17444 -0.25074 -0.51199 -0.048353 0.16786 -0.44947 0.061764 0.028348 -0.0039371 -0.21988 0.32096 0.19301 -0.46877 0.0076027 0.45417 -0.025936 0.051219 -0.17453 0.11007 -0.51961 -0.75598 -0.080042 0.23191 0.22934 -0.16927 0.26472 -0.08011 0.63256 0.089261 -0.17645 -0.020872 0.18837 0.01724 0.028622 -0.57386 0.25678 0.042169 -0.53358 0.11874 0.29032 0.68996 0.27027 -0.22122 -0.36466 -0.23204 -0.038652 -0.02369 -0.23799 -0.24197 0.10855 -0.077842 0.40792 -0.077304 0.26036 0.036909 0.092895 -0.037354 0.065524 0.27381 0.20308 -0.015142 0.29114 -0.58713 0.063926 0.40414 -0.33446 0.051016 0.32362 0.044352 -0.21238 -0.083801 -0.0053335\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linecache.getline(str(b.resolve()), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4554, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "c=np.random.uniform(low=-0.05, high=0.05, size=(4554, 50))\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4554 is out of bounds for axis 0 with size 4554",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e021f2b77998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4554\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 4554 is out of bounds for axis 0 with size 4554"
     ]
    }
   ],
   "source": [
    "c[4554]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<UNK>', 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = list(tok.word_index.items())\n",
    "h[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello 50 50 50 50'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 'hello 50 50 50 50'\n",
    "d.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03436674, -0.00615127,  0.04208718,  0.00806937, -0.02588832,\n",
       "       -0.04503144, -0.03547168,  0.04760892, -0.00275731, -0.03723368,\n",
       "       -0.03446525,  0.02533241, -0.03804036,  0.01703367, -0.00324602,\n",
       "        0.01917142, -0.04468261, -0.045914  ,  0.04559775, -0.01955871,\n",
       "        0.01973594, -0.0168532 , -0.03996611, -0.01072227,  0.03983544,\n",
       "       -0.00618201, -0.01242969,  0.01749668, -0.03591887,  0.03261453,\n",
       "        0.03764831, -0.02657069,  0.0257145 ,  0.03268912, -0.01167673,\n",
       "       -0.04949418,  0.03001373, -0.02660648, -0.01177249,  0.02424233,\n",
       "        0.04264256, -0.03420635, -0.03382716,  0.01070314, -0.04667419,\n",
       "       -0.00693614, -0.00454465,  0.01144933,  0.03883786,  0.01923784])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.uniform(low=-0.05, high=0.05, size=(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = [1, 2, 3, 4, 5]\n",
    "h[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
