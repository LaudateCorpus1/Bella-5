{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.pardir))\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Helper functions\n",
    "from tdparse.notebook_helper import write_json_data\n",
    "# Models\n",
    "from tdparse.models.tdparse import TDParse, TDParsePlus\n",
    "# Word Vector methods\n",
    "from tdparse.word_vectors import GensimVectors\n",
    "from tdparse.word_vectors import PreTrained\n",
    "# Dependency Parser\n",
    "from tdparse.dependency_parsers import tweebo, stanford\n",
    "# Sentiment lexicons\n",
    "from tdparse import lexicons\n",
    "# Get the data\n",
    "from tdparse.parsers import semeval_14, semeval_15_16, dong, election\n",
    "from tdparse.data_types import TargetCollection\n",
    "from tdparse.helper import read_config, full_path\n",
    "# Evaluation methods\n",
    "from tdparse.evaluation import evaluation_results, scores, get_results, \\\n",
    "                               save_results, combine_results, get_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all of the datasets\n",
    "youtubean_train = semeval_14(full_path(read_config('youtubean_train')))\n",
    "youtubean_test = semeval_14(full_path(read_config('youtubean_test')))\n",
    "semeval_14_rest_train = semeval_14(full_path(read_config('semeval_2014_rest_train')))\n",
    "semeval_14_lap_train = semeval_14(full_path(read_config('semeval_2014_lap_train')))\n",
    "semeval_14_rest_test = semeval_14(full_path(read_config('semeval_2014_rest_test')))\n",
    "semeval_14_lap_test = semeval_14(full_path(read_config('semeval_2014_lap_test')))\n",
    "semeval_15_rest_test = semeval_15_16(full_path(read_config('semeval_2015_rest_test')))\n",
    "semeval_16_rest_test = semeval_15_16(full_path(read_config('semeval_2016_rest_test')),\n",
    "                                     sep_16_from_15=True)\n",
    "dong_train = dong(full_path(read_config('dong_twit_train_data')))\n",
    "dong_test = dong(full_path(read_config('dong_twit_test_data')))\n",
    "election_train, election_test = election(full_path(read_config('election_folder_dir')))\n",
    "product_reviews_train = semeval_14(full_path(read_config('product_train')))\n",
    "product_reviews_test = semeval_14(full_path(read_config('product_test')))\n",
    "# Combine semeval 14 resturant train and test\n",
    "semeval_14_rest_all = TargetCollection.combine_collections(semeval_14_rest_train,\n",
    "                                                           semeval_14_rest_test)\n",
    "# Combine semeval 14 resturant all with 15 test\n",
    "semeval_14_15 = TargetCollection.combine_collections(semeval_14_rest_all,\n",
    "                                                     semeval_15_rest_test)\n",
    "\n",
    "train_test = {'SemEval 14 Laptop' : (semeval_14_lap_train, semeval_14_lap_test),\n",
    "              'SemEval 14 Restaurant' : (semeval_14_rest_train, semeval_14_rest_test),\n",
    "              'SemEval 16 Restaurant 14 Train' : (semeval_14_rest_train, semeval_16_rest_test),\n",
    "              'SemEval 16 Restaurant 14 All' : (semeval_14_rest_all, semeval_16_rest_test),\n",
    "              'SemEval 16 Restaurant 15&14' : (semeval_14_15, semeval_16_rest_test),\n",
    "              'Dong Twitter' : (dong_train, dong_test),\n",
    "              'Election Twitter' : (election_train, election_test),\n",
    "              'Product Reviews' : (product_reviews_train, product_reviews_test),\n",
    "              'YouTuBean' : (youtubean_train, youtubean_test)\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors\n",
    "w2v_path = full_path(read_config('word2vec_files')['vo_zhang'])\n",
    "w2v = GensimVectors(w2v_path, None, model='word2vec', name='w2v')\n",
    "sswe_path = full_path(read_config('sswe_files')['vo_zhang'])\n",
    "sswe = PreTrained(sswe_path, name='sswe')\n",
    "\n",
    "# Load the sentiment lexicons and remove all words that are not associated\n",
    "# to the Positive or Negative class.\n",
    "subset_cats = {'positive', 'negative'}\n",
    "mpqa_low = lexicons.Mpqa(subset_cats=subset_cats, lower=True)\n",
    "nrc_low = lexicons.NRC(subset_cats=subset_cats, lower=True)\n",
    "hu_liu_low = lexicons.HuLiu(subset_cats=subset_cats, lower=True)\n",
    "mpqa_huliu_low = lexicons.Lexicon.combine_lexicons(mpqa_low, hu_liu_low)\n",
    "all_three_low = lexicons.Lexicon.combine_lexicons(mpqa_huliu_low, nrc_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "got_wrong = []\n",
    "res = []\n",
    "\n",
    "for data_name, traintest in train_test.items():\n",
    "    try:\n",
    "        train, test = traintest\n",
    "        tdparse = TDParse()\n",
    "        std_model_parameters = {'word_vector' : [w2v, sswe], 'random_state' : 42, 'parser' : stanford, 'C' : 0.007,\n",
    "                                'scale' : True}\n",
    "        params = tdparse.get_params(**std_model_parameters)\n",
    "        tdparse.fit(train.data(), train.sentiment_data(), params=params)\n",
    "        predicted_values = tdparse.predict(test.data())\n",
    "        score = f1_score(test.sentiment_data(), predicted_values, average='macro')\n",
    "        res.append((data_name, score))\n",
    "    except Exception as e:\n",
    "        got_wrong.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Dong Twitter', 0.65976246243958037)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(63, 74)], 'target_id': 'laptop_train19280', 'target': 'motherboard', 'text': 'After about a week I finally got it back and was told that the motherboard had failed and so they installed a new motherboard.', 'sentiment': -1, 'sentence_id': 'laptop_train1928'})` norm target $motherboard$\"),\n",
       " ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(4, 9)], 'target_id': 'restaurants_train33590', 'target': 'pizza', 'text': 'The pizza is the best if you like thin crusted pizza.', 'sentiment': 1, 'sentence_id': 'restaurants_train3359'})` norm target $pizza$\"),\n",
       " ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(4, 9)], 'target_id': 'restaurants_train33590', 'target': 'pizza', 'text': 'The pizza is the best if you like thin crusted pizza.', 'sentiment': 1, 'sentence_id': 'restaurants_train3359'})` norm target $pizza$\"),\n",
       " ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(4, 9)], 'target_id': 'restaurants_train33590', 'target': 'pizza', 'text': 'The pizza is the best if you like thin crusted pizza.', 'sentiment': 1, 'sentence_id': 'restaurants_train3359'})` norm target $pizza$\"),\n",
       " ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(4, 9)], 'target_id': 'restaurants_train33590', 'target': 'pizza', 'text': 'The pizza is the best if you like thin crusted pizza.', 'sentiment': 1, 'sentence_id': 'restaurants_train3359'})` norm target $pizza$\"),\n",
       " ValueError('The number of identified targets `[]` not equal to the number of targets in the data `Target({\\'spans\\': [(102, 113)], \\'target_id\\': \\'election_data_bo_wang73635690174480384#3\\', \\'target\\': \\'immigration\\', \\'text\\': \"With even a Tory talking about 13,000 more NHS patients immigration wasn\\'t brought up. That\\'s because immigration is non-issue here. #bbcqt\", \\'sentiment\\': 0, \\'sentence_id\\': \\'election_data_bo_wang73635690174480384\\'})` norm target $immigration$'),\n",
       " ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(26, 30)], 'target_id': 'trainSpeaker341', 'target': 'sound', 'text': 'These speakers have great sound but they will buzz if you leave them on with the sound turned up .', 'sentiment': 1, 'sentence_id': 'trainSpeaker34'})` norm target $sound$\"),\n",
       " ValueError(\"The number of identified targets `[]` not equal to the number of targets in the data `Target({'spans': [(4, 9)], 'target_id': 'trainzV0u2UFwv6E:1031', 'target': 'video', 'text': 'The video does lack OIS, yes, but the autofocus is absolutely killer on this video.', 'sentiment': -1, 'sentence_id': 'trainzV0u2UFwv6E:103'})` norm target $video$\")]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_predictions(train, test, name, model, word_vector, random_state, \n",
    "                        sentiment_lexicon=None, result_file_path=None, \n",
    "                        c_file_path=None, re_write=True, save_raw_data=True):\n",
    "    if not re_write and result_file_path is not None:\n",
    "        results_df = get_results(result_file_path, name)\n",
    "        if save_raw_data and results_df is not None:\n",
    "            if get_raw_data(result_file_path, name, test):\n",
    "                return results_df\n",
    "        elif results_df is not None:\n",
    "            return results_df\n",
    "    # loading the data\n",
    "    data_train = train.data()\n",
    "    y_train = train.sentiment_data()\n",
    "    data_test = test.data()\n",
    "    y_test = test.sentiment_data()\n",
    "\n",
    "    # Finding the best C value for the model on this dataset\n",
    "    c_grid_params = {'word_vectors' : [word_vector], 'random_state' : random_state,\n",
    "                     'parsers' : [tweebo]}\n",
    "    if sentiment_lexicon is not None:\n",
    "        c_grid_params['senti_lexicons'] = [sentiment_lexicon]\n",
    "    best_c, c_scores = model.find_best_c(data_train, y_train, \n",
    "                                         grid_params=c_grid_params, cv=5, n_jobs=7)\n",
    "    if c_file_path is not None:\n",
    "        write_json_data(c_file_path, name, c_scores)\n",
    "    if sentiment_lexicon is not None:\n",
    "        print('The best C value for {} model with sentiment lexicon {}: {}'\\\n",
    "              .format(model, sentiment_lexicon, best_c))\n",
    "    else:\n",
    "        print('The best C value for {} model: {}'.format(model, best_c))\n",
    "    \n",
    "    # Fitting and getting predictions from the model.\n",
    "    parameters = {'word_vector' : word_vector, 'random_state' : random_state, \n",
    "                  'C' : best_c, 'parser' : tweebo}\n",
    "    if sentiment_lexicon is not None:\n",
    "        parameters['senti_lexicon'] = sentiment_lexicon\n",
    "    best_params = model.get_params(**parameters)\n",
    "    model.fit(data_train, y_train, params=best_params)\n",
    "    predicted_values = model.predict(data_test)\n",
    "    # Return the results\n",
    "    if result_file_path is not None:\n",
    "        return evaluation_results(predicted_values, test, name, \n",
    "                                  file_name=result_file_path, \n",
    "                                  save_raw_data=save_raw_data, re_write=re_write)\n",
    "    else:\n",
    "        return evaluation_results(predicted_values, test, name)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instances of the models\n",
    "tdparse = TDParse()\n",
    "tdparse_plus = TDParsePlus()\n",
    "models = [tdparse, tdparse_plus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{TDParse: ({'random_state': 42, 'word_vector': [w2v, sswe]},\n",
       "  '/home/moorea/tdparse/results/TDParse Models/TDParse.tsv',\n",
       "  '/home/moorea/tdparse/results/TDParse Models/TDParse C.json'),\n",
       " TDParse Plus: ({'random_state': 42,\n",
       "   'sentiment_lexicon': <tdparse.lexicons.Lexicon at 0x7f35f4faf160>,\n",
       "   'word_vector': [w2v, sswe]},\n",
       "  '/home/moorea/tdparse/results/TDParse Models/TDParsePlus.tsv',\n",
       "  '/home/moorea/tdparse/results/TDParse Models/TDParsePlus C.json')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the result files\n",
    "result_folder = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'results', 'TDParse Models'))\n",
    "os.makedirs(result_folder, exist_ok=True)\n",
    "model_result_files = ['TDParse.tsv', 'TDParsePlus.tsv']\n",
    "model_result_files = [os.path.join(result_folder, result_file) for result_file in model_result_files]\n",
    "C_result_files = ['TDParse C.json', 'TDParsePlus C.json']\n",
    "C_result_files = [os.path.join(result_folder, result_file) for result_file in C_result_files]\n",
    "# Parameters for each model\n",
    "std_model_parameters = {'word_vector' : [w2v, sswe], 'random_state' : 42}\n",
    "senti_model_parameters = {**std_model_parameters, 'sentiment_lexicon' : all_three_low}\n",
    "model_parameters = [std_model_parameters, senti_model_parameters]\n",
    "# Combining parameters and result files\n",
    "parameters_files = list(zip(model_parameters, model_result_files, C_result_files))\n",
    "\n",
    "model_result_files = dict(zip(models, parameters_files))\n",
    "model_result_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset SemEval 14 Laptop\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset SemEval 14 Restaurant\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset SemEval 16 Restaurant 14 Train\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset SemEval 16 Restaurant 14 All\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset SemEval 16 Restaurant 15&14\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset Dong Twitter\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset Election Twitter\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset Product Reviews\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "Processing dataset YouTuBean\n",
      "Processing model TDParse\n",
      "Processing model TDParse Plus\n",
      "The best C value for TDParse Plus model with sentiment lexicon Mpqa HuLiu NRC: 0.01\n",
      "in here /home/moorea/tdparse/results/TDParse Models/TDParsePlus.tsv\n",
      "Results None\n",
      "saving raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moorea/.virtualenvs/tdparse/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time_to_process = time.time()\n",
    "for dataset_name, train_test in train_test.items():\n",
    "    print('Processing dataset {}'.format(dataset_name))\n",
    "    train, test = train_test\n",
    "    for model, parameter_file_paths in model_result_files.items():\n",
    "        print('Processing model {}'.format(model))\n",
    "        parameters, result_file_path, c_file_path = parameter_file_paths\n",
    "        dataset_predictions(train, test, dataset_name, model, \n",
    "                            result_file_path=result_file_path,\n",
    "                            c_file_path=c_file_path,\n",
    "                            re_write=False, save_raw_data=True,\n",
    "                            **parameters)\n",
    "\n",
    "time_to_process = time.time() - time_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time it took to process all the datasets {{round(time_to_process / 3600, 2)}} hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45778418130344817"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_to_process/ 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
