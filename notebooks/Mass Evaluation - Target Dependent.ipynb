{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE\n",
    "**Please ensure that you have ran the *Mitchel and YouTuBean train test split* notebooks first so that all of the datasets are avaliable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Callable, List, Union, Tuple, Dict, Any\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# Models\n",
    "from bella.models.target import TargetDep, TargetDepPlus\n",
    "from bella.models.base import SKLearnModel\n",
    "# Word Vector methods\n",
    "from bella.word_vectors import GloveCommonCrawl, SSWE\n",
    "from bella.helper import read_config\n",
    "# Sentiment lexicons\n",
    "from bella import lexicons\n",
    "# Get the data\n",
    "from bella.parsers import semeval_14, dong, election\n",
    "from bella.data_types import TargetCollection\n",
    "# Tokenisers\n",
    "from bella.tokenisers import ark_twokenize\n",
    "# Evaluation\n",
    "from bella import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_words(tokeniser: Callable[[str], List[str]], \n",
    "              *datasets) -> List[str]:\n",
    "    words = []\n",
    "    for dataset in datasets:\n",
    "        words.extend(dataset.word_list(tokeniser))\n",
    "    return list(set(words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "#  ADD YOUR CONFIG FILE PATH HERE \n",
    "##\n",
    "CONFIG_FP = Path('..', 'config.yaml')\n",
    "\n",
    "# Getting the sentiment lexicons\n",
    "hu_liu_fp = Path(read_config('hu_liu_lexicon', CONFIG_FP))\n",
    "mpqa_fp = Path(read_config('mpqa_lexicon', CONFIG_FP))\n",
    "nrc_fp = Path(read_config('nrc_emotion_lexicon', CONFIG_FP))\n",
    "\n",
    "subset_cats = {'positive', 'negative'}\n",
    "mpqa_low = lexicons.Mpqa(mpqa_fp, subset_cats=subset_cats, lower=True)\n",
    "nrc_low = lexicons.NRC(nrc_fp, subset_cats=subset_cats, lower=True)\n",
    "hu_liu_low = lexicons.HuLiu(hu_liu_fp, subset_cats=subset_cats, lower=True)\n",
    "mpqa_huliu_low = lexicons.Lexicon.combine_lexicons(mpqa_low, hu_liu_low)\n",
    "all_three_low = lexicons.Lexicon.combine_lexicons(mpqa_huliu_low, nrc_low)\n",
    "\n",
    "\n",
    "# Load all of the datasets\n",
    "youtubean_train = semeval_14(read_config('youtubean_train', CONFIG_FP))\n",
    "youtubean_test = semeval_14(read_config('youtubean_test', CONFIG_FP))\n",
    "semeval_14_rest_train = semeval_14(read_config('semeval_2014_rest_train', CONFIG_FP))\n",
    "semeval_14_lap_train = semeval_14(read_config('semeval_2014_lap_train', CONFIG_FP))\n",
    "semeval_14_rest_test = semeval_14(read_config('semeval_2014_rest_test', CONFIG_FP))\n",
    "semeval_14_lap_test = semeval_14(read_config('semeval_2014_lap_test', CONFIG_FP))\n",
    "dong_train = dong(read_config('dong_twit_train_data', CONFIG_FP))\n",
    "dong_test = dong(read_config('dong_twit_test_data', CONFIG_FP))\n",
    "election_train, election_test = election(read_config('election_folder_dir', CONFIG_FP))\n",
    "mitchel_train = semeval_14(read_config('mitchel_train', CONFIG_FP))\n",
    "mitchel_test = semeval_14(read_config('mitchel_test', CONFIG_FP))\n",
    "\n",
    "\n",
    "dataset_train_test = [('SemEval 14 Laptop', semeval_14_lap_train, semeval_14_lap_test),\n",
    "                      ('SemEval 14 Restaurant', semeval_14_rest_train, semeval_14_rest_test),\n",
    "                      ('Dong Twitter', dong_train, dong_test),\n",
    "                      ('Election Twitter', election_train, election_test),\n",
    "                      ('YouTuBean', youtubean_train, youtubean_test),\n",
    "                      ('Mitchel', mitchel_train, mitchel_test)]\n",
    "\n",
    "results_folder = Path(read_config('results_folder', CONFIG_FP))\n",
    "results_folder = results_folder.joinpath('Target Dependent')\n",
    "results_folder.mkdir(parents=True, exist_ok=True)\n",
    "model_zoo_folder = Path(read_config('model_zoo_folder', CONFIG_FP))\n",
    "model_zoo_folder.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is just loading the data, sentiment lexicons and places to save the results of the experiments\n",
    "\n",
    "# Target Dependent methods applied across multiple datasets\n",
    "\n",
    "In this notebook we are going to look at the two best TDParse methods:\n",
    "1. Target Dependent\n",
    "2. Target Dependent+\n",
    "\n",
    "The first does not use a sentiment lexicon and the second does.\n",
    "\n",
    "We are going to test them over all 6 datasets:\n",
    "1. SemEval 2014 Laptop\n",
    "2. SemEval 2014 Resturant\n",
    "3. Dong Twitter\n",
    "4. Election Twitter\n",
    "5. YouTuBean\n",
    "6. Mitchel Twitter dataset\n",
    "\n",
    "Each of these are different some more so than others for full details on these datasets look at this [notebook](./datasets.ipynb). First each one of these models has to be fine tuned for each dataset that involves:\n",
    "1. Finding the Best C value for the SVM estimator for both methods.\n",
    "2. We will find the best word embeddings to use for each method.\n",
    "\n",
    "Once we have fine tuned our methods for each dataset on the training dataset using 5 fold cross validation we will predict on the test data and save the models for future use.\n",
    "\n",
    "\n",
    "## Finding the Best C value\n",
    "\n",
    "First we want to find the Best C value for each model for each dataset by performing 5 fold cross validation. \n",
    "\n",
    "We are first going to choose the best C value from a coarse grained set of C values and then create a more fine grained search around the best coarse grained C value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-05, 0.0001, 0.001, 0.01, 0.1, 1.0, 10.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coarse_range = []\n",
    "start = 0.00001\n",
    "stop = 10\n",
    "while True:\n",
    "    coarse_range.append(start)\n",
    "    start *= 10\n",
    "    if start > stop:\n",
    "        break\n",
    "coarse_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: SemEval 14 Laptop Model and C Value {\"<class 'bella.models.target.TargetDep'>\": '0.01', \"<class 'bella.models.target.TargetDepPlus'>\": '0.0035'}\n",
      "Dataset: SemEval 14 Restaurant Model and C Value {\"<class 'bella.models.target.TargetDep'>\": '0.035', \"<class 'bella.models.target.TargetDepPlus'>\": '0.01'}\n",
      "Dataset: Dong Twitter Model and C Value {\"<class 'bella.models.target.TargetDep'>\": '0.035', \"<class 'bella.models.target.TargetDepPlus'>\": '0.01'}\n",
      "Dataset: Election Twitter Model and C Value {\"<class 'bella.models.target.TargetDep'>\": '0.0035', \"<class 'bella.models.target.TargetDepPlus'>\": '0.0035'}\n",
      "Dataset: YouTuBean Model and C Value {\"<class 'bella.models.target.TargetDep'>\": '0.035', \"<class 'bella.models.target.TargetDepPlus'>\": '0.01'}\n",
      "Dataset: Mitchel Model and C Value {\"<class 'bella.models.target.TargetDep'>\": '0.01', \"<class 'bella.models.target.TargetDepPlus'>\": '0.007'}\n"
     ]
    }
   ],
   "source": [
    "models = [TargetDep, TargetDepPlus]\n",
    "n_cpus = 7\n",
    "\n",
    "dataset_model_c = {}\n",
    "best_c_file = results_folder.joinpath('Mass Evaluation Best C.json')\n",
    "if best_c_file.is_file():\n",
    "    with best_c_file.open('r') as best_c_json:\n",
    "        dataset_model_c = json.load(best_c_json)\n",
    "\n",
    "for dataset_name, train, test in dataset_train_test:\n",
    "    if dataset_name in dataset_model_c:\n",
    "        continue\n",
    "    model_kwargs = []\n",
    "    word_embedding = SSWE(filter_words=train.word_list(ark_twokenize))\n",
    "    for model in models:\n",
    "        kwargs = {'word_vectors': [[word_embedding]]}\n",
    "        if model == TargetDepPlus:\n",
    "            kwargs['senti_lexicon'] = [all_three_low]\n",
    "        model_kwargs.append((model, kwargs))\n",
    "    X_train = train.data()\n",
    "    y_train = train.sentiment_data()\n",
    "    model_c = SKLearnModel.models_best_parameter(model_kwargs, 'C', coarse_range, \n",
    "                                                 X_train, y_train, n_cpus)\n",
    "    model_fine_c = {}\n",
    "    for model_kwarg in model_kwargs:\n",
    "        model, kwarg = model_kwarg\n",
    "        best_coarse_c = float(model_c[model])\n",
    "        fine_range = [(best_coarse_c / 10) * 3.5,\n",
    "                      (best_coarse_c / 10) * 7, best_coarse_c,\n",
    "                       best_coarse_c * 3.5, best_coarse_c * 7]\n",
    "        temp_model_c = SKLearnModel.models_best_parameter([model_kwarg], 'C', fine_range, \n",
    "                                                          X_train, y_train, n_cpus)\n",
    "        model_fine_c[model] = temp_model_c[model]\n",
    "    model_c = {str(model): c for model, c in model_fine_c.items()}\n",
    "    dataset_model_c[dataset_name] = model_c\n",
    "    \n",
    "with best_c_file.open('w+') as best_c_json:\n",
    "        json.dump(dataset_model_c, best_c_json)\n",
    "for dataset_name, model_c in dataset_model_c.items():\n",
    "    print(f'Dataset: {dataset_name} Model and C Value {model_c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best word embeddings\n",
    "\n",
    "We are now going to perform 5 fold cross validation to find the best word embedding for each method on each dataset. The possible word embeddings are the following:\n",
    "1. [Glove 42 Billion Common Crawl](https://nlp.stanford.edu/projects/glove/) - 300 dimension these were trained on web data.\n",
    "2. [Sentiment Specific Word Embeddings (SSWE)](http://www.aclweb.org/anthology/P14-1146) - 50 dimension these were trained on Twitter data.\n",
    "\n",
    "We are going to use the Best C values while performing cross validation to find the best word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: SemEval 14 Laptop Model and Embedding {\"<class 'bella.models.target.TargetDep'>\": '[glove 300d 42b common crawl]', \"<class 'bella.models.target.TargetDepPlus'>\": '[glove 300d 42b common crawl]'}\n",
      "Dataset: SemEval 14 Restaurant Model and Embedding {\"<class 'bella.models.target.TargetDep'>\": '[sswe]', \"<class 'bella.models.target.TargetDepPlus'>\": '[sswe]'}\n",
      "Dataset: Dong Twitter Model and Embedding {\"<class 'bella.models.target.TargetDep'>\": '[glove 300d 42b common crawl]', \"<class 'bella.models.target.TargetDepPlus'>\": '[glove 300d 42b common crawl]'}\n",
      "Dataset: Election Twitter Model and Embedding {\"<class 'bella.models.target.TargetDep'>\": '[glove 300d 42b common crawl]', \"<class 'bella.models.target.TargetDepPlus'>\": '[glove 300d 42b common crawl]'}\n",
      "Dataset: YouTuBean Model and Embedding {\"<class 'bella.models.target.TargetDep'>\": '[sswe]', \"<class 'bella.models.target.TargetDepPlus'>\": '[sswe]'}\n",
      "Dataset: Mitchel Model and Embedding {\"<class 'bella.models.target.TargetDep'>\": '[sswe]', \"<class 'bella.models.target.TargetDepPlus'>\": '[sswe]'}\n"
     ]
    }
   ],
   "source": [
    "dataset_model_embedding = {}\n",
    "best_embedding_file = results_folder.joinpath('Mass Evaluation Best Embedding.json')\n",
    "if best_embedding_file.is_file():\n",
    "    with best_embedding_file.open('r') as best_embedding_json:\n",
    "        dataset_model_embedding = json.load(best_embedding_json)\n",
    "\n",
    "for dataset_name, train, test in dataset_train_test:\n",
    "    if dataset_name in dataset_model_embedding:\n",
    "        continue\n",
    "    # the different embeddings\n",
    "    filter_words = train.word_list(ark_twokenize)\n",
    "    sswe_embedding = SSWE(filter_words=filter_words)\n",
    "    glove_embedding = GloveCommonCrawl(42, filter_words=filter_words)\n",
    "    all_embeddings = [[sswe_embedding], [glove_embedding]]\n",
    "    model_kwargs = []\n",
    "    for model in models:\n",
    "        best_c = dataset_model_c[dataset_name][str(model)]\n",
    "        kwargs = {'C': [float(best_c)]}\n",
    "        if model == TargetDepPlus:\n",
    "            kwargs['senti_lexicon'] = [all_three_low]\n",
    "        model_kwargs.append((model, kwargs))\n",
    "    X_train = train.data()\n",
    "    y_train = train.sentiment_data()\n",
    "    model_embedding = SKLearnModel.models_best_parameter(model_kwargs, 'word_vectors', \n",
    "                                                         all_embeddings, \n",
    "                                                         X_train, y_train, n_cpus)\n",
    "    model_embedding = {str(model): embedding for model, embedding in model_embedding.items()}\n",
    "    dataset_model_embedding[dataset_name] = model_embedding\n",
    "\n",
    "with best_embedding_file.open('w+') as best_embedding_json:\n",
    "        json.dump(dataset_model_embedding, best_embedding_json)\n",
    "for dataset_name, model_embedding in dataset_model_embedding.items():\n",
    "    print(f'Dataset: {dataset_name} Model and Embedding {model_embedding}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions on the test data\n",
    "\n",
    "Now we have the best C value and embeddings for each dataset and for each model we shall use these to make the predictions on the test data of all the datasets. Once we have made these predictions we shall save the raw predictions and the machine learning models so that we can analysis and use them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset_predictions = defaultdict(lambda: dict())\n",
    "\n",
    "# Get the predictions data if it exists\n",
    "for model in models:\n",
    "    model_results_folder = results_folder.joinpath(model.name())\n",
    "    dataset_predictions_fp = model_results_folder.joinpath('dataset predictions.json')\n",
    "    if dataset_predictions_fp.is_file():\n",
    "        with dataset_predictions_fp.open('r') as dataset_predictions_json:\n",
    "            dataset_predictions = json.load(dataset_predictions_json)\n",
    "            model_dataset_predictions[model.name()] = dataset_predictions\n",
    "\n",
    "# Create the predictions for each dataset and for each model\n",
    "for dataset_name, train, test in dataset_train_test:\n",
    "    model_c = dataset_model_c[dataset_name]\n",
    "    model_embedding = dataset_model_embedding[dataset_name]\n",
    "        \n",
    "    X_train, y_train = train.data(), train.sentiment_data()\n",
    "    X_test, y_test = test.data(), test.sentiment_data()\n",
    "    dataset_words = all_words(ark_twokenize, train, test)\n",
    "    \n",
    "    \n",
    "    for model in models:\n",
    "        if dataset_name in model_dataset_predictions[model.name()]:\n",
    "            continue\n",
    "            \n",
    "        embedding = model_embedding[str(model)]\n",
    "        if embedding == '[glove 300d 42b common crawl]':\n",
    "            embedding = [GloveCommonCrawl(42, filter_words=dataset_words)]\n",
    "        elif embedding == '[sswe]':\n",
    "            embedding = [SSWE(filter_words=dataset_words)]\n",
    "        else:\n",
    "            raise Exception(f'Embeddings is not SSWE or Glove {embedding}')\n",
    "\n",
    "        if model == TargetDepPlus:\n",
    "            model_instance = model(embedding, all_three_low, \n",
    "                                   C=float(model_c[str(model)]))\n",
    "        else:\n",
    "            model_instance = model(embedding,\n",
    "                                   C=float(model_c[str(model)]))\n",
    "        if dataset_name in model_dataset_predictions[str(model)]:\n",
    "            continue\n",
    "        model_instance.fit(X_train, y_train)\n",
    "        predictions = model_instance.predict(X_test).tolist()\n",
    "        model_dataset_predictions[model.name()][dataset_name] = predictions\n",
    "        # Save the model to the model zoo\n",
    "        model_fp = model_zoo_folder.joinpath(f'{model.name()} {dataset_name}')\n",
    "        model.save(model_instance, model_fp)\n",
    "        \n",
    "# Save the results\n",
    "for model in models:\n",
    "    model_results_folder = results_folder.joinpath(model.name())\n",
    "    model_results_folder.mkdir(parents=True, exist_ok=True)\n",
    "    dataset_predictions_fp = model_results_folder.joinpath('dataset predictions.json')\n",
    "    dataset_predictions = model_dataset_predictions[model.name()]\n",
    "    with dataset_predictions_fp.open('w+') as dataset_predictions_file:\n",
    "        json.dump(dataset_predictions, dataset_predictions_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = {name: test for name, train, test in dataset_train_test}\n",
    "f1_results = evaluation.evaluate_models(f1_score, dataset_test, \n",
    "                                        model_dataset_predictions, \n",
    "                                        dataframe=True, average='macro')\n",
    "acc_results = evaluation.evaluate_models(accuracy_score, dataset_test, \n",
    "                                         model_dataset_predictions, \n",
    "                                         dataframe=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Dependent</th>\n",
       "      <th>Target Dependent Plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dong Twitter</th>\n",
       "      <td>67.34</td>\n",
       "      <td>67.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Twitter</th>\n",
       "      <td>57.65</td>\n",
       "      <td>56.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>72.64</td>\n",
       "      <td>72.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Laptop</th>\n",
       "      <td>67.87</td>\n",
       "      <td>70.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Restaurant</th>\n",
       "      <td>73.84</td>\n",
       "      <td>74.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTuBean</th>\n",
       "      <td>70.83</td>\n",
       "      <td>72.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>68.36</td>\n",
       "      <td>69.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Target Dependent  Target Dependent Plus\n",
       "Dong Twitter                      67.34                  67.77\n",
       "Election Twitter                  57.65                  56.63\n",
       "Mitchel                           72.64                  72.85\n",
       "SemEval 14 Laptop                 67.87                  70.85\n",
       "SemEval 14 Restaurant             73.84                  74.64\n",
       "YouTuBean                         70.83                  72.50\n",
       "Mean                              68.36                  69.21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_results * 100).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Macro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Dependent</th>\n",
       "      <th>Target Dependent Plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dong Twitter</th>\n",
       "      <td>65.66</td>\n",
       "      <td>65.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Election Twitter</th>\n",
       "      <td>45.47</td>\n",
       "      <td>45.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitchel</th>\n",
       "      <td>40.76</td>\n",
       "      <td>42.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Laptop</th>\n",
       "      <td>59.97</td>\n",
       "      <td>63.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SemEval 14 Restaurant</th>\n",
       "      <td>56.16</td>\n",
       "      <td>57.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YouTuBean</th>\n",
       "      <td>53.14</td>\n",
       "      <td>55.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>53.53</td>\n",
       "      <td>55.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Target Dependent  Target Dependent Plus\n",
       "Dong Twitter                      65.66                  65.67\n",
       "Election Twitter                  45.47                  45.93\n",
       "Mitchel                           40.76                  42.86\n",
       "SemEval 14 Laptop                 59.97                  63.73\n",
       "SemEval 14 Restaurant             56.16                  57.71\n",
       "YouTuBean                         53.14                  55.56\n",
       "Mean                              53.53                  55.24"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(f1_results * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
